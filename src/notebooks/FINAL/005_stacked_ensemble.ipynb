{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Select the best model from the grid and create the stacked ensembles\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import h2o\n",
    "h2o.init(min_mem_size='25G')\n",
    "\n",
    "DATA_LOCATION = \"../../data/\"\n",
    "MODELS_LOCATION = \"../../models/ALL_FEATURES/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = h2o.import_file( DATA_LOCATION + \"processed/final.train.tsv\")\n",
    "train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "test = h2o.import_file(\"../data/processed/final.test.tsv\")\n",
    "test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Identify predictors and response\n",
    "train_predictor_cols = train.columns\n",
    "train_response_col = \"Resistance_Status\"\n",
    "train_predictor_cols.remove('SampleID')\n",
    "train_predictor_cols.remove(train_response_col)\n",
    "print(\"train frame - predictor column: \", train_predictor_cols[0], train_predictor_cols[-1])\n",
    "print(\"train frame - response column: \", train_response_col)\n",
    "\n",
    "\n",
    "\n",
    "# Identify predictors and response\n",
    "test_predictor_cols = test.columns\n",
    "test_response_col = \"Resistance_Status\"\n",
    "test_predictor_cols.remove('SampleID')\n",
    "test_predictor_cols.remove(test_response_col)\n",
    "print(\"test frame - predictor columns: \", test_predictor_cols[0], test_predictor_cols[-1])\n",
    "print(\"test frame - response column: \", test_response_col)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# For binary classification, response should be a factor\n",
    "train[train_response_col] = train[train_response_col].asfactor()\n",
    "test[test_response_col] = test[test_response_col].asfactor()\n",
    "\n",
    "\n",
    "# Number of CV folds (to generate level-one data for stacking)\n",
    "nfolds = 5\n",
    "\n",
    "MAX_GRID_MODELS = 10\n",
    "\n",
    "\n",
    "x = train_predictor_cols\n",
    "y = train_response_col\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stacked ensemble from grid models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nb_grid = h2o.load_grid(\"../models/ALL_FEATURES/FINAL/./nb_grid/Grid_NaiveBayes_py_3_sid_9644_model_python_1604419067081_1\")\n",
    "\n",
    "\n",
    "\n",
    "glm_grid = h2o.load_grid(\"../models/ALL_FEATURES/FINAL/./glm_grid/Grid_GLM_py_3_sid_b7a1_model_python_1604419221083_1\")\n",
    "\n",
    "\n",
    "\n",
    "gbm_grid = h2o.load_grid(\"../models/ALL_FEATURES/FINAL/./gbm_grid/Grid_GBM_py_7_sid_9651_model_python_1604407520638_1\")\n",
    "\n",
    "\n",
    "\n",
    "xgb_grid = h2o.load_grid(\"../models/ALL_FEATURES/FINAL/./xgb_grid/Grid_XGBoost_py_7_sid_a3b5_model_python_1604427337744_1\")\n",
    "\n",
    "\n",
    "\n",
    "dl_grid = h2o.load_grid(\"../models/ALL_FEATURES/FINAL/./dl_grid/Grid_DeepLearning_py_3_sid_b7a1_model_python_1604419221083_608\")\n",
    "\n",
    "\n",
    "drf_grid = h2o.load_grid(\"../models/ALL_FEATURES/FINAL/./drf_grid/Grid_DRF_py_3_sid_9421_model_python_1604478808297_199\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def best_model_from_grid (model_grid):\n",
    "    best_model = model_grid[0]\n",
    "    for mdl in model_grid:\n",
    "        if (mdl.model_performance(test).auc() > best_model.model_performance(test).auc()):\n",
    "            best_model = mdl\n",
    "    print(best_model.model_performance(test).auc())\n",
    "    return best_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_nb_model = best_model_from_grid(nb_grid)\n",
    "best_glm_model = best_model_from_grid(glm_grid)\n",
    "best_gbm_model = best_model_from_grid(gbm_grid)\n",
    "best_xgb_model= best_model_from_grid(xgb_grid)\n",
    "best_dl_model= best_model_from_grid(dl_grid)\n",
    "best_drf_model= best_model_from_grid(drf_grid)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO Add additional params so that we can avoid **{**} later\n",
    "def extract_params_from_model(actual_params_dict, extra_params = []):\n",
    "    final_params = actual_params_dict\n",
    "\n",
    "    columns_to_be_removed =   [\n",
    "                                'model_id',\n",
    "                                'validation_frame',\n",
    "                                'response_column',\n",
    "                                'ignored_columns',\n",
    "                                'training_frame',\n",
    "                                *extra_params\n",
    "]\n",
    "\n",
    "    for col_name in columns_to_be_removed:\n",
    "        del  final_params[col_name]\n",
    "\n",
    "    return final_params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from h2o.estimators import H2ONaiveBayesEstimator\n",
    "\n",
    "top_nb = H2ONaiveBayesEstimator(**extract_params_from_model(best_nb_model.actual_params))\n",
    "\n",
    "top_nb.train(x=x, y=y, training_frame=train, validation_frame=test)\n",
    "\n",
    "print('AUC on test data: ', top_nb.model_performance(test).auc(), \"\\n\\n============================\")\n",
    "\n",
    "top_nb.model_performance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from h2o.estimators import H2OGeneralizedLinearEstimator\n",
    "\n",
    "top_glm = H2OGeneralizedLinearEstimator(**extract_params_from_model(best_glm_model.actual_params, ['lambda']))\n",
    "\n",
    "top_glm.train(x=x, y=y, training_frame=train, validation_frame=test)\n",
    "\n",
    "print('AUC on test data: ', top_glm.model_performance(test).auc(), \"\\n\\n============================\")\n",
    "\n",
    "top_glm.model_performance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from h2o.estimators import H2OGradientBoostingEstimator\n",
    "\n",
    "top_gbm = H2OGradientBoostingEstimator(**extract_params_from_model(best_gbm_model.actual_params))\n",
    "\n",
    "top_gbm.train(x=x, y=y, training_frame=train, validation_frame=test)\n",
    "\n",
    "print('AUC on test data: ', top_gbm.model_performance(test).auc(), \"\\n\\n============================\")\n",
    "\n",
    "top_gbm.model_performance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from h2o.estimators import H2OXGBoostEstimator\n",
    "\n",
    "top_xgb = H2OXGBoostEstimator(**extract_params_from_model(best_xgb_model.actual_params))\n",
    "\n",
    "top_xgb.train(x=x, y=y, training_frame=train, validation_frame=test)\n",
    "\n",
    "print('AUC on test data: ', top_xgb.model_performance(test).auc(), \"\\n\\n============================\")\n",
    "\n",
    "top_xgb.model_performance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from h2o.estimators import H2ODeepLearningEstimator\n",
    "\n",
    "top_dl = H2ODeepLearningEstimator(**extract_params_from_model(best_dl_model.actual_params))\n",
    "\n",
    "top_dl.train(x=x, y=y, training_frame=train, validation_frame=test)\n",
    "\n",
    "print('AUC on test data: ', top_dl.model_performance(test).auc(), \"\\n\\n============================\")\n",
    "\n",
    "top_dl.model_performance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from h2o.estimators import H2ORandomForestEstimator\n",
    "\n",
    "#top_drf = H2ORandomForestEstimator(**extract_params_from_model(best_drf_model.actual_params, ['weights_column']))\n",
    "\n",
    "\n",
    "top_drf = H2ORandomForestEstimator(**{**extract_params_from_model(best_drf_model.actual_params, ['weights_column']),\n",
    "                                    'nfolds':5,\n",
    "                                    'fold_assignment':'random'\n",
    "                                    })\n",
    "\n",
    "\n",
    "top_drf.train(x=x, y=y, training_frame=train, validation_frame=test)\n",
    "\n",
    "print('AUC on test data: ', top_drf.model_performance(test).auc(), \"\\n\\n============================\")\n",
    "\n",
    "top_drf.model_performance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator\n",
    "\n",
    "\n",
    "ensemble = H2OStackedEnsembleEstimator(\n",
    "                                       base_models= [\n",
    "                                                    top_nb,\n",
    "                                                    top_glm,\n",
    "\n",
    "                                                    # models with checkpoint available\n",
    "                                                    top_gbm,\n",
    "                                                    top_xgb,\n",
    "                                                    top_dl,\n",
    "                                                    top_drf\n",
    "                                                    ]\n",
    "                                       )\n",
    "\n",
    "ensemble.train(x=x, y=y, training_frame=train, validation_frame=test)\n",
    "\n",
    "print('AUC on test data: ', ensemble.model_performance(test).auc(), \"\\n\\n============================\")\n",
    "ensemble.model_performance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check for the best  meta-learner"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator\n",
    "\n",
    "collection_of_models = [top_nb,\n",
    "                        top_glm,\n",
    "\n",
    "                        # checkpoint-enabled models\n",
    "                        top_gbm,\n",
    "                        top_xgb,\n",
    "                        top_dl,\n",
    "                        top_drf]\n",
    "\n",
    "\n",
    "meta_algos = [\"auto\", \"xgboost\", \"drf\", \"gbm\", \"glm\", \"naivebayes\", \"deeplearning\"]\n",
    "\n",
    "ensemble_list = []\n",
    "\n",
    "for metalearner in meta_algos:\n",
    "    print(\"\\n\\n>>>>> \", metalearner, \" <<<<<<\")\n",
    "\n",
    "    ensemble = H2OStackedEnsembleEstimator(\n",
    "                                       base_models= collection_of_models,\n",
    "\n",
    "                                       model_id= \"stacked_ensemble_metalearner_\" + metalearner,\n",
    "\n",
    "                                       metalearner_algorithm= metalearner,\n",
    "\n",
    "                                       #metalearner_params\n",
    "                                       )\n",
    "    ensemble.train(x=x, y=y, training_frame=train, validation_frame=test)\n",
    "    print(\"AUC on test data: \",  ensemble.model_performance(test).auc())\n",
    "\n",
    "    ensemble_list.append(ensemble)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-f27e5417",
   "language": "python",
   "display_name": "PyCharm (drug-resistance-prediction-cambiohack)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}