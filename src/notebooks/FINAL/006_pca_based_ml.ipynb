{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "from matplotlib import pyplot\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "sns.set_style('darkgrid')\r\n",
        "sns.set_context('paper')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def print_ln():\r\n",
        "    print('-' * 80, '\\n')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "import h2o\r\n",
        "h2o.init(min_mem_size='25G')\r\n",
        "\r\n",
        "DATA_LOCATION = \"../../data/\"\r\n",
        "MODELS_LOCATION = \"../../models/\"\r\n",
        "\r\n",
        "MAX_MODELS = 10\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
            "Attempting to start a local H2O server...\n",
            "  Java Version: openjdk version \"1.8.0_265\"; OpenJDK Runtime Environment (build 1.8.0_265-8u265-b01-0ubuntu2~16.04-b01); OpenJDK 64-Bit Server VM (build 25.265-b01, mixed mode)\n",
            "  Starting server from /anaconda/envs/azureml_py36/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
            "  Ice root: /tmp/tmppseo7lnn\n",
            "  JVM stdout: /tmp/tmppseo7lnn/h2o_azureuser_started_from_python.out\n",
            "  JVM stderr: /tmp/tmppseo7lnn/h2o_azureuser_started_from_python.err\n",
            "  Server is running at http://127.0.0.1:54321\n",
            "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n",
            "Warning: Your H2O cluster version is too old (5 months and 14 days)! Please download and install the latest version from http://h2o.ai/download/\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "--------------------------  ------------------------------------------------------------------\nH2O_cluster_uptime:         01 secs\nH2O_cluster_timezone:       Etc/UTC\nH2O_data_parsing_timezone:  UTC\nH2O_cluster_version:        3.30.0.4\nH2O_cluster_version_age:    5 months and 14 days !!!\nH2O_cluster_name:           H2O_from_python_azureuser_kvrksj\nH2O_cluster_total_nodes:    1\nH2O_cluster_free_memory:    23.96 Gb\nH2O_cluster_total_cores:    4\nH2O_cluster_allowed_cores:  4\nH2O_cluster_status:         accepting new members, healthy\nH2O_connection_url:         http://127.0.0.1:54321\nH2O_connection_proxy:       {\"http\": null, \"https\": null}\nH2O_internal_security:      False\nH2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\nPython_version:             3.6.9 final\n--------------------------  ------------------------------------------------------------------",
            "text/html": "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n<td>01 secs</td></tr>\n<tr><td>H2O_cluster_timezone:</td>\n<td>Etc/UTC</td></tr>\n<tr><td>H2O_data_parsing_timezone:</td>\n<td>UTC</td></tr>\n<tr><td>H2O_cluster_version:</td>\n<td>3.30.0.4</td></tr>\n<tr><td>H2O_cluster_version_age:</td>\n<td>5 months and 14 days !!!</td></tr>\n<tr><td>H2O_cluster_name:</td>\n<td>H2O_from_python_azureuser_kvrksj</td></tr>\n<tr><td>H2O_cluster_total_nodes:</td>\n<td>1</td></tr>\n<tr><td>H2O_cluster_free_memory:</td>\n<td>23.96 Gb</td></tr>\n<tr><td>H2O_cluster_total_cores:</td>\n<td>4</td></tr>\n<tr><td>H2O_cluster_allowed_cores:</td>\n<td>4</td></tr>\n<tr><td>H2O_cluster_status:</td>\n<td>accepting new members, healthy</td></tr>\n<tr><td>H2O_connection_url:</td>\n<td>http://127.0.0.1:54321</td></tr>\n<tr><td>H2O_connection_proxy:</td>\n<td>{\"http\": null, \"https\": null}</td></tr>\n<tr><td>H2O_internal_security:</td>\n<td>False</td></tr>\n<tr><td>H2O_API_Extensions:</td>\n<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n<tr><td>Python_version:</td>\n<td>3.6.9 final</td></tr></table></div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1605467919943
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binarized_final_df = pd.read_csv(DATA_LOCATION + \"processed/final.binarized_final_monolabel_df.tsv\", \"\\t\", index_col= 'SampleID')\r\n",
        "binarized_final_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "           NC000962_3.22  NC000962_3.434  NC000962_3.524  NC000962_3.645  \\\nSampleID                                                                   \nERR027458              0               0               0               0   \nERR027459              0               0               0               0   \nERR027460              0               0               0               0   \nERR027461              0               0               0               0   \nERR027462              0               0               0               0   \n\n           NC000962_3.648  NC000962_3.654  NC000962_3.666  NC000962_3.675  \\\nSampleID                                                                    \nERR027458               0               0               0               0   \nERR027459               0               0               0               0   \nERR027460               0               0               0               0   \nERR027461               0               0               0               0   \nERR027462               0               0               0               0   \n\n           NC000962_3.678  NC000962_3.693        ...          \\\nSampleID                                         ...           \nERR027458               0               0        ...           \nERR027459               0               0        ...           \nERR027460               0               0        ...           \nERR027461               0               0        ...           \nERR027462               0               0        ...           \n\n           NC000962_3.4410251  NC000962_3.4410260  NC000962_3.4410272  \\\nSampleID                                                                \nERR027458                   0                   0                   0   \nERR027459                   0                   0                   0   \nERR027460                   0                   0                   0   \nERR027461                   0                   0                   0   \nERR027462                   0                   0                   0   \n\n           NC000962_3.4410278  NC000962_3.4410728  NC000962_3.4410850  \\\nSampleID                                                                \nERR027458                   0                   0                   0   \nERR027459                   0                   0                   0   \nERR027460                   0                   0                   0   \nERR027461                   0                   0                   0   \nERR027462                   0                   0                   0   \n\n           NC000962_3.4411016  NC000962_3.4411170  NC000962_3.4411327  \\\nSampleID                                                                \nERR027458                   0                   0                   0   \nERR027459                   0                   0                   0   \nERR027460                   0                   0                   0   \nERR027461                   0                   0                   0   \nERR027462                   0                   0                   0   \n\n           Resistance_Status  \nSampleID                      \nERR027458                1.0  \nERR027459                1.0  \nERR027460                0.0  \nERR027461                0.0  \nERR027462                0.0  \n\n[5 rows x 52683 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NC000962_3.22</th>\n      <th>NC000962_3.434</th>\n      <th>NC000962_3.524</th>\n      <th>NC000962_3.645</th>\n      <th>NC000962_3.648</th>\n      <th>NC000962_3.654</th>\n      <th>NC000962_3.666</th>\n      <th>NC000962_3.675</th>\n      <th>NC000962_3.678</th>\n      <th>NC000962_3.693</th>\n      <th>...</th>\n      <th>NC000962_3.4410251</th>\n      <th>NC000962_3.4410260</th>\n      <th>NC000962_3.4410272</th>\n      <th>NC000962_3.4410278</th>\n      <th>NC000962_3.4410728</th>\n      <th>NC000962_3.4410850</th>\n      <th>NC000962_3.4411016</th>\n      <th>NC000962_3.4411170</th>\n      <th>NC000962_3.4411327</th>\n      <th>Resistance_Status</th>\n    </tr>\n    <tr>\n      <th>SampleID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ERR027458</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>ERR027459</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>ERR027460</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>ERR027461</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>ERR027462</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 52683 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604929661843
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binarized_final_frame = h2o.import_file(DATA_LOCATION + \"processed/final.binarized_final_monolabel_df.tsv\")\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604929677276
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(DATA_LOCATION + \"processed/final.train.tsv\", \"\\t\", index_col= 'SampleID')\r\n",
        "train_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "             NC000962_3.22  NC000962_3.434  NC000962_3.524  NC000962_3.645  \\\nSampleID                                                                     \nSRR10525336              0               0               0               0   \nSRR10380004              0               0               0               0   \nSRR6807701               0               0               0               0   \nSRR11033700              0               0               0               0   \nSRR1163101               0               0               0               0   \n\n             NC000962_3.648  NC000962_3.654  NC000962_3.666  NC000962_3.675  \\\nSampleID                                                                      \nSRR10525336               0               0               0               0   \nSRR10380004               0               0               0               0   \nSRR6807701                0               0               0               0   \nSRR11033700               0               0               0               0   \nSRR1163101                0               0               0               0   \n\n             NC000962_3.678  NC000962_3.693        ...          \\\nSampleID                                           ...           \nSRR10525336               0               0        ...           \nSRR10380004               0               0        ...           \nSRR6807701                0               0        ...           \nSRR11033700               0               0        ...           \nSRR1163101                0               0        ...           \n\n             NC000962_3.4410251  NC000962_3.4410260  NC000962_3.4410272  \\\nSampleID                                                                  \nSRR10525336                   0                   0                   0   \nSRR10380004                   0                   0                   0   \nSRR6807701                    0                   0                   0   \nSRR11033700                   0                   0                   0   \nSRR1163101                    0                   0                   0   \n\n             NC000962_3.4410278  NC000962_3.4410728  NC000962_3.4410850  \\\nSampleID                                                                  \nSRR10525336                   0                   0                   0   \nSRR10380004                   0                   0                   0   \nSRR6807701                    0                   0                   0   \nSRR11033700                   0                   0                   0   \nSRR1163101                    0                   0                   0   \n\n             NC000962_3.4411016  NC000962_3.4411170  NC000962_3.4411327  \\\nSampleID                                                                  \nSRR10525336                   0                   0                   0   \nSRR10380004                   0                   0                   0   \nSRR6807701                    0                   0                   0   \nSRR11033700                   0                   0                   0   \nSRR1163101                    0                   0                   0   \n\n             Resistance_Status  \nSampleID                        \nSRR10525336                1.0  \nSRR10380004                1.0  \nSRR6807701                 1.0  \nSRR11033700                1.0  \nSRR1163101                 1.0  \n\n[5 rows x 52683 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NC000962_3.22</th>\n      <th>NC000962_3.434</th>\n      <th>NC000962_3.524</th>\n      <th>NC000962_3.645</th>\n      <th>NC000962_3.648</th>\n      <th>NC000962_3.654</th>\n      <th>NC000962_3.666</th>\n      <th>NC000962_3.675</th>\n      <th>NC000962_3.678</th>\n      <th>NC000962_3.693</th>\n      <th>...</th>\n      <th>NC000962_3.4410251</th>\n      <th>NC000962_3.4410260</th>\n      <th>NC000962_3.4410272</th>\n      <th>NC000962_3.4410278</th>\n      <th>NC000962_3.4410728</th>\n      <th>NC000962_3.4410850</th>\n      <th>NC000962_3.4411016</th>\n      <th>NC000962_3.4411170</th>\n      <th>NC000962_3.4411327</th>\n      <th>Resistance_Status</th>\n    </tr>\n    <tr>\n      <th>SampleID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>SRR10525336</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>SRR10380004</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>SRR6807701</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>SRR11033700</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>SRR1163101</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 52683 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604929720148
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "train_frame = h2o.import_file(DATA_LOCATION + \"processed/final.train.tsv\")\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604929736637
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv(DATA_LOCATION + \"processed/final.test.tsv\", \"\\t\", index_col= 'SampleID')\r\n",
        "test_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "            NC000962_3.22  NC000962_3.434  NC000962_3.524  NC000962_3.645  \\\nSampleID                                                                    \nERR3335735              0               0               0               0   \nSRR8552929              0               0               0               0   \nERR067629               0               0               0               0   \nERR067714               0               0               0               0   \nSRR5065314              0               0               0               0   \n\n            NC000962_3.648  NC000962_3.654  NC000962_3.666  NC000962_3.675  \\\nSampleID                                                                     \nERR3335735               0               0               0               0   \nSRR8552929               0               0               0               0   \nERR067629                0               0               0               0   \nERR067714                0               0               0               0   \nSRR5065314               0               0               0               0   \n\n            NC000962_3.678  NC000962_3.693        ...          \\\nSampleID                                          ...           \nERR3335735               0               0        ...           \nSRR8552929               0               0        ...           \nERR067629                0               0        ...           \nERR067714                0               0        ...           \nSRR5065314               0               0        ...           \n\n            NC000962_3.4410251  NC000962_3.4410260  NC000962_3.4410272  \\\nSampleID                                                                 \nERR3335735                   0                   0                   0   \nSRR8552929                   0                   0                   0   \nERR067629                    0                   0                   0   \nERR067714                    0                   0                   0   \nSRR5065314                   0                   0                   0   \n\n            NC000962_3.4410278  NC000962_3.4410728  NC000962_3.4410850  \\\nSampleID                                                                 \nERR3335735                   0                   0                   0   \nSRR8552929                   0                   0                   0   \nERR067629                    0                   0                   0   \nERR067714                    0                   0                   0   \nSRR5065314                   0                   0                   0   \n\n            NC000962_3.4411016  NC000962_3.4411170  NC000962_3.4411327  \\\nSampleID                                                                 \nERR3335735                   0                   0                   0   \nSRR8552929                   0                   0                   0   \nERR067629                    0                   0                   0   \nERR067714                    0                   0                   0   \nSRR5065314                   0                   0                   0   \n\n            Resistance_Status  \nSampleID                       \nERR3335735                1.0  \nSRR8552929                1.0  \nERR067629                 1.0  \nERR067714                 1.0  \nSRR5065314                1.0  \n\n[5 rows x 52683 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NC000962_3.22</th>\n      <th>NC000962_3.434</th>\n      <th>NC000962_3.524</th>\n      <th>NC000962_3.645</th>\n      <th>NC000962_3.648</th>\n      <th>NC000962_3.654</th>\n      <th>NC000962_3.666</th>\n      <th>NC000962_3.675</th>\n      <th>NC000962_3.678</th>\n      <th>NC000962_3.693</th>\n      <th>...</th>\n      <th>NC000962_3.4410251</th>\n      <th>NC000962_3.4410260</th>\n      <th>NC000962_3.4410272</th>\n      <th>NC000962_3.4410278</th>\n      <th>NC000962_3.4410728</th>\n      <th>NC000962_3.4410850</th>\n      <th>NC000962_3.4411016</th>\n      <th>NC000962_3.4411170</th>\n      <th>NC000962_3.4411327</th>\n      <th>Resistance_Status</th>\n    </tr>\n    <tr>\n      <th>SampleID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ERR3335735</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>SRR8552929</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>ERR067629</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>ERR067714</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>SRR5065314</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 52683 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604929459407
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "test_frame = h2o.import_file(DATA_LOCATION +  \"processed/final.test.tsv\")\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604929473146
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_col = 'SampleID'\r\n",
        "\r\n",
        "# Identify predictors and response columns\r\n",
        "predictor_cols = train_frame.columns\r\n",
        "response_col = \"Resistance_Status\"\r\n",
        "\r\n",
        "# Remove the index and response columns from predictor_columns list\r\n",
        "predictor_cols.remove(index_col)\r\n",
        "predictor_cols.remove(response_col)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# print(\"train frame - predictor column: \", predictor_cols[0], predictor_cols[-1])\r\n",
        "# print(\"train frame - response column: \", response_col)\r\n",
        "\r\n",
        "\r\n",
        "# print(\"test frame - predictor columns: \", predictor_cols[0], predictor_cols[-1])\r\n",
        "# print(\"test frame - response column: \", response_col)"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604929736668
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For binary classification, response should be a factor\r\n",
        "train_frame[response_col] = train_frame[response_col].asfactor()\r\n",
        "test_frame[response_col] = test_frame[response_col].asfactor()\r\n",
        "\r\n",
        "x = predictor_cols\r\n",
        "y = response_col"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604929473491
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from h2o.estimators import H2OPrincipalComponentAnalysisEstimator\r\n",
        "\r\n",
        "pca300 = H2OPrincipalComponentAnalysisEstimator(\r\n",
        "                                                   k = 300,\r\n",
        ")\r\n",
        "\r\n",
        "pca300.train(x=x, y=y, training_frame=binarized_final_df)\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model\r\n",
        "# model_path = h2o.save_model(model= my_pca, path=\"../models/my_pca_model\", force=True)\r\n",
        "\r\n",
        "model_path = MODELS_LOCATION + \"PCA300/PCA_model_python_1603962989759_1_k300\"\r\n",
        "\r\n",
        "# load the model\r\n",
        "pca300 = h2o.load_model(model_path)\r\n"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604929833551
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca300_df = pca300.summary().as_data_frame().set_index(\"\")\r\n",
        "pca300_df"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "                             pc1       pc2       pc3       pc4       pc5  \\\n                                                                           \nStandard deviation      8.748536  4.715628  3.877237  3.107335  2.784571   \nProportion of Variance  0.319086  0.092708  0.062673  0.040254  0.032326   \nCumulative Proportion   0.319086  0.411794  0.474467  0.514722  0.547048   \n\n                             pc6       pc7       pc8       pc9      pc10  \\\n                                                                           \nStandard deviation      2.583031  2.371838  1.989349  1.914256  1.835004   \nProportion of Variance  0.027816  0.023453  0.016499  0.015277  0.014038   \nCumulative Proportion   0.574864  0.598318  0.614817  0.630094  0.644132   \n\n                          ...        pc291     pc292     pc293     pc294  \\\n                          ...                                              \nStandard deviation        ...     0.241208  0.240459  0.239932  0.239419   \nProportion of Variance    ...     0.000243  0.000241  0.000240  0.000239   \nCumulative Proportion     ...     0.931150  0.931391  0.931631  0.931870   \n\n                           pc295     pc296     pc297     pc298     pc299  \\\n                                                                           \nStandard deviation      0.238373  0.237840  0.237656  0.237487  0.236259   \nProportion of Variance  0.000237  0.000236  0.000235  0.000235  0.000233   \nCumulative Proportion   0.932107  0.932342  0.932578  0.932813  0.933046   \n\n                           pc300  \n                                  \nStandard deviation      0.236189  \nProportion of Variance  0.000233  \nCumulative Proportion   0.933278  \n\n[3 rows x 300 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pc1</th>\n      <th>pc2</th>\n      <th>pc3</th>\n      <th>pc4</th>\n      <th>pc5</th>\n      <th>pc6</th>\n      <th>pc7</th>\n      <th>pc8</th>\n      <th>pc9</th>\n      <th>pc10</th>\n      <th>...</th>\n      <th>pc291</th>\n      <th>pc292</th>\n      <th>pc293</th>\n      <th>pc294</th>\n      <th>pc295</th>\n      <th>pc296</th>\n      <th>pc297</th>\n      <th>pc298</th>\n      <th>pc299</th>\n      <th>pc300</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Standard deviation</th>\n      <td>8.748536</td>\n      <td>4.715628</td>\n      <td>3.877237</td>\n      <td>3.107335</td>\n      <td>2.784571</td>\n      <td>2.583031</td>\n      <td>2.371838</td>\n      <td>1.989349</td>\n      <td>1.914256</td>\n      <td>1.835004</td>\n      <td>...</td>\n      <td>0.241208</td>\n      <td>0.240459</td>\n      <td>0.239932</td>\n      <td>0.239419</td>\n      <td>0.238373</td>\n      <td>0.237840</td>\n      <td>0.237656</td>\n      <td>0.237487</td>\n      <td>0.236259</td>\n      <td>0.236189</td>\n    </tr>\n    <tr>\n      <th>Proportion of Variance</th>\n      <td>0.319086</td>\n      <td>0.092708</td>\n      <td>0.062673</td>\n      <td>0.040254</td>\n      <td>0.032326</td>\n      <td>0.027816</td>\n      <td>0.023453</td>\n      <td>0.016499</td>\n      <td>0.015277</td>\n      <td>0.014038</td>\n      <td>...</td>\n      <td>0.000243</td>\n      <td>0.000241</td>\n      <td>0.000240</td>\n      <td>0.000239</td>\n      <td>0.000237</td>\n      <td>0.000236</td>\n      <td>0.000235</td>\n      <td>0.000235</td>\n      <td>0.000233</td>\n      <td>0.000233</td>\n    </tr>\n    <tr>\n      <th>Cumulative Proportion</th>\n      <td>0.319086</td>\n      <td>0.411794</td>\n      <td>0.474467</td>\n      <td>0.514722</td>\n      <td>0.547048</td>\n      <td>0.574864</td>\n      <td>0.598318</td>\n      <td>0.614817</td>\n      <td>0.630094</td>\n      <td>0.644132</td>\n      <td>...</td>\n      <td>0.931150</td>\n      <td>0.931391</td>\n      <td>0.931631</td>\n      <td>0.931870</td>\n      <td>0.932107</td>\n      <td>0.932342</td>\n      <td>0.932578</td>\n      <td>0.932813</td>\n      <td>0.933046</td>\n      <td>0.933278</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 300 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604807967367
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a4_dims = (15, 10)\r\n",
        "fig, ax = pyplot.subplots(figsize=a4_dims)\r\n",
        "ax.set_xticks([49,99,149, 199, 249, 299])\r\n",
        "sns.lineplot(ax=ax, data= pca300_df.loc['Cumulative Proportion'])\r\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "<AxesSubplot:ylabel='Cumulative Proportion'>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1080x720 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604807969098
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export the overall PCA transformed dataset - only for Predictors\r\n",
        "\r\n",
        "binarized_final_pca300_frame = pca300.predict(binarized_final_frame[predictor_cols])\r\n",
        "h2o.export_file(frame=binarized_final_pca300_frame, path= DATA_LOCATION + \"processed/final.binarized_final_monolabel_frame.pc300.tsv\", force=True)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pca prediction progress: |████████████████████████████████████████████████| 100%\n",
            "Export File progress: |███████████████████████████████████████████████████| 100%\n"
          ]
        }
      ],
      "execution_count": 20,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604930472097
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binarized_final_pca300_frame_df = binarized_final_pca300_frame.as_data_frame()\r\n",
        "binarized_final_pca300_frame_df.to_csv(DATA_LOCATION + \"processed/final.binarized_final_monolabel_df.pc300.tsv\", \"\\t\")\r\n"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604930474421
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the PCA transformed predictor columns"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_frame_pca = pca300.predict(train_frame[predictor_cols])\r\n",
        "# h2o.export_file(frame=train_frame_pca, path= DATA_LOCATION + \"processed/final.train_frame.pca300.tsv\", force=True)\r\n",
        "\r\n",
        "\r\n",
        "train_frame_pca = h2o.import_file(DATA_LOCATION + \"processed/final.train_frame.pca300.tsv\")\r\n",
        "train_frame_pca.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<table>\n<thead>\n<tr><th style=\"text-align: right;\">      PC1</th><th style=\"text-align: right;\">     PC2</th><th style=\"text-align: right;\">         PC3</th><th style=\"text-align: right;\">       PC4</th><th style=\"text-align: right;\">       PC5</th><th style=\"text-align: right;\">      PC6</th><th style=\"text-align: right;\">       PC7</th><th style=\"text-align: right;\">      PC8</th><th style=\"text-align: right;\">      PC9</th><th style=\"text-align: right;\">     PC10</th><th style=\"text-align: right;\">     PC11</th><th style=\"text-align: right;\">      PC12</th><th style=\"text-align: right;\">     PC13</th><th style=\"text-align: right;\">     PC14</th><th style=\"text-align: right;\">      PC15</th><th style=\"text-align: right;\">     PC16</th><th style=\"text-align: right;\">       PC17</th><th style=\"text-align: right;\">      PC18</th><th style=\"text-align: right;\">      PC19</th><th style=\"text-align: right;\">     PC20</th><th style=\"text-align: right;\">     PC21</th><th style=\"text-align: right;\">      PC22</th><th style=\"text-align: right;\">      PC23</th><th style=\"text-align: right;\">      PC24</th><th style=\"text-align: right;\">     PC25</th><th style=\"text-align: right;\">      PC26</th><th style=\"text-align: right;\">      PC27</th><th style=\"text-align: right;\">       PC28</th><th style=\"text-align: right;\">      PC29</th><th style=\"text-align: right;\">     PC30</th><th style=\"text-align: right;\">       PC31</th><th style=\"text-align: right;\">     PC32</th><th style=\"text-align: right;\">      PC33</th><th style=\"text-align: right;\">      PC34</th><th style=\"text-align: right;\">      PC35</th><th style=\"text-align: right;\">      PC36</th><th style=\"text-align: right;\">      PC37</th><th style=\"text-align: right;\">      PC38</th><th style=\"text-align: right;\">      PC39</th><th style=\"text-align: right;\">      PC40</th><th style=\"text-align: right;\">       PC41</th><th style=\"text-align: right;\">       PC42</th><th style=\"text-align: right;\">      PC43</th><th style=\"text-align: right;\">      PC44</th><th style=\"text-align: right;\">       PC45</th><th style=\"text-align: right;\">      PC46</th><th style=\"text-align: right;\">      PC47</th><th style=\"text-align: right;\">      PC48</th><th style=\"text-align: right;\">      PC49</th><th style=\"text-align: right;\">      PC50</th><th style=\"text-align: right;\">      PC51</th><th style=\"text-align: right;\">       PC52</th><th style=\"text-align: right;\">      PC53</th><th style=\"text-align: right;\">      PC54</th><th style=\"text-align: right;\">      PC55</th><th style=\"text-align: right;\">      PC56</th><th style=\"text-align: right;\">      PC57</th><th style=\"text-align: right;\">      PC58</th><th style=\"text-align: right;\">      PC59</th><th style=\"text-align: right;\">      PC60</th><th style=\"text-align: right;\">      PC61</th><th style=\"text-align: right;\">        PC62</th><th style=\"text-align: right;\">      PC63</th><th style=\"text-align: right;\">      PC64</th><th style=\"text-align: right;\">      PC65</th><th style=\"text-align: right;\">      PC66</th><th style=\"text-align: right;\">     PC67</th><th style=\"text-align: right;\">      PC68</th><th style=\"text-align: right;\">      PC69</th><th style=\"text-align: right;\">      PC70</th><th style=\"text-align: right;\">      PC71</th><th style=\"text-align: right;\">      PC72</th><th style=\"text-align: right;\">      PC73</th><th style=\"text-align: right;\">      PC74</th><th style=\"text-align: right;\">      PC75</th><th style=\"text-align: right;\">       PC76</th><th style=\"text-align: right;\">      PC77</th><th style=\"text-align: right;\">      PC78</th><th style=\"text-align: right;\">      PC79</th><th style=\"text-align: right;\">      PC80</th><th style=\"text-align: right;\">      PC81</th><th style=\"text-align: right;\">     PC82</th><th style=\"text-align: right;\">     PC83</th><th style=\"text-align: right;\">       PC84</th><th style=\"text-align: right;\">      PC85</th><th style=\"text-align: right;\">      PC86</th><th style=\"text-align: right;\">      PC87</th><th style=\"text-align: right;\">      PC88</th><th style=\"text-align: right;\">      PC89</th><th style=\"text-align: right;\">      PC90</th><th style=\"text-align: right;\">       PC91</th><th style=\"text-align: right;\">       PC92</th><th style=\"text-align: right;\">      PC93</th><th style=\"text-align: right;\">      PC94</th><th style=\"text-align: right;\">      PC95</th><th style=\"text-align: right;\">       PC96</th><th style=\"text-align: right;\">      PC97</th><th style=\"text-align: right;\">       PC98</th><th style=\"text-align: right;\">     PC99</th><th style=\"text-align: right;\">     PC100</th><th style=\"text-align: right;\">     PC101</th><th style=\"text-align: right;\">     PC102</th><th style=\"text-align: right;\">      PC103</th><th style=\"text-align: right;\">     PC104</th><th style=\"text-align: right;\">      PC105</th><th style=\"text-align: right;\">    PC106</th><th style=\"text-align: right;\">      PC107</th><th style=\"text-align: right;\">     PC108</th><th style=\"text-align: right;\">     PC109</th><th style=\"text-align: right;\">     PC110</th><th style=\"text-align: right;\">     PC111</th><th style=\"text-align: right;\">      PC112</th><th style=\"text-align: right;\">     PC113</th><th style=\"text-align: right;\">     PC114</th><th style=\"text-align: right;\">     PC115</th><th style=\"text-align: right;\">     PC116</th><th style=\"text-align: right;\">     PC117</th><th style=\"text-align: right;\">      PC118</th><th style=\"text-align: right;\">      PC119</th><th style=\"text-align: right;\">     PC120</th><th style=\"text-align: right;\">      PC121</th><th style=\"text-align: right;\">     PC122</th><th style=\"text-align: right;\">     PC123</th><th style=\"text-align: right;\">     PC124</th><th style=\"text-align: right;\">     PC125</th><th style=\"text-align: right;\">      PC126</th><th style=\"text-align: right;\">     PC127</th><th style=\"text-align: right;\">       PC128</th><th style=\"text-align: right;\">      PC129</th><th style=\"text-align: right;\">     PC130</th><th style=\"text-align: right;\">     PC131</th><th style=\"text-align: right;\">     PC132</th><th style=\"text-align: right;\">     PC133</th><th style=\"text-align: right;\">     PC134</th><th style=\"text-align: right;\">     PC135</th><th style=\"text-align: right;\">     PC136</th><th style=\"text-align: right;\">     PC137</th><th style=\"text-align: right;\">     PC138</th><th style=\"text-align: right;\">      PC139</th><th style=\"text-align: right;\">      PC140</th><th style=\"text-align: right;\">      PC141</th><th style=\"text-align: right;\">     PC142</th><th style=\"text-align: right;\">     PC143</th><th style=\"text-align: right;\">     PC144</th><th style=\"text-align: right;\">     PC145</th><th style=\"text-align: right;\">     PC146</th><th style=\"text-align: right;\">    PC147</th><th style=\"text-align: right;\">     PC148</th><th style=\"text-align: right;\">      PC149</th><th style=\"text-align: right;\">     PC150</th><th style=\"text-align: right;\">     PC151</th><th style=\"text-align: right;\">      PC152</th><th style=\"text-align: right;\">      PC153</th><th style=\"text-align: right;\">     PC154</th><th style=\"text-align: right;\">     PC155</th><th style=\"text-align: right;\">     PC156</th><th style=\"text-align: right;\">    PC157</th><th style=\"text-align: right;\">      PC158</th><th style=\"text-align: right;\">     PC159</th><th style=\"text-align: right;\">      PC160</th><th style=\"text-align: right;\">     PC161</th><th style=\"text-align: right;\">       PC162</th><th style=\"text-align: right;\">      PC163</th><th style=\"text-align: right;\">      PC164</th><th style=\"text-align: right;\">     PC165</th><th style=\"text-align: right;\">     PC166</th><th style=\"text-align: right;\">     PC167</th><th style=\"text-align: right;\">     PC168</th><th style=\"text-align: right;\">     PC169</th><th style=\"text-align: right;\">     PC170</th><th style=\"text-align: right;\">      PC171</th><th style=\"text-align: right;\">     PC172</th><th style=\"text-align: right;\">     PC173</th><th style=\"text-align: right;\">       PC174</th><th style=\"text-align: right;\">      PC175</th><th style=\"text-align: right;\">     PC176</th><th style=\"text-align: right;\">     PC177</th><th style=\"text-align: right;\">      PC178</th><th style=\"text-align: right;\">     PC179</th><th style=\"text-align: right;\">     PC180</th><th style=\"text-align: right;\">     PC181</th><th style=\"text-align: right;\">     PC182</th><th style=\"text-align: right;\">      PC183</th><th style=\"text-align: right;\">     PC184</th><th style=\"text-align: right;\">      PC185</th><th style=\"text-align: right;\">     PC186</th><th style=\"text-align: right;\">     PC187</th><th style=\"text-align: right;\">      PC188</th><th style=\"text-align: right;\">     PC189</th><th style=\"text-align: right;\">     PC190</th><th style=\"text-align: right;\">      PC191</th><th style=\"text-align: right;\">     PC192</th><th style=\"text-align: right;\">     PC193</th><th style=\"text-align: right;\">      PC194</th><th style=\"text-align: right;\">     PC195</th><th style=\"text-align: right;\">      PC196</th><th style=\"text-align: right;\">      PC197</th><th style=\"text-align: right;\">     PC198</th><th style=\"text-align: right;\">     PC199</th><th style=\"text-align: right;\">     PC200</th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\"> -7.21528</td><td style=\"text-align: right;\"> 5.48779</td><td style=\"text-align: right;\">-0.0457426  </td><td style=\"text-align: right;\">-3.29582  </td><td style=\"text-align: right;\">-8.02517  </td><td style=\"text-align: right;\">-2.94974 </td><td style=\"text-align: right;\">-2.96759  </td><td style=\"text-align: right;\">-2.26629 </td><td style=\"text-align: right;\">-0.652408</td><td style=\"text-align: right;\"> 0.578522</td><td style=\"text-align: right;\"> 0.182181</td><td style=\"text-align: right;\"> 0.434753 </td><td style=\"text-align: right;\"> 2.51645 </td><td style=\"text-align: right;\">-2.40717 </td><td style=\"text-align: right;\">-0.0528002</td><td style=\"text-align: right;\">-0.867347</td><td style=\"text-align: right;\">-0.77548   </td><td style=\"text-align: right;\"> 0.779273 </td><td style=\"text-align: right;\">-0.362249 </td><td style=\"text-align: right;\">-0.189216</td><td style=\"text-align: right;\">-1.43005 </td><td style=\"text-align: right;\"> 0.0339925</td><td style=\"text-align: right;\"> 0.0361673</td><td style=\"text-align: right;\">-0.59373  </td><td style=\"text-align: right;\"> 0.642088</td><td style=\"text-align: right;\">-0.0192343</td><td style=\"text-align: right;\"> 0.0159929</td><td style=\"text-align: right;\"> 0.10032   </td><td style=\"text-align: right;\">-2.14885  </td><td style=\"text-align: right;\"> 0.72847 </td><td style=\"text-align: right;\">-0.426612  </td><td style=\"text-align: right;\">-2.17743 </td><td style=\"text-align: right;\"> 0.564177 </td><td style=\"text-align: right;\">-0.419728 </td><td style=\"text-align: right;\">-0.040311 </td><td style=\"text-align: right;\"> 0.174175 </td><td style=\"text-align: right;\"> 0.0958375</td><td style=\"text-align: right;\">-0.840905 </td><td style=\"text-align: right;\">-0.412918 </td><td style=\"text-align: right;\"> 0.0362403</td><td style=\"text-align: right;\">-1.12543   </td><td style=\"text-align: right;\"> 1.47642   </td><td style=\"text-align: right;\">-0.288826 </td><td style=\"text-align: right;\"> 0.204485 </td><td style=\"text-align: right;\"> 0.970888  </td><td style=\"text-align: right;\"> 0.830999 </td><td style=\"text-align: right;\"> 0.392813 </td><td style=\"text-align: right;\">-0.160212 </td><td style=\"text-align: right;\"> 0.045166 </td><td style=\"text-align: right;\">-0.775327 </td><td style=\"text-align: right;\"> 0.854433 </td><td style=\"text-align: right;\"> 3.10933   </td><td style=\"text-align: right;\"> 1.62966  </td><td style=\"text-align: right;\">-0.403796 </td><td style=\"text-align: right;\"> 2.37824  </td><td style=\"text-align: right;\">-1.07053  </td><td style=\"text-align: right;\"> 1.22014  </td><td style=\"text-align: right;\">-0.0348898</td><td style=\"text-align: right;\"> 0.709709 </td><td style=\"text-align: right;\">-1.60722  </td><td style=\"text-align: right;\">-0.537093 </td><td style=\"text-align: right;\">-0.519959   </td><td style=\"text-align: right;\">-0.607373 </td><td style=\"text-align: right;\"> 1.96028  </td><td style=\"text-align: right;\">-1.37502  </td><td style=\"text-align: right;\"> 0.788434 </td><td style=\"text-align: right;\"> 0.623542</td><td style=\"text-align: right;\"> 0.117146 </td><td style=\"text-align: right;\">-0.662954 </td><td style=\"text-align: right;\">-0.788601 </td><td style=\"text-align: right;\"> 0.0349831</td><td style=\"text-align: right;\">-0.104036 </td><td style=\"text-align: right;\"> 0.64312  </td><td style=\"text-align: right;\"> 0.498023 </td><td style=\"text-align: right;\"> 1.10188  </td><td style=\"text-align: right;\"> 1.07592   </td><td style=\"text-align: right;\"> 0.471287 </td><td style=\"text-align: right;\">-0.870997 </td><td style=\"text-align: right;\"> 0.134068 </td><td style=\"text-align: right;\"> 0.192699 </td><td style=\"text-align: right;\"> 0.590267 </td><td style=\"text-align: right;\"> 1.93532 </td><td style=\"text-align: right;\"> 1.70993 </td><td style=\"text-align: right;\"> 0.0663423 </td><td style=\"text-align: right;\">-0.0086952</td><td style=\"text-align: right;\">-0.131918 </td><td style=\"text-align: right;\"> 0.4172   </td><td style=\"text-align: right;\">-1.12597  </td><td style=\"text-align: right;\"> 0.123066 </td><td style=\"text-align: right;\">-2.76761  </td><td style=\"text-align: right;\">-0.0105532 </td><td style=\"text-align: right;\">-0.186149  </td><td style=\"text-align: right;\">-0.528908 </td><td style=\"text-align: right;\">-0.59734  </td><td style=\"text-align: right;\">-0.125254 </td><td style=\"text-align: right;\"> 0.853391  </td><td style=\"text-align: right;\">-0.353671 </td><td style=\"text-align: right;\"> 0.527961  </td><td style=\"text-align: right;\">-1.19337 </td><td style=\"text-align: right;\"> 0.320649 </td><td style=\"text-align: right;\">-0.910347 </td><td style=\"text-align: right;\"> 0.726797 </td><td style=\"text-align: right;\">-1.19437   </td><td style=\"text-align: right;\"> 0.643785 </td><td style=\"text-align: right;\"> 2.2666    </td><td style=\"text-align: right;\"> 1.23807 </td><td style=\"text-align: right;\">-1.71336   </td><td style=\"text-align: right;\"> 1.6379   </td><td style=\"text-align: right;\">-1.35046  </td><td style=\"text-align: right;\">-0.0621283</td><td style=\"text-align: right;\">-2.1299   </td><td style=\"text-align: right;\"> 0.338774  </td><td style=\"text-align: right;\">-0.294789 </td><td style=\"text-align: right;\"> 0.635849 </td><td style=\"text-align: right;\"> 0.393347 </td><td style=\"text-align: right;\"> 0.461294 </td><td style=\"text-align: right;\"> 0.799493 </td><td style=\"text-align: right;\"> 0.182817  </td><td style=\"text-align: right;\">-0.0629657 </td><td style=\"text-align: right;\">-0.0312119</td><td style=\"text-align: right;\"> 0.38403   </td><td style=\"text-align: right;\">-0.29482  </td><td style=\"text-align: right;\"> 0.102779 </td><td style=\"text-align: right;\">-0.0105114</td><td style=\"text-align: right;\">-0.613126 </td><td style=\"text-align: right;\">-0.635172  </td><td style=\"text-align: right;\"> 0.318172 </td><td style=\"text-align: right;\">-0.604303   </td><td style=\"text-align: right;\">-1.23884   </td><td style=\"text-align: right;\">-0.367584 </td><td style=\"text-align: right;\"> 0.13739  </td><td style=\"text-align: right;\"> 0.403578 </td><td style=\"text-align: right;\"> 1.11971  </td><td style=\"text-align: right;\">-1.58696  </td><td style=\"text-align: right;\"> 0.0275307</td><td style=\"text-align: right;\"> 1.58684  </td><td style=\"text-align: right;\">-0.519128 </td><td style=\"text-align: right;\"> 0.250662 </td><td style=\"text-align: right;\">-0.731469  </td><td style=\"text-align: right;\"> 1.03236   </td><td style=\"text-align: right;\">-0.272874  </td><td style=\"text-align: right;\">-0.146155 </td><td style=\"text-align: right;\">-1.12871  </td><td style=\"text-align: right;\"> 0.518941 </td><td style=\"text-align: right;\">-0.731375 </td><td style=\"text-align: right;\">-0.186096 </td><td style=\"text-align: right;\"> 0.206038</td><td style=\"text-align: right;\">-0.129464 </td><td style=\"text-align: right;\"> 0.20192   </td><td style=\"text-align: right;\"> 0.0572525</td><td style=\"text-align: right;\"> 0.337063 </td><td style=\"text-align: right;\"> 1.8732    </td><td style=\"text-align: right;\"> 0.718144  </td><td style=\"text-align: right;\"> 0.609294 </td><td style=\"text-align: right;\">-0.0976525</td><td style=\"text-align: right;\"> 1.02692  </td><td style=\"text-align: right;\"> 1.16342 </td><td style=\"text-align: right;\">-0.027039  </td><td style=\"text-align: right;\">-0.366797 </td><td style=\"text-align: right;\">-0.126558  </td><td style=\"text-align: right;\"> 0.145244 </td><td style=\"text-align: right;\"> 0.0541146  </td><td style=\"text-align: right;\">-0.293231  </td><td style=\"text-align: right;\">-0.430163  </td><td style=\"text-align: right;\">-0.623036 </td><td style=\"text-align: right;\"> 0.119761 </td><td style=\"text-align: right;\"> 0.0857521</td><td style=\"text-align: right;\"> 0.654185 </td><td style=\"text-align: right;\">-0.597948 </td><td style=\"text-align: right;\"> 0.906505 </td><td style=\"text-align: right;\"> 0.00763198</td><td style=\"text-align: right;\"> 0.760529 </td><td style=\"text-align: right;\">-0.196652 </td><td style=\"text-align: right;\"> 1.37364    </td><td style=\"text-align: right;\"> 0.38687   </td><td style=\"text-align: right;\"> 1.06562  </td><td style=\"text-align: right;\">-0.592595 </td><td style=\"text-align: right;\"> 0.096302  </td><td style=\"text-align: right;\">-0.982776 </td><td style=\"text-align: right;\"> 0.205194 </td><td style=\"text-align: right;\"> 0.795516 </td><td style=\"text-align: right;\"> 1.4415   </td><td style=\"text-align: right;\"> 0.103181  </td><td style=\"text-align: right;\"> 0.958078 </td><td style=\"text-align: right;\">-0.024321  </td><td style=\"text-align: right;\"> 0.423626 </td><td style=\"text-align: right;\"> 0.416048 </td><td style=\"text-align: right;\">-0.422432  </td><td style=\"text-align: right;\">-0.822004 </td><td style=\"text-align: right;\"> 0.286042 </td><td style=\"text-align: right;\">-0.334727  </td><td style=\"text-align: right;\"> 0.236006 </td><td style=\"text-align: right;\"> 0.430699 </td><td style=\"text-align: right;\">-1.99712   </td><td style=\"text-align: right;\"> 0.0612397</td><td style=\"text-align: right;\">-0.281902  </td><td style=\"text-align: right;\"> 0.561714  </td><td style=\"text-align: right;\">-0.545934 </td><td style=\"text-align: right;\"> 0.920071 </td><td style=\"text-align: right;\">-0.603047 </td></tr>\n<tr><td style=\"text-align: right;\">-11.6    </td><td style=\"text-align: right;\"> 5.53472</td><td style=\"text-align: right;\">-0.0676378  </td><td style=\"text-align: right;\"> 0.442869 </td><td style=\"text-align: right;\"> 6.54339  </td><td style=\"text-align: right;\"> 0.485848</td><td style=\"text-align: right;\">-2.2913   </td><td style=\"text-align: right;\">-1.48508 </td><td style=\"text-align: right;\">-1.26789 </td><td style=\"text-align: right;\"> 2.48786 </td><td style=\"text-align: right;\"> 1.61519 </td><td style=\"text-align: right;\">-1.82951  </td><td style=\"text-align: right;\">-1.14724 </td><td style=\"text-align: right;\">-0.686728</td><td style=\"text-align: right;\"> 0.0791433</td><td style=\"text-align: right;\"> 0.244093</td><td style=\"text-align: right;\">-0.673544  </td><td style=\"text-align: right;\">-0.298431 </td><td style=\"text-align: right;\"> 0.569891 </td><td style=\"text-align: right;\"> 1.3156  </td><td style=\"text-align: right;\"> 0.936164</td><td style=\"text-align: right;\">-1.74636  </td><td style=\"text-align: right;\">-1.05101  </td><td style=\"text-align: right;\"> 0.351799 </td><td style=\"text-align: right;\">-0.744067</td><td style=\"text-align: right;\"> 0.26847  </td><td style=\"text-align: right;\">-0.322997 </td><td style=\"text-align: right;\">-0.0033458 </td><td style=\"text-align: right;\"> 0.139044 </td><td style=\"text-align: right;\"> 0.83802 </td><td style=\"text-align: right;\"> 0.0462784 </td><td style=\"text-align: right;\"> 0.18821 </td><td style=\"text-align: right;\"> 0.0188327</td><td style=\"text-align: right;\"> 0.311519 </td><td style=\"text-align: right;\">-0.103977 </td><td style=\"text-align: right;\"> 0.924853 </td><td style=\"text-align: right;\"> 1.06325  </td><td style=\"text-align: right;\">-0.617407 </td><td style=\"text-align: right;\"> 0.416026 </td><td style=\"text-align: right;\"> 0.152573 </td><td style=\"text-align: right;\">-0.00922459</td><td style=\"text-align: right;\">-0.540769  </td><td style=\"text-align: right;\">-0.42493  </td><td style=\"text-align: right;\"> 0.224336 </td><td style=\"text-align: right;\"> 0.842236  </td><td style=\"text-align: right;\">-0.0829223</td><td style=\"text-align: right;\"> 0.104743 </td><td style=\"text-align: right;\">-0.249455 </td><td style=\"text-align: right;\">-0.237306 </td><td style=\"text-align: right;\"> 0.123351 </td><td style=\"text-align: right;\"> 0.373262 </td><td style=\"text-align: right;\"> 0.402359  </td><td style=\"text-align: right;\"> 0.0419783</td><td style=\"text-align: right;\">-1.21117  </td><td style=\"text-align: right;\">-0.482892 </td><td style=\"text-align: right;\">-0.974701 </td><td style=\"text-align: right;\">-0.132585 </td><td style=\"text-align: right;\"> 0.422715 </td><td style=\"text-align: right;\">-0.532571 </td><td style=\"text-align: right;\">-0.512553 </td><td style=\"text-align: right;\">-0.417771 </td><td style=\"text-align: right;\"> 0.55964    </td><td style=\"text-align: right;\">-0.123657 </td><td style=\"text-align: right;\">-0.481367 </td><td style=\"text-align: right;\">-0.395624 </td><td style=\"text-align: right;\"> 0.235399 </td><td style=\"text-align: right;\">-0.338215</td><td style=\"text-align: right;\">-0.311371 </td><td style=\"text-align: right;\"> 0.25003  </td><td style=\"text-align: right;\">-0.187722 </td><td style=\"text-align: right;\">-0.145724 </td><td style=\"text-align: right;\"> 0.0526789</td><td style=\"text-align: right;\"> 0.49318  </td><td style=\"text-align: right;\"> 0.0865632</td><td style=\"text-align: right;\">-0.12011  </td><td style=\"text-align: right;\">-0.482305  </td><td style=\"text-align: right;\"> 0.176727 </td><td style=\"text-align: right;\">-0.126995 </td><td style=\"text-align: right;\">-0.1996   </td><td style=\"text-align: right;\">-0.169428 </td><td style=\"text-align: right;\"> 0.0459824</td><td style=\"text-align: right;\">-0.10309 </td><td style=\"text-align: right;\">-0.100268</td><td style=\"text-align: right;\">-0.066558  </td><td style=\"text-align: right;\"> 0.290223 </td><td style=\"text-align: right;\"> 0.0640084</td><td style=\"text-align: right;\"> 0.192294 </td><td style=\"text-align: right;\"> 0.367173 </td><td style=\"text-align: right;\">-0.726469 </td><td style=\"text-align: right;\">-0.255324 </td><td style=\"text-align: right;\"> 0.376527  </td><td style=\"text-align: right;\"> 0.0864552 </td><td style=\"text-align: right;\"> 0.429294 </td><td style=\"text-align: right;\"> 0.361994 </td><td style=\"text-align: right;\">-0.0955574</td><td style=\"text-align: right;\"> 0.10195   </td><td style=\"text-align: right;\"> 0.101228 </td><td style=\"text-align: right;\">-0.164574  </td><td style=\"text-align: right;\"> 0.105739</td><td style=\"text-align: right;\"> 0.0161596</td><td style=\"text-align: right;\">-0.309447 </td><td style=\"text-align: right;\">-0.148715 </td><td style=\"text-align: right;\"> 0.0122466 </td><td style=\"text-align: right;\"> 0.408371 </td><td style=\"text-align: right;\">-0.140452  </td><td style=\"text-align: right;\"> 0.34785 </td><td style=\"text-align: right;\"> 0.134036  </td><td style=\"text-align: right;\"> 0.312078 </td><td style=\"text-align: right;\"> 0.0964443</td><td style=\"text-align: right;\"> 0.262582 </td><td style=\"text-align: right;\"> 0.0372175</td><td style=\"text-align: right;\"> 0.103305  </td><td style=\"text-align: right;\"> 0.0706207</td><td style=\"text-align: right;\"> 0.0719518</td><td style=\"text-align: right;\"> 0.171051 </td><td style=\"text-align: right;\">-0.0878448</td><td style=\"text-align: right;\"> 0.0998239</td><td style=\"text-align: right;\">-0.0338992 </td><td style=\"text-align: right;\"> 0.00544983</td><td style=\"text-align: right;\"> 0.186707 </td><td style=\"text-align: right;\"> 0.281369  </td><td style=\"text-align: right;\">-0.021923 </td><td style=\"text-align: right;\"> 0.384559 </td><td style=\"text-align: right;\">-0.145023 </td><td style=\"text-align: right;\"> 0.107315 </td><td style=\"text-align: right;\">-0.314057  </td><td style=\"text-align: right;\"> 0.0957007</td><td style=\"text-align: right;\">-0.178865   </td><td style=\"text-align: right;\">-0.00989666</td><td style=\"text-align: right;\">-0.151766 </td><td style=\"text-align: right;\"> 0.141986 </td><td style=\"text-align: right;\">-0.228017 </td><td style=\"text-align: right;\">-0.237458 </td><td style=\"text-align: right;\">-0.12697  </td><td style=\"text-align: right;\">-0.318449 </td><td style=\"text-align: right;\"> 0.113567 </td><td style=\"text-align: right;\"> 0.30737  </td><td style=\"text-align: right;\">-0.20337  </td><td style=\"text-align: right;\"> 0.202596  </td><td style=\"text-align: right;\"> 0.386656  </td><td style=\"text-align: right;\">-0.266906  </td><td style=\"text-align: right;\"> 0.164085 </td><td style=\"text-align: right;\"> 0.318025 </td><td style=\"text-align: right;\"> 0.0820759</td><td style=\"text-align: right;\"> 0.14793  </td><td style=\"text-align: right;\"> 0.01882  </td><td style=\"text-align: right;\"> 0.495149</td><td style=\"text-align: right;\">-0.260415 </td><td style=\"text-align: right;\">-0.0617778 </td><td style=\"text-align: right;\"> 0.362951 </td><td style=\"text-align: right;\"> 0.0325297</td><td style=\"text-align: right;\"> 0.117637  </td><td style=\"text-align: right;\"> 0.113324  </td><td style=\"text-align: right;\"> 0.429079 </td><td style=\"text-align: right;\">-0.334004 </td><td style=\"text-align: right;\"> 0.0182072</td><td style=\"text-align: right;\">-0.187317</td><td style=\"text-align: right;\"> 0.081209  </td><td style=\"text-align: right;\"> 0.0555776</td><td style=\"text-align: right;\">-0.100039  </td><td style=\"text-align: right;\"> 0.183181 </td><td style=\"text-align: right;\">-0.027631   </td><td style=\"text-align: right;\"> 0.00739474</td><td style=\"text-align: right;\"> 0.274455  </td><td style=\"text-align: right;\">-0.186653 </td><td style=\"text-align: right;\"> 0.177429 </td><td style=\"text-align: right;\">-0.178171 </td><td style=\"text-align: right;\"> 0.108237 </td><td style=\"text-align: right;\"> 0.214357 </td><td style=\"text-align: right;\"> 0.279921 </td><td style=\"text-align: right;\">-0.100227  </td><td style=\"text-align: right;\"> 0.434997 </td><td style=\"text-align: right;\"> 0.0841473</td><td style=\"text-align: right;\"> 0.0511457  </td><td style=\"text-align: right;\">-0.231324  </td><td style=\"text-align: right;\">-0.0408152</td><td style=\"text-align: right;\"> 0.0517595</td><td style=\"text-align: right;\">-0.00591222</td><td style=\"text-align: right;\">-0.212198 </td><td style=\"text-align: right;\">-0.0753098</td><td style=\"text-align: right;\">-0.0714339</td><td style=\"text-align: right;\"> 0.0261387</td><td style=\"text-align: right;\"> 0.463119  </td><td style=\"text-align: right;\">-0.0376576</td><td style=\"text-align: right;\">-0.0828916 </td><td style=\"text-align: right;\"> 0.152708 </td><td style=\"text-align: right;\">-0.111939 </td><td style=\"text-align: right;\">-0.132567  </td><td style=\"text-align: right;\"> 0.0222411</td><td style=\"text-align: right;\">-0.0039838</td><td style=\"text-align: right;\">-0.211777  </td><td style=\"text-align: right;\">-0.19423  </td><td style=\"text-align: right;\">-0.156346 </td><td style=\"text-align: right;\">-0.166492  </td><td style=\"text-align: right;\"> 0.121824 </td><td style=\"text-align: right;\">-0.110317  </td><td style=\"text-align: right;\"> 0.217815  </td><td style=\"text-align: right;\">-0.0654254</td><td style=\"text-align: right;\">-0.119042 </td><td style=\"text-align: right;\">-0.0851808</td></tr>\n<tr><td style=\"text-align: right;\"> -9.1499 </td><td style=\"text-align: right;\">-4.45121</td><td style=\"text-align: right;\">-0.000560915</td><td style=\"text-align: right;\">-0.211492 </td><td style=\"text-align: right;\"> 0.891811 </td><td style=\"text-align: right;\">-1.61937 </td><td style=\"text-align: right;\">-0.0314806</td><td style=\"text-align: right;\">-1.11622 </td><td style=\"text-align: right;\">-0.521429</td><td style=\"text-align: right;\"> 0.226712</td><td style=\"text-align: right;\">-0.650277</td><td style=\"text-align: right;\">-0.479117 </td><td style=\"text-align: right;\">-0.996814</td><td style=\"text-align: right;\">-1.1133  </td><td style=\"text-align: right;\">-1.26154  </td><td style=\"text-align: right;\">-0.974177</td><td style=\"text-align: right;\">-0.00247332</td><td style=\"text-align: right;\">-0.0530825</td><td style=\"text-align: right;\">-0.201434 </td><td style=\"text-align: right;\">-1.98052 </td><td style=\"text-align: right;\">-1.29959 </td><td style=\"text-align: right;\">-0.260899 </td><td style=\"text-align: right;\"> 0.78139  </td><td style=\"text-align: right;\">-0.048447 </td><td style=\"text-align: right;\"> 0.238562</td><td style=\"text-align: right;\">-0.334514 </td><td style=\"text-align: right;\">-0.853045 </td><td style=\"text-align: right;\"> 0.0713396 </td><td style=\"text-align: right;\">-0.484966 </td><td style=\"text-align: right;\">-0.619925</td><td style=\"text-align: right;\">-0.21595   </td><td style=\"text-align: right;\"> 0.653184</td><td style=\"text-align: right;\">-1.5664   </td><td style=\"text-align: right;\"> 0.0428643</td><td style=\"text-align: right;\">-1.3497   </td><td style=\"text-align: right;\"> 0.0193528</td><td style=\"text-align: right;\">-0.51782  </td><td style=\"text-align: right;\"> 0.820135 </td><td style=\"text-align: right;\"> 0.293265 </td><td style=\"text-align: right;\">-0.509604 </td><td style=\"text-align: right;\"> 0.134869  </td><td style=\"text-align: right;\"> 0.00260967</td><td style=\"text-align: right;\">-0.452535 </td><td style=\"text-align: right;\">-0.293624 </td><td style=\"text-align: right;\">-0.00177784</td><td style=\"text-align: right;\">-0.149006 </td><td style=\"text-align: right;\">-0.594837 </td><td style=\"text-align: right;\"> 0.165374 </td><td style=\"text-align: right;\"> 0.351211 </td><td style=\"text-align: right;\">-0.462701 </td><td style=\"text-align: right;\">-1.30318  </td><td style=\"text-align: right;\"> 0.00425985</td><td style=\"text-align: right;\">-1.19819  </td><td style=\"text-align: right;\"> 0.371879 </td><td style=\"text-align: right;\"> 0.325116 </td><td style=\"text-align: right;\">-0.123847 </td><td style=\"text-align: right;\"> 0.937828 </td><td style=\"text-align: right;\"> 0.263567 </td><td style=\"text-align: right;\"> 0.0863833</td><td style=\"text-align: right;\"> 0.268786 </td><td style=\"text-align: right;\"> 0.402629 </td><td style=\"text-align: right;\">-0.26627    </td><td style=\"text-align: right;\"> 0.384837 </td><td style=\"text-align: right;\"> 0.60637  </td><td style=\"text-align: right;\">-0.152096 </td><td style=\"text-align: right;\">-0.0725101</td><td style=\"text-align: right;\"> 0.792331</td><td style=\"text-align: right;\">-0.0321351</td><td style=\"text-align: right;\">-0.481089 </td><td style=\"text-align: right;\">-0.42079  </td><td style=\"text-align: right;\">-0.0660262</td><td style=\"text-align: right;\">-0.148211 </td><td style=\"text-align: right;\"> 0.378529 </td><td style=\"text-align: right;\"> 0.02314  </td><td style=\"text-align: right;\">-0.0201441</td><td style=\"text-align: right;\"> 0.487322  </td><td style=\"text-align: right;\">-0.194526 </td><td style=\"text-align: right;\">-0.0200701</td><td style=\"text-align: right;\">-0.29859  </td><td style=\"text-align: right;\"> 0.0686552</td><td style=\"text-align: right;\">-0.199198 </td><td style=\"text-align: right;\">-0.241327</td><td style=\"text-align: right;\">-0.263722</td><td style=\"text-align: right;\"> 0.519523  </td><td style=\"text-align: right;\">-0.0661203</td><td style=\"text-align: right;\">-0.386223 </td><td style=\"text-align: right;\"> 0.337415 </td><td style=\"text-align: right;\">-0.0933436</td><td style=\"text-align: right;\">-0.738899 </td><td style=\"text-align: right;\"> 0.41998  </td><td style=\"text-align: right;\">-0.180534  </td><td style=\"text-align: right;\"> 0.162631  </td><td style=\"text-align: right;\"> 0.0589995</td><td style=\"text-align: right;\">-0.343279 </td><td style=\"text-align: right;\">-0.141084 </td><td style=\"text-align: right;\">-0.00846396</td><td style=\"text-align: right;\">-0.494676 </td><td style=\"text-align: right;\"> 0.062485  </td><td style=\"text-align: right;\"> 0.143639</td><td style=\"text-align: right;\">-0.154256 </td><td style=\"text-align: right;\"> 0.100058 </td><td style=\"text-align: right;\"> 0.0459747</td><td style=\"text-align: right;\">-0.10124   </td><td style=\"text-align: right;\"> 0.0749152</td><td style=\"text-align: right;\"> 0.0433454 </td><td style=\"text-align: right;\"> 0.407651</td><td style=\"text-align: right;\">-0.00085629</td><td style=\"text-align: right;\"> 0.272083 </td><td style=\"text-align: right;\">-0.36515  </td><td style=\"text-align: right;\"> 0.186306 </td><td style=\"text-align: right;\">-0.106947 </td><td style=\"text-align: right;\">-0.179909  </td><td style=\"text-align: right;\">-0.154551 </td><td style=\"text-align: right;\">-0.239001 </td><td style=\"text-align: right;\"> 0.390033 </td><td style=\"text-align: right;\"> 0.103301 </td><td style=\"text-align: right;\">-0.179483 </td><td style=\"text-align: right;\"> 0.22951   </td><td style=\"text-align: right;\">-0.0668002 </td><td style=\"text-align: right;\">-0.0825495</td><td style=\"text-align: right;\"> 0.0340617 </td><td style=\"text-align: right;\"> 0.203809 </td><td style=\"text-align: right;\">-0.275612 </td><td style=\"text-align: right;\"> 0.310813 </td><td style=\"text-align: right;\">-0.0216203</td><td style=\"text-align: right;\"> 0.0308512 </td><td style=\"text-align: right;\"> 0.295299 </td><td style=\"text-align: right;\"> 0.0617808  </td><td style=\"text-align: right;\"> 0.233424  </td><td style=\"text-align: right;\">-0.602807 </td><td style=\"text-align: right;\">-0.264453 </td><td style=\"text-align: right;\">-0.0983916</td><td style=\"text-align: right;\">-0.367157 </td><td style=\"text-align: right;\"> 0.33488  </td><td style=\"text-align: right;\">-0.248688 </td><td style=\"text-align: right;\">-0.0103886</td><td style=\"text-align: right;\"> 0.0212966</td><td style=\"text-align: right;\">-0.139436 </td><td style=\"text-align: right;\"> 0.126407  </td><td style=\"text-align: right;\"> 0.163799  </td><td style=\"text-align: right;\">-0.0999936 </td><td style=\"text-align: right;\"> 0.159078 </td><td style=\"text-align: right;\"> 0.326816 </td><td style=\"text-align: right;\">-0.422006 </td><td style=\"text-align: right;\"> 0.328108 </td><td style=\"text-align: right;\">-0.12589  </td><td style=\"text-align: right;\">-0.224009</td><td style=\"text-align: right;\"> 0.165427 </td><td style=\"text-align: right;\"> 0.00736128</td><td style=\"text-align: right;\"> 0.273949 </td><td style=\"text-align: right;\">-0.432772 </td><td style=\"text-align: right;\"> 0.261663  </td><td style=\"text-align: right;\">-0.032972  </td><td style=\"text-align: right;\">-0.417354 </td><td style=\"text-align: right;\">-0.222135 </td><td style=\"text-align: right;\">-0.277632 </td><td style=\"text-align: right;\">-0.151629</td><td style=\"text-align: right;\"> 0.199935  </td><td style=\"text-align: right;\">-0.109284 </td><td style=\"text-align: right;\"> 0.0932435 </td><td style=\"text-align: right;\"> 0.435215 </td><td style=\"text-align: right;\">-0.0667091  </td><td style=\"text-align: right;\">-0.0196309 </td><td style=\"text-align: right;\"> 0.346601  </td><td style=\"text-align: right;\">-0.0825501</td><td style=\"text-align: right;\"> 0.154359 </td><td style=\"text-align: right;\">-0.164206 </td><td style=\"text-align: right;\"> 0.37597  </td><td style=\"text-align: right;\">-0.136508 </td><td style=\"text-align: right;\"> 0.229612 </td><td style=\"text-align: right;\"> 0.213105  </td><td style=\"text-align: right;\"> 0.086485 </td><td style=\"text-align: right;\">-0.0631953</td><td style=\"text-align: right;\"> 0.159335   </td><td style=\"text-align: right;\">-0.214413  </td><td style=\"text-align: right;\">-0.114718 </td><td style=\"text-align: right;\"> 0.0446415</td><td style=\"text-align: right;\">-0.0986768 </td><td style=\"text-align: right;\"> 0.0589636</td><td style=\"text-align: right;\">-0.27537  </td><td style=\"text-align: right;\">-0.470475 </td><td style=\"text-align: right;\">-0.071911 </td><td style=\"text-align: right;\"> 0.185972  </td><td style=\"text-align: right;\">-0.316124 </td><td style=\"text-align: right;\"> 0.204503  </td><td style=\"text-align: right;\">-0.435719 </td><td style=\"text-align: right;\"> 0.31322  </td><td style=\"text-align: right;\"> 0.379372  </td><td style=\"text-align: right;\">-0.0453729</td><td style=\"text-align: right;\">-0.167095 </td><td style=\"text-align: right;\">-0.0395213 </td><td style=\"text-align: right;\"> 0.064882 </td><td style=\"text-align: right;\"> 0.348529 </td><td style=\"text-align: right;\"> 0.41005   </td><td style=\"text-align: right;\"> 0.0878616</td><td style=\"text-align: right;\">-0.0791032 </td><td style=\"text-align: right;\"> 0.187943  </td><td style=\"text-align: right;\"> 0.105175 </td><td style=\"text-align: right;\"> 0.19989  </td><td style=\"text-align: right;\">-0.0378579</td></tr>\n<tr><td style=\"text-align: right;\"> -4.59049</td><td style=\"text-align: right;\"> 5.31294</td><td style=\"text-align: right;\">-0.043539   </td><td style=\"text-align: right;\">-1.58611  </td><td style=\"text-align: right;\">-3.70249  </td><td style=\"text-align: right;\">-0.156249</td><td style=\"text-align: right;\"> 2.93034  </td><td style=\"text-align: right;\">-4.97455 </td><td style=\"text-align: right;\">-0.930162</td><td style=\"text-align: right;\">-0.817911</td><td style=\"text-align: right;\"> 1.69132 </td><td style=\"text-align: right;\"> 0.357042 </td><td style=\"text-align: right;\">-1.68802 </td><td style=\"text-align: right;\"> 1.82346 </td><td style=\"text-align: right;\"> 1.65873  </td><td style=\"text-align: right;\"> 0.993338</td><td style=\"text-align: right;\">-0.769028  </td><td style=\"text-align: right;\"> 0.648757 </td><td style=\"text-align: right;\"> 0.739181 </td><td style=\"text-align: right;\"> 0.40869 </td><td style=\"text-align: right;\"> 1.46154 </td><td style=\"text-align: right;\">-1.07547  </td><td style=\"text-align: right;\">-0.412326 </td><td style=\"text-align: right;\">-1.15372  </td><td style=\"text-align: right;\"> 0.033482</td><td style=\"text-align: right;\">-0.399165 </td><td style=\"text-align: right;\">-1.04086  </td><td style=\"text-align: right;\"> 0.0623232 </td><td style=\"text-align: right;\"> 0.0584557</td><td style=\"text-align: right;\"> 0.287642</td><td style=\"text-align: right;\"> 0.441088  </td><td style=\"text-align: right;\"> 1.40573 </td><td style=\"text-align: right;\"> 0.373167 </td><td style=\"text-align: right;\"> 0.595857 </td><td style=\"text-align: right;\"> 0.777845 </td><td style=\"text-align: right;\">-0.284434 </td><td style=\"text-align: right;\"> 0.893216 </td><td style=\"text-align: right;\"> 0.0325202</td><td style=\"text-align: right;\">-0.253651 </td><td style=\"text-align: right;\">-0.256632 </td><td style=\"text-align: right;\"> 0.216368  </td><td style=\"text-align: right;\">-1.11769   </td><td style=\"text-align: right;\"> 0.182434 </td><td style=\"text-align: right;\">-0.300572 </td><td style=\"text-align: right;\">-0.090939  </td><td style=\"text-align: right;\">-0.220814 </td><td style=\"text-align: right;\"> 0.592161 </td><td style=\"text-align: right;\"> 0.422401 </td><td style=\"text-align: right;\"> 0.615093 </td><td style=\"text-align: right;\">-0.910159 </td><td style=\"text-align: right;\">-0.441763 </td><td style=\"text-align: right;\"> 0.315778  </td><td style=\"text-align: right;\"> 0.165484 </td><td style=\"text-align: right;\"> 0.419825 </td><td style=\"text-align: right;\">-0.294703 </td><td style=\"text-align: right;\"> 0.0210309</td><td style=\"text-align: right;\"> 0.213716 </td><td style=\"text-align: right;\">-0.211021 </td><td style=\"text-align: right;\"> 0.879258 </td><td style=\"text-align: right;\"> 0.0419514</td><td style=\"text-align: right;\">-0.500143 </td><td style=\"text-align: right;\">-0.0916183  </td><td style=\"text-align: right;\"> 0.199057 </td><td style=\"text-align: right;\">-0.275862 </td><td style=\"text-align: right;\">-0.313245 </td><td style=\"text-align: right;\"> 0.239273 </td><td style=\"text-align: right;\"> 0.113842</td><td style=\"text-align: right;\">-0.159077 </td><td style=\"text-align: right;\"> 0.669248 </td><td style=\"text-align: right;\">-0.49075  </td><td style=\"text-align: right;\">-0.165403 </td><td style=\"text-align: right;\"> 0.175773 </td><td style=\"text-align: right;\"> 0.49225  </td><td style=\"text-align: right;\">-0.407117 </td><td style=\"text-align: right;\">-0.818282 </td><td style=\"text-align: right;\">-0.758563  </td><td style=\"text-align: right;\">-0.0963912</td><td style=\"text-align: right;\">-0.253328 </td><td style=\"text-align: right;\">-0.544874 </td><td style=\"text-align: right;\"> 0.221636 </td><td style=\"text-align: right;\"> 0.406422 </td><td style=\"text-align: right;\">-0.219667</td><td style=\"text-align: right;\"> 0.195245</td><td style=\"text-align: right;\">-0.149426  </td><td style=\"text-align: right;\">-0.317279 </td><td style=\"text-align: right;\"> 0.582046 </td><td style=\"text-align: right;\">-0.210104 </td><td style=\"text-align: right;\"> 0.849998 </td><td style=\"text-align: right;\">-0.506772 </td><td style=\"text-align: right;\"> 0.455948 </td><td style=\"text-align: right;\"> 0.468586  </td><td style=\"text-align: right;\">-0.264578  </td><td style=\"text-align: right;\">-0.197681 </td><td style=\"text-align: right;\"> 0.321523 </td><td style=\"text-align: right;\">-0.0873612</td><td style=\"text-align: right;\"> 0.234735  </td><td style=\"text-align: right;\">-0.205255 </td><td style=\"text-align: right;\">-0.356656  </td><td style=\"text-align: right;\"> 0.246365</td><td style=\"text-align: right;\">-0.374521 </td><td style=\"text-align: right;\"> 0.216978 </td><td style=\"text-align: right;\">-0.184585 </td><td style=\"text-align: right;\">-0.550619  </td><td style=\"text-align: right;\">-0.202771 </td><td style=\"text-align: right;\">-0.722441  </td><td style=\"text-align: right;\"> 0.21047 </td><td style=\"text-align: right;\">-0.227439  </td><td style=\"text-align: right;\"> 0.408528 </td><td style=\"text-align: right;\"> 0.615943 </td><td style=\"text-align: right;\"> 0.0445044</td><td style=\"text-align: right;\">-0.0414433</td><td style=\"text-align: right;\"> 0.340925  </td><td style=\"text-align: right;\"> 0.294431 </td><td style=\"text-align: right;\"> 0.648748 </td><td style=\"text-align: right;\">-0.191099 </td><td style=\"text-align: right;\"> 0.322158 </td><td style=\"text-align: right;\"> 0.419815 </td><td style=\"text-align: right;\"> 0.598406  </td><td style=\"text-align: right;\"> 0.141637  </td><td style=\"text-align: right;\">-0.274665 </td><td style=\"text-align: right;\"> 0.482582  </td><td style=\"text-align: right;\">-0.0160315</td><td style=\"text-align: right;\"> 0.0962388</td><td style=\"text-align: right;\">-0.450854 </td><td style=\"text-align: right;\">-0.0831487</td><td style=\"text-align: right;\"> 0.363272  </td><td style=\"text-align: right;\"> 0.0283987</td><td style=\"text-align: right;\">-0.304109   </td><td style=\"text-align: right;\"> 0.0881775 </td><td style=\"text-align: right;\">-0.281148 </td><td style=\"text-align: right;\">-0.347671 </td><td style=\"text-align: right;\"> 0.48956  </td><td style=\"text-align: right;\">-0.679409 </td><td style=\"text-align: right;\">-0.0465728</td><td style=\"text-align: right;\">-0.0229669</td><td style=\"text-align: right;\"> 0.305086 </td><td style=\"text-align: right;\"> 0.630215 </td><td style=\"text-align: right;\">-0.247286 </td><td style=\"text-align: right;\"> 0.0045951 </td><td style=\"text-align: right;\">-0.607346  </td><td style=\"text-align: right;\">-0.00771802</td><td style=\"text-align: right;\"> 0.229427 </td><td style=\"text-align: right;\">-0.398598 </td><td style=\"text-align: right;\">-0.666365 </td><td style=\"text-align: right;\">-0.153768 </td><td style=\"text-align: right;\">-0.323856 </td><td style=\"text-align: right;\">-0.209572</td><td style=\"text-align: right;\">-0.241635 </td><td style=\"text-align: right;\">-0.302749  </td><td style=\"text-align: right;\"> 0.194522 </td><td style=\"text-align: right;\"> 0.685216 </td><td style=\"text-align: right;\"> 0.00430719</td><td style=\"text-align: right;\"> 0.027653  </td><td style=\"text-align: right;\"> 0.318633 </td><td style=\"text-align: right;\"> 0.318989 </td><td style=\"text-align: right;\"> 0.333135 </td><td style=\"text-align: right;\"> 0.345507</td><td style=\"text-align: right;\">-0.145466  </td><td style=\"text-align: right;\"> 0.0686151</td><td style=\"text-align: right;\"> 0.115055  </td><td style=\"text-align: right;\">-0.362267 </td><td style=\"text-align: right;\">-0.616801   </td><td style=\"text-align: right;\"> 0.104639  </td><td style=\"text-align: right;\">-0.34185   </td><td style=\"text-align: right;\">-0.354017 </td><td style=\"text-align: right;\">-0.435519 </td><td style=\"text-align: right;\">-0.169556 </td><td style=\"text-align: right;\"> 0.060568 </td><td style=\"text-align: right;\"> 0.530617 </td><td style=\"text-align: right;\"> 0.252677 </td><td style=\"text-align: right;\">-0.0308713 </td><td style=\"text-align: right;\">-0.401517 </td><td style=\"text-align: right;\"> 0.370231 </td><td style=\"text-align: right;\"> 0.193731   </td><td style=\"text-align: right;\">-0.212494  </td><td style=\"text-align: right;\"> 0.212407 </td><td style=\"text-align: right;\"> 0.0962742</td><td style=\"text-align: right;\">-0.0251926 </td><td style=\"text-align: right;\"> 0.013189 </td><td style=\"text-align: right;\"> 0.237966 </td><td style=\"text-align: right;\">-0.0909133</td><td style=\"text-align: right;\">-0.31605  </td><td style=\"text-align: right;\">-0.045298  </td><td style=\"text-align: right;\"> 0.43653  </td><td style=\"text-align: right;\"> 0.0797025 </td><td style=\"text-align: right;\">-0.598752 </td><td style=\"text-align: right;\"> 0.219091 </td><td style=\"text-align: right;\">-0.246436  </td><td style=\"text-align: right;\"> 0.355176 </td><td style=\"text-align: right;\">-0.615051 </td><td style=\"text-align: right;\"> 0.214979  </td><td style=\"text-align: right;\">-0.228767 </td><td style=\"text-align: right;\"> 0.174032 </td><td style=\"text-align: right;\">-0.347543  </td><td style=\"text-align: right;\"> 0.355885 </td><td style=\"text-align: right;\">-0.970259  </td><td style=\"text-align: right;\"> 0.529508  </td><td style=\"text-align: right;\"> 0.348943 </td><td style=\"text-align: right;\">-0.0221957</td><td style=\"text-align: right;\"> 0.282418 </td></tr>\n<tr><td style=\"text-align: right;\"> -8.68246</td><td style=\"text-align: right;\">-4.77252</td><td style=\"text-align: right;\"> 0.00352481 </td><td style=\"text-align: right;\"> 0.0944094</td><td style=\"text-align: right;\"> 0.517031 </td><td style=\"text-align: right;\">-3.71639 </td><td style=\"text-align: right;\"> 0.988545 </td><td style=\"text-align: right;\"> 0.65286 </td><td style=\"text-align: right;\">-0.217747</td><td style=\"text-align: right;\"> 0.573477</td><td style=\"text-align: right;\"> 0.52632 </td><td style=\"text-align: right;\">-0.683847 </td><td style=\"text-align: right;\">-0.328461</td><td style=\"text-align: right;\">-0.396951</td><td style=\"text-align: right;\">-0.832451 </td><td style=\"text-align: right;\"> 0.354952</td><td style=\"text-align: right;\">-2.34578   </td><td style=\"text-align: right;\"> 1.25273  </td><td style=\"text-align: right;\">-0.0812596</td><td style=\"text-align: right;\">-0.894451</td><td style=\"text-align: right;\"> 1.79601 </td><td style=\"text-align: right;\">-0.755556 </td><td style=\"text-align: right;\">-1.18765  </td><td style=\"text-align: right;\">-0.329411 </td><td style=\"text-align: right;\"> 0.130982</td><td style=\"text-align: right;\"> 0.0222099</td><td style=\"text-align: right;\">-0.690187 </td><td style=\"text-align: right;\"> 0.0358821 </td><td style=\"text-align: right;\"> 0.24405  </td><td style=\"text-align: right;\">-0.157876</td><td style=\"text-align: right;\"> 0.157296  </td><td style=\"text-align: right;\">-0.45587 </td><td style=\"text-align: right;\">-0.32256  </td><td style=\"text-align: right;\"> 0.496656 </td><td style=\"text-align: right;\">-0.321544 </td><td style=\"text-align: right;\">-0.447171 </td><td style=\"text-align: right;\"> 0.0159054</td><td style=\"text-align: right;\">-0.071811 </td><td style=\"text-align: right;\">-0.527262 </td><td style=\"text-align: right;\"> 0.294327 </td><td style=\"text-align: right;\"> 0.0221319 </td><td style=\"text-align: right;\">-0.44001   </td><td style=\"text-align: right;\">-0.17165  </td><td style=\"text-align: right;\">-0.0971737</td><td style=\"text-align: right;\"> 0.0824659 </td><td style=\"text-align: right;\">-0.32426  </td><td style=\"text-align: right;\"> 0.175003 </td><td style=\"text-align: right;\">-0.121623 </td><td style=\"text-align: right;\">-0.332931 </td><td style=\"text-align: right;\">-0.109857 </td><td style=\"text-align: right;\"> 0.113921 </td><td style=\"text-align: right;\"> 0.185016  </td><td style=\"text-align: right;\">-0.172949 </td><td style=\"text-align: right;\">-0.146797 </td><td style=\"text-align: right;\"> 0.0518847</td><td style=\"text-align: right;\">-0.241559 </td><td style=\"text-align: right;\">-0.0679523</td><td style=\"text-align: right;\"> 0.0335394</td><td style=\"text-align: right;\">-0.397274 </td><td style=\"text-align: right;\">-0.122382 </td><td style=\"text-align: right;\">-1.07938  </td><td style=\"text-align: right;\"> 0.804987   </td><td style=\"text-align: right;\">-0.784403 </td><td style=\"text-align: right;\"> 0.049347 </td><td style=\"text-align: right;\"> 0.0892695</td><td style=\"text-align: right;\">-0.234216 </td><td style=\"text-align: right;\">-0.393779</td><td style=\"text-align: right;\"> 0.12618  </td><td style=\"text-align: right;\"> 0.110403 </td><td style=\"text-align: right;\">-0.293747 </td><td style=\"text-align: right;\">-0.196784 </td><td style=\"text-align: right;\">-0.247168 </td><td style=\"text-align: right;\"> 0.097565 </td><td style=\"text-align: right;\"> 0.275938 </td><td style=\"text-align: right;\">-0.0729131</td><td style=\"text-align: right;\"> 0.12785   </td><td style=\"text-align: right;\"> 0.167029 </td><td style=\"text-align: right;\">-0.0804026</td><td style=\"text-align: right;\"> 0.13433  </td><td style=\"text-align: right;\">-0.384247 </td><td style=\"text-align: right;\"> 0.0972462</td><td style=\"text-align: right;\">-0.068248</td><td style=\"text-align: right;\">-0.183705</td><td style=\"text-align: right;\"> 0.00138043</td><td style=\"text-align: right;\"> 0.345901 </td><td style=\"text-align: right;\"> 0.314085 </td><td style=\"text-align: right;\"> 0.432695 </td><td style=\"text-align: right;\"> 0.0817047</td><td style=\"text-align: right;\">-0.247884 </td><td style=\"text-align: right;\">-0.405813 </td><td style=\"text-align: right;\"> 0.264043  </td><td style=\"text-align: right;\">-0.181348  </td><td style=\"text-align: right;\">-0.0680196</td><td style=\"text-align: right;\"> 0.263482 </td><td style=\"text-align: right;\">-0.070708 </td><td style=\"text-align: right;\"> 0.145009  </td><td style=\"text-align: right;\">-0.180823 </td><td style=\"text-align: right;\"> 0.155849  </td><td style=\"text-align: right;\">-0.31145 </td><td style=\"text-align: right;\">-0.0989632</td><td style=\"text-align: right;\">-0.0866583</td><td style=\"text-align: right;\"> 0.464757 </td><td style=\"text-align: right;\"> 0.0708443 </td><td style=\"text-align: right;\"> 0.177191 </td><td style=\"text-align: right;\"> 0.00976185</td><td style=\"text-align: right;\"> 0.113518</td><td style=\"text-align: right;\">-0.0383682 </td><td style=\"text-align: right;\"> 0.0381381</td><td style=\"text-align: right;\"> 0.0265574</td><td style=\"text-align: right;\">-0.12861  </td><td style=\"text-align: right;\"> 0.16697  </td><td style=\"text-align: right;\">-0.331246  </td><td style=\"text-align: right;\"> 0.162963 </td><td style=\"text-align: right;\"> 0.3131   </td><td style=\"text-align: right;\"> 0.0116855</td><td style=\"text-align: right;\">-0.170562 </td><td style=\"text-align: right;\"> 0.0675353</td><td style=\"text-align: right;\">-0.135805  </td><td style=\"text-align: right;\"> 0.1076    </td><td style=\"text-align: right;\">-0.367674 </td><td style=\"text-align: right;\">-0.00944606</td><td style=\"text-align: right;\"> 0.664511 </td><td style=\"text-align: right;\">-0.0524581</td><td style=\"text-align: right;\"> 0.149948 </td><td style=\"text-align: right;\">-0.37418  </td><td style=\"text-align: right;\">-0.173271  </td><td style=\"text-align: right;\"> 0.374806 </td><td style=\"text-align: right;\"> 0.322866   </td><td style=\"text-align: right;\"> 0.0653631 </td><td style=\"text-align: right;\"> 0.117941 </td><td style=\"text-align: right;\"> 0.0171137</td><td style=\"text-align: right;\">-0.196438 </td><td style=\"text-align: right;\"> 0.183118 </td><td style=\"text-align: right;\">-0.184732 </td><td style=\"text-align: right;\">-0.196132 </td><td style=\"text-align: right;\"> 0.0925266</td><td style=\"text-align: right;\">-0.0897482</td><td style=\"text-align: right;\"> 0.0666219</td><td style=\"text-align: right;\">-0.00172925</td><td style=\"text-align: right;\"> 0.00750581</td><td style=\"text-align: right;\"> 0.0064723 </td><td style=\"text-align: right;\"> 0.157167 </td><td style=\"text-align: right;\">-0.30515  </td><td style=\"text-align: right;\"> 0.0055818</td><td style=\"text-align: right;\">-0.0963982</td><td style=\"text-align: right;\"> 0.110583 </td><td style=\"text-align: right;\">-0.139017</td><td style=\"text-align: right;\">-0.0481604</td><td style=\"text-align: right;\">-0.232714  </td><td style=\"text-align: right;\">-0.160162 </td><td style=\"text-align: right;\"> 0.173199 </td><td style=\"text-align: right;\">-0.0826625 </td><td style=\"text-align: right;\">-0.241485  </td><td style=\"text-align: right;\">-0.0495134</td><td style=\"text-align: right;\"> 0.151465 </td><td style=\"text-align: right;\"> 0.0346363</td><td style=\"text-align: right;\">-0.148535</td><td style=\"text-align: right;\">-0.144367  </td><td style=\"text-align: right;\"> 0.0784351</td><td style=\"text-align: right;\"> 0.09193   </td><td style=\"text-align: right;\"> 0.0801042</td><td style=\"text-align: right;\"> 0.103298   </td><td style=\"text-align: right;\">-0.0168575 </td><td style=\"text-align: right;\">-0.121607  </td><td style=\"text-align: right;\"> 0.137488 </td><td style=\"text-align: right;\">-0.080562 </td><td style=\"text-align: right;\">-0.0122179</td><td style=\"text-align: right;\"> 0.278007 </td><td style=\"text-align: right;\"> 0.300971 </td><td style=\"text-align: right;\"> 0.0471241</td><td style=\"text-align: right;\">-0.0783548 </td><td style=\"text-align: right;\"> 0.0483359</td><td style=\"text-align: right;\"> 0.26833  </td><td style=\"text-align: right;\">-0.148815   </td><td style=\"text-align: right;\"> 0.0062242 </td><td style=\"text-align: right;\"> 0.41095  </td><td style=\"text-align: right;\"> 0.1374   </td><td style=\"text-align: right;\">-0.0122015 </td><td style=\"text-align: right;\">-0.0344289</td><td style=\"text-align: right;\">-0.261423 </td><td style=\"text-align: right;\">-0.131396 </td><td style=\"text-align: right;\">-0.211338 </td><td style=\"text-align: right;\"> 0.00387303</td><td style=\"text-align: right;\"> 0.082486 </td><td style=\"text-align: right;\">-0.130322  </td><td style=\"text-align: right;\">-0.137823 </td><td style=\"text-align: right;\"> 0.0903963</td><td style=\"text-align: right;\"> 0.00290438</td><td style=\"text-align: right;\"> 0.0638734</td><td style=\"text-align: right;\"> 0.117863 </td><td style=\"text-align: right;\"> 0.00904495</td><td style=\"text-align: right;\">-0.0510632</td><td style=\"text-align: right;\">-0.0925759</td><td style=\"text-align: right;\">-0.00737436</td><td style=\"text-align: right;\">-0.108323 </td><td style=\"text-align: right;\">-0.00531824</td><td style=\"text-align: right;\"> 0.00543457</td><td style=\"text-align: right;\"> 0.276971 </td><td style=\"text-align: right;\"> 0.245328 </td><td style=\"text-align: right;\"> 0.10757  </td></tr>\n<tr><td style=\"text-align: right;\"> -9.19672</td><td style=\"text-align: right;\"> 7.94682</td><td style=\"text-align: right;\">-0.0615294  </td><td style=\"text-align: right;\">-1.82745  </td><td style=\"text-align: right;\">-4.61263  </td><td style=\"text-align: right;\">-2.20144 </td><td style=\"text-align: right;\">-6.78272  </td><td style=\"text-align: right;\"> 0.342489</td><td style=\"text-align: right;\"> 0.726244</td><td style=\"text-align: right;\">-2.52807 </td><td style=\"text-align: right;\"> 2.35922 </td><td style=\"text-align: right;\">-0.920174 </td><td style=\"text-align: right;\"> 1.58982 </td><td style=\"text-align: right;\"> 1.77681 </td><td style=\"text-align: right;\">-1.02456  </td><td style=\"text-align: right;\">-0.135104</td><td style=\"text-align: right;\">-1.06266   </td><td style=\"text-align: right;\">-1.23535  </td><td style=\"text-align: right;\">-1.06946  </td><td style=\"text-align: right;\"> 0.256949</td><td style=\"text-align: right;\">-0.135148</td><td style=\"text-align: right;\"> 0.0709823</td><td style=\"text-align: right;\"> 0.120553 </td><td style=\"text-align: right;\">-0.212403 </td><td style=\"text-align: right;\"> 0.314243</td><td style=\"text-align: right;\">-0.718003 </td><td style=\"text-align: right;\">-0.0869338</td><td style=\"text-align: right;\"> 0.124004  </td><td style=\"text-align: right;\">-2.44493  </td><td style=\"text-align: right;\"> 0.276341</td><td style=\"text-align: right;\"> 0.149156  </td><td style=\"text-align: right;\">-0.887986</td><td style=\"text-align: right;\"> 0.74151  </td><td style=\"text-align: right;\">-0.488781 </td><td style=\"text-align: right;\">-0.0879999</td><td style=\"text-align: right;\">-0.646071 </td><td style=\"text-align: right;\"> 0.247737 </td><td style=\"text-align: right;\"> 2.36842  </td><td style=\"text-align: right;\">-0.191677 </td><td style=\"text-align: right;\">-0.843649 </td><td style=\"text-align: right;\"> 0.932515  </td><td style=\"text-align: right;\">-0.412667  </td><td style=\"text-align: right;\">-1.76671  </td><td style=\"text-align: right;\"> 1.40751  </td><td style=\"text-align: right;\"> 0.31721   </td><td style=\"text-align: right;\"> 0.412233 </td><td style=\"text-align: right;\"> 0.636046 </td><td style=\"text-align: right;\"> 0.482982 </td><td style=\"text-align: right;\">-1.7244   </td><td style=\"text-align: right;\">-1.14457  </td><td style=\"text-align: right;\">-1.8538   </td><td style=\"text-align: right;\">-0.382721  </td><td style=\"text-align: right;\">-0.100829 </td><td style=\"text-align: right;\"> 1.13878  </td><td style=\"text-align: right;\">-0.671918 </td><td style=\"text-align: right;\">-1.06497  </td><td style=\"text-align: right;\">-1.17288  </td><td style=\"text-align: right;\">-0.097851 </td><td style=\"text-align: right;\">-0.69384  </td><td style=\"text-align: right;\"> 1.24439  </td><td style=\"text-align: right;\">-0.048193 </td><td style=\"text-align: right;\">-0.645799   </td><td style=\"text-align: right;\">-0.132279 </td><td style=\"text-align: right;\">-2.03033  </td><td style=\"text-align: right;\"> 2.31706  </td><td style=\"text-align: right;\"> 0.017334 </td><td style=\"text-align: right;\"> 0.431449</td><td style=\"text-align: right;\">-1.51772  </td><td style=\"text-align: right;\"> 0.162575 </td><td style=\"text-align: right;\"> 0.758915 </td><td style=\"text-align: right;\">-0.138466 </td><td style=\"text-align: right;\"> 0.136531 </td><td style=\"text-align: right;\">-0.49254  </td><td style=\"text-align: right;\">-0.298467 </td><td style=\"text-align: right;\">-1.42526  </td><td style=\"text-align: right;\">-0.740595  </td><td style=\"text-align: right;\">-1.18069  </td><td style=\"text-align: right;\"> 0.513582 </td><td style=\"text-align: right;\">-0.586936 </td><td style=\"text-align: right;\">-0.203759 </td><td style=\"text-align: right;\"> 0.627928 </td><td style=\"text-align: right;\"> 1.36234 </td><td style=\"text-align: right;\">-0.866153</td><td style=\"text-align: right;\">-1.29616   </td><td style=\"text-align: right;\"> 0.535693 </td><td style=\"text-align: right;\"> 0.415754 </td><td style=\"text-align: right;\"> 0.570849 </td><td style=\"text-align: right;\">-1.48843  </td><td style=\"text-align: right;\"> 0.270096 </td><td style=\"text-align: right;\"> 0.543689 </td><td style=\"text-align: right;\">-0.908162  </td><td style=\"text-align: right;\">-0.105914  </td><td style=\"text-align: right;\"> 0.339703 </td><td style=\"text-align: right;\"> 0.496366 </td><td style=\"text-align: right;\"> 0.925362 </td><td style=\"text-align: right;\">-0.933789  </td><td style=\"text-align: right;\">-1.00079  </td><td style=\"text-align: right;\"> 0.00877185</td><td style=\"text-align: right;\"> 0.322465</td><td style=\"text-align: right;\"> 0.91807  </td><td style=\"text-align: right;\">-1.99269  </td><td style=\"text-align: right;\"> 0.165965 </td><td style=\"text-align: right;\"> 0.353154  </td><td style=\"text-align: right;\"> 0.306088 </td><td style=\"text-align: right;\"> 0.326838  </td><td style=\"text-align: right;\">-0.952772</td><td style=\"text-align: right;\">-0.146353  </td><td style=\"text-align: right;\"> 0.434984 </td><td style=\"text-align: right;\">-0.340664 </td><td style=\"text-align: right;\"> 2.29767  </td><td style=\"text-align: right;\"> 0.0678048</td><td style=\"text-align: right;\"> 0.420068  </td><td style=\"text-align: right;\">-1.27611  </td><td style=\"text-align: right;\"> 0.259335 </td><td style=\"text-align: right;\"> 0.302944 </td><td style=\"text-align: right;\"> 0.911172 </td><td style=\"text-align: right;\">-0.762877 </td><td style=\"text-align: right;\"> 0.00954014</td><td style=\"text-align: right;\"> 1.78079   </td><td style=\"text-align: right;\">-0.326688 </td><td style=\"text-align: right;\">-0.603852  </td><td style=\"text-align: right;\"> 1.44774  </td><td style=\"text-align: right;\"> 0.267919 </td><td style=\"text-align: right;\">-0.226292 </td><td style=\"text-align: right;\"> 1.30767  </td><td style=\"text-align: right;\"> 0.233281  </td><td style=\"text-align: right;\"> 0.24383  </td><td style=\"text-align: right;\"> 0.0630102  </td><td style=\"text-align: right;\"> 0.122896  </td><td style=\"text-align: right;\"> 1.05555  </td><td style=\"text-align: right;\"> 0.280146 </td><td style=\"text-align: right;\">-0.134538 </td><td style=\"text-align: right;\">-0.731806 </td><td style=\"text-align: right;\">-0.285732 </td><td style=\"text-align: right;\">-1.32877  </td><td style=\"text-align: right;\">-0.335229 </td><td style=\"text-align: right;\">-0.519341 </td><td style=\"text-align: right;\">-0.643283 </td><td style=\"text-align: right;\"> 0.897955  </td><td style=\"text-align: right;\"> 0.672274  </td><td style=\"text-align: right;\"> 0.294411  </td><td style=\"text-align: right;\"> 0.143189 </td><td style=\"text-align: right;\">-0.0573502</td><td style=\"text-align: right;\"> 0.451826 </td><td style=\"text-align: right;\"> 0.42029  </td><td style=\"text-align: right;\">-0.324798 </td><td style=\"text-align: right;\">-1.14813 </td><td style=\"text-align: right;\"> 1.55177  </td><td style=\"text-align: right;\"> 0.302485  </td><td style=\"text-align: right;\"> 0.0641582</td><td style=\"text-align: right;\">-0.128799 </td><td style=\"text-align: right;\">-1.17716   </td><td style=\"text-align: right;\">-0.648077  </td><td style=\"text-align: right;\">-0.761746 </td><td style=\"text-align: right;\"> 0.782809 </td><td style=\"text-align: right;\">-1.34186  </td><td style=\"text-align: right;\">-0.948957</td><td style=\"text-align: right;\"> 0.617957  </td><td style=\"text-align: right;\"> 0.691935 </td><td style=\"text-align: right;\">-0.00794323</td><td style=\"text-align: right;\">-0.36627  </td><td style=\"text-align: right;\"> 0.5934     </td><td style=\"text-align: right;\"> 0.669587  </td><td style=\"text-align: right;\"> 0.0575043 </td><td style=\"text-align: right;\">-0.668937 </td><td style=\"text-align: right;\">-0.208462 </td><td style=\"text-align: right;\">-0.475375 </td><td style=\"text-align: right;\">-0.114637 </td><td style=\"text-align: right;\">-0.712252 </td><td style=\"text-align: right;\"> 0.706196 </td><td style=\"text-align: right;\"> 0.393449  </td><td style=\"text-align: right;\">-0.0882379</td><td style=\"text-align: right;\">-0.215291 </td><td style=\"text-align: right;\"> 0.000254881</td><td style=\"text-align: right;\">-1.08491   </td><td style=\"text-align: right;\"> 0.26807  </td><td style=\"text-align: right;\">-1.35235  </td><td style=\"text-align: right;\"> 0.83783   </td><td style=\"text-align: right;\"> 0.559586 </td><td style=\"text-align: right;\">-0.905636 </td><td style=\"text-align: right;\"> 0.771805 </td><td style=\"text-align: right;\">-0.450792 </td><td style=\"text-align: right;\">-0.428496  </td><td style=\"text-align: right;\"> 0.0861287</td><td style=\"text-align: right;\"> 0.379909  </td><td style=\"text-align: right;\">-0.448908 </td><td style=\"text-align: right;\">-0.729855 </td><td style=\"text-align: right;\">-1.16339   </td><td style=\"text-align: right;\"> 0.153952 </td><td style=\"text-align: right;\"> 0.492471 </td><td style=\"text-align: right;\"> 0.122041  </td><td style=\"text-align: right;\"> 0.834458 </td><td style=\"text-align: right;\"> 0.341664 </td><td style=\"text-align: right;\">-0.329075  </td><td style=\"text-align: right;\">-1.22     </td><td style=\"text-align: right;\"> 0.723765  </td><td style=\"text-align: right;\">-0.649107  </td><td style=\"text-align: right;\">-0.778855 </td><td style=\"text-align: right;\"> 2.10345  </td><td style=\"text-align: right;\">-0.932384 </td></tr>\n<tr><td style=\"text-align: right;\"> -8.97007</td><td style=\"text-align: right;\">-5.43213</td><td style=\"text-align: right;\"> 0.00272524 </td><td style=\"text-align: right;\"> 0.28841  </td><td style=\"text-align: right;\"> 0.0794467</td><td style=\"text-align: right;\">-3.89085 </td><td style=\"text-align: right;\"> 0.632721 </td><td style=\"text-align: right;\"> 0.5904  </td><td style=\"text-align: right;\">-0.127595</td><td style=\"text-align: right;\"> 0.102558</td><td style=\"text-align: right;\"> 0.71127 </td><td style=\"text-align: right;\">-0.632055 </td><td style=\"text-align: right;\">-0.726413</td><td style=\"text-align: right;\">-0.124563</td><td style=\"text-align: right;\">-0.851183 </td><td style=\"text-align: right;\">-0.054087</td><td style=\"text-align: right;\">-1.16743   </td><td style=\"text-align: right;\"> 0.376756 </td><td style=\"text-align: right;\">-0.485514 </td><td style=\"text-align: right;\"> 1.74656 </td><td style=\"text-align: right;\"> 1.82665 </td><td style=\"text-align: right;\">-0.158678 </td><td style=\"text-align: right;\">-0.241553 </td><td style=\"text-align: right;\">-0.364044 </td><td style=\"text-align: right;\">-0.217666</td><td style=\"text-align: right;\"> 0.325344 </td><td style=\"text-align: right;\">-0.32731  </td><td style=\"text-align: right;\">-0.00430132</td><td style=\"text-align: right;\"> 0.631429 </td><td style=\"text-align: right;\"> 0.602307</td><td style=\"text-align: right;\"> 0.00693307</td><td style=\"text-align: right;\">-0.100303</td><td style=\"text-align: right;\">-0.522723 </td><td style=\"text-align: right;\"> 0.60247  </td><td style=\"text-align: right;\"> 0.181705 </td><td style=\"text-align: right;\">-0.255738 </td><td style=\"text-align: right;\"> 0.049287 </td><td style=\"text-align: right;\">-0.0754982</td><td style=\"text-align: right;\">-0.0537969</td><td style=\"text-align: right;\"> 0.434123 </td><td style=\"text-align: right;\"> 0.0349033 </td><td style=\"text-align: right;\"> 0.0485308 </td><td style=\"text-align: right;\">-0.263522 </td><td style=\"text-align: right;\">-0.0376923</td><td style=\"text-align: right;\"> 0.143516  </td><td style=\"text-align: right;\">-0.22031  </td><td style=\"text-align: right;\"> 0.29255  </td><td style=\"text-align: right;\"> 0.0904726</td><td style=\"text-align: right;\">-0.0917416</td><td style=\"text-align: right;\">-0.0518825</td><td style=\"text-align: right;\">-0.134846 </td><td style=\"text-align: right;\">-0.0404059 </td><td style=\"text-align: right;\"> 0.205374 </td><td style=\"text-align: right;\"> 0.4644   </td><td style=\"text-align: right;\"> 0.010876 </td><td style=\"text-align: right;\"> 0.265961 </td><td style=\"text-align: right;\">-0.48591  </td><td style=\"text-align: right;\">-0.116062 </td><td style=\"text-align: right;\"> 0.246857 </td><td style=\"text-align: right;\"> 0.0471285</td><td style=\"text-align: right;\">-0.153093 </td><td style=\"text-align: right;\">-0.000917792</td><td style=\"text-align: right;\"> 0.0952652</td><td style=\"text-align: right;\">-0.0410535</td><td style=\"text-align: right;\"> 0.107979 </td><td style=\"text-align: right;\"> 0.0804973</td><td style=\"text-align: right;\">-0.144514</td><td style=\"text-align: right;\"> 0.118716 </td><td style=\"text-align: right;\">-0.216696 </td><td style=\"text-align: right;\"> 0.210607 </td><td style=\"text-align: right;\"> 0.135711 </td><td style=\"text-align: right;\"> 0.125965 </td><td style=\"text-align: right;\"> 0.0628714</td><td style=\"text-align: right;\"> 0.127415 </td><td style=\"text-align: right;\"> 0.469845 </td><td style=\"text-align: right;\">-0.0667844 </td><td style=\"text-align: right;\"> 0.299821 </td><td style=\"text-align: right;\">-0.12846  </td><td style=\"text-align: right;\">-0.310889 </td><td style=\"text-align: right;\">-0.0219621</td><td style=\"text-align: right;\">-0.0634152</td><td style=\"text-align: right;\"> 0.280179</td><td style=\"text-align: right;\">-0.190406</td><td style=\"text-align: right;\"> 0.080822  </td><td style=\"text-align: right;\"> 0.505054 </td><td style=\"text-align: right;\">-0.274689 </td><td style=\"text-align: right;\"> 0.0995224</td><td style=\"text-align: right;\"> 0.129501 </td><td style=\"text-align: right;\">-0.0746645</td><td style=\"text-align: right;\">-0.280162 </td><td style=\"text-align: right;\">-0.00093445</td><td style=\"text-align: right;\"> 0.325553  </td><td style=\"text-align: right;\"> 0.298584 </td><td style=\"text-align: right;\"> 0.290192 </td><td style=\"text-align: right;\">-0.221259 </td><td style=\"text-align: right;\">-0.316362  </td><td style=\"text-align: right;\">-0.0866782</td><td style=\"text-align: right;\"> 0.50856   </td><td style=\"text-align: right;\"> 0.115006</td><td style=\"text-align: right;\"> 0.386605 </td><td style=\"text-align: right;\">-0.0275449</td><td style=\"text-align: right;\"> 0.325659 </td><td style=\"text-align: right;\"> 0.125141  </td><td style=\"text-align: right;\"> 0.1233   </td><td style=\"text-align: right;\"> 0.118446  </td><td style=\"text-align: right;\"> 0.213108</td><td style=\"text-align: right;\">-0.21447   </td><td style=\"text-align: right;\"> 0.103515 </td><td style=\"text-align: right;\">-0.162711 </td><td style=\"text-align: right;\">-0.146634 </td><td style=\"text-align: right;\"> 0.207015 </td><td style=\"text-align: right;\">-0.172975  </td><td style=\"text-align: right;\"> 0.369363 </td><td style=\"text-align: right;\">-0.117679 </td><td style=\"text-align: right;\"> 0.127677 </td><td style=\"text-align: right;\">-0.0634523</td><td style=\"text-align: right;\">-0.0536918</td><td style=\"text-align: right;\"> 0.192478  </td><td style=\"text-align: right;\"> 0.198908  </td><td style=\"text-align: right;\"> 0.342845 </td><td style=\"text-align: right;\"> 0.0431692 </td><td style=\"text-align: right;\">-0.328894 </td><td style=\"text-align: right;\"> 0.326333 </td><td style=\"text-align: right;\">-0.0311168</td><td style=\"text-align: right;\">-0.245055 </td><td style=\"text-align: right;\"> 0.268527  </td><td style=\"text-align: right;\"> 0.193657 </td><td style=\"text-align: right;\">-0.103903   </td><td style=\"text-align: right;\">-0.0323027 </td><td style=\"text-align: right;\"> 0.321355 </td><td style=\"text-align: right;\">-0.0616184</td><td style=\"text-align: right;\">-0.0753923</td><td style=\"text-align: right;\">-0.0921688</td><td style=\"text-align: right;\">-0.204716 </td><td style=\"text-align: right;\">-0.410808 </td><td style=\"text-align: right;\"> 0.132522 </td><td style=\"text-align: right;\"> 0.0881262</td><td style=\"text-align: right;\">-0.0974992</td><td style=\"text-align: right;\">-0.0268259 </td><td style=\"text-align: right;\"> 0.118561  </td><td style=\"text-align: right;\"> 0.39624   </td><td style=\"text-align: right;\">-0.422308 </td><td style=\"text-align: right;\">-0.047406 </td><td style=\"text-align: right;\"> 0.0247631</td><td style=\"text-align: right;\">-0.0875903</td><td style=\"text-align: right;\"> 0.0627485</td><td style=\"text-align: right;\">-0.287498</td><td style=\"text-align: right;\">-0.0175366</td><td style=\"text-align: right;\">-0.152858  </td><td style=\"text-align: right;\">-0.0592951</td><td style=\"text-align: right;\"> 0.206058 </td><td style=\"text-align: right;\"> 0.0673219 </td><td style=\"text-align: right;\"> 0.0939456 </td><td style=\"text-align: right;\"> 0.0170619</td><td style=\"text-align: right;\">-0.254741 </td><td style=\"text-align: right;\">-0.0368757</td><td style=\"text-align: right;\"> 0.161321</td><td style=\"text-align: right;\">-0.00412753</td><td style=\"text-align: right;\">-0.240887 </td><td style=\"text-align: right;\"> 0.0474343 </td><td style=\"text-align: right;\"> 0.199414 </td><td style=\"text-align: right;\">-0.133641   </td><td style=\"text-align: right;\"> 0.165681  </td><td style=\"text-align: right;\"> 0.0410559 </td><td style=\"text-align: right;\">-0.242758 </td><td style=\"text-align: right;\"> 0.0618847</td><td style=\"text-align: right;\"> 0.129121 </td><td style=\"text-align: right;\">-0.0017245</td><td style=\"text-align: right;\">-0.135786 </td><td style=\"text-align: right;\">-0.104665 </td><td style=\"text-align: right;\">-0.0768873 </td><td style=\"text-align: right;\"> 0.155628 </td><td style=\"text-align: right;\">-0.226643 </td><td style=\"text-align: right;\">-0.311717   </td><td style=\"text-align: right;\">-0.00275112</td><td style=\"text-align: right;\">-0.265139 </td><td style=\"text-align: right;\">-0.243158 </td><td style=\"text-align: right;\"> 0.0752308 </td><td style=\"text-align: right;\">-0.0870046</td><td style=\"text-align: right;\">-0.183222 </td><td style=\"text-align: right;\">-0.145014 </td><td style=\"text-align: right;\"> 0.0244057</td><td style=\"text-align: right;\"> 0.0655492 </td><td style=\"text-align: right;\">-0.153869 </td><td style=\"text-align: right;\">-0.140731  </td><td style=\"text-align: right;\">-0.0511595</td><td style=\"text-align: right;\"> 0.305929 </td><td style=\"text-align: right;\"> 0.215741  </td><td style=\"text-align: right;\"> 0.0643249</td><td style=\"text-align: right;\">-0.111242 </td><td style=\"text-align: right;\"> 0.0574274 </td><td style=\"text-align: right;\"> 0.0537022</td><td style=\"text-align: right;\">-0.31474  </td><td style=\"text-align: right;\">-0.21632   </td><td style=\"text-align: right;\"> 0.0157848</td><td style=\"text-align: right;\"> 0.109514  </td><td style=\"text-align: right;\"> 0.0300488 </td><td style=\"text-align: right;\">-0.104866 </td><td style=\"text-align: right;\">-0.133928 </td><td style=\"text-align: right;\"> 0.277623 </td></tr>\n<tr><td style=\"text-align: right;\"> -6.99841</td><td style=\"text-align: right;\">-2.98309</td><td style=\"text-align: right;\">-0.00022671 </td><td style=\"text-align: right;\">-1.11203  </td><td style=\"text-align: right;\">-1.20356  </td><td style=\"text-align: right;\"> 2.99938 </td><td style=\"text-align: right;\"> 0.792167 </td><td style=\"text-align: right;\"> 1.05258 </td><td style=\"text-align: right;\"> 0.65212 </td><td style=\"text-align: right;\">-0.31234 </td><td style=\"text-align: right;\">-0.192416</td><td style=\"text-align: right;\"> 0.710371 </td><td style=\"text-align: right;\"> 1.59316 </td><td style=\"text-align: right;\"> 0.206608</td><td style=\"text-align: right;\">-0.346359 </td><td style=\"text-align: right;\"> 0.485749</td><td style=\"text-align: right;\"> 0.635867  </td><td style=\"text-align: right;\">-0.896472 </td><td style=\"text-align: right;\"> 0.680551 </td><td style=\"text-align: right;\">-2.08688 </td><td style=\"text-align: right;\"> 0.475259</td><td style=\"text-align: right;\">-1.7706   </td><td style=\"text-align: right;\">-0.62088  </td><td style=\"text-align: right;\"> 0.612203 </td><td style=\"text-align: right;\">-0.14104 </td><td style=\"text-align: right;\">-0.699463 </td><td style=\"text-align: right;\"> 0.650789 </td><td style=\"text-align: right;\">-0.0262048 </td><td style=\"text-align: right;\">-0.877455 </td><td style=\"text-align: right;\">-1.0542  </td><td style=\"text-align: right;\"> 0.856707  </td><td style=\"text-align: right;\"> 0.541396</td><td style=\"text-align: right;\"> 0.349956 </td><td style=\"text-align: right;\"> 0.331304 </td><td style=\"text-align: right;\">-0.213139 </td><td style=\"text-align: right;\"> 0.774679 </td><td style=\"text-align: right;\">-0.139329 </td><td style=\"text-align: right;\">-0.975618 </td><td style=\"text-align: right;\"> 0.463806 </td><td style=\"text-align: right;\"> 0.715431 </td><td style=\"text-align: right;\">-0.113045  </td><td style=\"text-align: right;\"> 0.272788  </td><td style=\"text-align: right;\"> 0.319152 </td><td style=\"text-align: right;\">-0.40954  </td><td style=\"text-align: right;\"> 0.27471   </td><td style=\"text-align: right;\"> 0.268401 </td><td style=\"text-align: right;\">-0.259543 </td><td style=\"text-align: right;\"> 0.272648 </td><td style=\"text-align: right;\">-0.40678  </td><td style=\"text-align: right;\"> 0.375968 </td><td style=\"text-align: right;\">-0.188106 </td><td style=\"text-align: right;\">-0.108689  </td><td style=\"text-align: right;\">-0.192379 </td><td style=\"text-align: right;\"> 0.104581 </td><td style=\"text-align: right;\"> 0.262699 </td><td style=\"text-align: right;\">-0.559073 </td><td style=\"text-align: right;\"> 0.27288  </td><td style=\"text-align: right;\"> 0.414692 </td><td style=\"text-align: right;\"> 0.290314 </td><td style=\"text-align: right;\">-0.357249 </td><td style=\"text-align: right;\"> 0.0937383</td><td style=\"text-align: right;\">-0.141974   </td><td style=\"text-align: right;\"> 0.278577 </td><td style=\"text-align: right;\"> 0.301905 </td><td style=\"text-align: right;\">-0.266512 </td><td style=\"text-align: right;\"> 0.455196 </td><td style=\"text-align: right;\"> 0.227363</td><td style=\"text-align: right;\"> 0.135629 </td><td style=\"text-align: right;\"> 0.354646 </td><td style=\"text-align: right;\"> 0.354206 </td><td style=\"text-align: right;\">-0.110135 </td><td style=\"text-align: right;\"> 0.046093 </td><td style=\"text-align: right;\">-0.536456 </td><td style=\"text-align: right;\"> 0.411382 </td><td style=\"text-align: right;\">-0.566792 </td><td style=\"text-align: right;\"> 0.125481  </td><td style=\"text-align: right;\"> 0.255462 </td><td style=\"text-align: right;\"> 0.0793334</td><td style=\"text-align: right;\">-0.157157 </td><td style=\"text-align: right;\"> 0.179331 </td><td style=\"text-align: right;\">-0.243474 </td><td style=\"text-align: right;\"> 0.172762</td><td style=\"text-align: right;\">-0.341583</td><td style=\"text-align: right;\"> 0.134515  </td><td style=\"text-align: right;\"> 0.140128 </td><td style=\"text-align: right;\">-0.0330968</td><td style=\"text-align: right;\">-0.587655 </td><td style=\"text-align: right;\"> 0.0485561</td><td style=\"text-align: right;\"> 0.235821 </td><td style=\"text-align: right;\">-0.0395163</td><td style=\"text-align: right;\">-0.205601  </td><td style=\"text-align: right;\"> 0.0350589 </td><td style=\"text-align: right;\"> 0.101773 </td><td style=\"text-align: right;\">-0.0747391</td><td style=\"text-align: right;\"> 0.271811 </td><td style=\"text-align: right;\">-0.0368525 </td><td style=\"text-align: right;\"> 0.215494 </td><td style=\"text-align: right;\"> 0.00417177</td><td style=\"text-align: right;\"> 0.11549 </td><td style=\"text-align: right;\"> 0.249065 </td><td style=\"text-align: right;\">-0.0919896</td><td style=\"text-align: right;\"> 0.147014 </td><td style=\"text-align: right;\"> 0.454241  </td><td style=\"text-align: right;\"> 0.0631964</td><td style=\"text-align: right;\">-0.0799047 </td><td style=\"text-align: right;\">-0.206424</td><td style=\"text-align: right;\"> 0.0626648 </td><td style=\"text-align: right;\"> 0.254552 </td><td style=\"text-align: right;\">-0.126758 </td><td style=\"text-align: right;\">-0.0135385</td><td style=\"text-align: right;\"> 0.103113 </td><td style=\"text-align: right;\">-0.0470452 </td><td style=\"text-align: right;\">-0.0234869</td><td style=\"text-align: right;\"> 0.0569321</td><td style=\"text-align: right;\"> 0.302449 </td><td style=\"text-align: right;\"> 0.107023 </td><td style=\"text-align: right;\"> 0.197454 </td><td style=\"text-align: right;\"> 0.105974  </td><td style=\"text-align: right;\">-0.0316742 </td><td style=\"text-align: right;\">-0.0724548</td><td style=\"text-align: right;\">-0.143969  </td><td style=\"text-align: right;\"> 0.0551029</td><td style=\"text-align: right;\">-0.152243 </td><td style=\"text-align: right;\">-0.124432 </td><td style=\"text-align: right;\">-0.1107   </td><td style=\"text-align: right;\">-0.0454275 </td><td style=\"text-align: right;\"> 0.375159 </td><td style=\"text-align: right;\">-0.13424    </td><td style=\"text-align: right;\"> 0.113136  </td><td style=\"text-align: right;\"> 0.0845437</td><td style=\"text-align: right;\">-0.0824407</td><td style=\"text-align: right;\">-0.0427799</td><td style=\"text-align: right;\"> 0.0288591</td><td style=\"text-align: right;\"> 0.0546468</td><td style=\"text-align: right;\"> 0.0112691</td><td style=\"text-align: right;\"> 0.254756 </td><td style=\"text-align: right;\">-0.0664561</td><td style=\"text-align: right;\">-0.0944385</td><td style=\"text-align: right;\">-0.0845776 </td><td style=\"text-align: right;\">-0.348813  </td><td style=\"text-align: right;\">-0.388426  </td><td style=\"text-align: right;\"> 0.331286 </td><td style=\"text-align: right;\"> 0.214688 </td><td style=\"text-align: right;\"> 0.12623  </td><td style=\"text-align: right;\"> 0.078729 </td><td style=\"text-align: right;\"> 0.133513 </td><td style=\"text-align: right;\">-0.055878</td><td style=\"text-align: right;\"> 0.361878 </td><td style=\"text-align: right;\"> 0.0198201 </td><td style=\"text-align: right;\"> 0.129158 </td><td style=\"text-align: right;\">-0.133021 </td><td style=\"text-align: right;\">-0.0430224 </td><td style=\"text-align: right;\">-0.104172  </td><td style=\"text-align: right;\">-0.0844451</td><td style=\"text-align: right;\"> 0.123224 </td><td style=\"text-align: right;\"> 0.0786226</td><td style=\"text-align: right;\">-0.154249</td><td style=\"text-align: right;\">-0.234724  </td><td style=\"text-align: right;\"> 0.214356 </td><td style=\"text-align: right;\">-0.176343  </td><td style=\"text-align: right;\">-0.04811  </td><td style=\"text-align: right;\">-0.278694   </td><td style=\"text-align: right;\"> 0.0631813 </td><td style=\"text-align: right;\">-0.00826134</td><td style=\"text-align: right;\">-0.0339437</td><td style=\"text-align: right;\"> 0.147426 </td><td style=\"text-align: right;\"> 0.21716  </td><td style=\"text-align: right;\"> 0.0806935</td><td style=\"text-align: right;\"> 0.0963404</td><td style=\"text-align: right;\">-0.123161 </td><td style=\"text-align: right;\"> 0.206812  </td><td style=\"text-align: right;\">-0.384298 </td><td style=\"text-align: right;\"> 0.0548116</td><td style=\"text-align: right;\"> 0.0746361  </td><td style=\"text-align: right;\"> 0.0921111 </td><td style=\"text-align: right;\"> 0.371321 </td><td style=\"text-align: right;\"> 0.292604 </td><td style=\"text-align: right;\"> 0.190858  </td><td style=\"text-align: right;\"> 0.205624 </td><td style=\"text-align: right;\">-0.305565 </td><td style=\"text-align: right;\"> 0.0741434</td><td style=\"text-align: right;\"> 0.0436073</td><td style=\"text-align: right;\">-0.0483075 </td><td style=\"text-align: right;\"> 0.129479 </td><td style=\"text-align: right;\"> 0.0881774 </td><td style=\"text-align: right;\"> 0.144502 </td><td style=\"text-align: right;\">-0.156171 </td><td style=\"text-align: right;\"> 0.154395  </td><td style=\"text-align: right;\">-0.0339808</td><td style=\"text-align: right;\"> 0.0232897</td><td style=\"text-align: right;\"> 0.070536  </td><td style=\"text-align: right;\"> 0.143951 </td><td style=\"text-align: right;\">-0.136796 </td><td style=\"text-align: right;\"> 0.311865  </td><td style=\"text-align: right;\">-0.0452586</td><td style=\"text-align: right;\">-0.127641  </td><td style=\"text-align: right;\">-0.00310456</td><td style=\"text-align: right;\">-0.0674689</td><td style=\"text-align: right;\">-0.220191 </td><td style=\"text-align: right;\"> 0.154635 </td></tr>\n<tr><td style=\"text-align: right;\">-11.4408 </td><td style=\"text-align: right;\"> 3.91069</td><td style=\"text-align: right;\">-0.0533963  </td><td style=\"text-align: right;\"> 1.10893  </td><td style=\"text-align: right;\"> 5.12126  </td><td style=\"text-align: right;\">-4.0803  </td><td style=\"text-align: right;\">-0.0529325</td><td style=\"text-align: right;\">-0.577976</td><td style=\"text-align: right;\">-0.522176</td><td style=\"text-align: right;\"> 1.24176 </td><td style=\"text-align: right;\"> 2.51208 </td><td style=\"text-align: right;\">-0.801427 </td><td style=\"text-align: right;\"> 1.1297  </td><td style=\"text-align: right;\"> 0.173791</td><td style=\"text-align: right;\"> 1.67921  </td><td style=\"text-align: right;\"> 1.44797 </td><td style=\"text-align: right;\">-2.08321   </td><td style=\"text-align: right;\">-0.945879 </td><td style=\"text-align: right;\"> 0.125994 </td><td style=\"text-align: right;\"> 1.41064 </td><td style=\"text-align: right;\"> 0.325474</td><td style=\"text-align: right;\">-1.19619  </td><td style=\"text-align: right;\"> 1.39569  </td><td style=\"text-align: right;\">-0.668194 </td><td style=\"text-align: right;\"> 0.101959</td><td style=\"text-align: right;\">-0.806764 </td><td style=\"text-align: right;\">-1.06909  </td><td style=\"text-align: right;\"> 0.0805773 </td><td style=\"text-align: right;\">-0.168554 </td><td style=\"text-align: right;\">-0.207682</td><td style=\"text-align: right;\">-0.179091  </td><td style=\"text-align: right;\"> 0.891167</td><td style=\"text-align: right;\"> 1.12312  </td><td style=\"text-align: right;\">-1.44565  </td><td style=\"text-align: right;\">-0.22525  </td><td style=\"text-align: right;\">-0.781858 </td><td style=\"text-align: right;\"> 0.780147 </td><td style=\"text-align: right;\"> 1.30059  </td><td style=\"text-align: right;\"> 0.0663721</td><td style=\"text-align: right;\"> 0.0359448</td><td style=\"text-align: right;\">-0.750649  </td><td style=\"text-align: right;\"> 0.958028  </td><td style=\"text-align: right;\"> 1.12601  </td><td style=\"text-align: right;\">-1.40816  </td><td style=\"text-align: right;\"> 0.400875  </td><td style=\"text-align: right;\">-0.107926 </td><td style=\"text-align: right;\"> 0.268149 </td><td style=\"text-align: right;\"> 0.303018 </td><td style=\"text-align: right;\">-0.481072 </td><td style=\"text-align: right;\">-0.102791 </td><td style=\"text-align: right;\">-0.0510634</td><td style=\"text-align: right;\">-0.824892  </td><td style=\"text-align: right;\"> 0.922151 </td><td style=\"text-align: right;\">-0.337871 </td><td style=\"text-align: right;\">-1.3525   </td><td style=\"text-align: right;\">-0.644757 </td><td style=\"text-align: right;\"> 1.3427   </td><td style=\"text-align: right;\"> 0.283754 </td><td style=\"text-align: right;\">-0.57398  </td><td style=\"text-align: right;\">-0.602533 </td><td style=\"text-align: right;\"> 0.881829 </td><td style=\"text-align: right;\">-0.876745   </td><td style=\"text-align: right;\">-0.584974 </td><td style=\"text-align: right;\"> 0.0359255</td><td style=\"text-align: right;\">-0.32868  </td><td style=\"text-align: right;\">-0.391202 </td><td style=\"text-align: right;\">-0.447582</td><td style=\"text-align: right;\"> 0.274852 </td><td style=\"text-align: right;\"> 0.142741 </td><td style=\"text-align: right;\">-0.667909 </td><td style=\"text-align: right;\">-0.863052 </td><td style=\"text-align: right;\"> 0.150856 </td><td style=\"text-align: right;\">-0.438702 </td><td style=\"text-align: right;\"> 0.750841 </td><td style=\"text-align: right;\">-0.385989 </td><td style=\"text-align: right;\">-0.310674  </td><td style=\"text-align: right;\">-0.0790464</td><td style=\"text-align: right;\">-0.0680184</td><td style=\"text-align: right;\"> 0.222167 </td><td style=\"text-align: right;\"> 0.557807 </td><td style=\"text-align: right;\">-0.11575  </td><td style=\"text-align: right;\"> 0.387843</td><td style=\"text-align: right;\"> 0.725434</td><td style=\"text-align: right;\">-0.402882  </td><td style=\"text-align: right;\">-0.535717 </td><td style=\"text-align: right;\">-0.0202945</td><td style=\"text-align: right;\"> 0.117413 </td><td style=\"text-align: right;\"> 0.429501 </td><td style=\"text-align: right;\"> 0.153339 </td><td style=\"text-align: right;\"> 0.107547 </td><td style=\"text-align: right;\"> 0.427923  </td><td style=\"text-align: right;\">-0.50234   </td><td style=\"text-align: right;\"> 0.129575 </td><td style=\"text-align: right;\">-0.141354 </td><td style=\"text-align: right;\"> 0.0388434</td><td style=\"text-align: right;\">-0.0238002 </td><td style=\"text-align: right;\">-0.290518 </td><td style=\"text-align: right;\"> 0.0415737 </td><td style=\"text-align: right;\"> 0.249019</td><td style=\"text-align: right;\">-0.536361 </td><td style=\"text-align: right;\"> 0.304088 </td><td style=\"text-align: right;\"> 0.0245802</td><td style=\"text-align: right;\"> 0.135671  </td><td style=\"text-align: right;\"> 0.179917 </td><td style=\"text-align: right;\"> 0.45321   </td><td style=\"text-align: right;\"> 0.63413 </td><td style=\"text-align: right;\"> 0.424292  </td><td style=\"text-align: right;\">-0.215174 </td><td style=\"text-align: right;\"> 0.247985 </td><td style=\"text-align: right;\"> 0.175937 </td><td style=\"text-align: right;\">-0.139369 </td><td style=\"text-align: right;\">-0.00493264</td><td style=\"text-align: right;\"> 0.377265 </td><td style=\"text-align: right;\"> 0.0013446</td><td style=\"text-align: right;\">-0.144286 </td><td style=\"text-align: right;\">-0.400853 </td><td style=\"text-align: right;\"> 0.245314 </td><td style=\"text-align: right;\">-0.0452821 </td><td style=\"text-align: right;\">-0.565764  </td><td style=\"text-align: right;\">-0.306721 </td><td style=\"text-align: right;\"> 0.324002  </td><td style=\"text-align: right;\"> 0.370195 </td><td style=\"text-align: right;\">-0.194664 </td><td style=\"text-align: right;\">-0.0298646</td><td style=\"text-align: right;\"> 0.376266 </td><td style=\"text-align: right;\"> 0.237367  </td><td style=\"text-align: right;\"> 0.290039 </td><td style=\"text-align: right;\"> 0.000584293</td><td style=\"text-align: right;\">-0.080829  </td><td style=\"text-align: right;\">-0.379429 </td><td style=\"text-align: right;\">-0.182291 </td><td style=\"text-align: right;\"> 0.984333 </td><td style=\"text-align: right;\"> 0.0874452</td><td style=\"text-align: right;\"> 0.135156 </td><td style=\"text-align: right;\"> 0.139681 </td><td style=\"text-align: right;\"> 0.240714 </td><td style=\"text-align: right;\">-0.0559758</td><td style=\"text-align: right;\">-0.148529 </td><td style=\"text-align: right;\"> 0.0806939 </td><td style=\"text-align: right;\">-0.633445  </td><td style=\"text-align: right;\"> 0.123141  </td><td style=\"text-align: right;\">-0.271885 </td><td style=\"text-align: right;\"> 0.196269 </td><td style=\"text-align: right;\"> 0.205204 </td><td style=\"text-align: right;\">-0.336892 </td><td style=\"text-align: right;\"> 0.410195 </td><td style=\"text-align: right;\">-0.165723</td><td style=\"text-align: right;\"> 0.561479 </td><td style=\"text-align: right;\">-0.59274   </td><td style=\"text-align: right;\">-0.224254 </td><td style=\"text-align: right;\">-0.325978 </td><td style=\"text-align: right;\">-0.140057  </td><td style=\"text-align: right;\">-0.193693  </td><td style=\"text-align: right;\">-0.0940802</td><td style=\"text-align: right;\">-0.162493 </td><td style=\"text-align: right;\"> 0.140356 </td><td style=\"text-align: right;\"> 0.183163</td><td style=\"text-align: right;\">-0.381249  </td><td style=\"text-align: right;\"> 0.251974 </td><td style=\"text-align: right;\">-0.334173  </td><td style=\"text-align: right;\"> 0.0931959</td><td style=\"text-align: right;\">-0.000737978</td><td style=\"text-align: right;\"> 0.117114  </td><td style=\"text-align: right;\">-0.206884  </td><td style=\"text-align: right;\"> 0.101043 </td><td style=\"text-align: right;\">-0.132863 </td><td style=\"text-align: right;\"> 0.152506 </td><td style=\"text-align: right;\">-0.134385 </td><td style=\"text-align: right;\"> 0.452986 </td><td style=\"text-align: right;\"> 0.152312 </td><td style=\"text-align: right;\"> 0.0582496 </td><td style=\"text-align: right;\"> 0.0839865</td><td style=\"text-align: right;\">-0.260468 </td><td style=\"text-align: right;\"> 0.478922   </td><td style=\"text-align: right;\">-0.232389  </td><td style=\"text-align: right;\">-0.137869 </td><td style=\"text-align: right;\"> 0.0222461</td><td style=\"text-align: right;\"> 0.0882454 </td><td style=\"text-align: right;\"> 0.173291 </td><td style=\"text-align: right;\">-0.206527 </td><td style=\"text-align: right;\"> 0.0762306</td><td style=\"text-align: right;\"> 0.114507 </td><td style=\"text-align: right;\"> 0.165444  </td><td style=\"text-align: right;\">-0.0534536</td><td style=\"text-align: right;\">-0.0920498 </td><td style=\"text-align: right;\">-0.0482851</td><td style=\"text-align: right;\"> 0.156824 </td><td style=\"text-align: right;\"> 0.278767  </td><td style=\"text-align: right;\">-0.235759 </td><td style=\"text-align: right;\">-0.103127 </td><td style=\"text-align: right;\"> 0.351468  </td><td style=\"text-align: right;\"> 0.0567588</td><td style=\"text-align: right;\">-0.0251241</td><td style=\"text-align: right;\"> 0.47271   </td><td style=\"text-align: right;\">-0.35859  </td><td style=\"text-align: right;\">-0.0731565 </td><td style=\"text-align: right;\">-0.128044  </td><td style=\"text-align: right;\"> 0.148674 </td><td style=\"text-align: right;\"> 0.234844 </td><td style=\"text-align: right;\"> 0.228908 </td></tr>\n<tr><td style=\"text-align: right;\"> -9.28681</td><td style=\"text-align: right;\">-4.90312</td><td style=\"text-align: right;\">-0.00260397 </td><td style=\"text-align: right;\">-0.0484381</td><td style=\"text-align: right;\"> 0.264835 </td><td style=\"text-align: right;\">-4.63516 </td><td style=\"text-align: right;\"> 1.50224  </td><td style=\"text-align: right;\"> 0.357337</td><td style=\"text-align: right;\">-0.17422 </td><td style=\"text-align: right;\"> 0.359103</td><td style=\"text-align: right;\">-0.99246 </td><td style=\"text-align: right;\"> 0.0470872</td><td style=\"text-align: right;\"> 0.236459</td><td style=\"text-align: right;\">-0.685021</td><td style=\"text-align: right;\">-0.497964 </td><td style=\"text-align: right;\"> 0.286454</td><td style=\"text-align: right;\">-1.0784    </td><td style=\"text-align: right;\"> 0.287785 </td><td style=\"text-align: right;\"> 0.142118 </td><td style=\"text-align: right;\">-1.95973 </td><td style=\"text-align: right;\"> 0.474228</td><td style=\"text-align: right;\">-0.131709 </td><td style=\"text-align: right;\">-0.65227  </td><td style=\"text-align: right;\">-0.0330496</td><td style=\"text-align: right;\">-0.160879</td><td style=\"text-align: right;\"> 0.0376077</td><td style=\"text-align: right;\">-0.284    </td><td style=\"text-align: right;\">-0.00654314</td><td style=\"text-align: right;\"> 0.860162 </td><td style=\"text-align: right;\"> 0.59502 </td><td style=\"text-align: right;\">-0.0143426 </td><td style=\"text-align: right;\">-0.310572</td><td style=\"text-align: right;\"> 1.18587  </td><td style=\"text-align: right;\">-0.76121  </td><td style=\"text-align: right;\"> 0.469566 </td><td style=\"text-align: right;\">-0.461658 </td><td style=\"text-align: right;\"> 0.66815  </td><td style=\"text-align: right;\"> 0.376559 </td><td style=\"text-align: right;\"> 0.294312 </td><td style=\"text-align: right;\">-0.52857  </td><td style=\"text-align: right;\">-0.0855447 </td><td style=\"text-align: right;\"> 0.393372  </td><td style=\"text-align: right;\">-0.0614584</td><td style=\"text-align: right;\"> 0.466387 </td><td style=\"text-align: right;\"> 0.167627  </td><td style=\"text-align: right;\">-0.166838 </td><td style=\"text-align: right;\">-0.0566179</td><td style=\"text-align: right;\"> 0.261778 </td><td style=\"text-align: right;\"> 0.23537  </td><td style=\"text-align: right;\">-0.023874 </td><td style=\"text-align: right;\">-0.269284 </td><td style=\"text-align: right;\">-0.301234  </td><td style=\"text-align: right;\"> 0.514908 </td><td style=\"text-align: right;\"> 0.0554866</td><td style=\"text-align: right;\"> 0.213697 </td><td style=\"text-align: right;\"> 0.17933  </td><td style=\"text-align: right;\"> 0.155894 </td><td style=\"text-align: right;\"> 0.168836 </td><td style=\"text-align: right;\">-0.581615 </td><td style=\"text-align: right;\"> 0.782444 </td><td style=\"text-align: right;\">-0.508643 </td><td style=\"text-align: right;\"> 0.309706   </td><td style=\"text-align: right;\">-0.0866412</td><td style=\"text-align: right;\"> 0.319645 </td><td style=\"text-align: right;\">-0.255015 </td><td style=\"text-align: right;\"> 0.373621 </td><td style=\"text-align: right;\"> 0.13159 </td><td style=\"text-align: right;\"> 0.355665 </td><td style=\"text-align: right;\">-0.0152177</td><td style=\"text-align: right;\"> 0.0343728</td><td style=\"text-align: right;\">-0.226289 </td><td style=\"text-align: right;\">-0.0396509</td><td style=\"text-align: right;\"> 0.0890247</td><td style=\"text-align: right;\">-0.314686 </td><td style=\"text-align: right;\"> 0.254015 </td><td style=\"text-align: right;\">-0.00557643</td><td style=\"text-align: right;\">-0.073443 </td><td style=\"text-align: right;\"> 0.0256341</td><td style=\"text-align: right;\">-0.0160978</td><td style=\"text-align: right;\">-0.194006 </td><td style=\"text-align: right;\">-0.0268144</td><td style=\"text-align: right;\"> 0.115604</td><td style=\"text-align: right;\"> 0.246627</td><td style=\"text-align: right;\">-0.255683  </td><td style=\"text-align: right;\"> 0.108665 </td><td style=\"text-align: right;\"> 0.26341  </td><td style=\"text-align: right;\"> 0.057678 </td><td style=\"text-align: right;\"> 0.14296  </td><td style=\"text-align: right;\"> 0.111766 </td><td style=\"text-align: right;\">-0.331197 </td><td style=\"text-align: right;\">-0.0193557 </td><td style=\"text-align: right;\">-0.00387406</td><td style=\"text-align: right;\">-0.124914 </td><td style=\"text-align: right;\"> 0.0608201</td><td style=\"text-align: right;\">-0.222559 </td><td style=\"text-align: right;\">-0.225016  </td><td style=\"text-align: right;\"> 0.0165621</td><td style=\"text-align: right;\">-0.0301462 </td><td style=\"text-align: right;\">-0.088343</td><td style=\"text-align: right;\"> 0.0176888</td><td style=\"text-align: right;\">-0.133887 </td><td style=\"text-align: right;\"> 0.13669  </td><td style=\"text-align: right;\"> 0.00392239</td><td style=\"text-align: right;\">-0.0276523</td><td style=\"text-align: right;\">-0.343728  </td><td style=\"text-align: right;\">-0.10763 </td><td style=\"text-align: right;\">-0.286567  </td><td style=\"text-align: right;\">-0.199684 </td><td style=\"text-align: right;\"> 0.0126868</td><td style=\"text-align: right;\">-0.17505  </td><td style=\"text-align: right;\"> 0.224408 </td><td style=\"text-align: right;\">-0.00865879</td><td style=\"text-align: right;\"> 0.20032  </td><td style=\"text-align: right;\"> 0.0144414</td><td style=\"text-align: right;\">-0.162134 </td><td style=\"text-align: right;\"> 0.0565026</td><td style=\"text-align: right;\">-0.0137815</td><td style=\"text-align: right;\"> 0.0879913 </td><td style=\"text-align: right;\"> 0.214719  </td><td style=\"text-align: right;\"> 0.086483 </td><td style=\"text-align: right;\"> 0.241405  </td><td style=\"text-align: right;\"> 0.307029 </td><td style=\"text-align: right;\">-0.188092 </td><td style=\"text-align: right;\"> 0.130884 </td><td style=\"text-align: right;\">-0.160446 </td><td style=\"text-align: right;\"> 0.00855652</td><td style=\"text-align: right;\">-0.345006 </td><td style=\"text-align: right;\"> 0.060206   </td><td style=\"text-align: right;\"> 0.0967177 </td><td style=\"text-align: right;\"> 0.109908 </td><td style=\"text-align: right;\">-0.0354725</td><td style=\"text-align: right;\"> 0.0919997</td><td style=\"text-align: right;\">-0.151296 </td><td style=\"text-align: right;\">-0.127584 </td><td style=\"text-align: right;\">-0.195341 </td><td style=\"text-align: right;\"> 0.168563 </td><td style=\"text-align: right;\"> 0.0190496</td><td style=\"text-align: right;\"> 0.0890706</td><td style=\"text-align: right;\"> 0.115683  </td><td style=\"text-align: right;\"> 0.112105  </td><td style=\"text-align: right;\">-0.115679  </td><td style=\"text-align: right;\">-0.0499728</td><td style=\"text-align: right;\">-0.0841381</td><td style=\"text-align: right;\">-0.15374  </td><td style=\"text-align: right;\"> 0.0492803</td><td style=\"text-align: right;\">-0.0540748</td><td style=\"text-align: right;\"> 0.111392</td><td style=\"text-align: right;\"> 0.137551 </td><td style=\"text-align: right;\">-0.27198   </td><td style=\"text-align: right;\"> 0.0150838</td><td style=\"text-align: right;\">-0.259813 </td><td style=\"text-align: right;\">-0.148247  </td><td style=\"text-align: right;\">-0.00539514</td><td style=\"text-align: right;\"> 0.0489178</td><td style=\"text-align: right;\">-0.063976 </td><td style=\"text-align: right;\"> 0.202161 </td><td style=\"text-align: right;\">-0.171876</td><td style=\"text-align: right;\"> 0.12256   </td><td style=\"text-align: right;\">-0.0702188</td><td style=\"text-align: right;\"> 0.254428  </td><td style=\"text-align: right;\">-0.19253  </td><td style=\"text-align: right;\"> 0.200451   </td><td style=\"text-align: right;\"> 0.010829  </td><td style=\"text-align: right;\">-0.0996432 </td><td style=\"text-align: right;\"> 0.112846 </td><td style=\"text-align: right;\"> 0.0234955</td><td style=\"text-align: right;\"> 0.0498658</td><td style=\"text-align: right;\"> 0.138928 </td><td style=\"text-align: right;\">-0.0556585</td><td style=\"text-align: right;\">-0.0764542</td><td style=\"text-align: right;\">-0.341671  </td><td style=\"text-align: right;\">-0.111084 </td><td style=\"text-align: right;\"> 0.141304 </td><td style=\"text-align: right;\">-0.0660777  </td><td style=\"text-align: right;\"> 0.0418051 </td><td style=\"text-align: right;\">-0.0573906</td><td style=\"text-align: right;\"> 0.148952 </td><td style=\"text-align: right;\"> 0.108492  </td><td style=\"text-align: right;\">-0.282072 </td><td style=\"text-align: right;\"> 0.164999 </td><td style=\"text-align: right;\"> 0.156052 </td><td style=\"text-align: right;\">-0.0552209</td><td style=\"text-align: right;\">-0.149022  </td><td style=\"text-align: right;\"> 0.0272333</td><td style=\"text-align: right;\">-0.00249091</td><td style=\"text-align: right;\">-0.195615 </td><td style=\"text-align: right;\"> 0.248751 </td><td style=\"text-align: right;\">-0.0022166 </td><td style=\"text-align: right;\">-0.204083 </td><td style=\"text-align: right;\"> 0.100609 </td><td style=\"text-align: right;\"> 0.150012  </td><td style=\"text-align: right;\">-0.12504  </td><td style=\"text-align: right;\"> 0.176794 </td><td style=\"text-align: right;\">-0.0911637 </td><td style=\"text-align: right;\">-0.0638807</td><td style=\"text-align: right;\"> 0.209557  </td><td style=\"text-align: right;\">-0.0724328 </td><td style=\"text-align: right;\">-0.186826 </td><td style=\"text-align: right;\"> 0.0963438</td><td style=\"text-align: right;\"> 0.144141 </td></tr>\n</tbody>\n</table>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604993152962
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test_frame_pca = pca300.predict(test_frame[predictor_cols])\r\n",
        "# h2o.export_file(frame=test_frame_pca, path= DATA_LOCATION + \"processed/final.test_frame.pca300.tsv\", force=True)\r\n",
        "\r\n",
        "test_frame_pca = h2o.import_file(DATA_LOCATION + \"processed/final.test_frame.pca300.tsv\")\r\n",
        "test_frame_pca.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<table>\n<thead>\n<tr><th style=\"text-align: right;\">      PC1</th><th style=\"text-align: right;\">     PC2</th><th style=\"text-align: right;\">         PC3</th><th style=\"text-align: right;\">        PC4</th><th style=\"text-align: right;\">      PC5</th><th style=\"text-align: right;\">      PC6</th><th style=\"text-align: right;\">      PC7</th><th style=\"text-align: right;\">       PC8</th><th style=\"text-align: right;\">       PC9</th><th style=\"text-align: right;\">       PC10</th><th style=\"text-align: right;\">      PC11</th><th style=\"text-align: right;\">      PC12</th><th style=\"text-align: right;\">      PC13</th><th style=\"text-align: right;\">     PC14</th><th style=\"text-align: right;\">      PC15</th><th style=\"text-align: right;\">     PC16</th><th style=\"text-align: right;\">      PC17</th><th style=\"text-align: right;\">      PC18</th><th style=\"text-align: right;\">      PC19</th><th style=\"text-align: right;\">     PC20</th><th style=\"text-align: right;\">     PC21</th><th style=\"text-align: right;\">      PC22</th><th style=\"text-align: right;\">      PC23</th><th style=\"text-align: right;\">      PC24</th><th style=\"text-align: right;\">       PC25</th><th style=\"text-align: right;\">      PC26</th><th style=\"text-align: right;\">      PC27</th><th style=\"text-align: right;\">       PC28</th><th style=\"text-align: right;\">     PC29</th><th style=\"text-align: right;\">     PC30</th><th style=\"text-align: right;\">       PC31</th><th style=\"text-align: right;\">      PC32</th><th style=\"text-align: right;\">      PC33</th><th style=\"text-align: right;\">      PC34</th><th style=\"text-align: right;\">       PC35</th><th style=\"text-align: right;\">      PC36</th><th style=\"text-align: right;\">      PC37</th><th style=\"text-align: right;\">      PC38</th><th style=\"text-align: right;\">      PC39</th><th style=\"text-align: right;\">       PC40</th><th style=\"text-align: right;\">       PC41</th><th style=\"text-align: right;\">      PC42</th><th style=\"text-align: right;\">      PC43</th><th style=\"text-align: right;\">      PC44</th><th style=\"text-align: right;\">      PC45</th><th style=\"text-align: right;\">      PC46</th><th style=\"text-align: right;\">      PC47</th><th style=\"text-align: right;\">      PC48</th><th style=\"text-align: right;\">      PC49</th><th style=\"text-align: right;\">       PC50</th><th style=\"text-align: right;\">       PC51</th><th style=\"text-align: right;\">      PC52</th><th style=\"text-align: right;\">       PC53</th><th style=\"text-align: right;\">      PC54</th><th style=\"text-align: right;\">       PC55</th><th style=\"text-align: right;\">      PC56</th><th style=\"text-align: right;\">      PC57</th><th style=\"text-align: right;\">      PC58</th><th style=\"text-align: right;\">       PC59</th><th style=\"text-align: right;\">       PC60</th><th style=\"text-align: right;\">      PC61</th><th style=\"text-align: right;\">       PC62</th><th style=\"text-align: right;\">      PC63</th><th style=\"text-align: right;\">       PC64</th><th style=\"text-align: right;\">      PC65</th><th style=\"text-align: right;\">      PC66</th><th style=\"text-align: right;\">       PC67</th><th style=\"text-align: right;\">        PC68</th><th style=\"text-align: right;\">       PC69</th><th style=\"text-align: right;\">      PC70</th><th style=\"text-align: right;\">      PC71</th><th style=\"text-align: right;\">      PC72</th><th style=\"text-align: right;\">      PC73</th><th style=\"text-align: right;\">      PC74</th><th style=\"text-align: right;\">       PC75</th><th style=\"text-align: right;\">      PC76</th><th style=\"text-align: right;\">      PC77</th><th style=\"text-align: right;\">       PC78</th><th style=\"text-align: right;\">      PC79</th><th style=\"text-align: right;\">       PC80</th><th style=\"text-align: right;\">      PC81</th><th style=\"text-align: right;\">       PC82</th><th style=\"text-align: right;\">      PC83</th><th style=\"text-align: right;\">       PC84</th><th style=\"text-align: right;\">      PC85</th><th style=\"text-align: right;\">       PC86</th><th style=\"text-align: right;\">        PC87</th><th style=\"text-align: right;\">       PC88</th><th style=\"text-align: right;\">       PC89</th><th style=\"text-align: right;\">       PC90</th><th style=\"text-align: right;\">       PC91</th><th style=\"text-align: right;\">      PC92</th><th style=\"text-align: right;\">      PC93</th><th style=\"text-align: right;\">      PC94</th><th style=\"text-align: right;\">       PC95</th><th style=\"text-align: right;\">      PC96</th><th style=\"text-align: right;\">      PC97</th><th style=\"text-align: right;\">      PC98</th><th style=\"text-align: right;\">      PC99</th><th style=\"text-align: right;\">      PC100</th><th style=\"text-align: right;\">     PC101</th><th style=\"text-align: right;\">      PC102</th><th style=\"text-align: right;\">     PC103</th><th style=\"text-align: right;\">     PC104</th><th style=\"text-align: right;\">     PC105</th><th style=\"text-align: right;\">     PC106</th><th style=\"text-align: right;\">      PC107</th><th style=\"text-align: right;\">      PC108</th><th style=\"text-align: right;\">      PC109</th><th style=\"text-align: right;\">     PC110</th><th style=\"text-align: right;\">      PC111</th><th style=\"text-align: right;\">      PC112</th><th style=\"text-align: right;\">      PC113</th><th style=\"text-align: right;\">     PC114</th><th style=\"text-align: right;\">     PC115</th><th style=\"text-align: right;\">     PC116</th><th style=\"text-align: right;\">     PC117</th><th style=\"text-align: right;\">      PC118</th><th style=\"text-align: right;\">      PC119</th><th style=\"text-align: right;\">     PC120</th><th style=\"text-align: right;\">      PC121</th><th style=\"text-align: right;\">     PC122</th><th style=\"text-align: right;\">      PC123</th><th style=\"text-align: right;\">      PC124</th><th style=\"text-align: right;\">       PC125</th><th style=\"text-align: right;\">      PC126</th><th style=\"text-align: right;\">      PC127</th><th style=\"text-align: right;\">      PC128</th><th style=\"text-align: right;\">       PC129</th><th style=\"text-align: right;\">      PC130</th><th style=\"text-align: right;\">      PC131</th><th style=\"text-align: right;\">       PC132</th><th style=\"text-align: right;\">     PC133</th><th style=\"text-align: right;\">     PC134</th><th style=\"text-align: right;\">     PC135</th><th style=\"text-align: right;\">      PC136</th><th style=\"text-align: right;\">       PC137</th><th style=\"text-align: right;\">      PC138</th><th style=\"text-align: right;\">      PC139</th><th style=\"text-align: right;\">      PC140</th><th style=\"text-align: right;\">      PC141</th><th style=\"text-align: right;\">      PC142</th><th style=\"text-align: right;\">      PC143</th><th style=\"text-align: right;\">      PC144</th><th style=\"text-align: right;\">      PC145</th><th style=\"text-align: right;\">       PC146</th><th style=\"text-align: right;\">      PC147</th><th style=\"text-align: right;\">      PC148</th><th style=\"text-align: right;\">      PC149</th><th style=\"text-align: right;\">     PC150</th><th style=\"text-align: right;\">      PC151</th><th style=\"text-align: right;\">     PC152</th><th style=\"text-align: right;\">      PC153</th><th style=\"text-align: right;\">      PC154</th><th style=\"text-align: right;\">     PC155</th><th style=\"text-align: right;\">      PC156</th><th style=\"text-align: right;\">     PC157</th><th style=\"text-align: right;\">      PC158</th><th style=\"text-align: right;\">       PC159</th><th style=\"text-align: right;\">      PC160</th><th style=\"text-align: right;\">      PC161</th><th style=\"text-align: right;\">     PC162</th><th style=\"text-align: right;\">      PC163</th><th style=\"text-align: right;\">      PC164</th><th style=\"text-align: right;\">     PC165</th><th style=\"text-align: right;\">      PC166</th><th style=\"text-align: right;\">      PC167</th><th style=\"text-align: right;\">     PC168</th><th style=\"text-align: right;\">      PC169</th><th style=\"text-align: right;\">      PC170</th><th style=\"text-align: right;\">      PC171</th><th style=\"text-align: right;\">     PC172</th><th style=\"text-align: right;\">      PC173</th><th style=\"text-align: right;\">      PC174</th><th style=\"text-align: right;\">      PC175</th><th style=\"text-align: right;\">      PC176</th><th style=\"text-align: right;\">      PC177</th><th style=\"text-align: right;\">      PC178</th><th style=\"text-align: right;\">     PC179</th><th style=\"text-align: right;\">      PC180</th><th style=\"text-align: right;\">      PC181</th><th style=\"text-align: right;\">      PC182</th><th style=\"text-align: right;\">     PC183</th><th style=\"text-align: right;\">      PC184</th><th style=\"text-align: right;\">     PC185</th><th style=\"text-align: right;\">      PC186</th><th style=\"text-align: right;\">       PC187</th><th style=\"text-align: right;\">       PC188</th><th style=\"text-align: right;\">      PC189</th><th style=\"text-align: right;\">      PC190</th><th style=\"text-align: right;\">      PC191</th><th style=\"text-align: right;\">     PC192</th><th style=\"text-align: right;\">      PC193</th><th style=\"text-align: right;\">      PC194</th><th style=\"text-align: right;\">     PC195</th><th style=\"text-align: right;\">      PC196</th><th style=\"text-align: right;\">       PC197</th><th style=\"text-align: right;\">      PC198</th><th style=\"text-align: right;\">      PC199</th><th style=\"text-align: right;\">       PC200</th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\"> -9.62946</td><td style=\"text-align: right;\"> 3.42749</td><td style=\"text-align: right;\">-0.0544876  </td><td style=\"text-align: right;\">-1.99728   </td><td style=\"text-align: right;\">-0.501536</td><td style=\"text-align: right;\"> 5.33675 </td><td style=\"text-align: right;\"> 1.88318 </td><td style=\"text-align: right;\"> 2.34222  </td><td style=\"text-align: right;\">  0.550157</td><td style=\"text-align: right;\">  2.24487  </td><td style=\"text-align: right;\"> 1.01714  </td><td style=\"text-align: right;\">-0.274509 </td><td style=\"text-align: right;\"> 0.473391 </td><td style=\"text-align: right;\">-1.15809 </td><td style=\"text-align: right;\"> 0.0800588</td><td style=\"text-align: right;\">-1.07554 </td><td style=\"text-align: right;\"> 1.76168  </td><td style=\"text-align: right;\"> 2.19104  </td><td style=\"text-align: right;\">-0.0812096</td><td style=\"text-align: right;\">-1.188   </td><td style=\"text-align: right;\"> 0.480369</td><td style=\"text-align: right;\"> 1.51523  </td><td style=\"text-align: right;\">-0.73458  </td><td style=\"text-align: right;\"> 0.856701 </td><td style=\"text-align: right;\">-0.463986  </td><td style=\"text-align: right;\"> 1.1826   </td><td style=\"text-align: right;\">-0.756524 </td><td style=\"text-align: right;\"> 0.0237812 </td><td style=\"text-align: right;\"> 0.516223</td><td style=\"text-align: right;\"> 1.13772 </td><td style=\"text-align: right;\">-0.564756  </td><td style=\"text-align: right;\"> 0.633247 </td><td style=\"text-align: right;\">-0.349465 </td><td style=\"text-align: right;\">-0.067741 </td><td style=\"text-align: right;\"> 0.234908  </td><td style=\"text-align: right;\">-0.444675 </td><td style=\"text-align: right;\"> 0.17611  </td><td style=\"text-align: right;\">-0.532194 </td><td style=\"text-align: right;\"> 0.0915564</td><td style=\"text-align: right;\">-0.113063  </td><td style=\"text-align: right;\"> 1.13146   </td><td style=\"text-align: right;\">-0.302093 </td><td style=\"text-align: right;\"> 0.490816 </td><td style=\"text-align: right;\">-0.493271 </td><td style=\"text-align: right;\">-0.585398 </td><td style=\"text-align: right;\"> 0.8064   </td><td style=\"text-align: right;\">-0.424099 </td><td style=\"text-align: right;\">-0.672412 </td><td style=\"text-align: right;\"> 0.236234 </td><td style=\"text-align: right;\"> 0.621226  </td><td style=\"text-align: right;\"> 0.421086  </td><td style=\"text-align: right;\">-0.957542 </td><td style=\"text-align: right;\"> 0.609662  </td><td style=\"text-align: right;\">-0.625019 </td><td style=\"text-align: right;\"> 0.188252  </td><td style=\"text-align: right;\"> 0.878188 </td><td style=\"text-align: right;\">-0.0257143</td><td style=\"text-align: right;\">-0.138875 </td><td style=\"text-align: right;\">-0.0223257 </td><td style=\"text-align: right;\"> 1.23374   </td><td style=\"text-align: right;\">-0.363303 </td><td style=\"text-align: right;\">-0.19214   </td><td style=\"text-align: right;\"> 0.637254 </td><td style=\"text-align: right;\"> 0.567913  </td><td style=\"text-align: right;\"> 0.199097 </td><td style=\"text-align: right;\">-0.825055 </td><td style=\"text-align: right;\"> 0.482516  </td><td style=\"text-align: right;\"> 0.0236314  </td><td style=\"text-align: right;\">-0.274883  </td><td style=\"text-align: right;\">-0.26622  </td><td style=\"text-align: right;\"> 0.389476 </td><td style=\"text-align: right;\">-0.254482 </td><td style=\"text-align: right;\"> 0.476774 </td><td style=\"text-align: right;\"> 0.806681 </td><td style=\"text-align: right;\">-0.515323  </td><td style=\"text-align: right;\">-0.268944 </td><td style=\"text-align: right;\">-0.521861 </td><td style=\"text-align: right;\">-0.0541904 </td><td style=\"text-align: right;\"> 0.0623078</td><td style=\"text-align: right;\">-0.427573  </td><td style=\"text-align: right;\"> 0.209428 </td><td style=\"text-align: right;\"> 0.675307  </td><td style=\"text-align: right;\">-0.156747 </td><td style=\"text-align: right;\">-0.488074  </td><td style=\"text-align: right;\"> 0.266841 </td><td style=\"text-align: right;\"> 0.216901  </td><td style=\"text-align: right;\">-0.365613   </td><td style=\"text-align: right;\">-0.483448  </td><td style=\"text-align: right;\">-0.16199   </td><td style=\"text-align: right;\">-0.311047  </td><td style=\"text-align: right;\">-0.877527  </td><td style=\"text-align: right;\">-0.30912  </td><td style=\"text-align: right;\">-0.48697  </td><td style=\"text-align: right;\"> 0.149168 </td><td style=\"text-align: right;\">-0.372397  </td><td style=\"text-align: right;\">-0.163269 </td><td style=\"text-align: right;\">-0.117403 </td><td style=\"text-align: right;\"> 0.138337 </td><td style=\"text-align: right;\">-0.19628  </td><td style=\"text-align: right;\"> 0.201152  </td><td style=\"text-align: right;\">-0.0601995</td><td style=\"text-align: right;\"> 0.192374  </td><td style=\"text-align: right;\">-0.52172  </td><td style=\"text-align: right;\">-0.127364 </td><td style=\"text-align: right;\">-0.232277 </td><td style=\"text-align: right;\">-0.0896376</td><td style=\"text-align: right;\">-0.125402  </td><td style=\"text-align: right;\"> 0.187321  </td><td style=\"text-align: right;\">-0.271664  </td><td style=\"text-align: right;\">-0.2616   </td><td style=\"text-align: right;\"> 0.0108175 </td><td style=\"text-align: right;\"> 0.43486   </td><td style=\"text-align: right;\">-0.319592  </td><td style=\"text-align: right;\"> 0.198224 </td><td style=\"text-align: right;\">-0.258672 </td><td style=\"text-align: right;\">-0.383842 </td><td style=\"text-align: right;\">-0.435208 </td><td style=\"text-align: right;\"> 0.323674  </td><td style=\"text-align: right;\">-0.708164  </td><td style=\"text-align: right;\">-0.422046 </td><td style=\"text-align: right;\">-0.207349  </td><td style=\"text-align: right;\">-0.780153 </td><td style=\"text-align: right;\"> 0.00302298</td><td style=\"text-align: right;\"> 0.213339  </td><td style=\"text-align: right;\"> 0.0179504  </td><td style=\"text-align: right;\"> 0.450774  </td><td style=\"text-align: right;\">-0.478498  </td><td style=\"text-align: right;\">-0.0366665 </td><td style=\"text-align: right;\"> 0.0296298  </td><td style=\"text-align: right;\"> 0.283827  </td><td style=\"text-align: right;\">-0.472738  </td><td style=\"text-align: right;\"> 0.0141913  </td><td style=\"text-align: right;\"> 0.275673 </td><td style=\"text-align: right;\"> 0.052553 </td><td style=\"text-align: right;\"> 0.255064 </td><td style=\"text-align: right;\"> 0.240547  </td><td style=\"text-align: right;\"> 0.15366    </td><td style=\"text-align: right;\">-0.170729  </td><td style=\"text-align: right;\"> 0.243725  </td><td style=\"text-align: right;\"> 0.588446  </td><td style=\"text-align: right;\"> 0.528715  </td><td style=\"text-align: right;\">-0.147671  </td><td style=\"text-align: right;\">-0.216204  </td><td style=\"text-align: right;\"> 0.56448   </td><td style=\"text-align: right;\">-0.525028  </td><td style=\"text-align: right;\"> 0.0715956  </td><td style=\"text-align: right;\"> 0.332453  </td><td style=\"text-align: right;\">-0.223248  </td><td style=\"text-align: right;\"> 0.61728   </td><td style=\"text-align: right;\"> 0.123985 </td><td style=\"text-align: right;\">-0.0749367 </td><td style=\"text-align: right;\"> 0.0996517</td><td style=\"text-align: right;\">-0.257484  </td><td style=\"text-align: right;\">-0.405051  </td><td style=\"text-align: right;\"> 0.293621 </td><td style=\"text-align: right;\">-0.227607  </td><td style=\"text-align: right;\">-0.427547 </td><td style=\"text-align: right;\">-0.384105  </td><td style=\"text-align: right;\"> 0.20133    </td><td style=\"text-align: right;\">-0.0139542 </td><td style=\"text-align: right;\">-0.396255  </td><td style=\"text-align: right;\"> 0.0760807</td><td style=\"text-align: right;\"> 0.15238   </td><td style=\"text-align: right;\"> 0.0874545 </td><td style=\"text-align: right;\"> 0.195867 </td><td style=\"text-align: right;\"> 0.241876  </td><td style=\"text-align: right;\"> 0.124269  </td><td style=\"text-align: right;\">-0.272356 </td><td style=\"text-align: right;\"> 0.188318  </td><td style=\"text-align: right;\"> 0.0350412 </td><td style=\"text-align: right;\"> 0.100087  </td><td style=\"text-align: right;\"> 0.0796334</td><td style=\"text-align: right;\">-0.349118  </td><td style=\"text-align: right;\"> 0.14185   </td><td style=\"text-align: right;\">-0.00669717</td><td style=\"text-align: right;\"> 0.19513   </td><td style=\"text-align: right;\"> 0.223768  </td><td style=\"text-align: right;\">-0.268808  </td><td style=\"text-align: right;\">-0.19858  </td><td style=\"text-align: right;\">-0.134069  </td><td style=\"text-align: right;\"> 0.213021  </td><td style=\"text-align: right;\">-0.0708481 </td><td style=\"text-align: right;\">-0.370438 </td><td style=\"text-align: right;\">-0.42775   </td><td style=\"text-align: right;\">-0.0108664</td><td style=\"text-align: right;\">-0.189859  </td><td style=\"text-align: right;\">-0.370499   </td><td style=\"text-align: right;\">-0.286406   </td><td style=\"text-align: right;\"> 0.192455  </td><td style=\"text-align: right;\"> 0.252574  </td><td style=\"text-align: right;\">-0.241866  </td><td style=\"text-align: right;\">-0.0577385</td><td style=\"text-align: right;\"> 0.207005  </td><td style=\"text-align: right;\">-0.373174  </td><td style=\"text-align: right;\">-0.254423 </td><td style=\"text-align: right;\"> 0.370247  </td><td style=\"text-align: right;\"> 0.0748705  </td><td style=\"text-align: right;\"> 0.00531612</td><td style=\"text-align: right;\"> 0.150201  </td><td style=\"text-align: right;\"> 0.0503638  </td></tr>\n<tr><td style=\"text-align: right;\"> -6.50059</td><td style=\"text-align: right;\"> 5.03212</td><td style=\"text-align: right;\"> 9.89964    </td><td style=\"text-align: right;\">-1.75115   </td><td style=\"text-align: right;\">-1.99842 </td><td style=\"text-align: right;\"> 5.18436 </td><td style=\"text-align: right;\"> 5.72881 </td><td style=\"text-align: right;\">22.9759   </td><td style=\"text-align: right;\">-72.9113  </td><td style=\"text-align: right;\">-19.4345   </td><td style=\"text-align: right;\"> 3.5075   </td><td style=\"text-align: right;\"> 0.688388 </td><td style=\"text-align: right;\"> 1.69246  </td><td style=\"text-align: right;\">-0.351719</td><td style=\"text-align: right;\"> 0.807579 </td><td style=\"text-align: right;\"> 0.162097</td><td style=\"text-align: right;\"> 0.751626 </td><td style=\"text-align: right;\">-0.18388  </td><td style=\"text-align: right;\"> 0.114748 </td><td style=\"text-align: right;\">-0.708287</td><td style=\"text-align: right;\">-0.431597</td><td style=\"text-align: right;\"> 0.0908924</td><td style=\"text-align: right;\"> 0.351024 </td><td style=\"text-align: right;\">-0.106659 </td><td style=\"text-align: right;\">-0.333741  </td><td style=\"text-align: right;\">-0.275902 </td><td style=\"text-align: right;\">-0.0169099</td><td style=\"text-align: right;\"> 0.738175  </td><td style=\"text-align: right;\"> 0.298389</td><td style=\"text-align: right;\"> 0.173786</td><td style=\"text-align: right;\">-0.232006  </td><td style=\"text-align: right;\">-0.157514 </td><td style=\"text-align: right;\">-0.0104423</td><td style=\"text-align: right;\">-0.0416099</td><td style=\"text-align: right;\"> 0.00259742</td><td style=\"text-align: right;\"> 0.153628 </td><td style=\"text-align: right;\">-0.130673 </td><td style=\"text-align: right;\">-0.0629438</td><td style=\"text-align: right;\"> 0.103533 </td><td style=\"text-align: right;\"> 0.00953883</td><td style=\"text-align: right;\">-0.0284005 </td><td style=\"text-align: right;\"> 0.101688 </td><td style=\"text-align: right;\">-0.15913  </td><td style=\"text-align: right;\"> 0.126722 </td><td style=\"text-align: right;\">-0.0756605</td><td style=\"text-align: right;\">-0.0757435</td><td style=\"text-align: right;\"> 0.0441156</td><td style=\"text-align: right;\"> 0.0158992</td><td style=\"text-align: right;\"> 0.0966239</td><td style=\"text-align: right;\">-0.0160974 </td><td style=\"text-align: right;\">-0.00503431</td><td style=\"text-align: right;\"> 0.0116024</td><td style=\"text-align: right;\"> 0.0095455 </td><td style=\"text-align: right;\">-0.0067565</td><td style=\"text-align: right;\">-0.026261  </td><td style=\"text-align: right;\">-0.0215083</td><td style=\"text-align: right;\"> 0.0502305</td><td style=\"text-align: right;\">-0.0297334</td><td style=\"text-align: right;\"> 0.00990971</td><td style=\"text-align: right;\">-0.0598099 </td><td style=\"text-align: right;\"> 0.0232784</td><td style=\"text-align: right;\">-0.0248749 </td><td style=\"text-align: right;\">-0.0285802</td><td style=\"text-align: right;\"> 0.00209873</td><td style=\"text-align: right;\"> 0.0368059</td><td style=\"text-align: right;\"> 0.0434571</td><td style=\"text-align: right;\">-0.0579956 </td><td style=\"text-align: right;\">-0.000134279</td><td style=\"text-align: right;\"> 0.0298716 </td><td style=\"text-align: right;\">-0.0178984</td><td style=\"text-align: right;\"> 0.0093227</td><td style=\"text-align: right;\">-0.0204604</td><td style=\"text-align: right;\">-0.0540928</td><td style=\"text-align: right;\"> 0.0371086</td><td style=\"text-align: right;\"> 0.00754352</td><td style=\"text-align: right;\">-0.0336085</td><td style=\"text-align: right;\">-0.0019139</td><td style=\"text-align: right;\"> 0.00628899</td><td style=\"text-align: right;\">-0.0455008</td><td style=\"text-align: right;\"> 0.052359  </td><td style=\"text-align: right;\"> 0.0163493</td><td style=\"text-align: right;\"> 0.00218547</td><td style=\"text-align: right;\"> 0.0132377</td><td style=\"text-align: right;\"> 0.00211587</td><td style=\"text-align: right;\">-0.0146862</td><td style=\"text-align: right;\">-0.00559338</td><td style=\"text-align: right;\">-0.000155938</td><td style=\"text-align: right;\"> 0.00755395</td><td style=\"text-align: right;\"> 0.0033325 </td><td style=\"text-align: right;\"> 0.00209277</td><td style=\"text-align: right;\"> 0.00105389</td><td style=\"text-align: right;\">-0.0748952</td><td style=\"text-align: right;\"> 0.0101986</td><td style=\"text-align: right;\">-0.0145325</td><td style=\"text-align: right;\">-0.00125014</td><td style=\"text-align: right;\">-0.0258381</td><td style=\"text-align: right;\">-0.0540903</td><td style=\"text-align: right;\">-0.0410478</td><td style=\"text-align: right;\"> 0.0387674</td><td style=\"text-align: right;\"> 0.00351536</td><td style=\"text-align: right;\"> 0.0128107</td><td style=\"text-align: right;\"> 0.00557929</td><td style=\"text-align: right;\">-0.0619911</td><td style=\"text-align: right;\"> 0.0247265</td><td style=\"text-align: right;\"> 0.0154274</td><td style=\"text-align: right;\">-0.0321825</td><td style=\"text-align: right;\">-0.00951977</td><td style=\"text-align: right;\"> 0.00769412</td><td style=\"text-align: right;\">-0.0357834 </td><td style=\"text-align: right;\">-0.0591719</td><td style=\"text-align: right;\">-0.00457642</td><td style=\"text-align: right;\">-0.00606525</td><td style=\"text-align: right;\"> 0.00840811</td><td style=\"text-align: right;\"> 0.0210038</td><td style=\"text-align: right;\"> 0.004185 </td><td style=\"text-align: right;\">-0.014654 </td><td style=\"text-align: right;\"> 0.0225778</td><td style=\"text-align: right;\">-0.00183399</td><td style=\"text-align: right;\"> 0.00217674</td><td style=\"text-align: right;\"> 0.0351158</td><td style=\"text-align: right;\">-0.00135192</td><td style=\"text-align: right;\">-0.0150031</td><td style=\"text-align: right;\"> 0.0036849 </td><td style=\"text-align: right;\">-0.00310188</td><td style=\"text-align: right;\"> 0.000879287</td><td style=\"text-align: right;\"> 0.00355384</td><td style=\"text-align: right;\">-0.0084746 </td><td style=\"text-align: right;\">-0.00534059</td><td style=\"text-align: right;\">-0.0105895  </td><td style=\"text-align: right;\"> 0.00742139</td><td style=\"text-align: right;\"> 0.011533  </td><td style=\"text-align: right;\">-0.00614121 </td><td style=\"text-align: right;\">-0.0129047</td><td style=\"text-align: right;\"> 0.020875 </td><td style=\"text-align: right;\">-0.0049962</td><td style=\"text-align: right;\">-0.00231064</td><td style=\"text-align: right;\"> 0.00582987 </td><td style=\"text-align: right;\">-0.00690987</td><td style=\"text-align: right;\">-0.00203907</td><td style=\"text-align: right;\"> 0.00527454</td><td style=\"text-align: right;\"> 0.00045267</td><td style=\"text-align: right;\"> 0.00388553</td><td style=\"text-align: right;\">-0.0197361 </td><td style=\"text-align: right;\"> 0.00423608</td><td style=\"text-align: right;\"> 0.00979886</td><td style=\"text-align: right;\"> 0.000483858</td><td style=\"text-align: right;\">-0.00017943</td><td style=\"text-align: right;\">-0.00964616</td><td style=\"text-align: right;\"> 0.0194447 </td><td style=\"text-align: right;\"> 0.0148543</td><td style=\"text-align: right;\"> 0.00513786</td><td style=\"text-align: right;\">-0.0106696</td><td style=\"text-align: right;\">-0.00341618</td><td style=\"text-align: right;\"> 0.00174641</td><td style=\"text-align: right;\"> 0.0118982</td><td style=\"text-align: right;\"> 0.00116556</td><td style=\"text-align: right;\"> 0.0209835</td><td style=\"text-align: right;\"> 0.00243423</td><td style=\"text-align: right;\">-0.000339955</td><td style=\"text-align: right;\"> 0.00521808</td><td style=\"text-align: right;\">-0.00359017</td><td style=\"text-align: right;\">-0.0172559</td><td style=\"text-align: right;\">-0.00280436</td><td style=\"text-align: right;\">-0.00727958</td><td style=\"text-align: right;\"> 0.026531 </td><td style=\"text-align: right;\"> 0.00720347</td><td style=\"text-align: right;\"> 0.00123806</td><td style=\"text-align: right;\"> 0.0154357</td><td style=\"text-align: right;\"> 0.00556288</td><td style=\"text-align: right;\"> 0.00342277</td><td style=\"text-align: right;\"> 0.0102327 </td><td style=\"text-align: right;\">-0.0109282</td><td style=\"text-align: right;\">-0.00307871</td><td style=\"text-align: right;\">-0.00308189</td><td style=\"text-align: right;\">-0.00206439</td><td style=\"text-align: right;\"> 0.0103463 </td><td style=\"text-align: right;\">-0.00746865</td><td style=\"text-align: right;\">-0.00659294</td><td style=\"text-align: right;\"> 0.0021469</td><td style=\"text-align: right;\"> 0.00023555</td><td style=\"text-align: right;\"> 0.0107691 </td><td style=\"text-align: right;\">-0.00834449</td><td style=\"text-align: right;\"> 0.0171208</td><td style=\"text-align: right;\"> 0.00355487</td><td style=\"text-align: right;\"> 0.0104005</td><td style=\"text-align: right;\"> 0.00500246</td><td style=\"text-align: right;\"> 0.000461584</td><td style=\"text-align: right;\"> 0.000601585</td><td style=\"text-align: right;\"> 0.00443169</td><td style=\"text-align: right;\"> 0.016988  </td><td style=\"text-align: right;\">-0.00255609</td><td style=\"text-align: right;\"> 0.0107808</td><td style=\"text-align: right;\"> 0.00364382</td><td style=\"text-align: right;\">-0.00654571</td><td style=\"text-align: right;\">-0.0063882</td><td style=\"text-align: right;\">-0.00536978</td><td style=\"text-align: right;\"> 0.000630954</td><td style=\"text-align: right;\"> 0.0107065 </td><td style=\"text-align: right;\"> 0.0136769 </td><td style=\"text-align: right;\">-0.000218748</td></tr>\n<tr><td style=\"text-align: right;\">-12.9479 </td><td style=\"text-align: right;\"> 4.52013</td><td style=\"text-align: right;\">-0.0727567  </td><td style=\"text-align: right;\"> 0.795501  </td><td style=\"text-align: right;\"> 5.60493 </td><td style=\"text-align: right;\">-3.83393 </td><td style=\"text-align: right;\">-0.123111</td><td style=\"text-align: right;\"> 0.276374 </td><td style=\"text-align: right;\"> -0.394928</td><td style=\"text-align: right;\">  1.5134   </td><td style=\"text-align: right;\"> 0.0998441</td><td style=\"text-align: right;\">-0.160441 </td><td style=\"text-align: right;\"> 0.875783 </td><td style=\"text-align: right;\"> 0.144141</td><td style=\"text-align: right;\"> 1.50295  </td><td style=\"text-align: right;\"> 0.662061</td><td style=\"text-align: right;\">-0.152918 </td><td style=\"text-align: right;\">-1.32294  </td><td style=\"text-align: right;\"> 0.494843 </td><td style=\"text-align: right;\"> 0.120914</td><td style=\"text-align: right;\"> 0.409421</td><td style=\"text-align: right;\"> 1.27984  </td><td style=\"text-align: right;\"> 0.89714  </td><td style=\"text-align: right;\">-0.4064   </td><td style=\"text-align: right;\"> 0.436947  </td><td style=\"text-align: right;\">-0.264961 </td><td style=\"text-align: right;\">-0.504652 </td><td style=\"text-align: right;\"> 0.0964939 </td><td style=\"text-align: right;\">-0.857363</td><td style=\"text-align: right;\"> 0.640224</td><td style=\"text-align: right;\"> 0.00723726</td><td style=\"text-align: right;\">-0.427967 </td><td style=\"text-align: right;\"> 0.128956 </td><td style=\"text-align: right;\">-0.386457 </td><td style=\"text-align: right;\">-0.294656  </td><td style=\"text-align: right;\">-0.138751 </td><td style=\"text-align: right;\">-0.556036 </td><td style=\"text-align: right;\">-0.0155012</td><td style=\"text-align: right;\">-0.478571 </td><td style=\"text-align: right;\"> 0.665948  </td><td style=\"text-align: right;\">-0.00757544</td><td style=\"text-align: right;\"> 0.0321201</td><td style=\"text-align: right;\">-0.430406 </td><td style=\"text-align: right;\">-0.53032  </td><td style=\"text-align: right;\"> 1.22734  </td><td style=\"text-align: right;\"> 0.12203  </td><td style=\"text-align: right;\"> 1.33503  </td><td style=\"text-align: right;\"> 0.968721 </td><td style=\"text-align: right;\">-0.417973 </td><td style=\"text-align: right;\"> 0.607955  </td><td style=\"text-align: right;\">-0.330774  </td><td style=\"text-align: right;\"> 0.561572 </td><td style=\"text-align: right;\"> 0.352208  </td><td style=\"text-align: right;\"> 1.5755   </td><td style=\"text-align: right;\">-0.707895  </td><td style=\"text-align: right;\">-0.909152 </td><td style=\"text-align: right;\"> 0.28725  </td><td style=\"text-align: right;\"> 0.0648046</td><td style=\"text-align: right;\">-0.0253563 </td><td style=\"text-align: right;\">-0.217064  </td><td style=\"text-align: right;\"> 0.413599 </td><td style=\"text-align: right;\"> 0.61586   </td><td style=\"text-align: right;\"> 0.537453 </td><td style=\"text-align: right;\"> 0.0908139 </td><td style=\"text-align: right;\">-0.675122 </td><td style=\"text-align: right;\">-0.489732 </td><td style=\"text-align: right;\"> 0.581519  </td><td style=\"text-align: right;\"> 0.330403   </td><td style=\"text-align: right;\">-0.240445  </td><td style=\"text-align: right;\"> 0.167285 </td><td style=\"text-align: right;\">-0.323837 </td><td style=\"text-align: right;\">-0.203957 </td><td style=\"text-align: right;\"> 0.662979 </td><td style=\"text-align: right;\">-0.2441   </td><td style=\"text-align: right;\"> 0.212523  </td><td style=\"text-align: right;\">-0.801479 </td><td style=\"text-align: right;\">-0.320418 </td><td style=\"text-align: right;\">-0.0492246 </td><td style=\"text-align: right;\"> 0.0482084</td><td style=\"text-align: right;\">-0.143322  </td><td style=\"text-align: right;\"> 0.540529 </td><td style=\"text-align: right;\"> 0.84252   </td><td style=\"text-align: right;\"> 0.304992 </td><td style=\"text-align: right;\"> 0.255836  </td><td style=\"text-align: right;\"> 0.296174 </td><td style=\"text-align: right;\">-0.203431  </td><td style=\"text-align: right;\"> 0.15144    </td><td style=\"text-align: right;\"> 0.0989564 </td><td style=\"text-align: right;\"> 0.231816  </td><td style=\"text-align: right;\">-0.0948375 </td><td style=\"text-align: right;\"> 0.383431  </td><td style=\"text-align: right;\">-0.130254 </td><td style=\"text-align: right;\"> 0.368513 </td><td style=\"text-align: right;\"> 0.10371  </td><td style=\"text-align: right;\"> 0.252825  </td><td style=\"text-align: right;\">-0.265766 </td><td style=\"text-align: right;\"> 0.268541 </td><td style=\"text-align: right;\"> 0.4523   </td><td style=\"text-align: right;\">-0.0431464</td><td style=\"text-align: right;\">-0.282415  </td><td style=\"text-align: right;\"> 0.455213 </td><td style=\"text-align: right;\">-0.159996  </td><td style=\"text-align: right;\"> 0.361028 </td><td style=\"text-align: right;\">-0.260988 </td><td style=\"text-align: right;\"> 0.186677 </td><td style=\"text-align: right;\"> 0.0308555</td><td style=\"text-align: right;\"> 0.137222  </td><td style=\"text-align: right;\">-0.0186495 </td><td style=\"text-align: right;\"> 0.273489  </td><td style=\"text-align: right;\">-0.342984 </td><td style=\"text-align: right;\"> 0.101656  </td><td style=\"text-align: right;\">-0.162863  </td><td style=\"text-align: right;\">-0.0422177 </td><td style=\"text-align: right;\"> 0.0131981</td><td style=\"text-align: right;\"> 0.0687778</td><td style=\"text-align: right;\">-0.845328 </td><td style=\"text-align: right;\">-0.289969 </td><td style=\"text-align: right;\"> 0.162009  </td><td style=\"text-align: right;\">-0.372335  </td><td style=\"text-align: right;\"> 0.472539 </td><td style=\"text-align: right;\"> 0.335047  </td><td style=\"text-align: right;\">-0.259656 </td><td style=\"text-align: right;\">-0.0743039 </td><td style=\"text-align: right;\"> 0.104449  </td><td style=\"text-align: right;\">-0.44302    </td><td style=\"text-align: right;\">-0.00990119</td><td style=\"text-align: right;\">-0.361591  </td><td style=\"text-align: right;\"> 0.0910314 </td><td style=\"text-align: right;\"> 0.184432   </td><td style=\"text-align: right;\">-0.366909  </td><td style=\"text-align: right;\"> 0.100612  </td><td style=\"text-align: right;\">-0.201271   </td><td style=\"text-align: right;\">-0.0203719</td><td style=\"text-align: right;\"> 0.0346376</td><td style=\"text-align: right;\">-0.0766412</td><td style=\"text-align: right;\"> 0.771028  </td><td style=\"text-align: right;\">-0.373069   </td><td style=\"text-align: right;\">-0.510017  </td><td style=\"text-align: right;\">-0.192733  </td><td style=\"text-align: right;\"> 0.511328  </td><td style=\"text-align: right;\">-0.358742  </td><td style=\"text-align: right;\"> 0.781616  </td><td style=\"text-align: right;\">-0.0907365 </td><td style=\"text-align: right;\">-0.162883  </td><td style=\"text-align: right;\"> 0.418575  </td><td style=\"text-align: right;\"> 0.385409   </td><td style=\"text-align: right;\"> 0.392492  </td><td style=\"text-align: right;\"> 0.235851  </td><td style=\"text-align: right;\"> 0.408559  </td><td style=\"text-align: right;\"> 0.663412 </td><td style=\"text-align: right;\">-0.288445  </td><td style=\"text-align: right;\">-0.388877 </td><td style=\"text-align: right;\">-0.377931  </td><td style=\"text-align: right;\"> 0.790468  </td><td style=\"text-align: right;\">-0.21487  </td><td style=\"text-align: right;\"> 0.369718  </td><td style=\"text-align: right;\"> 0.249138 </td><td style=\"text-align: right;\">-0.0841726 </td><td style=\"text-align: right;\"> 0.257572   </td><td style=\"text-align: right;\"> 0.43072   </td><td style=\"text-align: right;\">-0.0510586 </td><td style=\"text-align: right;\">-0.0270357</td><td style=\"text-align: right;\"> 0.427252  </td><td style=\"text-align: right;\"> 0.108473  </td><td style=\"text-align: right;\">-0.256147 </td><td style=\"text-align: right;\">-0.425715  </td><td style=\"text-align: right;\">-0.244946  </td><td style=\"text-align: right;\">-0.0475409</td><td style=\"text-align: right;\"> 0.134611  </td><td style=\"text-align: right;\">-0.35111   </td><td style=\"text-align: right;\">-0.00822583</td><td style=\"text-align: right;\">-0.169693 </td><td style=\"text-align: right;\">-0.156576  </td><td style=\"text-align: right;\"> 0.370779  </td><td style=\"text-align: right;\">-0.390898  </td><td style=\"text-align: right;\"> 0.140082  </td><td style=\"text-align: right;\">-0.15994   </td><td style=\"text-align: right;\">-0.218447  </td><td style=\"text-align: right;\">-0.174837 </td><td style=\"text-align: right;\">-0.127382  </td><td style=\"text-align: right;\"> 0.27608   </td><td style=\"text-align: right;\"> 0.102577  </td><td style=\"text-align: right;\"> 0.085631 </td><td style=\"text-align: right;\">-0.51676   </td><td style=\"text-align: right;\"> 0.410059 </td><td style=\"text-align: right;\"> 0.401514  </td><td style=\"text-align: right;\">-0.0918516  </td><td style=\"text-align: right;\">-0.368146   </td><td style=\"text-align: right;\"> 0.445533  </td><td style=\"text-align: right;\"> 0.517653  </td><td style=\"text-align: right;\"> 0.124488  </td><td style=\"text-align: right;\"> 0.10141  </td><td style=\"text-align: right;\"> 0.1146    </td><td style=\"text-align: right;\"> 0.217356  </td><td style=\"text-align: right;\"> 0.631302 </td><td style=\"text-align: right;\">-0.333418  </td><td style=\"text-align: right;\"> 0.342894   </td><td style=\"text-align: right;\">-0.226901  </td><td style=\"text-align: right;\">-0.293725  </td><td style=\"text-align: right;\">-0.149337   </td></tr>\n<tr><td style=\"text-align: right;\"> -8.94528</td><td style=\"text-align: right;\">-5.01545</td><td style=\"text-align: right;\"> 0.00218169 </td><td style=\"text-align: right;\"> 0.19758   </td><td style=\"text-align: right;\"> 0.776913</td><td style=\"text-align: right;\">-3.34027 </td><td style=\"text-align: right;\"> 0.435418</td><td style=\"text-align: right;\">-0.418539 </td><td style=\"text-align: right;\"> -0.392206</td><td style=\"text-align: right;\">  0.0628038</td><td style=\"text-align: right;\"> 0.194703 </td><td style=\"text-align: right;\">-0.470089 </td><td style=\"text-align: right;\">-0.505175 </td><td style=\"text-align: right;\">-0.666116</td><td style=\"text-align: right;\">-1.32472  </td><td style=\"text-align: right;\">-1.18856 </td><td style=\"text-align: right;\">-0.0948413</td><td style=\"text-align: right;\"> 0.846526 </td><td style=\"text-align: right;\">-0.351893 </td><td style=\"text-align: right;\"> 0.994438</td><td style=\"text-align: right;\"> 0.709866</td><td style=\"text-align: right;\"> 0.0946708</td><td style=\"text-align: right;\"> 0.730704 </td><td style=\"text-align: right;\">-0.415959 </td><td style=\"text-align: right;\"> 0.20027   </td><td style=\"text-align: right;\">-0.0269342</td><td style=\"text-align: right;\">-0.0357076</td><td style=\"text-align: right;\"> 0.00894854</td><td style=\"text-align: right;\">-0.396809</td><td style=\"text-align: right;\">-0.561537</td><td style=\"text-align: right;\"> 0.0696797 </td><td style=\"text-align: right;\"> 1.07964  </td><td style=\"text-align: right;\">-1.27838  </td><td style=\"text-align: right;\">-0.177258 </td><td style=\"text-align: right;\">-0.92883   </td><td style=\"text-align: right;\">-0.129073 </td><td style=\"text-align: right;\">-0.399533 </td><td style=\"text-align: right;\"> 0.0544567</td><td style=\"text-align: right;\">-0.503208 </td><td style=\"text-align: right;\"> 0.225213  </td><td style=\"text-align: right;\">-0.125742  </td><td style=\"text-align: right;\">-0.401784 </td><td style=\"text-align: right;\"> 0.0836486</td><td style=\"text-align: right;\">-0.0663367</td><td style=\"text-align: right;\">-0.339606 </td><td style=\"text-align: right;\">-0.0227511</td><td style=\"text-align: right;\"> 0.314145 </td><td style=\"text-align: right;\">-0.698153 </td><td style=\"text-align: right;\">-0.384385 </td><td style=\"text-align: right;\">-0.482622  </td><td style=\"text-align: right;\"> 0.123586  </td><td style=\"text-align: right;\"> 0.035008 </td><td style=\"text-align: right;\"> 0.0553435 </td><td style=\"text-align: right;\"> 0.375374 </td><td style=\"text-align: right;\">-0.165647  </td><td style=\"text-align: right;\"> 0.576548 </td><td style=\"text-align: right;\">-0.148979 </td><td style=\"text-align: right;\">-0.522299 </td><td style=\"text-align: right;\"> 0.35583   </td><td style=\"text-align: right;\">-0.475503  </td><td style=\"text-align: right;\">-0.117024 </td><td style=\"text-align: right;\">-0.0363074 </td><td style=\"text-align: right;\"> 0.171169 </td><td style=\"text-align: right;\">-0.0971223 </td><td style=\"text-align: right;\"> 0.175799 </td><td style=\"text-align: right;\">-0.0940921</td><td style=\"text-align: right;\">-0.145786  </td><td style=\"text-align: right;\">-0.0449375  </td><td style=\"text-align: right;\">-0.0327391 </td><td style=\"text-align: right;\"> 0.266942 </td><td style=\"text-align: right;\"> 0.371082 </td><td style=\"text-align: right;\"> 0.148319 </td><td style=\"text-align: right;\">-0.192359 </td><td style=\"text-align: right;\"> 0.114621 </td><td style=\"text-align: right;\"> 0.0116713 </td><td style=\"text-align: right;\">-0.0226767</td><td style=\"text-align: right;\">-0.0395446</td><td style=\"text-align: right;\"> 0.123841  </td><td style=\"text-align: right;\"> 0.0915411</td><td style=\"text-align: right;\">-0.368156  </td><td style=\"text-align: right;\"> 0.142615 </td><td style=\"text-align: right;\"> 0.0449073 </td><td style=\"text-align: right;\">-0.0961354</td><td style=\"text-align: right;\">-0.285895  </td><td style=\"text-align: right;\">-0.399253 </td><td style=\"text-align: right;\"> 0.336092  </td><td style=\"text-align: right;\"> 0.151977   </td><td style=\"text-align: right;\"> 0.227483  </td><td style=\"text-align: right;\"> 0.1069    </td><td style=\"text-align: right;\">-0.141486  </td><td style=\"text-align: right;\">-0.397814  </td><td style=\"text-align: right;\">-0.352355 </td><td style=\"text-align: right;\">-0.152311 </td><td style=\"text-align: right;\">-0.125061 </td><td style=\"text-align: right;\">-0.030034  </td><td style=\"text-align: right;\"> 0.219326 </td><td style=\"text-align: right;\"> 0.22168  </td><td style=\"text-align: right;\">-0.274953 </td><td style=\"text-align: right;\"> 0.037017 </td><td style=\"text-align: right;\">-0.214727  </td><td style=\"text-align: right;\">-0.0662301</td><td style=\"text-align: right;\"> 0.107729  </td><td style=\"text-align: right;\"> 0.27112  </td><td style=\"text-align: right;\"> 0.0018463</td><td style=\"text-align: right;\"> 0.0442201</td><td style=\"text-align: right;\">-0.279706 </td><td style=\"text-align: right;\">-0.0151437 </td><td style=\"text-align: right;\">-0.0484053 </td><td style=\"text-align: right;\"> 0.0693774 </td><td style=\"text-align: right;\">-0.150624 </td><td style=\"text-align: right;\">-0.0293918 </td><td style=\"text-align: right;\"> 0.0167988 </td><td style=\"text-align: right;\">-0.0950179 </td><td style=\"text-align: right;\">-0.343762 </td><td style=\"text-align: right;\">-0.0134441</td><td style=\"text-align: right;\">-0.0923724</td><td style=\"text-align: right;\"> 0.0734659</td><td style=\"text-align: right;\">-0.1104    </td><td style=\"text-align: right;\">-0.0647773 </td><td style=\"text-align: right;\">-0.27454  </td><td style=\"text-align: right;\"> 0.16298   </td><td style=\"text-align: right;\"> 0.160289 </td><td style=\"text-align: right;\">-0.337939  </td><td style=\"text-align: right;\"> 0.134666  </td><td style=\"text-align: right;\"> 0.0826234  </td><td style=\"text-align: right;\">-0.0991061 </td><td style=\"text-align: right;\"> 0.00194032</td><td style=\"text-align: right;\">-0.0835894 </td><td style=\"text-align: right;\"> 0.0239177  </td><td style=\"text-align: right;\"> 0.1042    </td><td style=\"text-align: right;\"> 0.0224501 </td><td style=\"text-align: right;\"> 0.264522   </td><td style=\"text-align: right;\">-0.0986982</td><td style=\"text-align: right;\"> 0.0640312</td><td style=\"text-align: right;\">-0.155391 </td><td style=\"text-align: right;\"> 0.038349  </td><td style=\"text-align: right;\">-0.0327791  </td><td style=\"text-align: right;\"> 0.052411  </td><td style=\"text-align: right;\"> 0.0375473 </td><td style=\"text-align: right;\"> 0.042954  </td><td style=\"text-align: right;\">-0.334741  </td><td style=\"text-align: right;\"> 0.101777  </td><td style=\"text-align: right;\">-0.00269391</td><td style=\"text-align: right;\">-0.0725712 </td><td style=\"text-align: right;\"> 0.142811  </td><td style=\"text-align: right;\">-0.197656   </td><td style=\"text-align: right;\"> 0.226308  </td><td style=\"text-align: right;\"> 0.21958   </td><td style=\"text-align: right;\"> 0.104074  </td><td style=\"text-align: right;\"> 0.0606405</td><td style=\"text-align: right;\"> 0.151589  </td><td style=\"text-align: right;\">-0.0177989</td><td style=\"text-align: right;\">-0.0394543 </td><td style=\"text-align: right;\">-0.060618  </td><td style=\"text-align: right;\"> 0.034742 </td><td style=\"text-align: right;\"> 0.117939  </td><td style=\"text-align: right;\">-0.0518007</td><td style=\"text-align: right;\">-0.0837149 </td><td style=\"text-align: right;\">-0.0975527  </td><td style=\"text-align: right;\">-0.203868  </td><td style=\"text-align: right;\">-0.169478  </td><td style=\"text-align: right;\">-0.268492 </td><td style=\"text-align: right;\">-0.051744  </td><td style=\"text-align: right;\"> 0.0340075 </td><td style=\"text-align: right;\">-0.114194 </td><td style=\"text-align: right;\">-0.0014794 </td><td style=\"text-align: right;\"> 0.184438  </td><td style=\"text-align: right;\">-0.115449 </td><td style=\"text-align: right;\"> 0.0871521 </td><td style=\"text-align: right;\"> 0.125626  </td><td style=\"text-align: right;\">-0.0201496 </td><td style=\"text-align: right;\">-0.211015 </td><td style=\"text-align: right;\"> 0.370505  </td><td style=\"text-align: right;\"> 0.161568  </td><td style=\"text-align: right;\">-0.0331975 </td><td style=\"text-align: right;\"> 0.115279  </td><td style=\"text-align: right;\">-0.0729038 </td><td style=\"text-align: right;\"> 0.167561  </td><td style=\"text-align: right;\"> 0.0427467</td><td style=\"text-align: right;\">-0.238144  </td><td style=\"text-align: right;\"> 0.0151419 </td><td style=\"text-align: right;\">-0.158566  </td><td style=\"text-align: right;\">-0.0342529</td><td style=\"text-align: right;\">-0.140659  </td><td style=\"text-align: right;\"> 0.0779365</td><td style=\"text-align: right;\"> 0.0792503 </td><td style=\"text-align: right;\">-0.208821   </td><td style=\"text-align: right;\">-0.0337909  </td><td style=\"text-align: right;\"> 0.168655  </td><td style=\"text-align: right;\">-0.0670168 </td><td style=\"text-align: right;\">-0.0351762 </td><td style=\"text-align: right;\"> 0.178609 </td><td style=\"text-align: right;\">-0.0471835 </td><td style=\"text-align: right;\"> 0.136935  </td><td style=\"text-align: right;\">-0.0638909</td><td style=\"text-align: right;\">-0.146832  </td><td style=\"text-align: right;\"> 0.177575   </td><td style=\"text-align: right;\"> 0.0438678 </td><td style=\"text-align: right;\"> 0.0781435 </td><td style=\"text-align: right;\">-0.19136    </td></tr>\n<tr><td style=\"text-align: right;\"> -8.61603</td><td style=\"text-align: right;\">-5.40221</td><td style=\"text-align: right;\"> 0.00811241 </td><td style=\"text-align: right;\">-0.470638  </td><td style=\"text-align: right;\">-0.436735</td><td style=\"text-align: right;\"> 2.80297 </td><td style=\"text-align: right;\">-0.717564</td><td style=\"text-align: right;\"> 0.0320249</td><td style=\"text-align: right;\">  0.384208</td><td style=\"text-align: right;\"> -0.915967 </td><td style=\"text-align: right;\"> 0.109527 </td><td style=\"text-align: right;\"> 0.47088  </td><td style=\"text-align: right;\"> 0.56927  </td><td style=\"text-align: right;\"> 0.160269</td><td style=\"text-align: right;\"> 1.68617  </td><td style=\"text-align: right;\"> 1.00034 </td><td style=\"text-align: right;\">-0.268822 </td><td style=\"text-align: right;\"> 0.0977931</td><td style=\"text-align: right;\"> 0.296411 </td><td style=\"text-align: right;\"> 0.619891</td><td style=\"text-align: right;\">-0.622163</td><td style=\"text-align: right;\"> 0.976312 </td><td style=\"text-align: right;\">-0.49164  </td><td style=\"text-align: right;\"> 0.403487 </td><td style=\"text-align: right;\">-0.389032  </td><td style=\"text-align: right;\"> 0.472982 </td><td style=\"text-align: right;\"> 1.40307  </td><td style=\"text-align: right;\">-0.0736759 </td><td style=\"text-align: right;\">-0.46472 </td><td style=\"text-align: right;\">-0.184554</td><td style=\"text-align: right;\"> 0.0479997 </td><td style=\"text-align: right;\">-0.334994 </td><td style=\"text-align: right;\"> 0.160773 </td><td style=\"text-align: right;\">-0.313563 </td><td style=\"text-align: right;\">-0.234564  </td><td style=\"text-align: right;\"> 0.0904426</td><td style=\"text-align: right;\"> 0.187123 </td><td style=\"text-align: right;\">-0.1894   </td><td style=\"text-align: right;\">-0.382194 </td><td style=\"text-align: right;\">-0.201534  </td><td style=\"text-align: right;\">-0.192287  </td><td style=\"text-align: right;\">-0.369397 </td><td style=\"text-align: right;\"> 0.24313  </td><td style=\"text-align: right;\"> 0.378067 </td><td style=\"text-align: right;\">-0.0988708</td><td style=\"text-align: right;\"> 0.0338374</td><td style=\"text-align: right;\"> 0.457246 </td><td style=\"text-align: right;\">-0.188525 </td><td style=\"text-align: right;\"> 0.658951 </td><td style=\"text-align: right;\">-0.130829  </td><td style=\"text-align: right;\"> 0.298092  </td><td style=\"text-align: right;\"> 0.200871 </td><td style=\"text-align: right;\">-0.00588034</td><td style=\"text-align: right;\">-0.0506975</td><td style=\"text-align: right;\"> 0.202035  </td><td style=\"text-align: right;\"> 0.0840065</td><td style=\"text-align: right;\">-0.336172 </td><td style=\"text-align: right;\">-0.217707 </td><td style=\"text-align: right;\"> 0.159621  </td><td style=\"text-align: right;\">-0.113108  </td><td style=\"text-align: right;\">-0.260194 </td><td style=\"text-align: right;\"> 0.210903  </td><td style=\"text-align: right;\">-0.297812 </td><td style=\"text-align: right;\"> 0.191484  </td><td style=\"text-align: right;\"> 0.329767 </td><td style=\"text-align: right;\"> 0.134989 </td><td style=\"text-align: right;\">-0.0103842 </td><td style=\"text-align: right;\"> 0.0685854  </td><td style=\"text-align: right;\">-0.00680479</td><td style=\"text-align: right;\"> 0.266239 </td><td style=\"text-align: right;\"> 0.0298477</td><td style=\"text-align: right;\">-0.0748851</td><td style=\"text-align: right;\">-0.226567 </td><td style=\"text-align: right;\"> 0.255102 </td><td style=\"text-align: right;\">-0.46267   </td><td style=\"text-align: right;\">-0.0558517</td><td style=\"text-align: right;\"> 0.335046 </td><td style=\"text-align: right;\">-0.145945  </td><td style=\"text-align: right;\"> 0.20236  </td><td style=\"text-align: right;\"> 0.304878  </td><td style=\"text-align: right;\">-0.078967 </td><td style=\"text-align: right;\"> 0.0183667 </td><td style=\"text-align: right;\"> 0.273161 </td><td style=\"text-align: right;\">-0.335248  </td><td style=\"text-align: right;\">-0.254011 </td><td style=\"text-align: right;\"> 0.118854  </td><td style=\"text-align: right;\"> 0.307712   </td><td style=\"text-align: right;\">-0.262988  </td><td style=\"text-align: right;\"> 0.00616952</td><td style=\"text-align: right;\"> 0.29753   </td><td style=\"text-align: right;\">-0.202918  </td><td style=\"text-align: right;\"> 0.468733 </td><td style=\"text-align: right;\">-0.188677 </td><td style=\"text-align: right;\">-0.11437  </td><td style=\"text-align: right;\"> 0.11525   </td><td style=\"text-align: right;\"> 0.48977  </td><td style=\"text-align: right;\"> 0.386582 </td><td style=\"text-align: right;\">-0.0465705</td><td style=\"text-align: right;\">-0.213999 </td><td style=\"text-align: right;\">-0.186912  </td><td style=\"text-align: right;\">-0.0642073</td><td style=\"text-align: right;\"> 0.258249  </td><td style=\"text-align: right;\"> 0.0956704</td><td style=\"text-align: right;\">-0.0400266</td><td style=\"text-align: right;\"> 0.295486 </td><td style=\"text-align: right;\">-0.194503 </td><td style=\"text-align: right;\"> 0.270661  </td><td style=\"text-align: right;\">-0.132432  </td><td style=\"text-align: right;\">-0.00319387</td><td style=\"text-align: right;\">-0.0266163</td><td style=\"text-align: right;\">-0.135375  </td><td style=\"text-align: right;\">-0.1325    </td><td style=\"text-align: right;\">-0.198468  </td><td style=\"text-align: right;\">-0.130475 </td><td style=\"text-align: right;\">-0.0800707</td><td style=\"text-align: right;\">-0.0386215</td><td style=\"text-align: right;\"> 0.249876 </td><td style=\"text-align: right;\">-0.126518  </td><td style=\"text-align: right;\"> 0.219047  </td><td style=\"text-align: right;\"> 0.0443893</td><td style=\"text-align: right;\"> 0.224987  </td><td style=\"text-align: right;\"> 0.300631 </td><td style=\"text-align: right;\">-0.0520516 </td><td style=\"text-align: right;\">-0.21036   </td><td style=\"text-align: right;\"> 0.354681   </td><td style=\"text-align: right;\"> 0.0235207 </td><td style=\"text-align: right;\"> 0.0676734 </td><td style=\"text-align: right;\">-0.0435437 </td><td style=\"text-align: right;\"> 0.000305147</td><td style=\"text-align: right;\"> 0.11257   </td><td style=\"text-align: right;\"> 0.0879637 </td><td style=\"text-align: right;\">-0.238431   </td><td style=\"text-align: right;\">-0.137048 </td><td style=\"text-align: right;\"> 0.119859 </td><td style=\"text-align: right;\"> 0.538576 </td><td style=\"text-align: right;\">-0.0492506 </td><td style=\"text-align: right;\"> 0.132892   </td><td style=\"text-align: right;\"> 0.171543  </td><td style=\"text-align: right;\">-0.207903  </td><td style=\"text-align: right;\">-0.220583  </td><td style=\"text-align: right;\">-0.0663057 </td><td style=\"text-align: right;\">-0.249994  </td><td style=\"text-align: right;\">-0.106164  </td><td style=\"text-align: right;\">-0.0968478 </td><td style=\"text-align: right;\">-0.0368319 </td><td style=\"text-align: right;\">-0.0663302  </td><td style=\"text-align: right;\"> 0.0632253 </td><td style=\"text-align: right;\"> 0.437415  </td><td style=\"text-align: right;\">-0.104386  </td><td style=\"text-align: right;\"> 0.335587 </td><td style=\"text-align: right;\">-0.24875   </td><td style=\"text-align: right;\">-0.0855293</td><td style=\"text-align: right;\"> 0.066421  </td><td style=\"text-align: right;\"> 0.119544  </td><td style=\"text-align: right;\"> 0.0120892</td><td style=\"text-align: right;\"> 0.0322334 </td><td style=\"text-align: right;\">-0.112484 </td><td style=\"text-align: right;\"> 0.199125  </td><td style=\"text-align: right;\">-0.284355   </td><td style=\"text-align: right;\">-0.180984  </td><td style=\"text-align: right;\"> 0.00111741</td><td style=\"text-align: right;\">-0.28127  </td><td style=\"text-align: right;\"> 0.0789765 </td><td style=\"text-align: right;\"> 0.0622286 </td><td style=\"text-align: right;\"> 0.100738 </td><td style=\"text-align: right;\">-0.213872  </td><td style=\"text-align: right;\"> 0.0294017 </td><td style=\"text-align: right;\">-0.0373952</td><td style=\"text-align: right;\">-0.237339  </td><td style=\"text-align: right;\"> 0.034477  </td><td style=\"text-align: right;\"> 0.103067  </td><td style=\"text-align: right;\"> 0.11292  </td><td style=\"text-align: right;\">-0.182185  </td><td style=\"text-align: right;\">-0.161504  </td><td style=\"text-align: right;\"> 0.0491328 </td><td style=\"text-align: right;\"> 0.532505  </td><td style=\"text-align: right;\"> 0.175996  </td><td style=\"text-align: right;\"> 0.078395  </td><td style=\"text-align: right;\">-0.0769586</td><td style=\"text-align: right;\">-0.0977332 </td><td style=\"text-align: right;\"> 0.0300075 </td><td style=\"text-align: right;\"> 0.148379  </td><td style=\"text-align: right;\">-0.277488 </td><td style=\"text-align: right;\">-0.140362  </td><td style=\"text-align: right;\"> 0.0533468</td><td style=\"text-align: right;\">-0.216524  </td><td style=\"text-align: right;\">-0.224543   </td><td style=\"text-align: right;\"> 0.13969    </td><td style=\"text-align: right;\"> 0.0212791 </td><td style=\"text-align: right;\"> 0.189716  </td><td style=\"text-align: right;\"> 0.263188  </td><td style=\"text-align: right;\">-0.333152 </td><td style=\"text-align: right;\"> 0.490811  </td><td style=\"text-align: right;\">-0.00826002</td><td style=\"text-align: right;\"> 0.250755 </td><td style=\"text-align: right;\">-0.0532916 </td><td style=\"text-align: right;\"> 0.420241   </td><td style=\"text-align: right;\">-0.003078  </td><td style=\"text-align: right;\"> 0.00691849</td><td style=\"text-align: right;\">-0.290798   </td></tr>\n<tr><td style=\"text-align: right;\"> -9.48605</td><td style=\"text-align: right;\">-4.62876</td><td style=\"text-align: right;\">-0.0113746  </td><td style=\"text-align: right;\"> 0.00264897</td><td style=\"text-align: right;\"> 0.775464</td><td style=\"text-align: right;\">-3.74757 </td><td style=\"text-align: right;\"> 0.77578 </td><td style=\"text-align: right;\">-0.347808 </td><td style=\"text-align: right;\"> -0.456373</td><td style=\"text-align: right;\">  0.557025 </td><td style=\"text-align: right;\">-0.34515  </td><td style=\"text-align: right;\">-0.525534 </td><td style=\"text-align: right;\">-0.770694 </td><td style=\"text-align: right;\">-0.893606</td><td style=\"text-align: right;\">-1.36622  </td><td style=\"text-align: right;\">-0.886175</td><td style=\"text-align: right;\">-0.660253 </td><td style=\"text-align: right;\"> 0.680601 </td><td style=\"text-align: right;\"> 0.087117 </td><td style=\"text-align: right;\">-1.99732 </td><td style=\"text-align: right;\"> 0.109212</td><td style=\"text-align: right;\">-0.287926 </td><td style=\"text-align: right;\"> 0.0916569</td><td style=\"text-align: right;\">-0.337078 </td><td style=\"text-align: right;\"> 0.529247  </td><td style=\"text-align: right;\">-0.370455 </td><td style=\"text-align: right;\">-0.353317 </td><td style=\"text-align: right;\"> 0.0351915 </td><td style=\"text-align: right;\">-0.315187</td><td style=\"text-align: right;\">-1.04475 </td><td style=\"text-align: right;\"> 0.0678574 </td><td style=\"text-align: right;\"> 0.129865 </td><td style=\"text-align: right;\">-0.294966 </td><td style=\"text-align: right;\">-0.138945 </td><td style=\"text-align: right;\">-1.23803   </td><td style=\"text-align: right;\">-0.174998 </td><td style=\"text-align: right;\">-1.22771  </td><td style=\"text-align: right;\">-0.148812 </td><td style=\"text-align: right;\">-0.438866 </td><td style=\"text-align: right;\"> 0.67779   </td><td style=\"text-align: right;\"> 0.609984  </td><td style=\"text-align: right;\">-0.491248 </td><td style=\"text-align: right;\">-0.811174 </td><td style=\"text-align: right;\">-0.267217 </td><td style=\"text-align: right;\">-0.687741 </td><td style=\"text-align: right;\">-0.44685  </td><td style=\"text-align: right;\">-0.208941 </td><td style=\"text-align: right;\"> 0.598894 </td><td style=\"text-align: right;\">-0.0131963</td><td style=\"text-align: right;\">-0.506304  </td><td style=\"text-align: right;\"> 0.214687  </td><td style=\"text-align: right;\">-0.442467 </td><td style=\"text-align: right;\">-0.0567995 </td><td style=\"text-align: right;\"> 0.638434 </td><td style=\"text-align: right;\">-0.290937  </td><td style=\"text-align: right;\"> 0.225813 </td><td style=\"text-align: right;\">-0.770266 </td><td style=\"text-align: right;\">-0.177163 </td><td style=\"text-align: right;\"> 0.494052  </td><td style=\"text-align: right;\">-0.00251475</td><td style=\"text-align: right;\">-0.551776 </td><td style=\"text-align: right;\"> 0.555569  </td><td style=\"text-align: right;\">-0.672519 </td><td style=\"text-align: right;\"> 0.0681414 </td><td style=\"text-align: right;\"> 0.143526 </td><td style=\"text-align: right;\">-0.141077 </td><td style=\"text-align: right;\">-0.12622   </td><td style=\"text-align: right;\">-1.1825     </td><td style=\"text-align: right;\">-0.890815  </td><td style=\"text-align: right;\"> 0.809135 </td><td style=\"text-align: right;\">-0.0734005</td><td style=\"text-align: right;\">-0.352972 </td><td style=\"text-align: right;\">-0.23503  </td><td style=\"text-align: right;\"> 0.146524 </td><td style=\"text-align: right;\"> 0.391508  </td><td style=\"text-align: right;\"> 0.223599 </td><td style=\"text-align: right;\"> 0.208097 </td><td style=\"text-align: right;\">-0.505177  </td><td style=\"text-align: right;\"> 0.0281984</td><td style=\"text-align: right;\">-0.184417  </td><td style=\"text-align: right;\"> 0.462344 </td><td style=\"text-align: right;\">-0.3132    </td><td style=\"text-align: right;\"> 0.0922791</td><td style=\"text-align: right;\">-0.260115  </td><td style=\"text-align: right;\">-0.502435 </td><td style=\"text-align: right;\"> 0.635807  </td><td style=\"text-align: right;\">-0.18061    </td><td style=\"text-align: right;\">-0.559209  </td><td style=\"text-align: right;\"> 0.172449  </td><td style=\"text-align: right;\">-0.236082  </td><td style=\"text-align: right;\"> 0.294326  </td><td style=\"text-align: right;\">-0.0327853</td><td style=\"text-align: right;\">-0.110448 </td><td style=\"text-align: right;\"> 0.316669 </td><td style=\"text-align: right;\">-0.50329   </td><td style=\"text-align: right;\">-0.467994 </td><td style=\"text-align: right;\">-0.386507 </td><td style=\"text-align: right;\"> 0.128248 </td><td style=\"text-align: right;\">-0.195392 </td><td style=\"text-align: right;\"> 0.214672  </td><td style=\"text-align: right;\">-0.433561 </td><td style=\"text-align: right;\">-0.17302   </td><td style=\"text-align: right;\">-0.418322 </td><td style=\"text-align: right;\">-0.225325 </td><td style=\"text-align: right;\">-0.198205 </td><td style=\"text-align: right;\">-0.409893 </td><td style=\"text-align: right;\"> 0.0723651 </td><td style=\"text-align: right;\"> 0.0195491 </td><td style=\"text-align: right;\">-0.119501  </td><td style=\"text-align: right;\"> 0.53044  </td><td style=\"text-align: right;\">-0.208966  </td><td style=\"text-align: right;\">-0.0434626 </td><td style=\"text-align: right;\"> 0.335261  </td><td style=\"text-align: right;\">-0.0186331</td><td style=\"text-align: right;\">-0.197542 </td><td style=\"text-align: right;\"> 0.542854 </td><td style=\"text-align: right;\"> 0.431388 </td><td style=\"text-align: right;\">-0.0885179 </td><td style=\"text-align: right;\">-0.0761147 </td><td style=\"text-align: right;\"> 0.34833  </td><td style=\"text-align: right;\">-0.286945  </td><td style=\"text-align: right;\"> 0.121582 </td><td style=\"text-align: right;\"> 0.163274  </td><td style=\"text-align: right;\"> 0.202084  </td><td style=\"text-align: right;\"> 0.0408521  </td><td style=\"text-align: right;\">-0.0559559 </td><td style=\"text-align: right;\">-0.00372374</td><td style=\"text-align: right;\">-0.405219  </td><td style=\"text-align: right;\"> 0.0149087  </td><td style=\"text-align: right;\"> 0.191357  </td><td style=\"text-align: right;\">-0.0619767 </td><td style=\"text-align: right;\">-0.0499176  </td><td style=\"text-align: right;\"> 0.163253 </td><td style=\"text-align: right;\">-0.177005 </td><td style=\"text-align: right;\">-0.693782 </td><td style=\"text-align: right;\">-0.0374278 </td><td style=\"text-align: right;\">-0.000758044</td><td style=\"text-align: right;\"> 0.0458899 </td><td style=\"text-align: right;\"> 0.0892009 </td><td style=\"text-align: right;\">-0.0336944 </td><td style=\"text-align: right;\"> 0.027149  </td><td style=\"text-align: right;\">-0.236796  </td><td style=\"text-align: right;\"> 0.165388  </td><td style=\"text-align: right;\"> 0.328765  </td><td style=\"text-align: right;\">-0.420372  </td><td style=\"text-align: right;\">-0.0441485  </td><td style=\"text-align: right;\">-0.541111  </td><td style=\"text-align: right;\"> 0.364678  </td><td style=\"text-align: right;\">-0.200678  </td><td style=\"text-align: right;\">-0.325924 </td><td style=\"text-align: right;\"> 0.434868  </td><td style=\"text-align: right;\">-0.0713203</td><td style=\"text-align: right;\">-0.308079  </td><td style=\"text-align: right;\"> 0.546199  </td><td style=\"text-align: right;\"> 0.208701 </td><td style=\"text-align: right;\">-0.428515  </td><td style=\"text-align: right;\"> 0.3897   </td><td style=\"text-align: right;\">-0.268265  </td><td style=\"text-align: right;\"> 0.0722884  </td><td style=\"text-align: right;\">-0.242711  </td><td style=\"text-align: right;\">-0.154381  </td><td style=\"text-align: right;\">-0.478868 </td><td style=\"text-align: right;\"> 0.111516  </td><td style=\"text-align: right;\"> 0.110804  </td><td style=\"text-align: right;\"> 0.013939 </td><td style=\"text-align: right;\">-0.561829  </td><td style=\"text-align: right;\"> 0.421027  </td><td style=\"text-align: right;\"> 0.396893 </td><td style=\"text-align: right;\">-0.509855  </td><td style=\"text-align: right;\"> 0.0646768 </td><td style=\"text-align: right;\">-0.29089   </td><td style=\"text-align: right;\"> 0.16559  </td><td style=\"text-align: right;\">-0.521093  </td><td style=\"text-align: right;\"> 0.611326  </td><td style=\"text-align: right;\"> 0.237163  </td><td style=\"text-align: right;\"> 0.185881  </td><td style=\"text-align: right;\"> 0.254386  </td><td style=\"text-align: right;\"> 0.363215  </td><td style=\"text-align: right;\">-0.119303 </td><td style=\"text-align: right;\"> 0.496844  </td><td style=\"text-align: right;\"> 0.139088  </td><td style=\"text-align: right;\"> 0.331454  </td><td style=\"text-align: right;\"> 0.210057 </td><td style=\"text-align: right;\">-0.419926  </td><td style=\"text-align: right;\"> 0.236703 </td><td style=\"text-align: right;\">-0.185421  </td><td style=\"text-align: right;\"> 0.14139    </td><td style=\"text-align: right;\">-0.0706251  </td><td style=\"text-align: right;\">-0.118829  </td><td style=\"text-align: right;\"> 0.00907507</td><td style=\"text-align: right;\"> 0.220119  </td><td style=\"text-align: right;\"> 0.233469 </td><td style=\"text-align: right;\">-0.210597  </td><td style=\"text-align: right;\">-0.422977  </td><td style=\"text-align: right;\"> 0.278417 </td><td style=\"text-align: right;\">-0.125613  </td><td style=\"text-align: right;\">-0.117672   </td><td style=\"text-align: right;\"> 0.204266  </td><td style=\"text-align: right;\"> 0.100809  </td><td style=\"text-align: right;\">-0.124034   </td></tr>\n<tr><td style=\"text-align: right;\"> -9.76658</td><td style=\"text-align: right;\">-5.5994 </td><td style=\"text-align: right;\">-3.89829e-05</td><td style=\"text-align: right;\"> 0.128426  </td><td style=\"text-align: right;\"> 0.275775</td><td style=\"text-align: right;\">-3.69459 </td><td style=\"text-align: right;\"> 0.934526</td><td style=\"text-align: right;\">-0.210841 </td><td style=\"text-align: right;\"> -0.167749</td><td style=\"text-align: right;\">  0.01654  </td><td style=\"text-align: right;\">-0.435993 </td><td style=\"text-align: right;\">-0.0865435</td><td style=\"text-align: right;\">-0.0988782</td><td style=\"text-align: right;\">-0.916727</td><td style=\"text-align: right;\">-1.00726  </td><td style=\"text-align: right;\">-0.965776</td><td style=\"text-align: right;\"> 0.394868 </td><td style=\"text-align: right;\"> 0.0572899</td><td style=\"text-align: right;\">-0.25157  </td><td style=\"text-align: right;\"> 0.346353</td><td style=\"text-align: right;\"> 0.402495</td><td style=\"text-align: right;\"> 0.564993 </td><td style=\"text-align: right;\"> 1.01356  </td><td style=\"text-align: right;\">-0.282266 </td><td style=\"text-align: right;\">-0.191537  </td><td style=\"text-align: right;\"> 0.143237 </td><td style=\"text-align: right;\"> 0.192089 </td><td style=\"text-align: right;\">-0.0401013 </td><td style=\"text-align: right;\"> 0.592642</td><td style=\"text-align: right;\"> 0.307771</td><td style=\"text-align: right;\">-0.210301  </td><td style=\"text-align: right;\"> 0.885181 </td><td style=\"text-align: right;\"> 0.623763 </td><td style=\"text-align: right;\">-1.24509  </td><td style=\"text-align: right;\"> 0.308801  </td><td style=\"text-align: right;\">-0.390058 </td><td style=\"text-align: right;\"> 0.0322479</td><td style=\"text-align: right;\">-0.378667 </td><td style=\"text-align: right;\">-0.171962 </td><td style=\"text-align: right;\">-0.388523  </td><td style=\"text-align: right;\">-0.203368  </td><td style=\"text-align: right;\"> 0.150018 </td><td style=\"text-align: right;\">-0.311775 </td><td style=\"text-align: right;\"> 0.716699 </td><td style=\"text-align: right;\">-0.34096  </td><td style=\"text-align: right;\">-0.123057 </td><td style=\"text-align: right;\"> 0.343106 </td><td style=\"text-align: right;\"> 0.0780912</td><td style=\"text-align: right;\"> 0.0999492</td><td style=\"text-align: right;\">-0.21739   </td><td style=\"text-align: right;\">-0.439137  </td><td style=\"text-align: right;\">-0.641553 </td><td style=\"text-align: right;\"> 0.63747   </td><td style=\"text-align: right;\"> 0.212651 </td><td style=\"text-align: right;\"> 0.00023834</td><td style=\"text-align: right;\"> 0.752072 </td><td style=\"text-align: right;\">-0.35732  </td><td style=\"text-align: right;\">-0.0844205</td><td style=\"text-align: right;\">-0.05655   </td><td style=\"text-align: right;\"> 0.486645  </td><td style=\"text-align: right;\">-0.144824 </td><td style=\"text-align: right;\"> 0.00930026</td><td style=\"text-align: right;\"> 0.509781 </td><td style=\"text-align: right;\"> 0.955677  </td><td style=\"text-align: right;\"> 0.156868 </td><td style=\"text-align: right;\"> 0.338637 </td><td style=\"text-align: right;\"> 0.235263  </td><td style=\"text-align: right;\"> 0.409853   </td><td style=\"text-align: right;\">-0.0224862 </td><td style=\"text-align: right;\"> 0.414458 </td><td style=\"text-align: right;\">-0.0496435</td><td style=\"text-align: right;\"> 0.25     </td><td style=\"text-align: right;\"> 0.0278119</td><td style=\"text-align: right;\"> 0.09181  </td><td style=\"text-align: right;\"> 0.325807  </td><td style=\"text-align: right;\"> 0.113944 </td><td style=\"text-align: right;\">-0.512569 </td><td style=\"text-align: right;\"> 0.211964  </td><td style=\"text-align: right;\">-0.40525  </td><td style=\"text-align: right;\">-0.00559174</td><td style=\"text-align: right;\">-0.335272 </td><td style=\"text-align: right;\">-0.0507388 </td><td style=\"text-align: right;\">-0.271236 </td><td style=\"text-align: right;\"> 0.506507  </td><td style=\"text-align: right;\">-0.0271158</td><td style=\"text-align: right;\"> 0.0993435 </td><td style=\"text-align: right;\">-0.264506   </td><td style=\"text-align: right;\"> 0.13633   </td><td style=\"text-align: right;\"> 0.0295806 </td><td style=\"text-align: right;\">-0.029975  </td><td style=\"text-align: right;\">-0.20447   </td><td style=\"text-align: right;\">-0.357801 </td><td style=\"text-align: right;\">-0.234231 </td><td style=\"text-align: right;\"> 0.271066 </td><td style=\"text-align: right;\"> 0.0340541 </td><td style=\"text-align: right;\"> 0.0197665</td><td style=\"text-align: right;\">-0.0858676</td><td style=\"text-align: right;\">-0.0685943</td><td style=\"text-align: right;\">-0.223353 </td><td style=\"text-align: right;\">-0.140029  </td><td style=\"text-align: right;\">-0.0177669</td><td style=\"text-align: right;\"> 0.13616   </td><td style=\"text-align: right;\">-0.0288363</td><td style=\"text-align: right;\">-0.144437 </td><td style=\"text-align: right;\">-0.216546 </td><td style=\"text-align: right;\">-0.481661 </td><td style=\"text-align: right;\">-0.241355  </td><td style=\"text-align: right;\"> 0.57967   </td><td style=\"text-align: right;\"> 0.381273  </td><td style=\"text-align: right;\"> 0.199381 </td><td style=\"text-align: right;\"> 0.0247126 </td><td style=\"text-align: right;\">-0.293661  </td><td style=\"text-align: right;\"> 0.0366443 </td><td style=\"text-align: right;\">-0.0894075</td><td style=\"text-align: right;\"> 0.284502 </td><td style=\"text-align: right;\"> 0.0516168</td><td style=\"text-align: right;\"> 0.392418 </td><td style=\"text-align: right;\"> 0.277646  </td><td style=\"text-align: right;\">-0.290867  </td><td style=\"text-align: right;\"> 0.181913 </td><td style=\"text-align: right;\">-0.253747  </td><td style=\"text-align: right;\">-0.172934 </td><td style=\"text-align: right;\"> 0.115745  </td><td style=\"text-align: right;\">-0.169049  </td><td style=\"text-align: right;\">-0.168836   </td><td style=\"text-align: right;\">-0.108469  </td><td style=\"text-align: right;\"> 0.060913  </td><td style=\"text-align: right;\"> 0.0477332 </td><td style=\"text-align: right;\"> 0.153886   </td><td style=\"text-align: right;\"> 0.17978   </td><td style=\"text-align: right;\">-0.390308  </td><td style=\"text-align: right;\">-0.000594149</td><td style=\"text-align: right;\">-0.0922742</td><td style=\"text-align: right;\"> 0.0948177</td><td style=\"text-align: right;\"> 0.1513   </td><td style=\"text-align: right;\"> 0.0629856 </td><td style=\"text-align: right;\">-0.0766572  </td><td style=\"text-align: right;\"> 0.0214414 </td><td style=\"text-align: right;\">-0.0950004 </td><td style=\"text-align: right;\"> 0.0877746 </td><td style=\"text-align: right;\"> 0.141019  </td><td style=\"text-align: right;\"> 0.0743689 </td><td style=\"text-align: right;\"> 0.0662412 </td><td style=\"text-align: right;\"> 0.520284  </td><td style=\"text-align: right;\">-0.303057  </td><td style=\"text-align: right;\"> 0.183541   </td><td style=\"text-align: right;\"> 0.166094  </td><td style=\"text-align: right;\"> 0.421861  </td><td style=\"text-align: right;\"> 0.136801  </td><td style=\"text-align: right;\">-0.11681  </td><td style=\"text-align: right;\">-0.163334  </td><td style=\"text-align: right;\">-0.0581083</td><td style=\"text-align: right;\">-0.158864  </td><td style=\"text-align: right;\"> 0.0991802 </td><td style=\"text-align: right;\">-0.157009 </td><td style=\"text-align: right;\"> 0.299469  </td><td style=\"text-align: right;\">-0.0443993</td><td style=\"text-align: right;\">-0.0668477 </td><td style=\"text-align: right;\">-0.0397008  </td><td style=\"text-align: right;\"> 0.0152228 </td><td style=\"text-align: right;\"> 0.0125098 </td><td style=\"text-align: right;\">-0.229027 </td><td style=\"text-align: right;\">-0.0256575 </td><td style=\"text-align: right;\">-0.152536  </td><td style=\"text-align: right;\"> 0.0809117</td><td style=\"text-align: right;\">-0.182133  </td><td style=\"text-align: right;\"> 0.0761649 </td><td style=\"text-align: right;\">-0.106114 </td><td style=\"text-align: right;\"> 0.112669  </td><td style=\"text-align: right;\"> 0.0769044 </td><td style=\"text-align: right;\"> 0.290035  </td><td style=\"text-align: right;\"> 0.082249 </td><td style=\"text-align: right;\">-0.161454  </td><td style=\"text-align: right;\">-0.23842   </td><td style=\"text-align: right;\"> 0.0490028 </td><td style=\"text-align: right;\"> 0.227777  </td><td style=\"text-align: right;\"> 0.0811296 </td><td style=\"text-align: right;\">-0.172135  </td><td style=\"text-align: right;\"> 0.198609 </td><td style=\"text-align: right;\">-0.048791  </td><td style=\"text-align: right;\"> 0.39733   </td><td style=\"text-align: right;\">-0.0440375 </td><td style=\"text-align: right;\">-0.302422 </td><td style=\"text-align: right;\"> 0.121435  </td><td style=\"text-align: right;\">-0.0814581</td><td style=\"text-align: right;\">-0.457707  </td><td style=\"text-align: right;\">-0.111481   </td><td style=\"text-align: right;\"> 0.157116   </td><td style=\"text-align: right;\">-0.261661  </td><td style=\"text-align: right;\">-0.0290202 </td><td style=\"text-align: right;\">-0.0832653 </td><td style=\"text-align: right;\">-0.15217  </td><td style=\"text-align: right;\"> 0.346027  </td><td style=\"text-align: right;\">-0.12647   </td><td style=\"text-align: right;\"> 0.101427 </td><td style=\"text-align: right;\">-0.0278872 </td><td style=\"text-align: right;\"> 0.0469565  </td><td style=\"text-align: right;\">-0.0606447 </td><td style=\"text-align: right;\"> 0.0924889 </td><td style=\"text-align: right;\">-0.0066635  </td></tr>\n<tr><td style=\"text-align: right;\"> -6.8708 </td><td style=\"text-align: right;\"> 2.68057</td><td style=\"text-align: right;\">-0.0355698  </td><td style=\"text-align: right;\">-0.699036  </td><td style=\"text-align: right;\"> 0.736729</td><td style=\"text-align: right;\"> 0.257921</td><td style=\"text-align: right;\"> 3.02569 </td><td style=\"text-align: right;\"> 1.1828   </td><td style=\"text-align: right;\">  0.413017</td><td style=\"text-align: right;\">  1.53433  </td><td style=\"text-align: right;\"> 5.12066  </td><td style=\"text-align: right;\">-1.7532   </td><td style=\"text-align: right;\">-0.738115 </td><td style=\"text-align: right;\">-2.14663 </td><td style=\"text-align: right;\">-0.683129 </td><td style=\"text-align: right;\">-0.654376</td><td style=\"text-align: right;\">-0.61325  </td><td style=\"text-align: right;\"> 0.185093 </td><td style=\"text-align: right;\"> 0.415841 </td><td style=\"text-align: right;\">-0.534862</td><td style=\"text-align: right;\">-0.220786</td><td style=\"text-align: right;\"> 1.42245  </td><td style=\"text-align: right;\"> 0.176689 </td><td style=\"text-align: right;\"> 0.0192469</td><td style=\"text-align: right;\"> 0.396607  </td><td style=\"text-align: right;\">-0.005357 </td><td style=\"text-align: right;\"> 1.40927  </td><td style=\"text-align: right;\">-0.0209309 </td><td style=\"text-align: right;\">-1.71154 </td><td style=\"text-align: right;\">-0.270967</td><td style=\"text-align: right;\"> 0.503112  </td><td style=\"text-align: right;\">-0.453672 </td><td style=\"text-align: right;\">-0.834217 </td><td style=\"text-align: right;\"> 1.10271  </td><td style=\"text-align: right;\"> 0.392462  </td><td style=\"text-align: right;\"> 1.47327  </td><td style=\"text-align: right;\"> 0.559773 </td><td style=\"text-align: right;\">-1.06503  </td><td style=\"text-align: right;\">-0.155041 </td><td style=\"text-align: right;\">-0.281089  </td><td style=\"text-align: right;\"> 0.336117  </td><td style=\"text-align: right;\"> 0.527712 </td><td style=\"text-align: right;\">-0.547592 </td><td style=\"text-align: right;\"> 0.625531 </td><td style=\"text-align: right;\">-0.584138 </td><td style=\"text-align: right;\">-0.408617 </td><td style=\"text-align: right;\"> 0.212724 </td><td style=\"text-align: right;\">-1.05129  </td><td style=\"text-align: right;\"> 0.307422 </td><td style=\"text-align: right;\"> 0.597414  </td><td style=\"text-align: right;\"> 0.308627  </td><td style=\"text-align: right;\"> 0.0839721</td><td style=\"text-align: right;\"> 1.0917    </td><td style=\"text-align: right;\">-0.797267 </td><td style=\"text-align: right;\"> 0.0857386 </td><td style=\"text-align: right;\"> 0.0500546</td><td style=\"text-align: right;\">-0.187399 </td><td style=\"text-align: right;\"> 0.159411 </td><td style=\"text-align: right;\">-0.0430745 </td><td style=\"text-align: right;\"> 0.0136178 </td><td style=\"text-align: right;\"> 0.29476  </td><td style=\"text-align: right;\">-0.168814  </td><td style=\"text-align: right;\">-0.2206   </td><td style=\"text-align: right;\"> 0.0783109 </td><td style=\"text-align: right;\">-0.132235 </td><td style=\"text-align: right;\"> 0.220012 </td><td style=\"text-align: right;\">-0.188318  </td><td style=\"text-align: right;\"> 0.24743    </td><td style=\"text-align: right;\"> 0.464853  </td><td style=\"text-align: right;\"> 0.0383091</td><td style=\"text-align: right;\">-0.686787 </td><td style=\"text-align: right;\"> 0.111268 </td><td style=\"text-align: right;\"> 0.0162829</td><td style=\"text-align: right;\"> 0.325926 </td><td style=\"text-align: right;\">-0.0904145 </td><td style=\"text-align: right;\"> 0.465747 </td><td style=\"text-align: right;\">-0.016556 </td><td style=\"text-align: right;\">-0.15027   </td><td style=\"text-align: right;\"> 0.207866 </td><td style=\"text-align: right;\"> 0.572747  </td><td style=\"text-align: right;\">-0.0418297</td><td style=\"text-align: right;\">-0.545091  </td><td style=\"text-align: right;\">-0.173507 </td><td style=\"text-align: right;\"> 0.15963   </td><td style=\"text-align: right;\"> 0.1852   </td><td style=\"text-align: right;\"> 0.314861  </td><td style=\"text-align: right;\">-0.299225   </td><td style=\"text-align: right;\"> 0.0272655 </td><td style=\"text-align: right;\">-0.134234  </td><td style=\"text-align: right;\"> 0.0170405 </td><td style=\"text-align: right;\"> 0.336794  </td><td style=\"text-align: right;\"> 0.288353 </td><td style=\"text-align: right;\">-0.139473 </td><td style=\"text-align: right;\"> 0.166308 </td><td style=\"text-align: right;\">-0.121751  </td><td style=\"text-align: right;\">-0.161998 </td><td style=\"text-align: right;\"> 0.0468824</td><td style=\"text-align: right;\">-0.132319 </td><td style=\"text-align: right;\"> 0.138868 </td><td style=\"text-align: right;\"> 0.0860348 </td><td style=\"text-align: right;\"> 0.200801 </td><td style=\"text-align: right;\"> 0.107458  </td><td style=\"text-align: right;\">-0.21358  </td><td style=\"text-align: right;\">-0.106988 </td><td style=\"text-align: right;\">-0.633656 </td><td style=\"text-align: right;\"> 0.121946 </td><td style=\"text-align: right;\">-0.123863  </td><td style=\"text-align: right;\">-0.320828  </td><td style=\"text-align: right;\">-0.344134  </td><td style=\"text-align: right;\"> 0.251929 </td><td style=\"text-align: right;\"> 0.0805143 </td><td style=\"text-align: right;\">-0.221949  </td><td style=\"text-align: right;\">-0.180121  </td><td style=\"text-align: right;\">-0.120502 </td><td style=\"text-align: right;\">-0.22436  </td><td style=\"text-align: right;\"> 0.204527 </td><td style=\"text-align: right;\"> 0.521209 </td><td style=\"text-align: right;\">-0.0929853 </td><td style=\"text-align: right;\">-0.116271  </td><td style=\"text-align: right;\"> 0.0938814</td><td style=\"text-align: right;\">-0.0186209 </td><td style=\"text-align: right;\">-0.122752 </td><td style=\"text-align: right;\">-0.0490904 </td><td style=\"text-align: right;\"> 0.221927  </td><td style=\"text-align: right;\"> 0.0744466  </td><td style=\"text-align: right;\"> 0.122014  </td><td style=\"text-align: right;\">-0.073049  </td><td style=\"text-align: right;\">-0.115816  </td><td style=\"text-align: right;\"> 0.0574372  </td><td style=\"text-align: right;\"> 0.277756  </td><td style=\"text-align: right;\">-0.00358919</td><td style=\"text-align: right;\"> 0.0481752  </td><td style=\"text-align: right;\">-0.341583 </td><td style=\"text-align: right;\"> 0.250432 </td><td style=\"text-align: right;\"> 0.0920894</td><td style=\"text-align: right;\"> 0.10257   </td><td style=\"text-align: right;\">-0.113817   </td><td style=\"text-align: right;\"> 0.10745   </td><td style=\"text-align: right;\"> 0.176046  </td><td style=\"text-align: right;\">-0.149467  </td><td style=\"text-align: right;\">-0.0509981 </td><td style=\"text-align: right;\"> 0.024196  </td><td style=\"text-align: right;\"> 0.00076316</td><td style=\"text-align: right;\">-0.0449122 </td><td style=\"text-align: right;\"> 0.091909  </td><td style=\"text-align: right;\">-0.0479243  </td><td style=\"text-align: right;\"> 0.214462  </td><td style=\"text-align: right;\"> 0.13844   </td><td style=\"text-align: right;\">-0.240763  </td><td style=\"text-align: right;\"> 0.269624 </td><td style=\"text-align: right;\">-0.194052  </td><td style=\"text-align: right;\">-0.209013 </td><td style=\"text-align: right;\"> 0.113906  </td><td style=\"text-align: right;\">-0.194578  </td><td style=\"text-align: right;\"> 0.140454 </td><td style=\"text-align: right;\">-0.1064    </td><td style=\"text-align: right;\">-0.581816 </td><td style=\"text-align: right;\">-0.131183  </td><td style=\"text-align: right;\">-0.349921   </td><td style=\"text-align: right;\">-0.168237  </td><td style=\"text-align: right;\">-0.0816458 </td><td style=\"text-align: right;\">-0.226236 </td><td style=\"text-align: right;\"> 0.150529  </td><td style=\"text-align: right;\"> 0.274294  </td><td style=\"text-align: right;\">-0.165284 </td><td style=\"text-align: right;\"> 0.00747436</td><td style=\"text-align: right;\">-0.0591628 </td><td style=\"text-align: right;\"> 0.0272055</td><td style=\"text-align: right;\">-0.0140462 </td><td style=\"text-align: right;\"> 0.0427684 </td><td style=\"text-align: right;\">-0.16886   </td><td style=\"text-align: right;\">-0.0207045</td><td style=\"text-align: right;\"> 0.186032  </td><td style=\"text-align: right;\">-0.264496  </td><td style=\"text-align: right;\"> 0.177216  </td><td style=\"text-align: right;\">-0.00905544</td><td style=\"text-align: right;\"> 0.0825891 </td><td style=\"text-align: right;\"> 0.246186  </td><td style=\"text-align: right;\"> 0.111854 </td><td style=\"text-align: right;\"> 0.448187  </td><td style=\"text-align: right;\"> 0.0607458 </td><td style=\"text-align: right;\">-0.189043  </td><td style=\"text-align: right;\"> 0.0269027</td><td style=\"text-align: right;\"> 0.299077  </td><td style=\"text-align: right;\">-0.141073 </td><td style=\"text-align: right;\">-0.0316477 </td><td style=\"text-align: right;\"> 0.048967   </td><td style=\"text-align: right;\"> 0.270196   </td><td style=\"text-align: right;\">-0.204264  </td><td style=\"text-align: right;\">-0.0493952 </td><td style=\"text-align: right;\">-0.116593  </td><td style=\"text-align: right;\"> 0.0616901</td><td style=\"text-align: right;\"> 0.229456  </td><td style=\"text-align: right;\"> 0.0879137 </td><td style=\"text-align: right;\">-0.0471718</td><td style=\"text-align: right;\">-0.0450974 </td><td style=\"text-align: right;\">-0.34514    </td><td style=\"text-align: right;\">-0.115519  </td><td style=\"text-align: right;\"> 0.108102  </td><td style=\"text-align: right;\"> 0.00262333 </td></tr>\n<tr><td style=\"text-align: right;\"> -9.7002 </td><td style=\"text-align: right;\"> 2.01993</td><td style=\"text-align: right;\">-0.0419022  </td><td style=\"text-align: right;\">-1.78693   </td><td style=\"text-align: right;\">-0.868938</td><td style=\"text-align: right;\"> 4.90576 </td><td style=\"text-align: right;\"> 3.07665 </td><td style=\"text-align: right;\"> 1.46937  </td><td style=\"text-align: right;\">  0.497968</td><td style=\"text-align: right;\">  2.8248   </td><td style=\"text-align: right;\"> 4.23813  </td><td style=\"text-align: right;\">-0.6334   </td><td style=\"text-align: right;\"> 1.22995  </td><td style=\"text-align: right;\">-1.28486 </td><td style=\"text-align: right;\"> 1.02514  </td><td style=\"text-align: right;\">-0.576321</td><td style=\"text-align: right;\"> 1.38022  </td><td style=\"text-align: right;\"> 1.20001  </td><td style=\"text-align: right;\"> 0.389443 </td><td style=\"text-align: right;\">-1.77273 </td><td style=\"text-align: right;\">-1.24207 </td><td style=\"text-align: right;\"> 1.16477  </td><td style=\"text-align: right;\"> 0.697286 </td><td style=\"text-align: right;\">-0.368327 </td><td style=\"text-align: right;\">-0.00249318</td><td style=\"text-align: right;\">-0.127154 </td><td style=\"text-align: right;\">-0.250148 </td><td style=\"text-align: right;\"> 0.0167133 </td><td style=\"text-align: right;\"> 0.617982</td><td style=\"text-align: right;\"> 0.592714</td><td style=\"text-align: right;\">-0.570079  </td><td style=\"text-align: right;\">-0.0316759</td><td style=\"text-align: right;\"> 0.315347 </td><td style=\"text-align: right;\">-0.637864 </td><td style=\"text-align: right;\"> 0.943744  </td><td style=\"text-align: right;\">-0.95563  </td><td style=\"text-align: right;\"> 0.0187535</td><td style=\"text-align: right;\"> 0.840864 </td><td style=\"text-align: right;\"> 0.614452 </td><td style=\"text-align: right;\"> 0.703567  </td><td style=\"text-align: right;\"> 0.732973  </td><td style=\"text-align: right;\">-0.135743 </td><td style=\"text-align: right;\"> 0.614975 </td><td style=\"text-align: right;\">-0.575716 </td><td style=\"text-align: right;\">-0.0218175</td><td style=\"text-align: right;\"> 0.879477 </td><td style=\"text-align: right;\">-0.0555101</td><td style=\"text-align: right;\"> 0.987613 </td><td style=\"text-align: right;\"> 0.5341   </td><td style=\"text-align: right;\"> 0.544382  </td><td style=\"text-align: right;\"> 0.144836  </td><td style=\"text-align: right;\">-0.530193 </td><td style=\"text-align: right;\"> 0.55032   </td><td style=\"text-align: right;\"> 0.189941 </td><td style=\"text-align: right;\"> 0.568939  </td><td style=\"text-align: right;\"> 0.555888 </td><td style=\"text-align: right;\">-1.45468  </td><td style=\"text-align: right;\"> 0.100443 </td><td style=\"text-align: right;\"> 0.243123  </td><td style=\"text-align: right;\">-0.106879  </td><td style=\"text-align: right;\">-0.545287 </td><td style=\"text-align: right;\"> 0.300738  </td><td style=\"text-align: right;\"> 0.213071 </td><td style=\"text-align: right;\"> 0.418881  </td><td style=\"text-align: right;\"> 0.230577 </td><td style=\"text-align: right;\">-0.797578 </td><td style=\"text-align: right;\"> 0.00839976</td><td style=\"text-align: right;\">-0.514347   </td><td style=\"text-align: right;\">-0.397928  </td><td style=\"text-align: right;\"> 0.251805 </td><td style=\"text-align: right;\"> 0.0655922</td><td style=\"text-align: right;\">-0.284184 </td><td style=\"text-align: right;\">-0.244452 </td><td style=\"text-align: right;\"> 0.0890336</td><td style=\"text-align: right;\">-0.235954  </td><td style=\"text-align: right;\"> 0.0687547</td><td style=\"text-align: right;\"> 0.59685  </td><td style=\"text-align: right;\">-0.381562  </td><td style=\"text-align: right;\"> 0.217461 </td><td style=\"text-align: right;\">-0.115784  </td><td style=\"text-align: right;\">-0.220976 </td><td style=\"text-align: right;\"> 0.135589  </td><td style=\"text-align: right;\"> 0.380991 </td><td style=\"text-align: right;\">-0.376626  </td><td style=\"text-align: right;\"> 0.153256 </td><td style=\"text-align: right;\"> 0.124564  </td><td style=\"text-align: right;\">-0.0237586  </td><td style=\"text-align: right;\"> 0.156169  </td><td style=\"text-align: right;\">-0.0594366 </td><td style=\"text-align: right;\"> 0.0874143 </td><td style=\"text-align: right;\">-0.296594  </td><td style=\"text-align: right;\">-0.0797775</td><td style=\"text-align: right;\"> 0.115377 </td><td style=\"text-align: right;\">-0.17258  </td><td style=\"text-align: right;\">-0.20333   </td><td style=\"text-align: right;\">-0.390256 </td><td style=\"text-align: right;\"> 0.61364  </td><td style=\"text-align: right;\"> 0.208968 </td><td style=\"text-align: right;\"> 0.196587 </td><td style=\"text-align: right;\"> 0.462276  </td><td style=\"text-align: right;\">-0.519164 </td><td style=\"text-align: right;\"> 0.158059  </td><td style=\"text-align: right;\"> 0.155647 </td><td style=\"text-align: right;\">-0.12425  </td><td style=\"text-align: right;\"> 0.0731028</td><td style=\"text-align: right;\"> 0.142651 </td><td style=\"text-align: right;\">-0.130596  </td><td style=\"text-align: right;\"> 0.217428  </td><td style=\"text-align: right;\"> 0.325612  </td><td style=\"text-align: right;\"> 0.215072 </td><td style=\"text-align: right;\">-0.101754  </td><td style=\"text-align: right;\">-0.514854  </td><td style=\"text-align: right;\"> 0.0425049 </td><td style=\"text-align: right;\"> 0.430603 </td><td style=\"text-align: right;\">-0.568491 </td><td style=\"text-align: right;\">-0.265812 </td><td style=\"text-align: right;\">-0.560729 </td><td style=\"text-align: right;\"> 0.140233  </td><td style=\"text-align: right;\">-0.331596  </td><td style=\"text-align: right;\"> 0.399495 </td><td style=\"text-align: right;\"> 0.0114895 </td><td style=\"text-align: right;\">-0.380821 </td><td style=\"text-align: right;\"> 0.0857853 </td><td style=\"text-align: right;\"> 0.476789  </td><td style=\"text-align: right;\"> 0.117023   </td><td style=\"text-align: right;\"> 0.0347636 </td><td style=\"text-align: right;\">-0.321351  </td><td style=\"text-align: right;\"> 0.0941885 </td><td style=\"text-align: right;\">-0.13162    </td><td style=\"text-align: right;\">-0.303511  </td><td style=\"text-align: right;\">-0.215142  </td><td style=\"text-align: right;\">-0.122692   </td><td style=\"text-align: right;\"> 0.898417 </td><td style=\"text-align: right;\">-0.0212619</td><td style=\"text-align: right;\">-0.231751 </td><td style=\"text-align: right;\"> 0.00636333</td><td style=\"text-align: right;\">-0.107066   </td><td style=\"text-align: right;\">-0.302672  </td><td style=\"text-align: right;\"> 0.21904   </td><td style=\"text-align: right;\">-0.264316  </td><td style=\"text-align: right;\">-0.114049  </td><td style=\"text-align: right;\">-0.359548  </td><td style=\"text-align: right;\"> 0.043984  </td><td style=\"text-align: right;\">-0.417547  </td><td style=\"text-align: right;\">-0.0733333 </td><td style=\"text-align: right;\"> 0.219099   </td><td style=\"text-align: right;\"> 0.00445267</td><td style=\"text-align: right;\">-0.24492   </td><td style=\"text-align: right;\">-0.00254248</td><td style=\"text-align: right;\"> 0.270459 </td><td style=\"text-align: right;\"> 0.258728  </td><td style=\"text-align: right;\"> 0.0124197</td><td style=\"text-align: right;\"> 0.0574718 </td><td style=\"text-align: right;\"> 0.118086  </td><td style=\"text-align: right;\"> 0.100874 </td><td style=\"text-align: right;\">-0.287752  </td><td style=\"text-align: right;\"> 0.216107 </td><td style=\"text-align: right;\">-0.524942  </td><td style=\"text-align: right;\">-0.188604   </td><td style=\"text-align: right;\"> 0.222052  </td><td style=\"text-align: right;\">-0.288676  </td><td style=\"text-align: right;\"> 0.0389674</td><td style=\"text-align: right;\">-0.039381  </td><td style=\"text-align: right;\">-0.0241603 </td><td style=\"text-align: right;\"> 0.131161 </td><td style=\"text-align: right;\"> 0.149168  </td><td style=\"text-align: right;\">-0.50884   </td><td style=\"text-align: right;\"> 0.314479 </td><td style=\"text-align: right;\"> 0.325975  </td><td style=\"text-align: right;\">-0.0304763 </td><td style=\"text-align: right;\"> 0.597556  </td><td style=\"text-align: right;\">-0.0751168</td><td style=\"text-align: right;\"> 0.285042  </td><td style=\"text-align: right;\"> 0.404374  </td><td style=\"text-align: right;\"> 0.340443  </td><td style=\"text-align: right;\">-0.246579  </td><td style=\"text-align: right;\"> 0.248091  </td><td style=\"text-align: right;\"> 0.225155  </td><td style=\"text-align: right;\">-0.158595 </td><td style=\"text-align: right;\">-0.219442  </td><td style=\"text-align: right;\">-0.00982387</td><td style=\"text-align: right;\">-0.0913876 </td><td style=\"text-align: right;\"> 0.116182 </td><td style=\"text-align: right;\"> 0.0220935 </td><td style=\"text-align: right;\">-0.179899 </td><td style=\"text-align: right;\"> 0.118903  </td><td style=\"text-align: right;\"> 0.164548   </td><td style=\"text-align: right;\">-0.103457   </td><td style=\"text-align: right;\">-0.324     </td><td style=\"text-align: right;\">-0.194148  </td><td style=\"text-align: right;\"> 0.205753  </td><td style=\"text-align: right;\"> 0.277896 </td><td style=\"text-align: right;\">-0.429106  </td><td style=\"text-align: right;\"> 0.325799  </td><td style=\"text-align: right;\">-0.452503 </td><td style=\"text-align: right;\">-0.35914   </td><td style=\"text-align: right;\"> 0.0457975  </td><td style=\"text-align: right;\">-0.103766  </td><td style=\"text-align: right;\">-0.226946  </td><td style=\"text-align: right;\">-0.345405   </td></tr>\n<tr><td style=\"text-align: right;\"> -8.54219</td><td style=\"text-align: right;\"> 1.20221</td><td style=\"text-align: right;\">-0.0337894  </td><td style=\"text-align: right;\">-1.70933   </td><td style=\"text-align: right;\">-1.31788 </td><td style=\"text-align: right;\"> 4.43432 </td><td style=\"text-align: right;\"> 2.78561 </td><td style=\"text-align: right;\"> 1.62459  </td><td style=\"text-align: right;\">  0.844757</td><td style=\"text-align: right;\">  1.30749  </td><td style=\"text-align: right;\"> 3.03594  </td><td style=\"text-align: right;\">-0.389582 </td><td style=\"text-align: right;\"> 1.38847  </td><td style=\"text-align: right;\">-0.790943</td><td style=\"text-align: right;\"> 0.411406 </td><td style=\"text-align: right;\">-0.215496</td><td style=\"text-align: right;\"> 0.0373483</td><td style=\"text-align: right;\"> 0.888375 </td><td style=\"text-align: right;\"> 0.217075 </td><td style=\"text-align: right;\">-1.25865 </td><td style=\"text-align: right;\">-0.840179</td><td style=\"text-align: right;\"> 0.762913 </td><td style=\"text-align: right;\"> 0.464845 </td><td style=\"text-align: right;\">-0.653663 </td><td style=\"text-align: right;\">-0.140936  </td><td style=\"text-align: right;\">-0.0993573</td><td style=\"text-align: right;\"> 0.698259 </td><td style=\"text-align: right;\">-0.0461487 </td><td style=\"text-align: right;\"> 0.244734</td><td style=\"text-align: right;\">-0.219995</td><td style=\"text-align: right;\"> 0.0686529 </td><td style=\"text-align: right;\">-0.408289 </td><td style=\"text-align: right;\">-0.0627849</td><td style=\"text-align: right;\">-0.532491 </td><td style=\"text-align: right;\"> 1.05035   </td><td style=\"text-align: right;\">-0.830271 </td><td style=\"text-align: right;\">-0.37178  </td><td style=\"text-align: right;\"> 0.551295 </td><td style=\"text-align: right;\">-0.0337151</td><td style=\"text-align: right;\"> 0.0254299 </td><td style=\"text-align: right;\">-0.739716  </td><td style=\"text-align: right;\">-0.237236 </td><td style=\"text-align: right;\">-0.268804 </td><td style=\"text-align: right;\"> 0.0528469</td><td style=\"text-align: right;\"> 0.253406 </td><td style=\"text-align: right;\">-0.314882 </td><td style=\"text-align: right;\"> 0.63836  </td><td style=\"text-align: right;\"> 0.479703 </td><td style=\"text-align: right;\">-0.512762 </td><td style=\"text-align: right;\"> 0.00980382</td><td style=\"text-align: right;\"> 0.0365693 </td><td style=\"text-align: right;\"> 0.283264 </td><td style=\"text-align: right;\"> 0.385486  </td><td style=\"text-align: right;\"> 0.844663 </td><td style=\"text-align: right;\">-0.722482  </td><td style=\"text-align: right;\"> 0.389155 </td><td style=\"text-align: right;\"> 0.518976 </td><td style=\"text-align: right;\"> 0.140026 </td><td style=\"text-align: right;\"> 0.367951  </td><td style=\"text-align: right;\"> 0.0578155 </td><td style=\"text-align: right;\">-0.237808 </td><td style=\"text-align: right;\"> 0.726078  </td><td style=\"text-align: right;\"> 0.0794338</td><td style=\"text-align: right;\">-0.396036  </td><td style=\"text-align: right;\"> 0.223692 </td><td style=\"text-align: right;\"> 0.564151 </td><td style=\"text-align: right;\"> 0.0105188 </td><td style=\"text-align: right;\">-0.751705   </td><td style=\"text-align: right;\">-0.127846  </td><td style=\"text-align: right;\"> 0.0994481</td><td style=\"text-align: right;\">-0.601196 </td><td style=\"text-align: right;\">-0.17901  </td><td style=\"text-align: right;\">-0.440456 </td><td style=\"text-align: right;\">-0.424434 </td><td style=\"text-align: right;\">-0.0342483 </td><td style=\"text-align: right;\">-0.281859 </td><td style=\"text-align: right;\"> 0.235901 </td><td style=\"text-align: right;\"> 0.18012   </td><td style=\"text-align: right;\"> 0.360096 </td><td style=\"text-align: right;\">-0.317282  </td><td style=\"text-align: right;\">-0.0694499</td><td style=\"text-align: right;\">-0.363567  </td><td style=\"text-align: right;\">-0.116735 </td><td style=\"text-align: right;\"> 0.340759  </td><td style=\"text-align: right;\">-0.673291 </td><td style=\"text-align: right;\"> 0.884106  </td><td style=\"text-align: right;\"> 0.606648   </td><td style=\"text-align: right;\"> 0.294978  </td><td style=\"text-align: right;\"> 0.175188  </td><td style=\"text-align: right;\">-0.245768  </td><td style=\"text-align: right;\"> 0.269212  </td><td style=\"text-align: right;\">-0.0200029</td><td style=\"text-align: right;\"> 0.124079 </td><td style=\"text-align: right;\"> 0.0252647</td><td style=\"text-align: right;\"> 0.21792   </td><td style=\"text-align: right;\"> 0.409602 </td><td style=\"text-align: right;\">-0.589638 </td><td style=\"text-align: right;\">-0.327337 </td><td style=\"text-align: right;\">-0.0520886</td><td style=\"text-align: right;\"> 0.411777  </td><td style=\"text-align: right;\"> 0.09315  </td><td style=\"text-align: right;\">-0.143922  </td><td style=\"text-align: right;\"> 0.38183  </td><td style=\"text-align: right;\"> 0.0916742</td><td style=\"text-align: right;\"> 0.201024 </td><td style=\"text-align: right;\">-0.10852  </td><td style=\"text-align: right;\"> 0.320168  </td><td style=\"text-align: right;\">-0.259112  </td><td style=\"text-align: right;\"> 0.39255   </td><td style=\"text-align: right;\">-0.172737 </td><td style=\"text-align: right;\"> 0.371132  </td><td style=\"text-align: right;\"> 0.460941  </td><td style=\"text-align: right;\">-0.0133471 </td><td style=\"text-align: right;\">-0.238938 </td><td style=\"text-align: right;\">-0.226956 </td><td style=\"text-align: right;\"> 0.297199 </td><td style=\"text-align: right;\">-0.314315 </td><td style=\"text-align: right;\"> 0.165405  </td><td style=\"text-align: right;\"> 0.0842257 </td><td style=\"text-align: right;\">-0.400583 </td><td style=\"text-align: right;\"> 0.151181  </td><td style=\"text-align: right;\"> 0.346786 </td><td style=\"text-align: right;\"> 0.275771  </td><td style=\"text-align: right;\">-0.433518  </td><td style=\"text-align: right;\">-0.234866   </td><td style=\"text-align: right;\">-0.367062  </td><td style=\"text-align: right;\"> 0.214556  </td><td style=\"text-align: right;\">-0.620324  </td><td style=\"text-align: right;\">-0.284036   </td><td style=\"text-align: right;\"> 0.230501  </td><td style=\"text-align: right;\"> 0.0543145 </td><td style=\"text-align: right;\"> 0.110878   </td><td style=\"text-align: right;\">-0.602834 </td><td style=\"text-align: right;\"> 0.455412 </td><td style=\"text-align: right;\"> 0.325825 </td><td style=\"text-align: right;\">-0.0291731 </td><td style=\"text-align: right;\"> 0.4177     </td><td style=\"text-align: right;\">-0.0487769 </td><td style=\"text-align: right;\"> 0.719916  </td><td style=\"text-align: right;\"> 0.091659  </td><td style=\"text-align: right;\">-0.0373595 </td><td style=\"text-align: right;\"> 0.0773591 </td><td style=\"text-align: right;\">-0.135434  </td><td style=\"text-align: right;\"> 0.0181273 </td><td style=\"text-align: right;\"> 0.0261117 </td><td style=\"text-align: right;\"> 0.14644    </td><td style=\"text-align: right;\">-0.0933808 </td><td style=\"text-align: right;\"> 0.105142  </td><td style=\"text-align: right;\"> 0.24001   </td><td style=\"text-align: right;\"> 0.0931343</td><td style=\"text-align: right;\"> 0.0627232 </td><td style=\"text-align: right;\"> 0.101432 </td><td style=\"text-align: right;\">-0.11545   </td><td style=\"text-align: right;\"> 0.102735  </td><td style=\"text-align: right;\">-0.0011381</td><td style=\"text-align: right;\"> 0.520417  </td><td style=\"text-align: right;\">-0.0511215</td><td style=\"text-align: right;\"> 0.347643  </td><td style=\"text-align: right;\"> 0.156714   </td><td style=\"text-align: right;\">-0.248581  </td><td style=\"text-align: right;\">-0.213454  </td><td style=\"text-align: right;\">-0.277386 </td><td style=\"text-align: right;\"> 0.193475  </td><td style=\"text-align: right;\"> 0.0239697 </td><td style=\"text-align: right;\"> 0.345145 </td><td style=\"text-align: right;\">-0.284584  </td><td style=\"text-align: right;\">-0.189322  </td><td style=\"text-align: right;\">-0.287148 </td><td style=\"text-align: right;\">-0.207969  </td><td style=\"text-align: right;\">-0.202163  </td><td style=\"text-align: right;\">-0.0796535 </td><td style=\"text-align: right;\">-0.105895 </td><td style=\"text-align: right;\">-0.229858  </td><td style=\"text-align: right;\">-0.236454  </td><td style=\"text-align: right;\">-0.246952  </td><td style=\"text-align: right;\"> 0.103366  </td><td style=\"text-align: right;\">-0.0597777 </td><td style=\"text-align: right;\">-0.110702  </td><td style=\"text-align: right;\"> 0.254327 </td><td style=\"text-align: right;\"> 0.00290837</td><td style=\"text-align: right;\"> 0.111981  </td><td style=\"text-align: right;\">-0.240961  </td><td style=\"text-align: right;\"> 0.0804205</td><td style=\"text-align: right;\">-0.203052  </td><td style=\"text-align: right;\"> 0.291348 </td><td style=\"text-align: right;\"> 0.380352  </td><td style=\"text-align: right;\"> 0.339571   </td><td style=\"text-align: right;\">-0.166293   </td><td style=\"text-align: right;\">-0.205874  </td><td style=\"text-align: right;\">-0.10269   </td><td style=\"text-align: right;\">-0.173863  </td><td style=\"text-align: right;\">-0.411589 </td><td style=\"text-align: right;\"> 0.0428641 </td><td style=\"text-align: right;\">-0.0847032 </td><td style=\"text-align: right;\"> 0.371689 </td><td style=\"text-align: right;\">-0.238893  </td><td style=\"text-align: right;\"> 0.530464   </td><td style=\"text-align: right;\"> 0.244679  </td><td style=\"text-align: right;\"> 0.389905  </td><td style=\"text-align: right;\"> 0.34426    </td></tr>\n</tbody>\n</table>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604993158054
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create new dataframes from the PCA components"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_frame_pca_df = train_frame_pca.as_data_frame()\r\n",
        "train_frame_pca_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 42,
          "data": {
            "text/plain": "         PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n0  -7.215279  5.487787 -0.045743 -3.295824 -8.025171 -2.949743 -2.967593   \n1 -11.599985  5.534724 -0.067638  0.442869  6.543390  0.485848 -2.291297   \n2  -9.149900 -4.451211 -0.000561 -0.211492  0.891811 -1.619368 -0.031481   \n3  -4.590492  5.312944 -0.043539 -1.586112 -3.702485 -0.156249  2.930343   \n4  -8.682463 -4.772522  0.003525  0.094409  0.517031 -3.716390  0.988545   \n\n        PC8       PC9      PC10    ...        PC291     PC292     PC293  \\\n0 -2.266287 -0.652408  0.578522    ...     0.012587  0.371804 -0.071848   \n1 -1.485078 -1.267895  2.487861    ...     0.054867  0.137572  0.059569   \n2 -1.116217 -0.521429  0.226712    ...    -0.161497  0.041387  0.080233   \n3 -4.974554 -0.930162 -0.817911    ...    -0.465097  0.220127  0.127802   \n4  0.652860 -0.217747  0.573477    ...    -0.182978 -0.093368  0.121302   \n\n      PC294     PC295     PC296     PC297     PC298     PC299     PC300  \n0 -0.341443  0.465335 -0.433011 -0.265740 -0.491029 -0.128080  0.655469  \n1  0.114289 -0.194232  0.028769  0.060136  0.102203  0.070037 -0.115447  \n2 -0.031551  0.088953  0.104130  0.031573 -0.036647  0.139434  0.224164  \n3  0.044233  0.098754  0.005934 -0.151121  0.346246  0.041682 -0.487852  \n4  0.067732 -0.121732  0.079970 -0.121168  0.044018 -0.070295  0.017215  \n\n[5 rows x 300 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PC1</th>\n      <th>PC2</th>\n      <th>PC3</th>\n      <th>PC4</th>\n      <th>PC5</th>\n      <th>PC6</th>\n      <th>PC7</th>\n      <th>PC8</th>\n      <th>PC9</th>\n      <th>PC10</th>\n      <th>...</th>\n      <th>PC291</th>\n      <th>PC292</th>\n      <th>PC293</th>\n      <th>PC294</th>\n      <th>PC295</th>\n      <th>PC296</th>\n      <th>PC297</th>\n      <th>PC298</th>\n      <th>PC299</th>\n      <th>PC300</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-7.215279</td>\n      <td>5.487787</td>\n      <td>-0.045743</td>\n      <td>-3.295824</td>\n      <td>-8.025171</td>\n      <td>-2.949743</td>\n      <td>-2.967593</td>\n      <td>-2.266287</td>\n      <td>-0.652408</td>\n      <td>0.578522</td>\n      <td>...</td>\n      <td>0.012587</td>\n      <td>0.371804</td>\n      <td>-0.071848</td>\n      <td>-0.341443</td>\n      <td>0.465335</td>\n      <td>-0.433011</td>\n      <td>-0.265740</td>\n      <td>-0.491029</td>\n      <td>-0.128080</td>\n      <td>0.655469</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-11.599985</td>\n      <td>5.534724</td>\n      <td>-0.067638</td>\n      <td>0.442869</td>\n      <td>6.543390</td>\n      <td>0.485848</td>\n      <td>-2.291297</td>\n      <td>-1.485078</td>\n      <td>-1.267895</td>\n      <td>2.487861</td>\n      <td>...</td>\n      <td>0.054867</td>\n      <td>0.137572</td>\n      <td>0.059569</td>\n      <td>0.114289</td>\n      <td>-0.194232</td>\n      <td>0.028769</td>\n      <td>0.060136</td>\n      <td>0.102203</td>\n      <td>0.070037</td>\n      <td>-0.115447</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-9.149900</td>\n      <td>-4.451211</td>\n      <td>-0.000561</td>\n      <td>-0.211492</td>\n      <td>0.891811</td>\n      <td>-1.619368</td>\n      <td>-0.031481</td>\n      <td>-1.116217</td>\n      <td>-0.521429</td>\n      <td>0.226712</td>\n      <td>...</td>\n      <td>-0.161497</td>\n      <td>0.041387</td>\n      <td>0.080233</td>\n      <td>-0.031551</td>\n      <td>0.088953</td>\n      <td>0.104130</td>\n      <td>0.031573</td>\n      <td>-0.036647</td>\n      <td>0.139434</td>\n      <td>0.224164</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-4.590492</td>\n      <td>5.312944</td>\n      <td>-0.043539</td>\n      <td>-1.586112</td>\n      <td>-3.702485</td>\n      <td>-0.156249</td>\n      <td>2.930343</td>\n      <td>-4.974554</td>\n      <td>-0.930162</td>\n      <td>-0.817911</td>\n      <td>...</td>\n      <td>-0.465097</td>\n      <td>0.220127</td>\n      <td>0.127802</td>\n      <td>0.044233</td>\n      <td>0.098754</td>\n      <td>0.005934</td>\n      <td>-0.151121</td>\n      <td>0.346246</td>\n      <td>0.041682</td>\n      <td>-0.487852</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-8.682463</td>\n      <td>-4.772522</td>\n      <td>0.003525</td>\n      <td>0.094409</td>\n      <td>0.517031</td>\n      <td>-3.716390</td>\n      <td>0.988545</td>\n      <td>0.652860</td>\n      <td>-0.217747</td>\n      <td>0.573477</td>\n      <td>...</td>\n      <td>-0.182978</td>\n      <td>-0.093368</td>\n      <td>0.121302</td>\n      <td>0.067732</td>\n      <td>-0.121732</td>\n      <td>0.079970</td>\n      <td>-0.121168</td>\n      <td>0.044018</td>\n      <td>-0.070295</td>\n      <td>0.017215</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 300 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 42,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604809447737
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_frame_pca_df = test_frame_pca.as_data_frame()\r\n",
        "test_frame_pca_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 43,
          "data": {
            "text/plain": "         PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n0  -9.629457  3.427494 -0.054488 -1.997283 -0.501536  5.336753  1.883176   \n1  -6.500589  5.032125  9.899641 -1.751147 -1.998420  5.184365  5.728812   \n2 -12.947850  4.520129 -0.072757  0.795501  5.604925 -3.833929 -0.123111   \n3  -8.945284 -5.015450  0.002182  0.197580  0.776913 -3.340270  0.435418   \n4  -8.616033 -5.402211  0.008112 -0.470638 -0.436735  2.802968 -0.717564   \n\n         PC8        PC9       PC10    ...        PC291     PC292     PC293  \\\n0   2.342219   0.550157   2.244874    ...     0.127281  0.080378  0.342437   \n1  22.975901 -72.911270 -19.434493    ...    -0.005212 -0.002507 -0.001169   \n2   0.276374  -0.394928   1.513401    ...    -0.052364 -0.218587  0.404883   \n3  -0.418539  -0.392206   0.062804    ...     0.033338 -0.027150  0.042037   \n4   0.032025   0.384208  -0.915967    ...     0.317406 -0.058061  0.173129   \n\n      PC294     PC295     PC296     PC297     PC298     PC299     PC300  \n0 -0.283436 -0.272764 -0.157943 -0.103696 -0.056571 -0.413420 -0.201708  \n1  0.001140 -0.000947  0.004027  0.005030 -0.003485  0.002891 -0.003535  \n2  0.508618  0.063992  0.420349 -0.243656 -0.125900 -0.114601  0.135860  \n3 -0.027205 -0.192404 -0.003779 -0.075270 -0.038884  0.059448  0.089166  \n4  0.315004  0.085500  0.000209  0.275298  0.104563 -0.004634  0.090837  \n\n[5 rows x 300 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PC1</th>\n      <th>PC2</th>\n      <th>PC3</th>\n      <th>PC4</th>\n      <th>PC5</th>\n      <th>PC6</th>\n      <th>PC7</th>\n      <th>PC8</th>\n      <th>PC9</th>\n      <th>PC10</th>\n      <th>...</th>\n      <th>PC291</th>\n      <th>PC292</th>\n      <th>PC293</th>\n      <th>PC294</th>\n      <th>PC295</th>\n      <th>PC296</th>\n      <th>PC297</th>\n      <th>PC298</th>\n      <th>PC299</th>\n      <th>PC300</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-9.629457</td>\n      <td>3.427494</td>\n      <td>-0.054488</td>\n      <td>-1.997283</td>\n      <td>-0.501536</td>\n      <td>5.336753</td>\n      <td>1.883176</td>\n      <td>2.342219</td>\n      <td>0.550157</td>\n      <td>2.244874</td>\n      <td>...</td>\n      <td>0.127281</td>\n      <td>0.080378</td>\n      <td>0.342437</td>\n      <td>-0.283436</td>\n      <td>-0.272764</td>\n      <td>-0.157943</td>\n      <td>-0.103696</td>\n      <td>-0.056571</td>\n      <td>-0.413420</td>\n      <td>-0.201708</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-6.500589</td>\n      <td>5.032125</td>\n      <td>9.899641</td>\n      <td>-1.751147</td>\n      <td>-1.998420</td>\n      <td>5.184365</td>\n      <td>5.728812</td>\n      <td>22.975901</td>\n      <td>-72.911270</td>\n      <td>-19.434493</td>\n      <td>...</td>\n      <td>-0.005212</td>\n      <td>-0.002507</td>\n      <td>-0.001169</td>\n      <td>0.001140</td>\n      <td>-0.000947</td>\n      <td>0.004027</td>\n      <td>0.005030</td>\n      <td>-0.003485</td>\n      <td>0.002891</td>\n      <td>-0.003535</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-12.947850</td>\n      <td>4.520129</td>\n      <td>-0.072757</td>\n      <td>0.795501</td>\n      <td>5.604925</td>\n      <td>-3.833929</td>\n      <td>-0.123111</td>\n      <td>0.276374</td>\n      <td>-0.394928</td>\n      <td>1.513401</td>\n      <td>...</td>\n      <td>-0.052364</td>\n      <td>-0.218587</td>\n      <td>0.404883</td>\n      <td>0.508618</td>\n      <td>0.063992</td>\n      <td>0.420349</td>\n      <td>-0.243656</td>\n      <td>-0.125900</td>\n      <td>-0.114601</td>\n      <td>0.135860</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-8.945284</td>\n      <td>-5.015450</td>\n      <td>0.002182</td>\n      <td>0.197580</td>\n      <td>0.776913</td>\n      <td>-3.340270</td>\n      <td>0.435418</td>\n      <td>-0.418539</td>\n      <td>-0.392206</td>\n      <td>0.062804</td>\n      <td>...</td>\n      <td>0.033338</td>\n      <td>-0.027150</td>\n      <td>0.042037</td>\n      <td>-0.027205</td>\n      <td>-0.192404</td>\n      <td>-0.003779</td>\n      <td>-0.075270</td>\n      <td>-0.038884</td>\n      <td>0.059448</td>\n      <td>0.089166</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-8.616033</td>\n      <td>-5.402211</td>\n      <td>0.008112</td>\n      <td>-0.470638</td>\n      <td>-0.436735</td>\n      <td>2.802968</td>\n      <td>-0.717564</td>\n      <td>0.032025</td>\n      <td>0.384208</td>\n      <td>-0.915967</td>\n      <td>...</td>\n      <td>0.317406</td>\n      <td>-0.058061</td>\n      <td>0.173129</td>\n      <td>0.315004</td>\n      <td>0.085500</td>\n      <td>0.000209</td>\n      <td>0.275298</td>\n      <td>0.104563</td>\n      <td>-0.004634</td>\n      <td>0.090837</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 300 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 43,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604809448050
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response_col_df = train_frame[response_col].as_data_frame()\r\n",
        "index_col_df = train_frame[index_col].as_data_frame()\r\n",
        "\r\n",
        "train_pca_df = (train_frame_pca_df.join(response_col_df)).join(index_col_df).set_index('SampleID')\r\n",
        "train_pca_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 44,
          "data": {
            "text/plain": "                   PC1       PC2       PC3       PC4       PC5       PC6  \\\nSampleID                                                                   \nSRR10525336  -7.215279  5.487787 -0.045743 -3.295824 -8.025171 -2.949743   \nSRR10380004 -11.599985  5.534724 -0.067638  0.442869  6.543390  0.485848   \nSRR6807701   -9.149900 -4.451211 -0.000561 -0.211492  0.891811 -1.619368   \nSRR11033700  -4.590492  5.312944 -0.043539 -1.586112 -3.702485 -0.156249   \nSRR1163101   -8.682463 -4.772522  0.003525  0.094409  0.517031 -3.716390   \n\n                  PC7       PC8       PC9      PC10        ...          \\\nSampleID                                                   ...           \nSRR10525336 -2.967593 -2.266287 -0.652408  0.578522        ...           \nSRR10380004 -2.291297 -1.485078 -1.267895  2.487861        ...           \nSRR6807701  -0.031481 -1.116217 -0.521429  0.226712        ...           \nSRR11033700  2.930343 -4.974554 -0.930162 -0.817911        ...           \nSRR1163101   0.988545  0.652860 -0.217747  0.573477        ...           \n\n                PC292     PC293     PC294     PC295     PC296     PC297  \\\nSampleID                                                                  \nSRR10525336  0.371804 -0.071848 -0.341443  0.465335 -0.433011 -0.265740   \nSRR10380004  0.137572  0.059569  0.114289 -0.194232  0.028769  0.060136   \nSRR6807701   0.041387  0.080233 -0.031551  0.088953  0.104130  0.031573   \nSRR11033700  0.220127  0.127802  0.044233  0.098754  0.005934 -0.151121   \nSRR1163101  -0.093368  0.121302  0.067732 -0.121732  0.079970 -0.121168   \n\n                PC298     PC299     PC300  Resistance_Status  \nSampleID                                                      \nSRR10525336 -0.491029 -0.128080  0.655469                  1  \nSRR10380004  0.102203  0.070037 -0.115447                  1  \nSRR6807701  -0.036647  0.139434  0.224164                  1  \nSRR11033700  0.346246  0.041682 -0.487852                  1  \nSRR1163101   0.044018 -0.070295  0.017215                  1  \n\n[5 rows x 301 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PC1</th>\n      <th>PC2</th>\n      <th>PC3</th>\n      <th>PC4</th>\n      <th>PC5</th>\n      <th>PC6</th>\n      <th>PC7</th>\n      <th>PC8</th>\n      <th>PC9</th>\n      <th>PC10</th>\n      <th>...</th>\n      <th>PC292</th>\n      <th>PC293</th>\n      <th>PC294</th>\n      <th>PC295</th>\n      <th>PC296</th>\n      <th>PC297</th>\n      <th>PC298</th>\n      <th>PC299</th>\n      <th>PC300</th>\n      <th>Resistance_Status</th>\n    </tr>\n    <tr>\n      <th>SampleID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>SRR10525336</th>\n      <td>-7.215279</td>\n      <td>5.487787</td>\n      <td>-0.045743</td>\n      <td>-3.295824</td>\n      <td>-8.025171</td>\n      <td>-2.949743</td>\n      <td>-2.967593</td>\n      <td>-2.266287</td>\n      <td>-0.652408</td>\n      <td>0.578522</td>\n      <td>...</td>\n      <td>0.371804</td>\n      <td>-0.071848</td>\n      <td>-0.341443</td>\n      <td>0.465335</td>\n      <td>-0.433011</td>\n      <td>-0.265740</td>\n      <td>-0.491029</td>\n      <td>-0.128080</td>\n      <td>0.655469</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>SRR10380004</th>\n      <td>-11.599985</td>\n      <td>5.534724</td>\n      <td>-0.067638</td>\n      <td>0.442869</td>\n      <td>6.543390</td>\n      <td>0.485848</td>\n      <td>-2.291297</td>\n      <td>-1.485078</td>\n      <td>-1.267895</td>\n      <td>2.487861</td>\n      <td>...</td>\n      <td>0.137572</td>\n      <td>0.059569</td>\n      <td>0.114289</td>\n      <td>-0.194232</td>\n      <td>0.028769</td>\n      <td>0.060136</td>\n      <td>0.102203</td>\n      <td>0.070037</td>\n      <td>-0.115447</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>SRR6807701</th>\n      <td>-9.149900</td>\n      <td>-4.451211</td>\n      <td>-0.000561</td>\n      <td>-0.211492</td>\n      <td>0.891811</td>\n      <td>-1.619368</td>\n      <td>-0.031481</td>\n      <td>-1.116217</td>\n      <td>-0.521429</td>\n      <td>0.226712</td>\n      <td>...</td>\n      <td>0.041387</td>\n      <td>0.080233</td>\n      <td>-0.031551</td>\n      <td>0.088953</td>\n      <td>0.104130</td>\n      <td>0.031573</td>\n      <td>-0.036647</td>\n      <td>0.139434</td>\n      <td>0.224164</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>SRR11033700</th>\n      <td>-4.590492</td>\n      <td>5.312944</td>\n      <td>-0.043539</td>\n      <td>-1.586112</td>\n      <td>-3.702485</td>\n      <td>-0.156249</td>\n      <td>2.930343</td>\n      <td>-4.974554</td>\n      <td>-0.930162</td>\n      <td>-0.817911</td>\n      <td>...</td>\n      <td>0.220127</td>\n      <td>0.127802</td>\n      <td>0.044233</td>\n      <td>0.098754</td>\n      <td>0.005934</td>\n      <td>-0.151121</td>\n      <td>0.346246</td>\n      <td>0.041682</td>\n      <td>-0.487852</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>SRR1163101</th>\n      <td>-8.682463</td>\n      <td>-4.772522</td>\n      <td>0.003525</td>\n      <td>0.094409</td>\n      <td>0.517031</td>\n      <td>-3.716390</td>\n      <td>0.988545</td>\n      <td>0.652860</td>\n      <td>-0.217747</td>\n      <td>0.573477</td>\n      <td>...</td>\n      <td>-0.093368</td>\n      <td>0.121302</td>\n      <td>0.067732</td>\n      <td>-0.121732</td>\n      <td>0.079970</td>\n      <td>-0.121168</td>\n      <td>0.044018</td>\n      <td>-0.070295</td>\n      <td>0.017215</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 301 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 44,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604809481862
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_pca_df.to_csv(DATA_LOCATION + \"processed/train_pca_df.tsv\", \"\\t\")\r\n",
        "\r\n",
        "train_pca_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 46,
          "data": {
            "text/plain": "                   PC1       PC2       PC3       PC4       PC5       PC6  \\\nSampleID                                                                   \nSRR10525336  -7.215279  5.487787 -0.045743 -3.295824 -8.025171 -2.949743   \nSRR10380004 -11.599985  5.534724 -0.067638  0.442869  6.543390  0.485848   \nSRR6807701   -9.149900 -4.451211 -0.000561 -0.211492  0.891811 -1.619368   \nSRR11033700  -4.590492  5.312944 -0.043539 -1.586112 -3.702485 -0.156249   \nSRR1163101   -8.682463 -4.772522  0.003525  0.094409  0.517031 -3.716390   \n\n                  PC7       PC8       PC9      PC10        ...          \\\nSampleID                                                   ...           \nSRR10525336 -2.967593 -2.266287 -0.652408  0.578522        ...           \nSRR10380004 -2.291297 -1.485078 -1.267895  2.487861        ...           \nSRR6807701  -0.031481 -1.116217 -0.521429  0.226712        ...           \nSRR11033700  2.930343 -4.974554 -0.930162 -0.817911        ...           \nSRR1163101   0.988545  0.652860 -0.217747  0.573477        ...           \n\n                PC292     PC293     PC294     PC295     PC296     PC297  \\\nSampleID                                                                  \nSRR10525336  0.371804 -0.071848 -0.341443  0.465335 -0.433011 -0.265740   \nSRR10380004  0.137572  0.059569  0.114289 -0.194232  0.028769  0.060136   \nSRR6807701   0.041387  0.080233 -0.031551  0.088953  0.104130  0.031573   \nSRR11033700  0.220127  0.127802  0.044233  0.098754  0.005934 -0.151121   \nSRR1163101  -0.093368  0.121302  0.067732 -0.121732  0.079970 -0.121168   \n\n                PC298     PC299     PC300  Resistance_Status  \nSampleID                                                      \nSRR10525336 -0.491029 -0.128080  0.655469                  1  \nSRR10380004  0.102203  0.070037 -0.115447                  1  \nSRR6807701  -0.036647  0.139434  0.224164                  1  \nSRR11033700  0.346246  0.041682 -0.487852                  1  \nSRR1163101   0.044018 -0.070295  0.017215                  1  \n\n[5 rows x 301 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PC1</th>\n      <th>PC2</th>\n      <th>PC3</th>\n      <th>PC4</th>\n      <th>PC5</th>\n      <th>PC6</th>\n      <th>PC7</th>\n      <th>PC8</th>\n      <th>PC9</th>\n      <th>PC10</th>\n      <th>...</th>\n      <th>PC292</th>\n      <th>PC293</th>\n      <th>PC294</th>\n      <th>PC295</th>\n      <th>PC296</th>\n      <th>PC297</th>\n      <th>PC298</th>\n      <th>PC299</th>\n      <th>PC300</th>\n      <th>Resistance_Status</th>\n    </tr>\n    <tr>\n      <th>SampleID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>SRR10525336</th>\n      <td>-7.215279</td>\n      <td>5.487787</td>\n      <td>-0.045743</td>\n      <td>-3.295824</td>\n      <td>-8.025171</td>\n      <td>-2.949743</td>\n      <td>-2.967593</td>\n      <td>-2.266287</td>\n      <td>-0.652408</td>\n      <td>0.578522</td>\n      <td>...</td>\n      <td>0.371804</td>\n      <td>-0.071848</td>\n      <td>-0.341443</td>\n      <td>0.465335</td>\n      <td>-0.433011</td>\n      <td>-0.265740</td>\n      <td>-0.491029</td>\n      <td>-0.128080</td>\n      <td>0.655469</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>SRR10380004</th>\n      <td>-11.599985</td>\n      <td>5.534724</td>\n      <td>-0.067638</td>\n      <td>0.442869</td>\n      <td>6.543390</td>\n      <td>0.485848</td>\n      <td>-2.291297</td>\n      <td>-1.485078</td>\n      <td>-1.267895</td>\n      <td>2.487861</td>\n      <td>...</td>\n      <td>0.137572</td>\n      <td>0.059569</td>\n      <td>0.114289</td>\n      <td>-0.194232</td>\n      <td>0.028769</td>\n      <td>0.060136</td>\n      <td>0.102203</td>\n      <td>0.070037</td>\n      <td>-0.115447</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>SRR6807701</th>\n      <td>-9.149900</td>\n      <td>-4.451211</td>\n      <td>-0.000561</td>\n      <td>-0.211492</td>\n      <td>0.891811</td>\n      <td>-1.619368</td>\n      <td>-0.031481</td>\n      <td>-1.116217</td>\n      <td>-0.521429</td>\n      <td>0.226712</td>\n      <td>...</td>\n      <td>0.041387</td>\n      <td>0.080233</td>\n      <td>-0.031551</td>\n      <td>0.088953</td>\n      <td>0.104130</td>\n      <td>0.031573</td>\n      <td>-0.036647</td>\n      <td>0.139434</td>\n      <td>0.224164</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>SRR11033700</th>\n      <td>-4.590492</td>\n      <td>5.312944</td>\n      <td>-0.043539</td>\n      <td>-1.586112</td>\n      <td>-3.702485</td>\n      <td>-0.156249</td>\n      <td>2.930343</td>\n      <td>-4.974554</td>\n      <td>-0.930162</td>\n      <td>-0.817911</td>\n      <td>...</td>\n      <td>0.220127</td>\n      <td>0.127802</td>\n      <td>0.044233</td>\n      <td>0.098754</td>\n      <td>0.005934</td>\n      <td>-0.151121</td>\n      <td>0.346246</td>\n      <td>0.041682</td>\n      <td>-0.487852</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>SRR1163101</th>\n      <td>-8.682463</td>\n      <td>-4.772522</td>\n      <td>0.003525</td>\n      <td>0.094409</td>\n      <td>0.517031</td>\n      <td>-3.716390</td>\n      <td>0.988545</td>\n      <td>0.652860</td>\n      <td>-0.217747</td>\n      <td>0.573477</td>\n      <td>...</td>\n      <td>-0.093368</td>\n      <td>0.121302</td>\n      <td>0.067732</td>\n      <td>-0.121732</td>\n      <td>0.079970</td>\n      <td>-0.121168</td>\n      <td>0.044018</td>\n      <td>-0.070295</td>\n      <td>0.017215</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 301 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 46,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604809534013
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response_col_df = test_frame[response_col].as_data_frame()\r\n",
        "index_col_df = test_frame[index_col].as_data_frame()\r\n",
        "\r\n",
        "test_pca_df = (test_frame_pca_df.join(response_col_df)).join(index_col_df).set_index('SampleID')\r\n",
        "test_pca_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 45,
          "data": {
            "text/plain": "                  PC1       PC2       PC3       PC4       PC5       PC6  \\\nSampleID                                                                  \nERR3335735  -9.629457  3.427494 -0.054488 -1.997283 -0.501536  5.336753   \nSRR8552929  -6.500589  5.032125  9.899641 -1.751147 -1.998420  5.184365   \nERR067629  -12.947850  4.520129 -0.072757  0.795501  5.604925 -3.833929   \nERR067714   -8.945284 -5.015450  0.002182  0.197580  0.776913 -3.340270   \nSRR5065314  -8.616033 -5.402211  0.008112 -0.470638 -0.436735  2.802968   \n\n                 PC7        PC8        PC9       PC10        ...          \\\nSampleID                                                     ...           \nERR3335735  1.883176   2.342219   0.550157   2.244874        ...           \nSRR8552929  5.728812  22.975901 -72.911270 -19.434493        ...           \nERR067629  -0.123111   0.276374  -0.394928   1.513401        ...           \nERR067714   0.435418  -0.418539  -0.392206   0.062804        ...           \nSRR5065314 -0.717564   0.032025   0.384208  -0.915967        ...           \n\n               PC292     PC293     PC294     PC295     PC296     PC297  \\\nSampleID                                                                 \nERR3335735  0.080378  0.342437 -0.283436 -0.272764 -0.157943 -0.103696   \nSRR8552929 -0.002507 -0.001169  0.001140 -0.000947  0.004027  0.005030   \nERR067629  -0.218587  0.404883  0.508618  0.063992  0.420349 -0.243656   \nERR067714  -0.027150  0.042037 -0.027205 -0.192404 -0.003779 -0.075270   \nSRR5065314 -0.058061  0.173129  0.315004  0.085500  0.000209  0.275298   \n\n               PC298     PC299     PC300  Resistance_Status  \nSampleID                                                     \nERR3335735 -0.056571 -0.413420 -0.201708                  1  \nSRR8552929 -0.003485  0.002891 -0.003535                  1  \nERR067629  -0.125900 -0.114601  0.135860                  1  \nERR067714  -0.038884  0.059448  0.089166                  1  \nSRR5065314  0.104563 -0.004634  0.090837                  1  \n\n[5 rows x 301 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PC1</th>\n      <th>PC2</th>\n      <th>PC3</th>\n      <th>PC4</th>\n      <th>PC5</th>\n      <th>PC6</th>\n      <th>PC7</th>\n      <th>PC8</th>\n      <th>PC9</th>\n      <th>PC10</th>\n      <th>...</th>\n      <th>PC292</th>\n      <th>PC293</th>\n      <th>PC294</th>\n      <th>PC295</th>\n      <th>PC296</th>\n      <th>PC297</th>\n      <th>PC298</th>\n      <th>PC299</th>\n      <th>PC300</th>\n      <th>Resistance_Status</th>\n    </tr>\n    <tr>\n      <th>SampleID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ERR3335735</th>\n      <td>-9.629457</td>\n      <td>3.427494</td>\n      <td>-0.054488</td>\n      <td>-1.997283</td>\n      <td>-0.501536</td>\n      <td>5.336753</td>\n      <td>1.883176</td>\n      <td>2.342219</td>\n      <td>0.550157</td>\n      <td>2.244874</td>\n      <td>...</td>\n      <td>0.080378</td>\n      <td>0.342437</td>\n      <td>-0.283436</td>\n      <td>-0.272764</td>\n      <td>-0.157943</td>\n      <td>-0.103696</td>\n      <td>-0.056571</td>\n      <td>-0.413420</td>\n      <td>-0.201708</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>SRR8552929</th>\n      <td>-6.500589</td>\n      <td>5.032125</td>\n      <td>9.899641</td>\n      <td>-1.751147</td>\n      <td>-1.998420</td>\n      <td>5.184365</td>\n      <td>5.728812</td>\n      <td>22.975901</td>\n      <td>-72.911270</td>\n      <td>-19.434493</td>\n      <td>...</td>\n      <td>-0.002507</td>\n      <td>-0.001169</td>\n      <td>0.001140</td>\n      <td>-0.000947</td>\n      <td>0.004027</td>\n      <td>0.005030</td>\n      <td>-0.003485</td>\n      <td>0.002891</td>\n      <td>-0.003535</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>ERR067629</th>\n      <td>-12.947850</td>\n      <td>4.520129</td>\n      <td>-0.072757</td>\n      <td>0.795501</td>\n      <td>5.604925</td>\n      <td>-3.833929</td>\n      <td>-0.123111</td>\n      <td>0.276374</td>\n      <td>-0.394928</td>\n      <td>1.513401</td>\n      <td>...</td>\n      <td>-0.218587</td>\n      <td>0.404883</td>\n      <td>0.508618</td>\n      <td>0.063992</td>\n      <td>0.420349</td>\n      <td>-0.243656</td>\n      <td>-0.125900</td>\n      <td>-0.114601</td>\n      <td>0.135860</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>ERR067714</th>\n      <td>-8.945284</td>\n      <td>-5.015450</td>\n      <td>0.002182</td>\n      <td>0.197580</td>\n      <td>0.776913</td>\n      <td>-3.340270</td>\n      <td>0.435418</td>\n      <td>-0.418539</td>\n      <td>-0.392206</td>\n      <td>0.062804</td>\n      <td>...</td>\n      <td>-0.027150</td>\n      <td>0.042037</td>\n      <td>-0.027205</td>\n      <td>-0.192404</td>\n      <td>-0.003779</td>\n      <td>-0.075270</td>\n      <td>-0.038884</td>\n      <td>0.059448</td>\n      <td>0.089166</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>SRR5065314</th>\n      <td>-8.616033</td>\n      <td>-5.402211</td>\n      <td>0.008112</td>\n      <td>-0.470638</td>\n      <td>-0.436735</td>\n      <td>2.802968</td>\n      <td>-0.717564</td>\n      <td>0.032025</td>\n      <td>0.384208</td>\n      <td>-0.915967</td>\n      <td>...</td>\n      <td>-0.058061</td>\n      <td>0.173129</td>\n      <td>0.315004</td>\n      <td>0.085500</td>\n      <td>0.000209</td>\n      <td>0.275298</td>\n      <td>0.104563</td>\n      <td>-0.004634</td>\n      <td>0.090837</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 301 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 45,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604809484476
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_pca_df.to_csv(DATA_LOCATION + \"processed/test_pca_df.tsv\", \"\\t\")\r\n",
        "\r\n",
        "test_pca_df.head()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'test_pca_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-9c1ff35e6473>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_pca_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_LOCATION\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"processed/test_pca_df.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_pca_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_pca_df' is not defined"
          ]
        }
      ],
      "execution_count": 41,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604809563788
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_pca_df_frame = h2o.H2OFrame(train_pca_df)\r\n",
        "train_pca_df_frame = h2o.import_file(DATA_LOCATION + \"processed/train_pca_df.tsv\")\r\n",
        "\r\n",
        "train_pca_df_frame.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<table>\n<thead>\n<tr><th>SampleID   </th><th style=\"text-align: right;\">      PC1</th><th style=\"text-align: right;\">     PC2</th><th style=\"text-align: right;\">         PC3</th><th style=\"text-align: right;\">       PC4</th><th style=\"text-align: right;\">       PC5</th><th style=\"text-align: right;\">      PC6</th><th style=\"text-align: right;\">       PC7</th><th style=\"text-align: right;\">      PC8</th><th style=\"text-align: right;\">      PC9</th><th style=\"text-align: right;\">     PC10</th><th style=\"text-align: right;\">     PC11</th><th style=\"text-align: right;\">      PC12</th><th style=\"text-align: right;\">     PC13</th><th style=\"text-align: right;\">     PC14</th><th style=\"text-align: right;\">      PC15</th><th style=\"text-align: right;\">     PC16</th><th style=\"text-align: right;\">       PC17</th><th style=\"text-align: right;\">      PC18</th><th style=\"text-align: right;\">      PC19</th><th style=\"text-align: right;\">     PC20</th><th style=\"text-align: right;\">     PC21</th><th style=\"text-align: right;\">      PC22</th><th style=\"text-align: right;\">      PC23</th><th style=\"text-align: right;\">      PC24</th><th style=\"text-align: right;\">     PC25</th><th style=\"text-align: right;\">      PC26</th><th style=\"text-align: right;\">      PC27</th><th style=\"text-align: right;\">       PC28</th><th style=\"text-align: right;\">      PC29</th><th style=\"text-align: right;\">     PC30</th><th style=\"text-align: right;\">       PC31</th><th style=\"text-align: right;\">     PC32</th><th style=\"text-align: right;\">      PC33</th><th style=\"text-align: right;\">      PC34</th><th style=\"text-align: right;\">      PC35</th><th style=\"text-align: right;\">      PC36</th><th style=\"text-align: right;\">      PC37</th><th style=\"text-align: right;\">      PC38</th><th style=\"text-align: right;\">      PC39</th><th style=\"text-align: right;\">      PC40</th><th style=\"text-align: right;\">       PC41</th><th style=\"text-align: right;\">       PC42</th><th style=\"text-align: right;\">      PC43</th><th style=\"text-align: right;\">      PC44</th><th style=\"text-align: right;\">       PC45</th><th style=\"text-align: right;\">      PC46</th><th style=\"text-align: right;\">      PC47</th><th style=\"text-align: right;\">      PC48</th><th style=\"text-align: right;\">      PC49</th><th style=\"text-align: right;\">      PC50</th><th style=\"text-align: right;\">      PC51</th><th style=\"text-align: right;\">       PC52</th><th style=\"text-align: right;\">      PC53</th><th style=\"text-align: right;\">      PC54</th><th style=\"text-align: right;\">      PC55</th><th style=\"text-align: right;\">      PC56</th><th style=\"text-align: right;\">      PC57</th><th style=\"text-align: right;\">      PC58</th><th style=\"text-align: right;\">      PC59</th><th style=\"text-align: right;\">      PC60</th><th style=\"text-align: right;\">      PC61</th><th style=\"text-align: right;\">        PC62</th><th style=\"text-align: right;\">      PC63</th><th style=\"text-align: right;\">      PC64</th><th style=\"text-align: right;\">      PC65</th><th style=\"text-align: right;\">      PC66</th><th style=\"text-align: right;\">     PC67</th><th style=\"text-align: right;\">      PC68</th><th style=\"text-align: right;\">      PC69</th><th style=\"text-align: right;\">      PC70</th><th style=\"text-align: right;\">      PC71</th><th style=\"text-align: right;\">      PC72</th><th style=\"text-align: right;\">      PC73</th><th style=\"text-align: right;\">      PC74</th><th style=\"text-align: right;\">      PC75</th><th style=\"text-align: right;\">       PC76</th><th style=\"text-align: right;\">      PC77</th><th style=\"text-align: right;\">      PC78</th><th style=\"text-align: right;\">      PC79</th><th style=\"text-align: right;\">      PC80</th><th style=\"text-align: right;\">      PC81</th><th style=\"text-align: right;\">     PC82</th><th style=\"text-align: right;\">     PC83</th><th style=\"text-align: right;\">       PC84</th><th style=\"text-align: right;\">      PC85</th><th style=\"text-align: right;\">      PC86</th><th style=\"text-align: right;\">      PC87</th><th style=\"text-align: right;\">      PC88</th><th style=\"text-align: right;\">      PC89</th><th style=\"text-align: right;\">      PC90</th><th style=\"text-align: right;\">       PC91</th><th style=\"text-align: right;\">       PC92</th><th style=\"text-align: right;\">      PC93</th><th style=\"text-align: right;\">      PC94</th><th style=\"text-align: right;\">      PC95</th><th style=\"text-align: right;\">       PC96</th><th style=\"text-align: right;\">      PC97</th><th style=\"text-align: right;\">       PC98</th><th style=\"text-align: right;\">     PC99</th><th style=\"text-align: right;\">     PC100</th><th style=\"text-align: right;\">     PC101</th><th style=\"text-align: right;\">     PC102</th><th style=\"text-align: right;\">      PC103</th><th style=\"text-align: right;\">     PC104</th><th style=\"text-align: right;\">      PC105</th><th style=\"text-align: right;\">    PC106</th><th style=\"text-align: right;\">      PC107</th><th style=\"text-align: right;\">     PC108</th><th style=\"text-align: right;\">     PC109</th><th style=\"text-align: right;\">     PC110</th><th style=\"text-align: right;\">     PC111</th><th style=\"text-align: right;\">      PC112</th><th style=\"text-align: right;\">     PC113</th><th style=\"text-align: right;\">     PC114</th><th style=\"text-align: right;\">     PC115</th><th style=\"text-align: right;\">     PC116</th><th style=\"text-align: right;\">     PC117</th><th style=\"text-align: right;\">      PC118</th><th style=\"text-align: right;\">      PC119</th><th style=\"text-align: right;\">     PC120</th><th style=\"text-align: right;\">      PC121</th><th style=\"text-align: right;\">     PC122</th><th style=\"text-align: right;\">     PC123</th><th style=\"text-align: right;\">     PC124</th><th style=\"text-align: right;\">     PC125</th><th style=\"text-align: right;\">      PC126</th><th style=\"text-align: right;\">     PC127</th><th style=\"text-align: right;\">       PC128</th><th style=\"text-align: right;\">      PC129</th><th style=\"text-align: right;\">     PC130</th><th style=\"text-align: right;\">     PC131</th><th style=\"text-align: right;\">     PC132</th><th style=\"text-align: right;\">     PC133</th><th style=\"text-align: right;\">     PC134</th><th style=\"text-align: right;\">     PC135</th><th style=\"text-align: right;\">     PC136</th><th style=\"text-align: right;\">     PC137</th><th style=\"text-align: right;\">     PC138</th><th style=\"text-align: right;\">      PC139</th><th style=\"text-align: right;\">      PC140</th><th style=\"text-align: right;\">      PC141</th><th style=\"text-align: right;\">     PC142</th><th style=\"text-align: right;\">     PC143</th><th style=\"text-align: right;\">     PC144</th><th style=\"text-align: right;\">     PC145</th><th style=\"text-align: right;\">     PC146</th><th style=\"text-align: right;\">    PC147</th><th style=\"text-align: right;\">     PC148</th><th style=\"text-align: right;\">      PC149</th><th style=\"text-align: right;\">     PC150</th><th style=\"text-align: right;\">     PC151</th><th style=\"text-align: right;\">      PC152</th><th style=\"text-align: right;\">      PC153</th><th style=\"text-align: right;\">     PC154</th><th style=\"text-align: right;\">     PC155</th><th style=\"text-align: right;\">     PC156</th><th style=\"text-align: right;\">    PC157</th><th style=\"text-align: right;\">      PC158</th><th style=\"text-align: right;\">     PC159</th><th style=\"text-align: right;\">      PC160</th><th style=\"text-align: right;\">     PC161</th><th style=\"text-align: right;\">       PC162</th><th style=\"text-align: right;\">      PC163</th><th style=\"text-align: right;\">      PC164</th><th style=\"text-align: right;\">     PC165</th><th style=\"text-align: right;\">     PC166</th><th style=\"text-align: right;\">     PC167</th><th style=\"text-align: right;\">     PC168</th><th style=\"text-align: right;\">     PC169</th><th style=\"text-align: right;\">     PC170</th><th style=\"text-align: right;\">      PC171</th><th style=\"text-align: right;\">     PC172</th><th style=\"text-align: right;\">     PC173</th><th style=\"text-align: right;\">       PC174</th><th style=\"text-align: right;\">      PC175</th><th style=\"text-align: right;\">     PC176</th><th style=\"text-align: right;\">     PC177</th><th style=\"text-align: right;\">      PC178</th><th style=\"text-align: right;\">     PC179</th><th style=\"text-align: right;\">     PC180</th><th style=\"text-align: right;\">     PC181</th><th style=\"text-align: right;\">     PC182</th><th style=\"text-align: right;\">      PC183</th><th style=\"text-align: right;\">     PC184</th><th style=\"text-align: right;\">      PC185</th><th style=\"text-align: right;\">     PC186</th><th style=\"text-align: right;\">     PC187</th><th style=\"text-align: right;\">      PC188</th><th style=\"text-align: right;\">     PC189</th><th style=\"text-align: right;\">     PC190</th><th style=\"text-align: right;\">      PC191</th><th style=\"text-align: right;\">     PC192</th><th style=\"text-align: right;\">     PC193</th><th style=\"text-align: right;\">      PC194</th><th style=\"text-align: right;\">     PC195</th><th style=\"text-align: right;\">      PC196</th><th style=\"text-align: right;\">      PC197</th><th style=\"text-align: right;\">     PC198</th><th style=\"text-align: right;\">     PC199</th></tr>\n</thead>\n<tbody>\n<tr><td>SRR10525336</td><td style=\"text-align: right;\"> -7.21528</td><td style=\"text-align: right;\"> 5.48779</td><td style=\"text-align: right;\">-0.0457426  </td><td style=\"text-align: right;\">-3.29582  </td><td style=\"text-align: right;\">-8.02517  </td><td style=\"text-align: right;\">-2.94974 </td><td style=\"text-align: right;\">-2.96759  </td><td style=\"text-align: right;\">-2.26629 </td><td style=\"text-align: right;\">-0.652408</td><td style=\"text-align: right;\"> 0.578522</td><td style=\"text-align: right;\"> 0.182181</td><td style=\"text-align: right;\"> 0.434753 </td><td style=\"text-align: right;\"> 2.51645 </td><td style=\"text-align: right;\">-2.40717 </td><td style=\"text-align: right;\">-0.0528002</td><td style=\"text-align: right;\">-0.867347</td><td style=\"text-align: right;\">-0.77548   </td><td style=\"text-align: right;\"> 0.779273 </td><td style=\"text-align: right;\">-0.362249 </td><td style=\"text-align: right;\">-0.189216</td><td style=\"text-align: right;\">-1.43005 </td><td style=\"text-align: right;\"> 0.0339925</td><td style=\"text-align: right;\"> 0.0361673</td><td style=\"text-align: right;\">-0.59373  </td><td style=\"text-align: right;\"> 0.642088</td><td style=\"text-align: right;\">-0.0192343</td><td style=\"text-align: right;\"> 0.0159929</td><td style=\"text-align: right;\"> 0.10032   </td><td style=\"text-align: right;\">-2.14885  </td><td style=\"text-align: right;\"> 0.72847 </td><td style=\"text-align: right;\">-0.426612  </td><td style=\"text-align: right;\">-2.17743 </td><td style=\"text-align: right;\"> 0.564177 </td><td style=\"text-align: right;\">-0.419728 </td><td style=\"text-align: right;\">-0.040311 </td><td style=\"text-align: right;\"> 0.174175 </td><td style=\"text-align: right;\"> 0.0958375</td><td style=\"text-align: right;\">-0.840905 </td><td style=\"text-align: right;\">-0.412918 </td><td style=\"text-align: right;\"> 0.0362403</td><td style=\"text-align: right;\">-1.12543   </td><td style=\"text-align: right;\"> 1.47642   </td><td style=\"text-align: right;\">-0.288826 </td><td style=\"text-align: right;\"> 0.204485 </td><td style=\"text-align: right;\"> 0.970888  </td><td style=\"text-align: right;\"> 0.830999 </td><td style=\"text-align: right;\"> 0.392813 </td><td style=\"text-align: right;\">-0.160212 </td><td style=\"text-align: right;\"> 0.045166 </td><td style=\"text-align: right;\">-0.775327 </td><td style=\"text-align: right;\"> 0.854433 </td><td style=\"text-align: right;\"> 3.10933   </td><td style=\"text-align: right;\"> 1.62966  </td><td style=\"text-align: right;\">-0.403796 </td><td style=\"text-align: right;\"> 2.37824  </td><td style=\"text-align: right;\">-1.07053  </td><td style=\"text-align: right;\"> 1.22014  </td><td style=\"text-align: right;\">-0.0348898</td><td style=\"text-align: right;\"> 0.709709 </td><td style=\"text-align: right;\">-1.60722  </td><td style=\"text-align: right;\">-0.537093 </td><td style=\"text-align: right;\">-0.519959   </td><td style=\"text-align: right;\">-0.607373 </td><td style=\"text-align: right;\"> 1.96028  </td><td style=\"text-align: right;\">-1.37502  </td><td style=\"text-align: right;\"> 0.788434 </td><td style=\"text-align: right;\"> 0.623542</td><td style=\"text-align: right;\"> 0.117146 </td><td style=\"text-align: right;\">-0.662954 </td><td style=\"text-align: right;\">-0.788601 </td><td style=\"text-align: right;\"> 0.0349831</td><td style=\"text-align: right;\">-0.104036 </td><td style=\"text-align: right;\"> 0.64312  </td><td style=\"text-align: right;\"> 0.498023 </td><td style=\"text-align: right;\"> 1.10188  </td><td style=\"text-align: right;\"> 1.07592   </td><td style=\"text-align: right;\"> 0.471287 </td><td style=\"text-align: right;\">-0.870997 </td><td style=\"text-align: right;\"> 0.134068 </td><td style=\"text-align: right;\"> 0.192699 </td><td style=\"text-align: right;\"> 0.590267 </td><td style=\"text-align: right;\"> 1.93532 </td><td style=\"text-align: right;\"> 1.70993 </td><td style=\"text-align: right;\"> 0.0663423 </td><td style=\"text-align: right;\">-0.0086952</td><td style=\"text-align: right;\">-0.131918 </td><td style=\"text-align: right;\"> 0.4172   </td><td style=\"text-align: right;\">-1.12597  </td><td style=\"text-align: right;\"> 0.123066 </td><td style=\"text-align: right;\">-2.76761  </td><td style=\"text-align: right;\">-0.0105532 </td><td style=\"text-align: right;\">-0.186149  </td><td style=\"text-align: right;\">-0.528908 </td><td style=\"text-align: right;\">-0.59734  </td><td style=\"text-align: right;\">-0.125254 </td><td style=\"text-align: right;\"> 0.853391  </td><td style=\"text-align: right;\">-0.353671 </td><td style=\"text-align: right;\"> 0.527961  </td><td style=\"text-align: right;\">-1.19337 </td><td style=\"text-align: right;\"> 0.320649 </td><td style=\"text-align: right;\">-0.910347 </td><td style=\"text-align: right;\"> 0.726797 </td><td style=\"text-align: right;\">-1.19437   </td><td style=\"text-align: right;\"> 0.643785 </td><td style=\"text-align: right;\"> 2.2666    </td><td style=\"text-align: right;\"> 1.23807 </td><td style=\"text-align: right;\">-1.71336   </td><td style=\"text-align: right;\"> 1.6379   </td><td style=\"text-align: right;\">-1.35046  </td><td style=\"text-align: right;\">-0.0621283</td><td style=\"text-align: right;\">-2.1299   </td><td style=\"text-align: right;\"> 0.338774  </td><td style=\"text-align: right;\">-0.294789 </td><td style=\"text-align: right;\"> 0.635849 </td><td style=\"text-align: right;\"> 0.393347 </td><td style=\"text-align: right;\"> 0.461294 </td><td style=\"text-align: right;\"> 0.799493 </td><td style=\"text-align: right;\"> 0.182817  </td><td style=\"text-align: right;\">-0.0629657 </td><td style=\"text-align: right;\">-0.0312119</td><td style=\"text-align: right;\"> 0.38403   </td><td style=\"text-align: right;\">-0.29482  </td><td style=\"text-align: right;\"> 0.102779 </td><td style=\"text-align: right;\">-0.0105114</td><td style=\"text-align: right;\">-0.613126 </td><td style=\"text-align: right;\">-0.635172  </td><td style=\"text-align: right;\"> 0.318172 </td><td style=\"text-align: right;\">-0.604303   </td><td style=\"text-align: right;\">-1.23884   </td><td style=\"text-align: right;\">-0.367584 </td><td style=\"text-align: right;\"> 0.13739  </td><td style=\"text-align: right;\"> 0.403578 </td><td style=\"text-align: right;\"> 1.11971  </td><td style=\"text-align: right;\">-1.58696  </td><td style=\"text-align: right;\"> 0.0275307</td><td style=\"text-align: right;\"> 1.58684  </td><td style=\"text-align: right;\">-0.519128 </td><td style=\"text-align: right;\"> 0.250662 </td><td style=\"text-align: right;\">-0.731469  </td><td style=\"text-align: right;\"> 1.03236   </td><td style=\"text-align: right;\">-0.272874  </td><td style=\"text-align: right;\">-0.146155 </td><td style=\"text-align: right;\">-1.12871  </td><td style=\"text-align: right;\"> 0.518941 </td><td style=\"text-align: right;\">-0.731375 </td><td style=\"text-align: right;\">-0.186096 </td><td style=\"text-align: right;\"> 0.206038</td><td style=\"text-align: right;\">-0.129464 </td><td style=\"text-align: right;\"> 0.20192   </td><td style=\"text-align: right;\"> 0.0572525</td><td style=\"text-align: right;\"> 0.337063 </td><td style=\"text-align: right;\"> 1.8732    </td><td style=\"text-align: right;\"> 0.718144  </td><td style=\"text-align: right;\"> 0.609294 </td><td style=\"text-align: right;\">-0.0976525</td><td style=\"text-align: right;\"> 1.02692  </td><td style=\"text-align: right;\"> 1.16342 </td><td style=\"text-align: right;\">-0.027039  </td><td style=\"text-align: right;\">-0.366797 </td><td style=\"text-align: right;\">-0.126558  </td><td style=\"text-align: right;\"> 0.145244 </td><td style=\"text-align: right;\"> 0.0541146  </td><td style=\"text-align: right;\">-0.293231  </td><td style=\"text-align: right;\">-0.430163  </td><td style=\"text-align: right;\">-0.623036 </td><td style=\"text-align: right;\"> 0.119761 </td><td style=\"text-align: right;\"> 0.0857521</td><td style=\"text-align: right;\"> 0.654185 </td><td style=\"text-align: right;\">-0.597948 </td><td style=\"text-align: right;\"> 0.906505 </td><td style=\"text-align: right;\"> 0.00763198</td><td style=\"text-align: right;\"> 0.760529 </td><td style=\"text-align: right;\">-0.196652 </td><td style=\"text-align: right;\"> 1.37364    </td><td style=\"text-align: right;\"> 0.38687   </td><td style=\"text-align: right;\"> 1.06562  </td><td style=\"text-align: right;\">-0.592595 </td><td style=\"text-align: right;\"> 0.096302  </td><td style=\"text-align: right;\">-0.982776 </td><td style=\"text-align: right;\"> 0.205194 </td><td style=\"text-align: right;\"> 0.795516 </td><td style=\"text-align: right;\"> 1.4415   </td><td style=\"text-align: right;\"> 0.103181  </td><td style=\"text-align: right;\"> 0.958078 </td><td style=\"text-align: right;\">-0.024321  </td><td style=\"text-align: right;\"> 0.423626 </td><td style=\"text-align: right;\"> 0.416048 </td><td style=\"text-align: right;\">-0.422432  </td><td style=\"text-align: right;\">-0.822004 </td><td style=\"text-align: right;\"> 0.286042 </td><td style=\"text-align: right;\">-0.334727  </td><td style=\"text-align: right;\"> 0.236006 </td><td style=\"text-align: right;\"> 0.430699 </td><td style=\"text-align: right;\">-1.99712   </td><td style=\"text-align: right;\"> 0.0612397</td><td style=\"text-align: right;\">-0.281902  </td><td style=\"text-align: right;\"> 0.561714  </td><td style=\"text-align: right;\">-0.545934 </td><td style=\"text-align: right;\"> 0.920071 </td></tr>\n<tr><td>SRR10380004</td><td style=\"text-align: right;\">-11.6    </td><td style=\"text-align: right;\"> 5.53472</td><td style=\"text-align: right;\">-0.0676378  </td><td style=\"text-align: right;\"> 0.442869 </td><td style=\"text-align: right;\"> 6.54339  </td><td style=\"text-align: right;\"> 0.485848</td><td style=\"text-align: right;\">-2.2913   </td><td style=\"text-align: right;\">-1.48508 </td><td style=\"text-align: right;\">-1.26789 </td><td style=\"text-align: right;\"> 2.48786 </td><td style=\"text-align: right;\"> 1.61519 </td><td style=\"text-align: right;\">-1.82951  </td><td style=\"text-align: right;\">-1.14724 </td><td style=\"text-align: right;\">-0.686728</td><td style=\"text-align: right;\"> 0.0791433</td><td style=\"text-align: right;\"> 0.244093</td><td style=\"text-align: right;\">-0.673544  </td><td style=\"text-align: right;\">-0.298431 </td><td style=\"text-align: right;\"> 0.569891 </td><td style=\"text-align: right;\"> 1.3156  </td><td style=\"text-align: right;\"> 0.936164</td><td style=\"text-align: right;\">-1.74636  </td><td style=\"text-align: right;\">-1.05101  </td><td style=\"text-align: right;\"> 0.351799 </td><td style=\"text-align: right;\">-0.744067</td><td style=\"text-align: right;\"> 0.26847  </td><td style=\"text-align: right;\">-0.322997 </td><td style=\"text-align: right;\">-0.0033458 </td><td style=\"text-align: right;\"> 0.139044 </td><td style=\"text-align: right;\"> 0.83802 </td><td style=\"text-align: right;\"> 0.0462784 </td><td style=\"text-align: right;\"> 0.18821 </td><td style=\"text-align: right;\"> 0.0188327</td><td style=\"text-align: right;\"> 0.311519 </td><td style=\"text-align: right;\">-0.103977 </td><td style=\"text-align: right;\"> 0.924853 </td><td style=\"text-align: right;\"> 1.06325  </td><td style=\"text-align: right;\">-0.617407 </td><td style=\"text-align: right;\"> 0.416026 </td><td style=\"text-align: right;\"> 0.152573 </td><td style=\"text-align: right;\">-0.00922459</td><td style=\"text-align: right;\">-0.540769  </td><td style=\"text-align: right;\">-0.42493  </td><td style=\"text-align: right;\"> 0.224336 </td><td style=\"text-align: right;\"> 0.842236  </td><td style=\"text-align: right;\">-0.0829223</td><td style=\"text-align: right;\"> 0.104743 </td><td style=\"text-align: right;\">-0.249455 </td><td style=\"text-align: right;\">-0.237306 </td><td style=\"text-align: right;\"> 0.123351 </td><td style=\"text-align: right;\"> 0.373262 </td><td style=\"text-align: right;\"> 0.402359  </td><td style=\"text-align: right;\"> 0.0419783</td><td style=\"text-align: right;\">-1.21117  </td><td style=\"text-align: right;\">-0.482892 </td><td style=\"text-align: right;\">-0.974701 </td><td style=\"text-align: right;\">-0.132585 </td><td style=\"text-align: right;\"> 0.422715 </td><td style=\"text-align: right;\">-0.532571 </td><td style=\"text-align: right;\">-0.512553 </td><td style=\"text-align: right;\">-0.417771 </td><td style=\"text-align: right;\"> 0.55964    </td><td style=\"text-align: right;\">-0.123657 </td><td style=\"text-align: right;\">-0.481367 </td><td style=\"text-align: right;\">-0.395624 </td><td style=\"text-align: right;\"> 0.235399 </td><td style=\"text-align: right;\">-0.338215</td><td style=\"text-align: right;\">-0.311371 </td><td style=\"text-align: right;\"> 0.25003  </td><td style=\"text-align: right;\">-0.187722 </td><td style=\"text-align: right;\">-0.145724 </td><td style=\"text-align: right;\"> 0.0526789</td><td style=\"text-align: right;\"> 0.49318  </td><td style=\"text-align: right;\"> 0.0865632</td><td style=\"text-align: right;\">-0.12011  </td><td style=\"text-align: right;\">-0.482305  </td><td style=\"text-align: right;\"> 0.176727 </td><td style=\"text-align: right;\">-0.126995 </td><td style=\"text-align: right;\">-0.1996   </td><td style=\"text-align: right;\">-0.169428 </td><td style=\"text-align: right;\"> 0.0459824</td><td style=\"text-align: right;\">-0.10309 </td><td style=\"text-align: right;\">-0.100268</td><td style=\"text-align: right;\">-0.066558  </td><td style=\"text-align: right;\"> 0.290223 </td><td style=\"text-align: right;\"> 0.0640084</td><td style=\"text-align: right;\"> 0.192294 </td><td style=\"text-align: right;\"> 0.367173 </td><td style=\"text-align: right;\">-0.726469 </td><td style=\"text-align: right;\">-0.255324 </td><td style=\"text-align: right;\"> 0.376527  </td><td style=\"text-align: right;\"> 0.0864552 </td><td style=\"text-align: right;\"> 0.429294 </td><td style=\"text-align: right;\"> 0.361994 </td><td style=\"text-align: right;\">-0.0955574</td><td style=\"text-align: right;\"> 0.10195   </td><td style=\"text-align: right;\"> 0.101228 </td><td style=\"text-align: right;\">-0.164574  </td><td style=\"text-align: right;\"> 0.105739</td><td style=\"text-align: right;\"> 0.0161596</td><td style=\"text-align: right;\">-0.309447 </td><td style=\"text-align: right;\">-0.148715 </td><td style=\"text-align: right;\"> 0.0122466 </td><td style=\"text-align: right;\"> 0.408371 </td><td style=\"text-align: right;\">-0.140452  </td><td style=\"text-align: right;\"> 0.34785 </td><td style=\"text-align: right;\"> 0.134036  </td><td style=\"text-align: right;\"> 0.312078 </td><td style=\"text-align: right;\"> 0.0964443</td><td style=\"text-align: right;\"> 0.262582 </td><td style=\"text-align: right;\"> 0.0372175</td><td style=\"text-align: right;\"> 0.103305  </td><td style=\"text-align: right;\"> 0.0706207</td><td style=\"text-align: right;\"> 0.0719518</td><td style=\"text-align: right;\"> 0.171051 </td><td style=\"text-align: right;\">-0.0878448</td><td style=\"text-align: right;\"> 0.0998239</td><td style=\"text-align: right;\">-0.0338992 </td><td style=\"text-align: right;\"> 0.00544983</td><td style=\"text-align: right;\"> 0.186707 </td><td style=\"text-align: right;\"> 0.281369  </td><td style=\"text-align: right;\">-0.021923 </td><td style=\"text-align: right;\"> 0.384559 </td><td style=\"text-align: right;\">-0.145023 </td><td style=\"text-align: right;\"> 0.107315 </td><td style=\"text-align: right;\">-0.314057  </td><td style=\"text-align: right;\"> 0.0957007</td><td style=\"text-align: right;\">-0.178865   </td><td style=\"text-align: right;\">-0.00989666</td><td style=\"text-align: right;\">-0.151766 </td><td style=\"text-align: right;\"> 0.141986 </td><td style=\"text-align: right;\">-0.228017 </td><td style=\"text-align: right;\">-0.237458 </td><td style=\"text-align: right;\">-0.12697  </td><td style=\"text-align: right;\">-0.318449 </td><td style=\"text-align: right;\"> 0.113567 </td><td style=\"text-align: right;\"> 0.30737  </td><td style=\"text-align: right;\">-0.20337  </td><td style=\"text-align: right;\"> 0.202596  </td><td style=\"text-align: right;\"> 0.386656  </td><td style=\"text-align: right;\">-0.266906  </td><td style=\"text-align: right;\"> 0.164085 </td><td style=\"text-align: right;\"> 0.318025 </td><td style=\"text-align: right;\"> 0.0820759</td><td style=\"text-align: right;\"> 0.14793  </td><td style=\"text-align: right;\"> 0.01882  </td><td style=\"text-align: right;\"> 0.495149</td><td style=\"text-align: right;\">-0.260415 </td><td style=\"text-align: right;\">-0.0617778 </td><td style=\"text-align: right;\"> 0.362951 </td><td style=\"text-align: right;\"> 0.0325297</td><td style=\"text-align: right;\"> 0.117637  </td><td style=\"text-align: right;\"> 0.113324  </td><td style=\"text-align: right;\"> 0.429079 </td><td style=\"text-align: right;\">-0.334004 </td><td style=\"text-align: right;\"> 0.0182072</td><td style=\"text-align: right;\">-0.187317</td><td style=\"text-align: right;\"> 0.081209  </td><td style=\"text-align: right;\"> 0.0555776</td><td style=\"text-align: right;\">-0.100039  </td><td style=\"text-align: right;\"> 0.183181 </td><td style=\"text-align: right;\">-0.027631   </td><td style=\"text-align: right;\"> 0.00739474</td><td style=\"text-align: right;\"> 0.274455  </td><td style=\"text-align: right;\">-0.186653 </td><td style=\"text-align: right;\"> 0.177429 </td><td style=\"text-align: right;\">-0.178171 </td><td style=\"text-align: right;\"> 0.108237 </td><td style=\"text-align: right;\"> 0.214357 </td><td style=\"text-align: right;\"> 0.279921 </td><td style=\"text-align: right;\">-0.100227  </td><td style=\"text-align: right;\"> 0.434997 </td><td style=\"text-align: right;\"> 0.0841473</td><td style=\"text-align: right;\"> 0.0511457  </td><td style=\"text-align: right;\">-0.231324  </td><td style=\"text-align: right;\">-0.0408152</td><td style=\"text-align: right;\"> 0.0517595</td><td style=\"text-align: right;\">-0.00591222</td><td style=\"text-align: right;\">-0.212198 </td><td style=\"text-align: right;\">-0.0753098</td><td style=\"text-align: right;\">-0.0714339</td><td style=\"text-align: right;\"> 0.0261387</td><td style=\"text-align: right;\"> 0.463119  </td><td style=\"text-align: right;\">-0.0376576</td><td style=\"text-align: right;\">-0.0828916 </td><td style=\"text-align: right;\"> 0.152708 </td><td style=\"text-align: right;\">-0.111939 </td><td style=\"text-align: right;\">-0.132567  </td><td style=\"text-align: right;\"> 0.0222411</td><td style=\"text-align: right;\">-0.0039838</td><td style=\"text-align: right;\">-0.211777  </td><td style=\"text-align: right;\">-0.19423  </td><td style=\"text-align: right;\">-0.156346 </td><td style=\"text-align: right;\">-0.166492  </td><td style=\"text-align: right;\"> 0.121824 </td><td style=\"text-align: right;\">-0.110317  </td><td style=\"text-align: right;\"> 0.217815  </td><td style=\"text-align: right;\">-0.0654254</td><td style=\"text-align: right;\">-0.119042 </td></tr>\n<tr><td>SRR6807701 </td><td style=\"text-align: right;\"> -9.1499 </td><td style=\"text-align: right;\">-4.45121</td><td style=\"text-align: right;\">-0.000560915</td><td style=\"text-align: right;\">-0.211492 </td><td style=\"text-align: right;\"> 0.891811 </td><td style=\"text-align: right;\">-1.61937 </td><td style=\"text-align: right;\">-0.0314806</td><td style=\"text-align: right;\">-1.11622 </td><td style=\"text-align: right;\">-0.521429</td><td style=\"text-align: right;\"> 0.226712</td><td style=\"text-align: right;\">-0.650277</td><td style=\"text-align: right;\">-0.479117 </td><td style=\"text-align: right;\">-0.996814</td><td style=\"text-align: right;\">-1.1133  </td><td style=\"text-align: right;\">-1.26154  </td><td style=\"text-align: right;\">-0.974177</td><td style=\"text-align: right;\">-0.00247332</td><td style=\"text-align: right;\">-0.0530825</td><td style=\"text-align: right;\">-0.201434 </td><td style=\"text-align: right;\">-1.98052 </td><td style=\"text-align: right;\">-1.29959 </td><td style=\"text-align: right;\">-0.260899 </td><td style=\"text-align: right;\"> 0.78139  </td><td style=\"text-align: right;\">-0.048447 </td><td style=\"text-align: right;\"> 0.238562</td><td style=\"text-align: right;\">-0.334514 </td><td style=\"text-align: right;\">-0.853045 </td><td style=\"text-align: right;\"> 0.0713396 </td><td style=\"text-align: right;\">-0.484966 </td><td style=\"text-align: right;\">-0.619925</td><td style=\"text-align: right;\">-0.21595   </td><td style=\"text-align: right;\"> 0.653184</td><td style=\"text-align: right;\">-1.5664   </td><td style=\"text-align: right;\"> 0.0428643</td><td style=\"text-align: right;\">-1.3497   </td><td style=\"text-align: right;\"> 0.0193528</td><td style=\"text-align: right;\">-0.51782  </td><td style=\"text-align: right;\"> 0.820135 </td><td style=\"text-align: right;\"> 0.293265 </td><td style=\"text-align: right;\">-0.509604 </td><td style=\"text-align: right;\"> 0.134869  </td><td style=\"text-align: right;\"> 0.00260967</td><td style=\"text-align: right;\">-0.452535 </td><td style=\"text-align: right;\">-0.293624 </td><td style=\"text-align: right;\">-0.00177784</td><td style=\"text-align: right;\">-0.149006 </td><td style=\"text-align: right;\">-0.594837 </td><td style=\"text-align: right;\"> 0.165374 </td><td style=\"text-align: right;\"> 0.351211 </td><td style=\"text-align: right;\">-0.462701 </td><td style=\"text-align: right;\">-1.30318  </td><td style=\"text-align: right;\"> 0.00425985</td><td style=\"text-align: right;\">-1.19819  </td><td style=\"text-align: right;\"> 0.371879 </td><td style=\"text-align: right;\"> 0.325116 </td><td style=\"text-align: right;\">-0.123847 </td><td style=\"text-align: right;\"> 0.937828 </td><td style=\"text-align: right;\"> 0.263567 </td><td style=\"text-align: right;\"> 0.0863833</td><td style=\"text-align: right;\"> 0.268786 </td><td style=\"text-align: right;\"> 0.402629 </td><td style=\"text-align: right;\">-0.26627    </td><td style=\"text-align: right;\"> 0.384837 </td><td style=\"text-align: right;\"> 0.60637  </td><td style=\"text-align: right;\">-0.152096 </td><td style=\"text-align: right;\">-0.0725101</td><td style=\"text-align: right;\"> 0.792331</td><td style=\"text-align: right;\">-0.0321351</td><td style=\"text-align: right;\">-0.481089 </td><td style=\"text-align: right;\">-0.42079  </td><td style=\"text-align: right;\">-0.0660262</td><td style=\"text-align: right;\">-0.148211 </td><td style=\"text-align: right;\"> 0.378529 </td><td style=\"text-align: right;\"> 0.02314  </td><td style=\"text-align: right;\">-0.0201441</td><td style=\"text-align: right;\"> 0.487322  </td><td style=\"text-align: right;\">-0.194526 </td><td style=\"text-align: right;\">-0.0200701</td><td style=\"text-align: right;\">-0.29859  </td><td style=\"text-align: right;\"> 0.0686552</td><td style=\"text-align: right;\">-0.199198 </td><td style=\"text-align: right;\">-0.241327</td><td style=\"text-align: right;\">-0.263722</td><td style=\"text-align: right;\"> 0.519523  </td><td style=\"text-align: right;\">-0.0661203</td><td style=\"text-align: right;\">-0.386223 </td><td style=\"text-align: right;\"> 0.337415 </td><td style=\"text-align: right;\">-0.0933436</td><td style=\"text-align: right;\">-0.738899 </td><td style=\"text-align: right;\"> 0.41998  </td><td style=\"text-align: right;\">-0.180534  </td><td style=\"text-align: right;\"> 0.162631  </td><td style=\"text-align: right;\"> 0.0589995</td><td style=\"text-align: right;\">-0.343279 </td><td style=\"text-align: right;\">-0.141084 </td><td style=\"text-align: right;\">-0.00846396</td><td style=\"text-align: right;\">-0.494676 </td><td style=\"text-align: right;\"> 0.062485  </td><td style=\"text-align: right;\"> 0.143639</td><td style=\"text-align: right;\">-0.154256 </td><td style=\"text-align: right;\"> 0.100058 </td><td style=\"text-align: right;\"> 0.0459747</td><td style=\"text-align: right;\">-0.10124   </td><td style=\"text-align: right;\"> 0.0749152</td><td style=\"text-align: right;\"> 0.0433454 </td><td style=\"text-align: right;\"> 0.407651</td><td style=\"text-align: right;\">-0.00085629</td><td style=\"text-align: right;\"> 0.272083 </td><td style=\"text-align: right;\">-0.36515  </td><td style=\"text-align: right;\"> 0.186306 </td><td style=\"text-align: right;\">-0.106947 </td><td style=\"text-align: right;\">-0.179909  </td><td style=\"text-align: right;\">-0.154551 </td><td style=\"text-align: right;\">-0.239001 </td><td style=\"text-align: right;\"> 0.390033 </td><td style=\"text-align: right;\"> 0.103301 </td><td style=\"text-align: right;\">-0.179483 </td><td style=\"text-align: right;\"> 0.22951   </td><td style=\"text-align: right;\">-0.0668002 </td><td style=\"text-align: right;\">-0.0825495</td><td style=\"text-align: right;\"> 0.0340617 </td><td style=\"text-align: right;\"> 0.203809 </td><td style=\"text-align: right;\">-0.275612 </td><td style=\"text-align: right;\"> 0.310813 </td><td style=\"text-align: right;\">-0.0216203</td><td style=\"text-align: right;\"> 0.0308512 </td><td style=\"text-align: right;\"> 0.295299 </td><td style=\"text-align: right;\"> 0.0617808  </td><td style=\"text-align: right;\"> 0.233424  </td><td style=\"text-align: right;\">-0.602807 </td><td style=\"text-align: right;\">-0.264453 </td><td style=\"text-align: right;\">-0.0983916</td><td style=\"text-align: right;\">-0.367157 </td><td style=\"text-align: right;\"> 0.33488  </td><td style=\"text-align: right;\">-0.248688 </td><td style=\"text-align: right;\">-0.0103886</td><td style=\"text-align: right;\"> 0.0212966</td><td style=\"text-align: right;\">-0.139436 </td><td style=\"text-align: right;\"> 0.126407  </td><td style=\"text-align: right;\"> 0.163799  </td><td style=\"text-align: right;\">-0.0999936 </td><td style=\"text-align: right;\"> 0.159078 </td><td style=\"text-align: right;\"> 0.326816 </td><td style=\"text-align: right;\">-0.422006 </td><td style=\"text-align: right;\"> 0.328108 </td><td style=\"text-align: right;\">-0.12589  </td><td style=\"text-align: right;\">-0.224009</td><td style=\"text-align: right;\"> 0.165427 </td><td style=\"text-align: right;\"> 0.00736128</td><td style=\"text-align: right;\"> 0.273949 </td><td style=\"text-align: right;\">-0.432772 </td><td style=\"text-align: right;\"> 0.261663  </td><td style=\"text-align: right;\">-0.032972  </td><td style=\"text-align: right;\">-0.417354 </td><td style=\"text-align: right;\">-0.222135 </td><td style=\"text-align: right;\">-0.277632 </td><td style=\"text-align: right;\">-0.151629</td><td style=\"text-align: right;\"> 0.199935  </td><td style=\"text-align: right;\">-0.109284 </td><td style=\"text-align: right;\"> 0.0932435 </td><td style=\"text-align: right;\"> 0.435215 </td><td style=\"text-align: right;\">-0.0667091  </td><td style=\"text-align: right;\">-0.0196309 </td><td style=\"text-align: right;\"> 0.346601  </td><td style=\"text-align: right;\">-0.0825501</td><td style=\"text-align: right;\"> 0.154359 </td><td style=\"text-align: right;\">-0.164206 </td><td style=\"text-align: right;\"> 0.37597  </td><td style=\"text-align: right;\">-0.136508 </td><td style=\"text-align: right;\"> 0.229612 </td><td style=\"text-align: right;\"> 0.213105  </td><td style=\"text-align: right;\"> 0.086485 </td><td style=\"text-align: right;\">-0.0631953</td><td style=\"text-align: right;\"> 0.159335   </td><td style=\"text-align: right;\">-0.214413  </td><td style=\"text-align: right;\">-0.114718 </td><td style=\"text-align: right;\"> 0.0446415</td><td style=\"text-align: right;\">-0.0986768 </td><td style=\"text-align: right;\"> 0.0589636</td><td style=\"text-align: right;\">-0.27537  </td><td style=\"text-align: right;\">-0.470475 </td><td style=\"text-align: right;\">-0.071911 </td><td style=\"text-align: right;\"> 0.185972  </td><td style=\"text-align: right;\">-0.316124 </td><td style=\"text-align: right;\"> 0.204503  </td><td style=\"text-align: right;\">-0.435719 </td><td style=\"text-align: right;\"> 0.31322  </td><td style=\"text-align: right;\"> 0.379372  </td><td style=\"text-align: right;\">-0.0453729</td><td style=\"text-align: right;\">-0.167095 </td><td style=\"text-align: right;\">-0.0395213 </td><td style=\"text-align: right;\"> 0.064882 </td><td style=\"text-align: right;\"> 0.348529 </td><td style=\"text-align: right;\"> 0.41005   </td><td style=\"text-align: right;\"> 0.0878616</td><td style=\"text-align: right;\">-0.0791032 </td><td style=\"text-align: right;\"> 0.187943  </td><td style=\"text-align: right;\"> 0.105175 </td><td style=\"text-align: right;\"> 0.19989  </td></tr>\n<tr><td>SRR11033700</td><td style=\"text-align: right;\"> -4.59049</td><td style=\"text-align: right;\"> 5.31294</td><td style=\"text-align: right;\">-0.043539   </td><td style=\"text-align: right;\">-1.58611  </td><td style=\"text-align: right;\">-3.70249  </td><td style=\"text-align: right;\">-0.156249</td><td style=\"text-align: right;\"> 2.93034  </td><td style=\"text-align: right;\">-4.97455 </td><td style=\"text-align: right;\">-0.930162</td><td style=\"text-align: right;\">-0.817911</td><td style=\"text-align: right;\"> 1.69132 </td><td style=\"text-align: right;\"> 0.357042 </td><td style=\"text-align: right;\">-1.68802 </td><td style=\"text-align: right;\"> 1.82346 </td><td style=\"text-align: right;\"> 1.65873  </td><td style=\"text-align: right;\"> 0.993338</td><td style=\"text-align: right;\">-0.769028  </td><td style=\"text-align: right;\"> 0.648757 </td><td style=\"text-align: right;\"> 0.739181 </td><td style=\"text-align: right;\"> 0.40869 </td><td style=\"text-align: right;\"> 1.46154 </td><td style=\"text-align: right;\">-1.07547  </td><td style=\"text-align: right;\">-0.412326 </td><td style=\"text-align: right;\">-1.15372  </td><td style=\"text-align: right;\"> 0.033482</td><td style=\"text-align: right;\">-0.399165 </td><td style=\"text-align: right;\">-1.04086  </td><td style=\"text-align: right;\"> 0.0623232 </td><td style=\"text-align: right;\"> 0.0584557</td><td style=\"text-align: right;\"> 0.287642</td><td style=\"text-align: right;\"> 0.441088  </td><td style=\"text-align: right;\"> 1.40573 </td><td style=\"text-align: right;\"> 0.373167 </td><td style=\"text-align: right;\"> 0.595857 </td><td style=\"text-align: right;\"> 0.777845 </td><td style=\"text-align: right;\">-0.284434 </td><td style=\"text-align: right;\"> 0.893216 </td><td style=\"text-align: right;\"> 0.0325202</td><td style=\"text-align: right;\">-0.253651 </td><td style=\"text-align: right;\">-0.256632 </td><td style=\"text-align: right;\"> 0.216368  </td><td style=\"text-align: right;\">-1.11769   </td><td style=\"text-align: right;\"> 0.182434 </td><td style=\"text-align: right;\">-0.300572 </td><td style=\"text-align: right;\">-0.090939  </td><td style=\"text-align: right;\">-0.220814 </td><td style=\"text-align: right;\"> 0.592161 </td><td style=\"text-align: right;\"> 0.422401 </td><td style=\"text-align: right;\"> 0.615093 </td><td style=\"text-align: right;\">-0.910159 </td><td style=\"text-align: right;\">-0.441763 </td><td style=\"text-align: right;\"> 0.315778  </td><td style=\"text-align: right;\"> 0.165484 </td><td style=\"text-align: right;\"> 0.419825 </td><td style=\"text-align: right;\">-0.294703 </td><td style=\"text-align: right;\"> 0.0210309</td><td style=\"text-align: right;\"> 0.213716 </td><td style=\"text-align: right;\">-0.211021 </td><td style=\"text-align: right;\"> 0.879258 </td><td style=\"text-align: right;\"> 0.0419514</td><td style=\"text-align: right;\">-0.500143 </td><td style=\"text-align: right;\">-0.0916183  </td><td style=\"text-align: right;\"> 0.199057 </td><td style=\"text-align: right;\">-0.275862 </td><td style=\"text-align: right;\">-0.313245 </td><td style=\"text-align: right;\"> 0.239273 </td><td style=\"text-align: right;\"> 0.113842</td><td style=\"text-align: right;\">-0.159077 </td><td style=\"text-align: right;\"> 0.669248 </td><td style=\"text-align: right;\">-0.49075  </td><td style=\"text-align: right;\">-0.165403 </td><td style=\"text-align: right;\"> 0.175773 </td><td style=\"text-align: right;\"> 0.49225  </td><td style=\"text-align: right;\">-0.407117 </td><td style=\"text-align: right;\">-0.818282 </td><td style=\"text-align: right;\">-0.758563  </td><td style=\"text-align: right;\">-0.0963912</td><td style=\"text-align: right;\">-0.253328 </td><td style=\"text-align: right;\">-0.544874 </td><td style=\"text-align: right;\"> 0.221636 </td><td style=\"text-align: right;\"> 0.406422 </td><td style=\"text-align: right;\">-0.219667</td><td style=\"text-align: right;\"> 0.195245</td><td style=\"text-align: right;\">-0.149426  </td><td style=\"text-align: right;\">-0.317279 </td><td style=\"text-align: right;\"> 0.582046 </td><td style=\"text-align: right;\">-0.210104 </td><td style=\"text-align: right;\"> 0.849998 </td><td style=\"text-align: right;\">-0.506772 </td><td style=\"text-align: right;\"> 0.455948 </td><td style=\"text-align: right;\"> 0.468586  </td><td style=\"text-align: right;\">-0.264578  </td><td style=\"text-align: right;\">-0.197681 </td><td style=\"text-align: right;\"> 0.321523 </td><td style=\"text-align: right;\">-0.0873612</td><td style=\"text-align: right;\"> 0.234735  </td><td style=\"text-align: right;\">-0.205255 </td><td style=\"text-align: right;\">-0.356656  </td><td style=\"text-align: right;\"> 0.246365</td><td style=\"text-align: right;\">-0.374521 </td><td style=\"text-align: right;\"> 0.216978 </td><td style=\"text-align: right;\">-0.184585 </td><td style=\"text-align: right;\">-0.550619  </td><td style=\"text-align: right;\">-0.202771 </td><td style=\"text-align: right;\">-0.722441  </td><td style=\"text-align: right;\"> 0.21047 </td><td style=\"text-align: right;\">-0.227439  </td><td style=\"text-align: right;\"> 0.408528 </td><td style=\"text-align: right;\"> 0.615943 </td><td style=\"text-align: right;\"> 0.0445044</td><td style=\"text-align: right;\">-0.0414433</td><td style=\"text-align: right;\"> 0.340925  </td><td style=\"text-align: right;\"> 0.294431 </td><td style=\"text-align: right;\"> 0.648748 </td><td style=\"text-align: right;\">-0.191099 </td><td style=\"text-align: right;\"> 0.322158 </td><td style=\"text-align: right;\"> 0.419815 </td><td style=\"text-align: right;\"> 0.598406  </td><td style=\"text-align: right;\"> 0.141637  </td><td style=\"text-align: right;\">-0.274665 </td><td style=\"text-align: right;\"> 0.482582  </td><td style=\"text-align: right;\">-0.0160315</td><td style=\"text-align: right;\"> 0.0962388</td><td style=\"text-align: right;\">-0.450854 </td><td style=\"text-align: right;\">-0.0831487</td><td style=\"text-align: right;\"> 0.363272  </td><td style=\"text-align: right;\"> 0.0283987</td><td style=\"text-align: right;\">-0.304109   </td><td style=\"text-align: right;\"> 0.0881775 </td><td style=\"text-align: right;\">-0.281148 </td><td style=\"text-align: right;\">-0.347671 </td><td style=\"text-align: right;\"> 0.48956  </td><td style=\"text-align: right;\">-0.679409 </td><td style=\"text-align: right;\">-0.0465728</td><td style=\"text-align: right;\">-0.0229669</td><td style=\"text-align: right;\"> 0.305086 </td><td style=\"text-align: right;\"> 0.630215 </td><td style=\"text-align: right;\">-0.247286 </td><td style=\"text-align: right;\"> 0.0045951 </td><td style=\"text-align: right;\">-0.607346  </td><td style=\"text-align: right;\">-0.00771802</td><td style=\"text-align: right;\"> 0.229427 </td><td style=\"text-align: right;\">-0.398598 </td><td style=\"text-align: right;\">-0.666365 </td><td style=\"text-align: right;\">-0.153768 </td><td style=\"text-align: right;\">-0.323856 </td><td style=\"text-align: right;\">-0.209572</td><td style=\"text-align: right;\">-0.241635 </td><td style=\"text-align: right;\">-0.302749  </td><td style=\"text-align: right;\"> 0.194522 </td><td style=\"text-align: right;\"> 0.685216 </td><td style=\"text-align: right;\"> 0.00430719</td><td style=\"text-align: right;\"> 0.027653  </td><td style=\"text-align: right;\"> 0.318633 </td><td style=\"text-align: right;\"> 0.318989 </td><td style=\"text-align: right;\"> 0.333135 </td><td style=\"text-align: right;\"> 0.345507</td><td style=\"text-align: right;\">-0.145466  </td><td style=\"text-align: right;\"> 0.0686151</td><td style=\"text-align: right;\"> 0.115055  </td><td style=\"text-align: right;\">-0.362267 </td><td style=\"text-align: right;\">-0.616801   </td><td style=\"text-align: right;\"> 0.104639  </td><td style=\"text-align: right;\">-0.34185   </td><td style=\"text-align: right;\">-0.354017 </td><td style=\"text-align: right;\">-0.435519 </td><td style=\"text-align: right;\">-0.169556 </td><td style=\"text-align: right;\"> 0.060568 </td><td style=\"text-align: right;\"> 0.530617 </td><td style=\"text-align: right;\"> 0.252677 </td><td style=\"text-align: right;\">-0.0308713 </td><td style=\"text-align: right;\">-0.401517 </td><td style=\"text-align: right;\"> 0.370231 </td><td style=\"text-align: right;\"> 0.193731   </td><td style=\"text-align: right;\">-0.212494  </td><td style=\"text-align: right;\"> 0.212407 </td><td style=\"text-align: right;\"> 0.0962742</td><td style=\"text-align: right;\">-0.0251926 </td><td style=\"text-align: right;\"> 0.013189 </td><td style=\"text-align: right;\"> 0.237966 </td><td style=\"text-align: right;\">-0.0909133</td><td style=\"text-align: right;\">-0.31605  </td><td style=\"text-align: right;\">-0.045298  </td><td style=\"text-align: right;\"> 0.43653  </td><td style=\"text-align: right;\"> 0.0797025 </td><td style=\"text-align: right;\">-0.598752 </td><td style=\"text-align: right;\"> 0.219091 </td><td style=\"text-align: right;\">-0.246436  </td><td style=\"text-align: right;\"> 0.355176 </td><td style=\"text-align: right;\">-0.615051 </td><td style=\"text-align: right;\"> 0.214979  </td><td style=\"text-align: right;\">-0.228767 </td><td style=\"text-align: right;\"> 0.174032 </td><td style=\"text-align: right;\">-0.347543  </td><td style=\"text-align: right;\"> 0.355885 </td><td style=\"text-align: right;\">-0.970259  </td><td style=\"text-align: right;\"> 0.529508  </td><td style=\"text-align: right;\"> 0.348943 </td><td style=\"text-align: right;\">-0.0221957</td></tr>\n<tr><td>SRR1163101 </td><td style=\"text-align: right;\"> -8.68246</td><td style=\"text-align: right;\">-4.77252</td><td style=\"text-align: right;\"> 0.00352481 </td><td style=\"text-align: right;\"> 0.0944094</td><td style=\"text-align: right;\"> 0.517031 </td><td style=\"text-align: right;\">-3.71639 </td><td style=\"text-align: right;\"> 0.988545 </td><td style=\"text-align: right;\"> 0.65286 </td><td style=\"text-align: right;\">-0.217747</td><td style=\"text-align: right;\"> 0.573477</td><td style=\"text-align: right;\"> 0.52632 </td><td style=\"text-align: right;\">-0.683847 </td><td style=\"text-align: right;\">-0.328461</td><td style=\"text-align: right;\">-0.396951</td><td style=\"text-align: right;\">-0.832451 </td><td style=\"text-align: right;\"> 0.354952</td><td style=\"text-align: right;\">-2.34578   </td><td style=\"text-align: right;\"> 1.25273  </td><td style=\"text-align: right;\">-0.0812596</td><td style=\"text-align: right;\">-0.894451</td><td style=\"text-align: right;\"> 1.79601 </td><td style=\"text-align: right;\">-0.755556 </td><td style=\"text-align: right;\">-1.18765  </td><td style=\"text-align: right;\">-0.329411 </td><td style=\"text-align: right;\"> 0.130982</td><td style=\"text-align: right;\"> 0.0222099</td><td style=\"text-align: right;\">-0.690187 </td><td style=\"text-align: right;\"> 0.0358821 </td><td style=\"text-align: right;\"> 0.24405  </td><td style=\"text-align: right;\">-0.157876</td><td style=\"text-align: right;\"> 0.157296  </td><td style=\"text-align: right;\">-0.45587 </td><td style=\"text-align: right;\">-0.32256  </td><td style=\"text-align: right;\"> 0.496656 </td><td style=\"text-align: right;\">-0.321544 </td><td style=\"text-align: right;\">-0.447171 </td><td style=\"text-align: right;\"> 0.0159054</td><td style=\"text-align: right;\">-0.071811 </td><td style=\"text-align: right;\">-0.527262 </td><td style=\"text-align: right;\"> 0.294327 </td><td style=\"text-align: right;\"> 0.0221319 </td><td style=\"text-align: right;\">-0.44001   </td><td style=\"text-align: right;\">-0.17165  </td><td style=\"text-align: right;\">-0.0971737</td><td style=\"text-align: right;\"> 0.0824659 </td><td style=\"text-align: right;\">-0.32426  </td><td style=\"text-align: right;\"> 0.175003 </td><td style=\"text-align: right;\">-0.121623 </td><td style=\"text-align: right;\">-0.332931 </td><td style=\"text-align: right;\">-0.109857 </td><td style=\"text-align: right;\"> 0.113921 </td><td style=\"text-align: right;\"> 0.185016  </td><td style=\"text-align: right;\">-0.172949 </td><td style=\"text-align: right;\">-0.146797 </td><td style=\"text-align: right;\"> 0.0518847</td><td style=\"text-align: right;\">-0.241559 </td><td style=\"text-align: right;\">-0.0679523</td><td style=\"text-align: right;\"> 0.0335394</td><td style=\"text-align: right;\">-0.397274 </td><td style=\"text-align: right;\">-0.122382 </td><td style=\"text-align: right;\">-1.07938  </td><td style=\"text-align: right;\"> 0.804987   </td><td style=\"text-align: right;\">-0.784403 </td><td style=\"text-align: right;\"> 0.049347 </td><td style=\"text-align: right;\"> 0.0892695</td><td style=\"text-align: right;\">-0.234216 </td><td style=\"text-align: right;\">-0.393779</td><td style=\"text-align: right;\"> 0.12618  </td><td style=\"text-align: right;\"> 0.110403 </td><td style=\"text-align: right;\">-0.293747 </td><td style=\"text-align: right;\">-0.196784 </td><td style=\"text-align: right;\">-0.247168 </td><td style=\"text-align: right;\"> 0.097565 </td><td style=\"text-align: right;\"> 0.275938 </td><td style=\"text-align: right;\">-0.0729131</td><td style=\"text-align: right;\"> 0.12785   </td><td style=\"text-align: right;\"> 0.167029 </td><td style=\"text-align: right;\">-0.0804026</td><td style=\"text-align: right;\"> 0.13433  </td><td style=\"text-align: right;\">-0.384247 </td><td style=\"text-align: right;\"> 0.0972462</td><td style=\"text-align: right;\">-0.068248</td><td style=\"text-align: right;\">-0.183705</td><td style=\"text-align: right;\"> 0.00138043</td><td style=\"text-align: right;\"> 0.345901 </td><td style=\"text-align: right;\"> 0.314085 </td><td style=\"text-align: right;\"> 0.432695 </td><td style=\"text-align: right;\"> 0.0817047</td><td style=\"text-align: right;\">-0.247884 </td><td style=\"text-align: right;\">-0.405813 </td><td style=\"text-align: right;\"> 0.264043  </td><td style=\"text-align: right;\">-0.181348  </td><td style=\"text-align: right;\">-0.0680196</td><td style=\"text-align: right;\"> 0.263482 </td><td style=\"text-align: right;\">-0.070708 </td><td style=\"text-align: right;\"> 0.145009  </td><td style=\"text-align: right;\">-0.180823 </td><td style=\"text-align: right;\"> 0.155849  </td><td style=\"text-align: right;\">-0.31145 </td><td style=\"text-align: right;\">-0.0989632</td><td style=\"text-align: right;\">-0.0866583</td><td style=\"text-align: right;\"> 0.464757 </td><td style=\"text-align: right;\"> 0.0708443 </td><td style=\"text-align: right;\"> 0.177191 </td><td style=\"text-align: right;\"> 0.00976185</td><td style=\"text-align: right;\"> 0.113518</td><td style=\"text-align: right;\">-0.0383682 </td><td style=\"text-align: right;\"> 0.0381381</td><td style=\"text-align: right;\"> 0.0265574</td><td style=\"text-align: right;\">-0.12861  </td><td style=\"text-align: right;\"> 0.16697  </td><td style=\"text-align: right;\">-0.331246  </td><td style=\"text-align: right;\"> 0.162963 </td><td style=\"text-align: right;\"> 0.3131   </td><td style=\"text-align: right;\"> 0.0116855</td><td style=\"text-align: right;\">-0.170562 </td><td style=\"text-align: right;\"> 0.0675353</td><td style=\"text-align: right;\">-0.135805  </td><td style=\"text-align: right;\"> 0.1076    </td><td style=\"text-align: right;\">-0.367674 </td><td style=\"text-align: right;\">-0.00944606</td><td style=\"text-align: right;\"> 0.664511 </td><td style=\"text-align: right;\">-0.0524581</td><td style=\"text-align: right;\"> 0.149948 </td><td style=\"text-align: right;\">-0.37418  </td><td style=\"text-align: right;\">-0.173271  </td><td style=\"text-align: right;\"> 0.374806 </td><td style=\"text-align: right;\"> 0.322866   </td><td style=\"text-align: right;\"> 0.0653631 </td><td style=\"text-align: right;\"> 0.117941 </td><td style=\"text-align: right;\"> 0.0171137</td><td style=\"text-align: right;\">-0.196438 </td><td style=\"text-align: right;\"> 0.183118 </td><td style=\"text-align: right;\">-0.184732 </td><td style=\"text-align: right;\">-0.196132 </td><td style=\"text-align: right;\"> 0.0925266</td><td style=\"text-align: right;\">-0.0897482</td><td style=\"text-align: right;\"> 0.0666219</td><td style=\"text-align: right;\">-0.00172925</td><td style=\"text-align: right;\"> 0.00750581</td><td style=\"text-align: right;\"> 0.0064723 </td><td style=\"text-align: right;\"> 0.157167 </td><td style=\"text-align: right;\">-0.30515  </td><td style=\"text-align: right;\"> 0.0055818</td><td style=\"text-align: right;\">-0.0963982</td><td style=\"text-align: right;\"> 0.110583 </td><td style=\"text-align: right;\">-0.139017</td><td style=\"text-align: right;\">-0.0481604</td><td style=\"text-align: right;\">-0.232714  </td><td style=\"text-align: right;\">-0.160162 </td><td style=\"text-align: right;\"> 0.173199 </td><td style=\"text-align: right;\">-0.0826625 </td><td style=\"text-align: right;\">-0.241485  </td><td style=\"text-align: right;\">-0.0495134</td><td style=\"text-align: right;\"> 0.151465 </td><td style=\"text-align: right;\"> 0.0346363</td><td style=\"text-align: right;\">-0.148535</td><td style=\"text-align: right;\">-0.144367  </td><td style=\"text-align: right;\"> 0.0784351</td><td style=\"text-align: right;\"> 0.09193   </td><td style=\"text-align: right;\"> 0.0801042</td><td style=\"text-align: right;\"> 0.103298   </td><td style=\"text-align: right;\">-0.0168575 </td><td style=\"text-align: right;\">-0.121607  </td><td style=\"text-align: right;\"> 0.137488 </td><td style=\"text-align: right;\">-0.080562 </td><td style=\"text-align: right;\">-0.0122179</td><td style=\"text-align: right;\"> 0.278007 </td><td style=\"text-align: right;\"> 0.300971 </td><td style=\"text-align: right;\"> 0.0471241</td><td style=\"text-align: right;\">-0.0783548 </td><td style=\"text-align: right;\"> 0.0483359</td><td style=\"text-align: right;\"> 0.26833  </td><td style=\"text-align: right;\">-0.148815   </td><td style=\"text-align: right;\"> 0.0062242 </td><td style=\"text-align: right;\"> 0.41095  </td><td style=\"text-align: right;\"> 0.1374   </td><td style=\"text-align: right;\">-0.0122015 </td><td style=\"text-align: right;\">-0.0344289</td><td style=\"text-align: right;\">-0.261423 </td><td style=\"text-align: right;\">-0.131396 </td><td style=\"text-align: right;\">-0.211338 </td><td style=\"text-align: right;\"> 0.00387303</td><td style=\"text-align: right;\"> 0.082486 </td><td style=\"text-align: right;\">-0.130322  </td><td style=\"text-align: right;\">-0.137823 </td><td style=\"text-align: right;\"> 0.0903963</td><td style=\"text-align: right;\"> 0.00290438</td><td style=\"text-align: right;\"> 0.0638734</td><td style=\"text-align: right;\"> 0.117863 </td><td style=\"text-align: right;\"> 0.00904495</td><td style=\"text-align: right;\">-0.0510632</td><td style=\"text-align: right;\">-0.0925759</td><td style=\"text-align: right;\">-0.00737436</td><td style=\"text-align: right;\">-0.108323 </td><td style=\"text-align: right;\">-0.00531824</td><td style=\"text-align: right;\"> 0.00543457</td><td style=\"text-align: right;\"> 0.276971 </td><td style=\"text-align: right;\"> 0.245328 </td></tr>\n<tr><td>SRR7592336 </td><td style=\"text-align: right;\"> -9.19672</td><td style=\"text-align: right;\"> 7.94682</td><td style=\"text-align: right;\">-0.0615294  </td><td style=\"text-align: right;\">-1.82745  </td><td style=\"text-align: right;\">-4.61263  </td><td style=\"text-align: right;\">-2.20144 </td><td style=\"text-align: right;\">-6.78272  </td><td style=\"text-align: right;\"> 0.342489</td><td style=\"text-align: right;\"> 0.726244</td><td style=\"text-align: right;\">-2.52807 </td><td style=\"text-align: right;\"> 2.35922 </td><td style=\"text-align: right;\">-0.920174 </td><td style=\"text-align: right;\"> 1.58982 </td><td style=\"text-align: right;\"> 1.77681 </td><td style=\"text-align: right;\">-1.02456  </td><td style=\"text-align: right;\">-0.135104</td><td style=\"text-align: right;\">-1.06266   </td><td style=\"text-align: right;\">-1.23535  </td><td style=\"text-align: right;\">-1.06946  </td><td style=\"text-align: right;\"> 0.256949</td><td style=\"text-align: right;\">-0.135148</td><td style=\"text-align: right;\"> 0.0709823</td><td style=\"text-align: right;\"> 0.120553 </td><td style=\"text-align: right;\">-0.212403 </td><td style=\"text-align: right;\"> 0.314243</td><td style=\"text-align: right;\">-0.718003 </td><td style=\"text-align: right;\">-0.0869338</td><td style=\"text-align: right;\"> 0.124004  </td><td style=\"text-align: right;\">-2.44493  </td><td style=\"text-align: right;\"> 0.276341</td><td style=\"text-align: right;\"> 0.149156  </td><td style=\"text-align: right;\">-0.887986</td><td style=\"text-align: right;\"> 0.74151  </td><td style=\"text-align: right;\">-0.488781 </td><td style=\"text-align: right;\">-0.0879999</td><td style=\"text-align: right;\">-0.646071 </td><td style=\"text-align: right;\"> 0.247737 </td><td style=\"text-align: right;\"> 2.36842  </td><td style=\"text-align: right;\">-0.191677 </td><td style=\"text-align: right;\">-0.843649 </td><td style=\"text-align: right;\"> 0.932515  </td><td style=\"text-align: right;\">-0.412667  </td><td style=\"text-align: right;\">-1.76671  </td><td style=\"text-align: right;\"> 1.40751  </td><td style=\"text-align: right;\"> 0.31721   </td><td style=\"text-align: right;\"> 0.412233 </td><td style=\"text-align: right;\"> 0.636046 </td><td style=\"text-align: right;\"> 0.482982 </td><td style=\"text-align: right;\">-1.7244   </td><td style=\"text-align: right;\">-1.14457  </td><td style=\"text-align: right;\">-1.8538   </td><td style=\"text-align: right;\">-0.382721  </td><td style=\"text-align: right;\">-0.100829 </td><td style=\"text-align: right;\"> 1.13878  </td><td style=\"text-align: right;\">-0.671918 </td><td style=\"text-align: right;\">-1.06497  </td><td style=\"text-align: right;\">-1.17288  </td><td style=\"text-align: right;\">-0.097851 </td><td style=\"text-align: right;\">-0.69384  </td><td style=\"text-align: right;\"> 1.24439  </td><td style=\"text-align: right;\">-0.048193 </td><td style=\"text-align: right;\">-0.645799   </td><td style=\"text-align: right;\">-0.132279 </td><td style=\"text-align: right;\">-2.03033  </td><td style=\"text-align: right;\"> 2.31706  </td><td style=\"text-align: right;\"> 0.017334 </td><td style=\"text-align: right;\"> 0.431449</td><td style=\"text-align: right;\">-1.51772  </td><td style=\"text-align: right;\"> 0.162575 </td><td style=\"text-align: right;\"> 0.758915 </td><td style=\"text-align: right;\">-0.138466 </td><td style=\"text-align: right;\"> 0.136531 </td><td style=\"text-align: right;\">-0.49254  </td><td style=\"text-align: right;\">-0.298467 </td><td style=\"text-align: right;\">-1.42526  </td><td style=\"text-align: right;\">-0.740595  </td><td style=\"text-align: right;\">-1.18069  </td><td style=\"text-align: right;\"> 0.513582 </td><td style=\"text-align: right;\">-0.586936 </td><td style=\"text-align: right;\">-0.203759 </td><td style=\"text-align: right;\"> 0.627928 </td><td style=\"text-align: right;\"> 1.36234 </td><td style=\"text-align: right;\">-0.866153</td><td style=\"text-align: right;\">-1.29616   </td><td style=\"text-align: right;\"> 0.535693 </td><td style=\"text-align: right;\"> 0.415754 </td><td style=\"text-align: right;\"> 0.570849 </td><td style=\"text-align: right;\">-1.48843  </td><td style=\"text-align: right;\"> 0.270096 </td><td style=\"text-align: right;\"> 0.543689 </td><td style=\"text-align: right;\">-0.908162  </td><td style=\"text-align: right;\">-0.105914  </td><td style=\"text-align: right;\"> 0.339703 </td><td style=\"text-align: right;\"> 0.496366 </td><td style=\"text-align: right;\"> 0.925362 </td><td style=\"text-align: right;\">-0.933789  </td><td style=\"text-align: right;\">-1.00079  </td><td style=\"text-align: right;\"> 0.00877185</td><td style=\"text-align: right;\"> 0.322465</td><td style=\"text-align: right;\"> 0.91807  </td><td style=\"text-align: right;\">-1.99269  </td><td style=\"text-align: right;\"> 0.165965 </td><td style=\"text-align: right;\"> 0.353154  </td><td style=\"text-align: right;\"> 0.306088 </td><td style=\"text-align: right;\"> 0.326838  </td><td style=\"text-align: right;\">-0.952772</td><td style=\"text-align: right;\">-0.146353  </td><td style=\"text-align: right;\"> 0.434984 </td><td style=\"text-align: right;\">-0.340664 </td><td style=\"text-align: right;\"> 2.29767  </td><td style=\"text-align: right;\"> 0.0678048</td><td style=\"text-align: right;\"> 0.420068  </td><td style=\"text-align: right;\">-1.27611  </td><td style=\"text-align: right;\"> 0.259335 </td><td style=\"text-align: right;\"> 0.302944 </td><td style=\"text-align: right;\"> 0.911172 </td><td style=\"text-align: right;\">-0.762877 </td><td style=\"text-align: right;\"> 0.00954014</td><td style=\"text-align: right;\"> 1.78079   </td><td style=\"text-align: right;\">-0.326688 </td><td style=\"text-align: right;\">-0.603852  </td><td style=\"text-align: right;\"> 1.44774  </td><td style=\"text-align: right;\"> 0.267919 </td><td style=\"text-align: right;\">-0.226292 </td><td style=\"text-align: right;\"> 1.30767  </td><td style=\"text-align: right;\"> 0.233281  </td><td style=\"text-align: right;\"> 0.24383  </td><td style=\"text-align: right;\"> 0.0630102  </td><td style=\"text-align: right;\"> 0.122896  </td><td style=\"text-align: right;\"> 1.05555  </td><td style=\"text-align: right;\"> 0.280146 </td><td style=\"text-align: right;\">-0.134538 </td><td style=\"text-align: right;\">-0.731806 </td><td style=\"text-align: right;\">-0.285732 </td><td style=\"text-align: right;\">-1.32877  </td><td style=\"text-align: right;\">-0.335229 </td><td style=\"text-align: right;\">-0.519341 </td><td style=\"text-align: right;\">-0.643283 </td><td style=\"text-align: right;\"> 0.897955  </td><td style=\"text-align: right;\"> 0.672274  </td><td style=\"text-align: right;\"> 0.294411  </td><td style=\"text-align: right;\"> 0.143189 </td><td style=\"text-align: right;\">-0.0573502</td><td style=\"text-align: right;\"> 0.451826 </td><td style=\"text-align: right;\"> 0.42029  </td><td style=\"text-align: right;\">-0.324798 </td><td style=\"text-align: right;\">-1.14813 </td><td style=\"text-align: right;\"> 1.55177  </td><td style=\"text-align: right;\"> 0.302485  </td><td style=\"text-align: right;\"> 0.0641582</td><td style=\"text-align: right;\">-0.128799 </td><td style=\"text-align: right;\">-1.17716   </td><td style=\"text-align: right;\">-0.648077  </td><td style=\"text-align: right;\">-0.761746 </td><td style=\"text-align: right;\"> 0.782809 </td><td style=\"text-align: right;\">-1.34186  </td><td style=\"text-align: right;\">-0.948957</td><td style=\"text-align: right;\"> 0.617957  </td><td style=\"text-align: right;\"> 0.691935 </td><td style=\"text-align: right;\">-0.00794323</td><td style=\"text-align: right;\">-0.36627  </td><td style=\"text-align: right;\"> 0.5934     </td><td style=\"text-align: right;\"> 0.669587  </td><td style=\"text-align: right;\"> 0.0575043 </td><td style=\"text-align: right;\">-0.668937 </td><td style=\"text-align: right;\">-0.208462 </td><td style=\"text-align: right;\">-0.475375 </td><td style=\"text-align: right;\">-0.114637 </td><td style=\"text-align: right;\">-0.712252 </td><td style=\"text-align: right;\"> 0.706196 </td><td style=\"text-align: right;\"> 0.393449  </td><td style=\"text-align: right;\">-0.0882379</td><td style=\"text-align: right;\">-0.215291 </td><td style=\"text-align: right;\"> 0.000254881</td><td style=\"text-align: right;\">-1.08491   </td><td style=\"text-align: right;\"> 0.26807  </td><td style=\"text-align: right;\">-1.35235  </td><td style=\"text-align: right;\"> 0.83783   </td><td style=\"text-align: right;\"> 0.559586 </td><td style=\"text-align: right;\">-0.905636 </td><td style=\"text-align: right;\"> 0.771805 </td><td style=\"text-align: right;\">-0.450792 </td><td style=\"text-align: right;\">-0.428496  </td><td style=\"text-align: right;\"> 0.0861287</td><td style=\"text-align: right;\"> 0.379909  </td><td style=\"text-align: right;\">-0.448908 </td><td style=\"text-align: right;\">-0.729855 </td><td style=\"text-align: right;\">-1.16339   </td><td style=\"text-align: right;\"> 0.153952 </td><td style=\"text-align: right;\"> 0.492471 </td><td style=\"text-align: right;\"> 0.122041  </td><td style=\"text-align: right;\"> 0.834458 </td><td style=\"text-align: right;\"> 0.341664 </td><td style=\"text-align: right;\">-0.329075  </td><td style=\"text-align: right;\">-1.22     </td><td style=\"text-align: right;\"> 0.723765  </td><td style=\"text-align: right;\">-0.649107  </td><td style=\"text-align: right;\">-0.778855 </td><td style=\"text-align: right;\"> 2.10345  </td></tr>\n<tr><td>SRR1163415 </td><td style=\"text-align: right;\"> -8.97007</td><td style=\"text-align: right;\">-5.43213</td><td style=\"text-align: right;\"> 0.00272524 </td><td style=\"text-align: right;\"> 0.28841  </td><td style=\"text-align: right;\"> 0.0794467</td><td style=\"text-align: right;\">-3.89085 </td><td style=\"text-align: right;\"> 0.632721 </td><td style=\"text-align: right;\"> 0.5904  </td><td style=\"text-align: right;\">-0.127595</td><td style=\"text-align: right;\"> 0.102558</td><td style=\"text-align: right;\"> 0.71127 </td><td style=\"text-align: right;\">-0.632055 </td><td style=\"text-align: right;\">-0.726413</td><td style=\"text-align: right;\">-0.124563</td><td style=\"text-align: right;\">-0.851183 </td><td style=\"text-align: right;\">-0.054087</td><td style=\"text-align: right;\">-1.16743   </td><td style=\"text-align: right;\"> 0.376756 </td><td style=\"text-align: right;\">-0.485514 </td><td style=\"text-align: right;\"> 1.74656 </td><td style=\"text-align: right;\"> 1.82665 </td><td style=\"text-align: right;\">-0.158678 </td><td style=\"text-align: right;\">-0.241553 </td><td style=\"text-align: right;\">-0.364044 </td><td style=\"text-align: right;\">-0.217666</td><td style=\"text-align: right;\"> 0.325344 </td><td style=\"text-align: right;\">-0.32731  </td><td style=\"text-align: right;\">-0.00430132</td><td style=\"text-align: right;\"> 0.631429 </td><td style=\"text-align: right;\"> 0.602307</td><td style=\"text-align: right;\"> 0.00693307</td><td style=\"text-align: right;\">-0.100303</td><td style=\"text-align: right;\">-0.522723 </td><td style=\"text-align: right;\"> 0.60247  </td><td style=\"text-align: right;\"> 0.181705 </td><td style=\"text-align: right;\">-0.255738 </td><td style=\"text-align: right;\"> 0.049287 </td><td style=\"text-align: right;\">-0.0754982</td><td style=\"text-align: right;\">-0.0537969</td><td style=\"text-align: right;\"> 0.434123 </td><td style=\"text-align: right;\"> 0.0349033 </td><td style=\"text-align: right;\"> 0.0485308 </td><td style=\"text-align: right;\">-0.263522 </td><td style=\"text-align: right;\">-0.0376923</td><td style=\"text-align: right;\"> 0.143516  </td><td style=\"text-align: right;\">-0.22031  </td><td style=\"text-align: right;\"> 0.29255  </td><td style=\"text-align: right;\"> 0.0904726</td><td style=\"text-align: right;\">-0.0917416</td><td style=\"text-align: right;\">-0.0518825</td><td style=\"text-align: right;\">-0.134846 </td><td style=\"text-align: right;\">-0.0404059 </td><td style=\"text-align: right;\"> 0.205374 </td><td style=\"text-align: right;\"> 0.4644   </td><td style=\"text-align: right;\"> 0.010876 </td><td style=\"text-align: right;\"> 0.265961 </td><td style=\"text-align: right;\">-0.48591  </td><td style=\"text-align: right;\">-0.116062 </td><td style=\"text-align: right;\"> 0.246857 </td><td style=\"text-align: right;\"> 0.0471285</td><td style=\"text-align: right;\">-0.153093 </td><td style=\"text-align: right;\">-0.000917792</td><td style=\"text-align: right;\"> 0.0952652</td><td style=\"text-align: right;\">-0.0410535</td><td style=\"text-align: right;\"> 0.107979 </td><td style=\"text-align: right;\"> 0.0804973</td><td style=\"text-align: right;\">-0.144514</td><td style=\"text-align: right;\"> 0.118716 </td><td style=\"text-align: right;\">-0.216696 </td><td style=\"text-align: right;\"> 0.210607 </td><td style=\"text-align: right;\"> 0.135711 </td><td style=\"text-align: right;\"> 0.125965 </td><td style=\"text-align: right;\"> 0.0628714</td><td style=\"text-align: right;\"> 0.127415 </td><td style=\"text-align: right;\"> 0.469845 </td><td style=\"text-align: right;\">-0.0667844 </td><td style=\"text-align: right;\"> 0.299821 </td><td style=\"text-align: right;\">-0.12846  </td><td style=\"text-align: right;\">-0.310889 </td><td style=\"text-align: right;\">-0.0219621</td><td style=\"text-align: right;\">-0.0634152</td><td style=\"text-align: right;\"> 0.280179</td><td style=\"text-align: right;\">-0.190406</td><td style=\"text-align: right;\"> 0.080822  </td><td style=\"text-align: right;\"> 0.505054 </td><td style=\"text-align: right;\">-0.274689 </td><td style=\"text-align: right;\"> 0.0995224</td><td style=\"text-align: right;\"> 0.129501 </td><td style=\"text-align: right;\">-0.0746645</td><td style=\"text-align: right;\">-0.280162 </td><td style=\"text-align: right;\">-0.00093445</td><td style=\"text-align: right;\"> 0.325553  </td><td style=\"text-align: right;\"> 0.298584 </td><td style=\"text-align: right;\"> 0.290192 </td><td style=\"text-align: right;\">-0.221259 </td><td style=\"text-align: right;\">-0.316362  </td><td style=\"text-align: right;\">-0.0866782</td><td style=\"text-align: right;\"> 0.50856   </td><td style=\"text-align: right;\"> 0.115006</td><td style=\"text-align: right;\"> 0.386605 </td><td style=\"text-align: right;\">-0.0275449</td><td style=\"text-align: right;\"> 0.325659 </td><td style=\"text-align: right;\"> 0.125141  </td><td style=\"text-align: right;\"> 0.1233   </td><td style=\"text-align: right;\"> 0.118446  </td><td style=\"text-align: right;\"> 0.213108</td><td style=\"text-align: right;\">-0.21447   </td><td style=\"text-align: right;\"> 0.103515 </td><td style=\"text-align: right;\">-0.162711 </td><td style=\"text-align: right;\">-0.146634 </td><td style=\"text-align: right;\"> 0.207015 </td><td style=\"text-align: right;\">-0.172975  </td><td style=\"text-align: right;\"> 0.369363 </td><td style=\"text-align: right;\">-0.117679 </td><td style=\"text-align: right;\"> 0.127677 </td><td style=\"text-align: right;\">-0.0634523</td><td style=\"text-align: right;\">-0.0536918</td><td style=\"text-align: right;\"> 0.192478  </td><td style=\"text-align: right;\"> 0.198908  </td><td style=\"text-align: right;\"> 0.342845 </td><td style=\"text-align: right;\"> 0.0431692 </td><td style=\"text-align: right;\">-0.328894 </td><td style=\"text-align: right;\"> 0.326333 </td><td style=\"text-align: right;\">-0.0311168</td><td style=\"text-align: right;\">-0.245055 </td><td style=\"text-align: right;\"> 0.268527  </td><td style=\"text-align: right;\"> 0.193657 </td><td style=\"text-align: right;\">-0.103903   </td><td style=\"text-align: right;\">-0.0323027 </td><td style=\"text-align: right;\"> 0.321355 </td><td style=\"text-align: right;\">-0.0616184</td><td style=\"text-align: right;\">-0.0753923</td><td style=\"text-align: right;\">-0.0921688</td><td style=\"text-align: right;\">-0.204716 </td><td style=\"text-align: right;\">-0.410808 </td><td style=\"text-align: right;\"> 0.132522 </td><td style=\"text-align: right;\"> 0.0881262</td><td style=\"text-align: right;\">-0.0974992</td><td style=\"text-align: right;\">-0.0268259 </td><td style=\"text-align: right;\"> 0.118561  </td><td style=\"text-align: right;\"> 0.39624   </td><td style=\"text-align: right;\">-0.422308 </td><td style=\"text-align: right;\">-0.047406 </td><td style=\"text-align: right;\"> 0.0247631</td><td style=\"text-align: right;\">-0.0875903</td><td style=\"text-align: right;\"> 0.0627485</td><td style=\"text-align: right;\">-0.287498</td><td style=\"text-align: right;\">-0.0175366</td><td style=\"text-align: right;\">-0.152858  </td><td style=\"text-align: right;\">-0.0592951</td><td style=\"text-align: right;\"> 0.206058 </td><td style=\"text-align: right;\"> 0.0673219 </td><td style=\"text-align: right;\"> 0.0939456 </td><td style=\"text-align: right;\"> 0.0170619</td><td style=\"text-align: right;\">-0.254741 </td><td style=\"text-align: right;\">-0.0368757</td><td style=\"text-align: right;\"> 0.161321</td><td style=\"text-align: right;\">-0.00412753</td><td style=\"text-align: right;\">-0.240887 </td><td style=\"text-align: right;\"> 0.0474343 </td><td style=\"text-align: right;\"> 0.199414 </td><td style=\"text-align: right;\">-0.133641   </td><td style=\"text-align: right;\"> 0.165681  </td><td style=\"text-align: right;\"> 0.0410559 </td><td style=\"text-align: right;\">-0.242758 </td><td style=\"text-align: right;\"> 0.0618847</td><td style=\"text-align: right;\"> 0.129121 </td><td style=\"text-align: right;\">-0.0017245</td><td style=\"text-align: right;\">-0.135786 </td><td style=\"text-align: right;\">-0.104665 </td><td style=\"text-align: right;\">-0.0768873 </td><td style=\"text-align: right;\"> 0.155628 </td><td style=\"text-align: right;\">-0.226643 </td><td style=\"text-align: right;\">-0.311717   </td><td style=\"text-align: right;\">-0.00275112</td><td style=\"text-align: right;\">-0.265139 </td><td style=\"text-align: right;\">-0.243158 </td><td style=\"text-align: right;\"> 0.0752308 </td><td style=\"text-align: right;\">-0.0870046</td><td style=\"text-align: right;\">-0.183222 </td><td style=\"text-align: right;\">-0.145014 </td><td style=\"text-align: right;\"> 0.0244057</td><td style=\"text-align: right;\"> 0.0655492 </td><td style=\"text-align: right;\">-0.153869 </td><td style=\"text-align: right;\">-0.140731  </td><td style=\"text-align: right;\">-0.0511595</td><td style=\"text-align: right;\"> 0.305929 </td><td style=\"text-align: right;\"> 0.215741  </td><td style=\"text-align: right;\"> 0.0643249</td><td style=\"text-align: right;\">-0.111242 </td><td style=\"text-align: right;\"> 0.0574274 </td><td style=\"text-align: right;\"> 0.0537022</td><td style=\"text-align: right;\">-0.31474  </td><td style=\"text-align: right;\">-0.21632   </td><td style=\"text-align: right;\"> 0.0157848</td><td style=\"text-align: right;\"> 0.109514  </td><td style=\"text-align: right;\"> 0.0300488 </td><td style=\"text-align: right;\">-0.104866 </td><td style=\"text-align: right;\">-0.133928 </td></tr>\n<tr><td>SRR6458388 </td><td style=\"text-align: right;\"> -6.99841</td><td style=\"text-align: right;\">-2.98309</td><td style=\"text-align: right;\">-0.00022671 </td><td style=\"text-align: right;\">-1.11203  </td><td style=\"text-align: right;\">-1.20356  </td><td style=\"text-align: right;\"> 2.99938 </td><td style=\"text-align: right;\"> 0.792167 </td><td style=\"text-align: right;\"> 1.05258 </td><td style=\"text-align: right;\"> 0.65212 </td><td style=\"text-align: right;\">-0.31234 </td><td style=\"text-align: right;\">-0.192416</td><td style=\"text-align: right;\"> 0.710371 </td><td style=\"text-align: right;\"> 1.59316 </td><td style=\"text-align: right;\"> 0.206608</td><td style=\"text-align: right;\">-0.346359 </td><td style=\"text-align: right;\"> 0.485749</td><td style=\"text-align: right;\"> 0.635867  </td><td style=\"text-align: right;\">-0.896472 </td><td style=\"text-align: right;\"> 0.680551 </td><td style=\"text-align: right;\">-2.08688 </td><td style=\"text-align: right;\"> 0.475259</td><td style=\"text-align: right;\">-1.7706   </td><td style=\"text-align: right;\">-0.62088  </td><td style=\"text-align: right;\"> 0.612203 </td><td style=\"text-align: right;\">-0.14104 </td><td style=\"text-align: right;\">-0.699463 </td><td style=\"text-align: right;\"> 0.650789 </td><td style=\"text-align: right;\">-0.0262048 </td><td style=\"text-align: right;\">-0.877455 </td><td style=\"text-align: right;\">-1.0542  </td><td style=\"text-align: right;\"> 0.856707  </td><td style=\"text-align: right;\"> 0.541396</td><td style=\"text-align: right;\"> 0.349956 </td><td style=\"text-align: right;\"> 0.331304 </td><td style=\"text-align: right;\">-0.213139 </td><td style=\"text-align: right;\"> 0.774679 </td><td style=\"text-align: right;\">-0.139329 </td><td style=\"text-align: right;\">-0.975618 </td><td style=\"text-align: right;\"> 0.463806 </td><td style=\"text-align: right;\"> 0.715431 </td><td style=\"text-align: right;\">-0.113045  </td><td style=\"text-align: right;\"> 0.272788  </td><td style=\"text-align: right;\"> 0.319152 </td><td style=\"text-align: right;\">-0.40954  </td><td style=\"text-align: right;\"> 0.27471   </td><td style=\"text-align: right;\"> 0.268401 </td><td style=\"text-align: right;\">-0.259543 </td><td style=\"text-align: right;\"> 0.272648 </td><td style=\"text-align: right;\">-0.40678  </td><td style=\"text-align: right;\"> 0.375968 </td><td style=\"text-align: right;\">-0.188106 </td><td style=\"text-align: right;\">-0.108689  </td><td style=\"text-align: right;\">-0.192379 </td><td style=\"text-align: right;\"> 0.104581 </td><td style=\"text-align: right;\"> 0.262699 </td><td style=\"text-align: right;\">-0.559073 </td><td style=\"text-align: right;\"> 0.27288  </td><td style=\"text-align: right;\"> 0.414692 </td><td style=\"text-align: right;\"> 0.290314 </td><td style=\"text-align: right;\">-0.357249 </td><td style=\"text-align: right;\"> 0.0937383</td><td style=\"text-align: right;\">-0.141974   </td><td style=\"text-align: right;\"> 0.278577 </td><td style=\"text-align: right;\"> 0.301905 </td><td style=\"text-align: right;\">-0.266512 </td><td style=\"text-align: right;\"> 0.455196 </td><td style=\"text-align: right;\"> 0.227363</td><td style=\"text-align: right;\"> 0.135629 </td><td style=\"text-align: right;\"> 0.354646 </td><td style=\"text-align: right;\"> 0.354206 </td><td style=\"text-align: right;\">-0.110135 </td><td style=\"text-align: right;\"> 0.046093 </td><td style=\"text-align: right;\">-0.536456 </td><td style=\"text-align: right;\"> 0.411382 </td><td style=\"text-align: right;\">-0.566792 </td><td style=\"text-align: right;\"> 0.125481  </td><td style=\"text-align: right;\"> 0.255462 </td><td style=\"text-align: right;\"> 0.0793334</td><td style=\"text-align: right;\">-0.157157 </td><td style=\"text-align: right;\"> 0.179331 </td><td style=\"text-align: right;\">-0.243474 </td><td style=\"text-align: right;\"> 0.172762</td><td style=\"text-align: right;\">-0.341583</td><td style=\"text-align: right;\"> 0.134515  </td><td style=\"text-align: right;\"> 0.140128 </td><td style=\"text-align: right;\">-0.0330968</td><td style=\"text-align: right;\">-0.587655 </td><td style=\"text-align: right;\"> 0.0485561</td><td style=\"text-align: right;\"> 0.235821 </td><td style=\"text-align: right;\">-0.0395163</td><td style=\"text-align: right;\">-0.205601  </td><td style=\"text-align: right;\"> 0.0350589 </td><td style=\"text-align: right;\"> 0.101773 </td><td style=\"text-align: right;\">-0.0747391</td><td style=\"text-align: right;\"> 0.271811 </td><td style=\"text-align: right;\">-0.0368525 </td><td style=\"text-align: right;\"> 0.215494 </td><td style=\"text-align: right;\"> 0.00417177</td><td style=\"text-align: right;\"> 0.11549 </td><td style=\"text-align: right;\"> 0.249065 </td><td style=\"text-align: right;\">-0.0919896</td><td style=\"text-align: right;\"> 0.147014 </td><td style=\"text-align: right;\"> 0.454241  </td><td style=\"text-align: right;\"> 0.0631964</td><td style=\"text-align: right;\">-0.0799047 </td><td style=\"text-align: right;\">-0.206424</td><td style=\"text-align: right;\"> 0.0626648 </td><td style=\"text-align: right;\"> 0.254552 </td><td style=\"text-align: right;\">-0.126758 </td><td style=\"text-align: right;\">-0.0135385</td><td style=\"text-align: right;\"> 0.103113 </td><td style=\"text-align: right;\">-0.0470452 </td><td style=\"text-align: right;\">-0.0234869</td><td style=\"text-align: right;\"> 0.0569321</td><td style=\"text-align: right;\"> 0.302449 </td><td style=\"text-align: right;\"> 0.107023 </td><td style=\"text-align: right;\"> 0.197454 </td><td style=\"text-align: right;\"> 0.105974  </td><td style=\"text-align: right;\">-0.0316742 </td><td style=\"text-align: right;\">-0.0724548</td><td style=\"text-align: right;\">-0.143969  </td><td style=\"text-align: right;\"> 0.0551029</td><td style=\"text-align: right;\">-0.152243 </td><td style=\"text-align: right;\">-0.124432 </td><td style=\"text-align: right;\">-0.1107   </td><td style=\"text-align: right;\">-0.0454275 </td><td style=\"text-align: right;\"> 0.375159 </td><td style=\"text-align: right;\">-0.13424    </td><td style=\"text-align: right;\"> 0.113136  </td><td style=\"text-align: right;\"> 0.0845437</td><td style=\"text-align: right;\">-0.0824407</td><td style=\"text-align: right;\">-0.0427799</td><td style=\"text-align: right;\"> 0.0288591</td><td style=\"text-align: right;\"> 0.0546468</td><td style=\"text-align: right;\"> 0.0112691</td><td style=\"text-align: right;\"> 0.254756 </td><td style=\"text-align: right;\">-0.0664561</td><td style=\"text-align: right;\">-0.0944385</td><td style=\"text-align: right;\">-0.0845776 </td><td style=\"text-align: right;\">-0.348813  </td><td style=\"text-align: right;\">-0.388426  </td><td style=\"text-align: right;\"> 0.331286 </td><td style=\"text-align: right;\"> 0.214688 </td><td style=\"text-align: right;\"> 0.12623  </td><td style=\"text-align: right;\"> 0.078729 </td><td style=\"text-align: right;\"> 0.133513 </td><td style=\"text-align: right;\">-0.055878</td><td style=\"text-align: right;\"> 0.361878 </td><td style=\"text-align: right;\"> 0.0198201 </td><td style=\"text-align: right;\"> 0.129158 </td><td style=\"text-align: right;\">-0.133021 </td><td style=\"text-align: right;\">-0.0430224 </td><td style=\"text-align: right;\">-0.104172  </td><td style=\"text-align: right;\">-0.0844451</td><td style=\"text-align: right;\"> 0.123224 </td><td style=\"text-align: right;\"> 0.0786226</td><td style=\"text-align: right;\">-0.154249</td><td style=\"text-align: right;\">-0.234724  </td><td style=\"text-align: right;\"> 0.214356 </td><td style=\"text-align: right;\">-0.176343  </td><td style=\"text-align: right;\">-0.04811  </td><td style=\"text-align: right;\">-0.278694   </td><td style=\"text-align: right;\"> 0.0631813 </td><td style=\"text-align: right;\">-0.00826134</td><td style=\"text-align: right;\">-0.0339437</td><td style=\"text-align: right;\"> 0.147426 </td><td style=\"text-align: right;\"> 0.21716  </td><td style=\"text-align: right;\"> 0.0806935</td><td style=\"text-align: right;\"> 0.0963404</td><td style=\"text-align: right;\">-0.123161 </td><td style=\"text-align: right;\"> 0.206812  </td><td style=\"text-align: right;\">-0.384298 </td><td style=\"text-align: right;\"> 0.0548116</td><td style=\"text-align: right;\"> 0.0746361  </td><td style=\"text-align: right;\"> 0.0921111 </td><td style=\"text-align: right;\"> 0.371321 </td><td style=\"text-align: right;\"> 0.292604 </td><td style=\"text-align: right;\"> 0.190858  </td><td style=\"text-align: right;\"> 0.205624 </td><td style=\"text-align: right;\">-0.305565 </td><td style=\"text-align: right;\"> 0.0741434</td><td style=\"text-align: right;\"> 0.0436073</td><td style=\"text-align: right;\">-0.0483075 </td><td style=\"text-align: right;\"> 0.129479 </td><td style=\"text-align: right;\"> 0.0881774 </td><td style=\"text-align: right;\"> 0.144502 </td><td style=\"text-align: right;\">-0.156171 </td><td style=\"text-align: right;\"> 0.154395  </td><td style=\"text-align: right;\">-0.0339808</td><td style=\"text-align: right;\"> 0.0232897</td><td style=\"text-align: right;\"> 0.070536  </td><td style=\"text-align: right;\"> 0.143951 </td><td style=\"text-align: right;\">-0.136796 </td><td style=\"text-align: right;\"> 0.311865  </td><td style=\"text-align: right;\">-0.0452586</td><td style=\"text-align: right;\">-0.127641  </td><td style=\"text-align: right;\">-0.00310456</td><td style=\"text-align: right;\">-0.0674689</td><td style=\"text-align: right;\">-0.220191 </td></tr>\n<tr><td>SRR5153333 </td><td style=\"text-align: right;\">-11.4408 </td><td style=\"text-align: right;\"> 3.91069</td><td style=\"text-align: right;\">-0.0533963  </td><td style=\"text-align: right;\"> 1.10893  </td><td style=\"text-align: right;\"> 5.12126  </td><td style=\"text-align: right;\">-4.0803  </td><td style=\"text-align: right;\">-0.0529325</td><td style=\"text-align: right;\">-0.577976</td><td style=\"text-align: right;\">-0.522176</td><td style=\"text-align: right;\"> 1.24176 </td><td style=\"text-align: right;\"> 2.51208 </td><td style=\"text-align: right;\">-0.801427 </td><td style=\"text-align: right;\"> 1.1297  </td><td style=\"text-align: right;\"> 0.173791</td><td style=\"text-align: right;\"> 1.67921  </td><td style=\"text-align: right;\"> 1.44797 </td><td style=\"text-align: right;\">-2.08321   </td><td style=\"text-align: right;\">-0.945879 </td><td style=\"text-align: right;\"> 0.125994 </td><td style=\"text-align: right;\"> 1.41064 </td><td style=\"text-align: right;\"> 0.325474</td><td style=\"text-align: right;\">-1.19619  </td><td style=\"text-align: right;\"> 1.39569  </td><td style=\"text-align: right;\">-0.668194 </td><td style=\"text-align: right;\"> 0.101959</td><td style=\"text-align: right;\">-0.806764 </td><td style=\"text-align: right;\">-1.06909  </td><td style=\"text-align: right;\"> 0.0805773 </td><td style=\"text-align: right;\">-0.168554 </td><td style=\"text-align: right;\">-0.207682</td><td style=\"text-align: right;\">-0.179091  </td><td style=\"text-align: right;\"> 0.891167</td><td style=\"text-align: right;\"> 1.12312  </td><td style=\"text-align: right;\">-1.44565  </td><td style=\"text-align: right;\">-0.22525  </td><td style=\"text-align: right;\">-0.781858 </td><td style=\"text-align: right;\"> 0.780147 </td><td style=\"text-align: right;\"> 1.30059  </td><td style=\"text-align: right;\"> 0.0663721</td><td style=\"text-align: right;\"> 0.0359448</td><td style=\"text-align: right;\">-0.750649  </td><td style=\"text-align: right;\"> 0.958028  </td><td style=\"text-align: right;\"> 1.12601  </td><td style=\"text-align: right;\">-1.40816  </td><td style=\"text-align: right;\"> 0.400875  </td><td style=\"text-align: right;\">-0.107926 </td><td style=\"text-align: right;\"> 0.268149 </td><td style=\"text-align: right;\"> 0.303018 </td><td style=\"text-align: right;\">-0.481072 </td><td style=\"text-align: right;\">-0.102791 </td><td style=\"text-align: right;\">-0.0510634</td><td style=\"text-align: right;\">-0.824892  </td><td style=\"text-align: right;\"> 0.922151 </td><td style=\"text-align: right;\">-0.337871 </td><td style=\"text-align: right;\">-1.3525   </td><td style=\"text-align: right;\">-0.644757 </td><td style=\"text-align: right;\"> 1.3427   </td><td style=\"text-align: right;\"> 0.283754 </td><td style=\"text-align: right;\">-0.57398  </td><td style=\"text-align: right;\">-0.602533 </td><td style=\"text-align: right;\"> 0.881829 </td><td style=\"text-align: right;\">-0.876745   </td><td style=\"text-align: right;\">-0.584974 </td><td style=\"text-align: right;\"> 0.0359255</td><td style=\"text-align: right;\">-0.32868  </td><td style=\"text-align: right;\">-0.391202 </td><td style=\"text-align: right;\">-0.447582</td><td style=\"text-align: right;\"> 0.274852 </td><td style=\"text-align: right;\"> 0.142741 </td><td style=\"text-align: right;\">-0.667909 </td><td style=\"text-align: right;\">-0.863052 </td><td style=\"text-align: right;\"> 0.150856 </td><td style=\"text-align: right;\">-0.438702 </td><td style=\"text-align: right;\"> 0.750841 </td><td style=\"text-align: right;\">-0.385989 </td><td style=\"text-align: right;\">-0.310674  </td><td style=\"text-align: right;\">-0.0790464</td><td style=\"text-align: right;\">-0.0680184</td><td style=\"text-align: right;\"> 0.222167 </td><td style=\"text-align: right;\"> 0.557807 </td><td style=\"text-align: right;\">-0.11575  </td><td style=\"text-align: right;\"> 0.387843</td><td style=\"text-align: right;\"> 0.725434</td><td style=\"text-align: right;\">-0.402882  </td><td style=\"text-align: right;\">-0.535717 </td><td style=\"text-align: right;\">-0.0202945</td><td style=\"text-align: right;\"> 0.117413 </td><td style=\"text-align: right;\"> 0.429501 </td><td style=\"text-align: right;\"> 0.153339 </td><td style=\"text-align: right;\"> 0.107547 </td><td style=\"text-align: right;\"> 0.427923  </td><td style=\"text-align: right;\">-0.50234   </td><td style=\"text-align: right;\"> 0.129575 </td><td style=\"text-align: right;\">-0.141354 </td><td style=\"text-align: right;\"> 0.0388434</td><td style=\"text-align: right;\">-0.0238002 </td><td style=\"text-align: right;\">-0.290518 </td><td style=\"text-align: right;\"> 0.0415737 </td><td style=\"text-align: right;\"> 0.249019</td><td style=\"text-align: right;\">-0.536361 </td><td style=\"text-align: right;\"> 0.304088 </td><td style=\"text-align: right;\"> 0.0245802</td><td style=\"text-align: right;\"> 0.135671  </td><td style=\"text-align: right;\"> 0.179917 </td><td style=\"text-align: right;\"> 0.45321   </td><td style=\"text-align: right;\"> 0.63413 </td><td style=\"text-align: right;\"> 0.424292  </td><td style=\"text-align: right;\">-0.215174 </td><td style=\"text-align: right;\"> 0.247985 </td><td style=\"text-align: right;\"> 0.175937 </td><td style=\"text-align: right;\">-0.139369 </td><td style=\"text-align: right;\">-0.00493264</td><td style=\"text-align: right;\"> 0.377265 </td><td style=\"text-align: right;\"> 0.0013446</td><td style=\"text-align: right;\">-0.144286 </td><td style=\"text-align: right;\">-0.400853 </td><td style=\"text-align: right;\"> 0.245314 </td><td style=\"text-align: right;\">-0.0452821 </td><td style=\"text-align: right;\">-0.565764  </td><td style=\"text-align: right;\">-0.306721 </td><td style=\"text-align: right;\"> 0.324002  </td><td style=\"text-align: right;\"> 0.370195 </td><td style=\"text-align: right;\">-0.194664 </td><td style=\"text-align: right;\">-0.0298646</td><td style=\"text-align: right;\"> 0.376266 </td><td style=\"text-align: right;\"> 0.237367  </td><td style=\"text-align: right;\"> 0.290039 </td><td style=\"text-align: right;\"> 0.000584293</td><td style=\"text-align: right;\">-0.080829  </td><td style=\"text-align: right;\">-0.379429 </td><td style=\"text-align: right;\">-0.182291 </td><td style=\"text-align: right;\"> 0.984333 </td><td style=\"text-align: right;\"> 0.0874452</td><td style=\"text-align: right;\"> 0.135156 </td><td style=\"text-align: right;\"> 0.139681 </td><td style=\"text-align: right;\"> 0.240714 </td><td style=\"text-align: right;\">-0.0559758</td><td style=\"text-align: right;\">-0.148529 </td><td style=\"text-align: right;\"> 0.0806939 </td><td style=\"text-align: right;\">-0.633445  </td><td style=\"text-align: right;\"> 0.123141  </td><td style=\"text-align: right;\">-0.271885 </td><td style=\"text-align: right;\"> 0.196269 </td><td style=\"text-align: right;\"> 0.205204 </td><td style=\"text-align: right;\">-0.336892 </td><td style=\"text-align: right;\"> 0.410195 </td><td style=\"text-align: right;\">-0.165723</td><td style=\"text-align: right;\"> 0.561479 </td><td style=\"text-align: right;\">-0.59274   </td><td style=\"text-align: right;\">-0.224254 </td><td style=\"text-align: right;\">-0.325978 </td><td style=\"text-align: right;\">-0.140057  </td><td style=\"text-align: right;\">-0.193693  </td><td style=\"text-align: right;\">-0.0940802</td><td style=\"text-align: right;\">-0.162493 </td><td style=\"text-align: right;\"> 0.140356 </td><td style=\"text-align: right;\"> 0.183163</td><td style=\"text-align: right;\">-0.381249  </td><td style=\"text-align: right;\"> 0.251974 </td><td style=\"text-align: right;\">-0.334173  </td><td style=\"text-align: right;\"> 0.0931959</td><td style=\"text-align: right;\">-0.000737978</td><td style=\"text-align: right;\"> 0.117114  </td><td style=\"text-align: right;\">-0.206884  </td><td style=\"text-align: right;\"> 0.101043 </td><td style=\"text-align: right;\">-0.132863 </td><td style=\"text-align: right;\"> 0.152506 </td><td style=\"text-align: right;\">-0.134385 </td><td style=\"text-align: right;\"> 0.452986 </td><td style=\"text-align: right;\"> 0.152312 </td><td style=\"text-align: right;\"> 0.0582496 </td><td style=\"text-align: right;\"> 0.0839865</td><td style=\"text-align: right;\">-0.260468 </td><td style=\"text-align: right;\"> 0.478922   </td><td style=\"text-align: right;\">-0.232389  </td><td style=\"text-align: right;\">-0.137869 </td><td style=\"text-align: right;\"> 0.0222461</td><td style=\"text-align: right;\"> 0.0882454 </td><td style=\"text-align: right;\"> 0.173291 </td><td style=\"text-align: right;\">-0.206527 </td><td style=\"text-align: right;\"> 0.0762306</td><td style=\"text-align: right;\"> 0.114507 </td><td style=\"text-align: right;\"> 0.165444  </td><td style=\"text-align: right;\">-0.0534536</td><td style=\"text-align: right;\">-0.0920498 </td><td style=\"text-align: right;\">-0.0482851</td><td style=\"text-align: right;\"> 0.156824 </td><td style=\"text-align: right;\"> 0.278767  </td><td style=\"text-align: right;\">-0.235759 </td><td style=\"text-align: right;\">-0.103127 </td><td style=\"text-align: right;\"> 0.351468  </td><td style=\"text-align: right;\"> 0.0567588</td><td style=\"text-align: right;\">-0.0251241</td><td style=\"text-align: right;\"> 0.47271   </td><td style=\"text-align: right;\">-0.35859  </td><td style=\"text-align: right;\">-0.0731565 </td><td style=\"text-align: right;\">-0.128044  </td><td style=\"text-align: right;\"> 0.148674 </td><td style=\"text-align: right;\"> 0.234844 </td></tr>\n<tr><td>SRR5152963 </td><td style=\"text-align: right;\"> -9.28681</td><td style=\"text-align: right;\">-4.90312</td><td style=\"text-align: right;\">-0.00260397 </td><td style=\"text-align: right;\">-0.0484381</td><td style=\"text-align: right;\"> 0.264835 </td><td style=\"text-align: right;\">-4.63516 </td><td style=\"text-align: right;\"> 1.50224  </td><td style=\"text-align: right;\"> 0.357337</td><td style=\"text-align: right;\">-0.17422 </td><td style=\"text-align: right;\"> 0.359103</td><td style=\"text-align: right;\">-0.99246 </td><td style=\"text-align: right;\"> 0.0470872</td><td style=\"text-align: right;\"> 0.236459</td><td style=\"text-align: right;\">-0.685021</td><td style=\"text-align: right;\">-0.497964 </td><td style=\"text-align: right;\"> 0.286454</td><td style=\"text-align: right;\">-1.0784    </td><td style=\"text-align: right;\"> 0.287785 </td><td style=\"text-align: right;\"> 0.142118 </td><td style=\"text-align: right;\">-1.95973 </td><td style=\"text-align: right;\"> 0.474228</td><td style=\"text-align: right;\">-0.131709 </td><td style=\"text-align: right;\">-0.65227  </td><td style=\"text-align: right;\">-0.0330496</td><td style=\"text-align: right;\">-0.160879</td><td style=\"text-align: right;\"> 0.0376077</td><td style=\"text-align: right;\">-0.284    </td><td style=\"text-align: right;\">-0.00654314</td><td style=\"text-align: right;\"> 0.860162 </td><td style=\"text-align: right;\"> 0.59502 </td><td style=\"text-align: right;\">-0.0143426 </td><td style=\"text-align: right;\">-0.310572</td><td style=\"text-align: right;\"> 1.18587  </td><td style=\"text-align: right;\">-0.76121  </td><td style=\"text-align: right;\"> 0.469566 </td><td style=\"text-align: right;\">-0.461658 </td><td style=\"text-align: right;\"> 0.66815  </td><td style=\"text-align: right;\"> 0.376559 </td><td style=\"text-align: right;\"> 0.294312 </td><td style=\"text-align: right;\">-0.52857  </td><td style=\"text-align: right;\">-0.0855447 </td><td style=\"text-align: right;\"> 0.393372  </td><td style=\"text-align: right;\">-0.0614584</td><td style=\"text-align: right;\"> 0.466387 </td><td style=\"text-align: right;\"> 0.167627  </td><td style=\"text-align: right;\">-0.166838 </td><td style=\"text-align: right;\">-0.0566179</td><td style=\"text-align: right;\"> 0.261778 </td><td style=\"text-align: right;\"> 0.23537  </td><td style=\"text-align: right;\">-0.023874 </td><td style=\"text-align: right;\">-0.269284 </td><td style=\"text-align: right;\">-0.301234  </td><td style=\"text-align: right;\"> 0.514908 </td><td style=\"text-align: right;\"> 0.0554866</td><td style=\"text-align: right;\"> 0.213697 </td><td style=\"text-align: right;\"> 0.17933  </td><td style=\"text-align: right;\"> 0.155894 </td><td style=\"text-align: right;\"> 0.168836 </td><td style=\"text-align: right;\">-0.581615 </td><td style=\"text-align: right;\"> 0.782444 </td><td style=\"text-align: right;\">-0.508643 </td><td style=\"text-align: right;\"> 0.309706   </td><td style=\"text-align: right;\">-0.0866412</td><td style=\"text-align: right;\"> 0.319645 </td><td style=\"text-align: right;\">-0.255015 </td><td style=\"text-align: right;\"> 0.373621 </td><td style=\"text-align: right;\"> 0.13159 </td><td style=\"text-align: right;\"> 0.355665 </td><td style=\"text-align: right;\">-0.0152177</td><td style=\"text-align: right;\"> 0.0343728</td><td style=\"text-align: right;\">-0.226289 </td><td style=\"text-align: right;\">-0.0396509</td><td style=\"text-align: right;\"> 0.0890247</td><td style=\"text-align: right;\">-0.314686 </td><td style=\"text-align: right;\"> 0.254015 </td><td style=\"text-align: right;\">-0.00557643</td><td style=\"text-align: right;\">-0.073443 </td><td style=\"text-align: right;\"> 0.0256341</td><td style=\"text-align: right;\">-0.0160978</td><td style=\"text-align: right;\">-0.194006 </td><td style=\"text-align: right;\">-0.0268144</td><td style=\"text-align: right;\"> 0.115604</td><td style=\"text-align: right;\"> 0.246627</td><td style=\"text-align: right;\">-0.255683  </td><td style=\"text-align: right;\"> 0.108665 </td><td style=\"text-align: right;\"> 0.26341  </td><td style=\"text-align: right;\"> 0.057678 </td><td style=\"text-align: right;\"> 0.14296  </td><td style=\"text-align: right;\"> 0.111766 </td><td style=\"text-align: right;\">-0.331197 </td><td style=\"text-align: right;\">-0.0193557 </td><td style=\"text-align: right;\">-0.00387406</td><td style=\"text-align: right;\">-0.124914 </td><td style=\"text-align: right;\"> 0.0608201</td><td style=\"text-align: right;\">-0.222559 </td><td style=\"text-align: right;\">-0.225016  </td><td style=\"text-align: right;\"> 0.0165621</td><td style=\"text-align: right;\">-0.0301462 </td><td style=\"text-align: right;\">-0.088343</td><td style=\"text-align: right;\"> 0.0176888</td><td style=\"text-align: right;\">-0.133887 </td><td style=\"text-align: right;\"> 0.13669  </td><td style=\"text-align: right;\"> 0.00392239</td><td style=\"text-align: right;\">-0.0276523</td><td style=\"text-align: right;\">-0.343728  </td><td style=\"text-align: right;\">-0.10763 </td><td style=\"text-align: right;\">-0.286567  </td><td style=\"text-align: right;\">-0.199684 </td><td style=\"text-align: right;\"> 0.0126868</td><td style=\"text-align: right;\">-0.17505  </td><td style=\"text-align: right;\"> 0.224408 </td><td style=\"text-align: right;\">-0.00865879</td><td style=\"text-align: right;\"> 0.20032  </td><td style=\"text-align: right;\"> 0.0144414</td><td style=\"text-align: right;\">-0.162134 </td><td style=\"text-align: right;\"> 0.0565026</td><td style=\"text-align: right;\">-0.0137815</td><td style=\"text-align: right;\"> 0.0879913 </td><td style=\"text-align: right;\"> 0.214719  </td><td style=\"text-align: right;\"> 0.086483 </td><td style=\"text-align: right;\"> 0.241405  </td><td style=\"text-align: right;\"> 0.307029 </td><td style=\"text-align: right;\">-0.188092 </td><td style=\"text-align: right;\"> 0.130884 </td><td style=\"text-align: right;\">-0.160446 </td><td style=\"text-align: right;\"> 0.00855652</td><td style=\"text-align: right;\">-0.345006 </td><td style=\"text-align: right;\"> 0.060206   </td><td style=\"text-align: right;\"> 0.0967177 </td><td style=\"text-align: right;\"> 0.109908 </td><td style=\"text-align: right;\">-0.0354725</td><td style=\"text-align: right;\"> 0.0919997</td><td style=\"text-align: right;\">-0.151296 </td><td style=\"text-align: right;\">-0.127584 </td><td style=\"text-align: right;\">-0.195341 </td><td style=\"text-align: right;\"> 0.168563 </td><td style=\"text-align: right;\"> 0.0190496</td><td style=\"text-align: right;\"> 0.0890706</td><td style=\"text-align: right;\"> 0.115683  </td><td style=\"text-align: right;\"> 0.112105  </td><td style=\"text-align: right;\">-0.115679  </td><td style=\"text-align: right;\">-0.0499728</td><td style=\"text-align: right;\">-0.0841381</td><td style=\"text-align: right;\">-0.15374  </td><td style=\"text-align: right;\"> 0.0492803</td><td style=\"text-align: right;\">-0.0540748</td><td style=\"text-align: right;\"> 0.111392</td><td style=\"text-align: right;\"> 0.137551 </td><td style=\"text-align: right;\">-0.27198   </td><td style=\"text-align: right;\"> 0.0150838</td><td style=\"text-align: right;\">-0.259813 </td><td style=\"text-align: right;\">-0.148247  </td><td style=\"text-align: right;\">-0.00539514</td><td style=\"text-align: right;\"> 0.0489178</td><td style=\"text-align: right;\">-0.063976 </td><td style=\"text-align: right;\"> 0.202161 </td><td style=\"text-align: right;\">-0.171876</td><td style=\"text-align: right;\"> 0.12256   </td><td style=\"text-align: right;\">-0.0702188</td><td style=\"text-align: right;\"> 0.254428  </td><td style=\"text-align: right;\">-0.19253  </td><td style=\"text-align: right;\"> 0.200451   </td><td style=\"text-align: right;\"> 0.010829  </td><td style=\"text-align: right;\">-0.0996432 </td><td style=\"text-align: right;\"> 0.112846 </td><td style=\"text-align: right;\"> 0.0234955</td><td style=\"text-align: right;\"> 0.0498658</td><td style=\"text-align: right;\"> 0.138928 </td><td style=\"text-align: right;\">-0.0556585</td><td style=\"text-align: right;\">-0.0764542</td><td style=\"text-align: right;\">-0.341671  </td><td style=\"text-align: right;\">-0.111084 </td><td style=\"text-align: right;\"> 0.141304 </td><td style=\"text-align: right;\">-0.0660777  </td><td style=\"text-align: right;\"> 0.0418051 </td><td style=\"text-align: right;\">-0.0573906</td><td style=\"text-align: right;\"> 0.148952 </td><td style=\"text-align: right;\"> 0.108492  </td><td style=\"text-align: right;\">-0.282072 </td><td style=\"text-align: right;\"> 0.164999 </td><td style=\"text-align: right;\"> 0.156052 </td><td style=\"text-align: right;\">-0.0552209</td><td style=\"text-align: right;\">-0.149022  </td><td style=\"text-align: right;\"> 0.0272333</td><td style=\"text-align: right;\">-0.00249091</td><td style=\"text-align: right;\">-0.195615 </td><td style=\"text-align: right;\"> 0.248751 </td><td style=\"text-align: right;\">-0.0022166 </td><td style=\"text-align: right;\">-0.204083 </td><td style=\"text-align: right;\"> 0.100609 </td><td style=\"text-align: right;\"> 0.150012  </td><td style=\"text-align: right;\">-0.12504  </td><td style=\"text-align: right;\"> 0.176794 </td><td style=\"text-align: right;\">-0.0911637 </td><td style=\"text-align: right;\">-0.0638807</td><td style=\"text-align: right;\"> 0.209557  </td><td style=\"text-align: right;\">-0.0724328 </td><td style=\"text-align: right;\">-0.186826 </td><td style=\"text-align: right;\"> 0.0963438</td></tr>\n</tbody>\n</table>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 42,
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "execution_count": 42,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605467954314
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test_pca_df_frame = h2o.H2OFrame(test_pca_df)\r\n",
        "test_pca_df_frame = h2o.import_file(DATA_LOCATION + \"processed/test_pca_df.tsv\")\r\n",
        "\r\n",
        "test_pca_df_frame.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<table>\n<thead>\n<tr><th>SampleID  </th><th style=\"text-align: right;\">      PC1</th><th style=\"text-align: right;\">     PC2</th><th style=\"text-align: right;\">         PC3</th><th style=\"text-align: right;\">        PC4</th><th style=\"text-align: right;\">      PC5</th><th style=\"text-align: right;\">      PC6</th><th style=\"text-align: right;\">      PC7</th><th style=\"text-align: right;\">       PC8</th><th style=\"text-align: right;\">       PC9</th><th style=\"text-align: right;\">       PC10</th><th style=\"text-align: right;\">      PC11</th><th style=\"text-align: right;\">      PC12</th><th style=\"text-align: right;\">      PC13</th><th style=\"text-align: right;\">     PC14</th><th style=\"text-align: right;\">      PC15</th><th style=\"text-align: right;\">     PC16</th><th style=\"text-align: right;\">      PC17</th><th style=\"text-align: right;\">      PC18</th><th style=\"text-align: right;\">      PC19</th><th style=\"text-align: right;\">     PC20</th><th style=\"text-align: right;\">     PC21</th><th style=\"text-align: right;\">      PC22</th><th style=\"text-align: right;\">      PC23</th><th style=\"text-align: right;\">      PC24</th><th style=\"text-align: right;\">       PC25</th><th style=\"text-align: right;\">      PC26</th><th style=\"text-align: right;\">      PC27</th><th style=\"text-align: right;\">       PC28</th><th style=\"text-align: right;\">     PC29</th><th style=\"text-align: right;\">     PC30</th><th style=\"text-align: right;\">       PC31</th><th style=\"text-align: right;\">      PC32</th><th style=\"text-align: right;\">      PC33</th><th style=\"text-align: right;\">      PC34</th><th style=\"text-align: right;\">       PC35</th><th style=\"text-align: right;\">      PC36</th><th style=\"text-align: right;\">      PC37</th><th style=\"text-align: right;\">      PC38</th><th style=\"text-align: right;\">      PC39</th><th style=\"text-align: right;\">       PC40</th><th style=\"text-align: right;\">       PC41</th><th style=\"text-align: right;\">      PC42</th><th style=\"text-align: right;\">      PC43</th><th style=\"text-align: right;\">      PC44</th><th style=\"text-align: right;\">      PC45</th><th style=\"text-align: right;\">      PC46</th><th style=\"text-align: right;\">      PC47</th><th style=\"text-align: right;\">      PC48</th><th style=\"text-align: right;\">      PC49</th><th style=\"text-align: right;\">       PC50</th><th style=\"text-align: right;\">       PC51</th><th style=\"text-align: right;\">      PC52</th><th style=\"text-align: right;\">       PC53</th><th style=\"text-align: right;\">      PC54</th><th style=\"text-align: right;\">       PC55</th><th style=\"text-align: right;\">      PC56</th><th style=\"text-align: right;\">      PC57</th><th style=\"text-align: right;\">      PC58</th><th style=\"text-align: right;\">       PC59</th><th style=\"text-align: right;\">       PC60</th><th style=\"text-align: right;\">      PC61</th><th style=\"text-align: right;\">       PC62</th><th style=\"text-align: right;\">      PC63</th><th style=\"text-align: right;\">       PC64</th><th style=\"text-align: right;\">      PC65</th><th style=\"text-align: right;\">      PC66</th><th style=\"text-align: right;\">       PC67</th><th style=\"text-align: right;\">        PC68</th><th style=\"text-align: right;\">       PC69</th><th style=\"text-align: right;\">      PC70</th><th style=\"text-align: right;\">      PC71</th><th style=\"text-align: right;\">      PC72</th><th style=\"text-align: right;\">      PC73</th><th style=\"text-align: right;\">      PC74</th><th style=\"text-align: right;\">       PC75</th><th style=\"text-align: right;\">      PC76</th><th style=\"text-align: right;\">      PC77</th><th style=\"text-align: right;\">       PC78</th><th style=\"text-align: right;\">      PC79</th><th style=\"text-align: right;\">       PC80</th><th style=\"text-align: right;\">      PC81</th><th style=\"text-align: right;\">       PC82</th><th style=\"text-align: right;\">      PC83</th><th style=\"text-align: right;\">       PC84</th><th style=\"text-align: right;\">      PC85</th><th style=\"text-align: right;\">       PC86</th><th style=\"text-align: right;\">        PC87</th><th style=\"text-align: right;\">       PC88</th><th style=\"text-align: right;\">       PC89</th><th style=\"text-align: right;\">       PC90</th><th style=\"text-align: right;\">       PC91</th><th style=\"text-align: right;\">      PC92</th><th style=\"text-align: right;\">      PC93</th><th style=\"text-align: right;\">      PC94</th><th style=\"text-align: right;\">       PC95</th><th style=\"text-align: right;\">      PC96</th><th style=\"text-align: right;\">      PC97</th><th style=\"text-align: right;\">      PC98</th><th style=\"text-align: right;\">      PC99</th><th style=\"text-align: right;\">      PC100</th><th style=\"text-align: right;\">     PC101</th><th style=\"text-align: right;\">      PC102</th><th style=\"text-align: right;\">     PC103</th><th style=\"text-align: right;\">     PC104</th><th style=\"text-align: right;\">     PC105</th><th style=\"text-align: right;\">     PC106</th><th style=\"text-align: right;\">      PC107</th><th style=\"text-align: right;\">      PC108</th><th style=\"text-align: right;\">      PC109</th><th style=\"text-align: right;\">     PC110</th><th style=\"text-align: right;\">      PC111</th><th style=\"text-align: right;\">      PC112</th><th style=\"text-align: right;\">      PC113</th><th style=\"text-align: right;\">     PC114</th><th style=\"text-align: right;\">     PC115</th><th style=\"text-align: right;\">     PC116</th><th style=\"text-align: right;\">     PC117</th><th style=\"text-align: right;\">      PC118</th><th style=\"text-align: right;\">      PC119</th><th style=\"text-align: right;\">     PC120</th><th style=\"text-align: right;\">      PC121</th><th style=\"text-align: right;\">     PC122</th><th style=\"text-align: right;\">      PC123</th><th style=\"text-align: right;\">      PC124</th><th style=\"text-align: right;\">       PC125</th><th style=\"text-align: right;\">      PC126</th><th style=\"text-align: right;\">      PC127</th><th style=\"text-align: right;\">      PC128</th><th style=\"text-align: right;\">       PC129</th><th style=\"text-align: right;\">      PC130</th><th style=\"text-align: right;\">      PC131</th><th style=\"text-align: right;\">       PC132</th><th style=\"text-align: right;\">     PC133</th><th style=\"text-align: right;\">     PC134</th><th style=\"text-align: right;\">     PC135</th><th style=\"text-align: right;\">      PC136</th><th style=\"text-align: right;\">       PC137</th><th style=\"text-align: right;\">      PC138</th><th style=\"text-align: right;\">      PC139</th><th style=\"text-align: right;\">      PC140</th><th style=\"text-align: right;\">      PC141</th><th style=\"text-align: right;\">      PC142</th><th style=\"text-align: right;\">      PC143</th><th style=\"text-align: right;\">      PC144</th><th style=\"text-align: right;\">      PC145</th><th style=\"text-align: right;\">       PC146</th><th style=\"text-align: right;\">      PC147</th><th style=\"text-align: right;\">      PC148</th><th style=\"text-align: right;\">      PC149</th><th style=\"text-align: right;\">     PC150</th><th style=\"text-align: right;\">      PC151</th><th style=\"text-align: right;\">     PC152</th><th style=\"text-align: right;\">      PC153</th><th style=\"text-align: right;\">      PC154</th><th style=\"text-align: right;\">     PC155</th><th style=\"text-align: right;\">      PC156</th><th style=\"text-align: right;\">     PC157</th><th style=\"text-align: right;\">      PC158</th><th style=\"text-align: right;\">       PC159</th><th style=\"text-align: right;\">      PC160</th><th style=\"text-align: right;\">      PC161</th><th style=\"text-align: right;\">     PC162</th><th style=\"text-align: right;\">      PC163</th><th style=\"text-align: right;\">      PC164</th><th style=\"text-align: right;\">     PC165</th><th style=\"text-align: right;\">      PC166</th><th style=\"text-align: right;\">      PC167</th><th style=\"text-align: right;\">     PC168</th><th style=\"text-align: right;\">      PC169</th><th style=\"text-align: right;\">      PC170</th><th style=\"text-align: right;\">      PC171</th><th style=\"text-align: right;\">     PC172</th><th style=\"text-align: right;\">      PC173</th><th style=\"text-align: right;\">      PC174</th><th style=\"text-align: right;\">      PC175</th><th style=\"text-align: right;\">      PC176</th><th style=\"text-align: right;\">      PC177</th><th style=\"text-align: right;\">      PC178</th><th style=\"text-align: right;\">     PC179</th><th style=\"text-align: right;\">      PC180</th><th style=\"text-align: right;\">      PC181</th><th style=\"text-align: right;\">      PC182</th><th style=\"text-align: right;\">     PC183</th><th style=\"text-align: right;\">      PC184</th><th style=\"text-align: right;\">     PC185</th><th style=\"text-align: right;\">      PC186</th><th style=\"text-align: right;\">       PC187</th><th style=\"text-align: right;\">       PC188</th><th style=\"text-align: right;\">      PC189</th><th style=\"text-align: right;\">      PC190</th><th style=\"text-align: right;\">      PC191</th><th style=\"text-align: right;\">     PC192</th><th style=\"text-align: right;\">      PC193</th><th style=\"text-align: right;\">      PC194</th><th style=\"text-align: right;\">     PC195</th><th style=\"text-align: right;\">      PC196</th><th style=\"text-align: right;\">       PC197</th><th style=\"text-align: right;\">      PC198</th><th style=\"text-align: right;\">      PC199</th></tr>\n</thead>\n<tbody>\n<tr><td>ERR3335735</td><td style=\"text-align: right;\"> -9.62946</td><td style=\"text-align: right;\"> 3.42749</td><td style=\"text-align: right;\">-0.0544876  </td><td style=\"text-align: right;\">-1.99728   </td><td style=\"text-align: right;\">-0.501536</td><td style=\"text-align: right;\"> 5.33675 </td><td style=\"text-align: right;\"> 1.88318 </td><td style=\"text-align: right;\"> 2.34222  </td><td style=\"text-align: right;\">  0.550157</td><td style=\"text-align: right;\">  2.24487  </td><td style=\"text-align: right;\"> 1.01714  </td><td style=\"text-align: right;\">-0.274509 </td><td style=\"text-align: right;\"> 0.473391 </td><td style=\"text-align: right;\">-1.15809 </td><td style=\"text-align: right;\"> 0.0800588</td><td style=\"text-align: right;\">-1.07554 </td><td style=\"text-align: right;\"> 1.76168  </td><td style=\"text-align: right;\"> 2.19104  </td><td style=\"text-align: right;\">-0.0812096</td><td style=\"text-align: right;\">-1.188   </td><td style=\"text-align: right;\"> 0.480369</td><td style=\"text-align: right;\"> 1.51523  </td><td style=\"text-align: right;\">-0.73458  </td><td style=\"text-align: right;\"> 0.856701 </td><td style=\"text-align: right;\">-0.463986  </td><td style=\"text-align: right;\"> 1.1826   </td><td style=\"text-align: right;\">-0.756524 </td><td style=\"text-align: right;\"> 0.0237812 </td><td style=\"text-align: right;\"> 0.516223</td><td style=\"text-align: right;\"> 1.13772 </td><td style=\"text-align: right;\">-0.564756  </td><td style=\"text-align: right;\"> 0.633247 </td><td style=\"text-align: right;\">-0.349465 </td><td style=\"text-align: right;\">-0.067741 </td><td style=\"text-align: right;\"> 0.234908  </td><td style=\"text-align: right;\">-0.444675 </td><td style=\"text-align: right;\"> 0.17611  </td><td style=\"text-align: right;\">-0.532194 </td><td style=\"text-align: right;\"> 0.0915564</td><td style=\"text-align: right;\">-0.113063  </td><td style=\"text-align: right;\"> 1.13146   </td><td style=\"text-align: right;\">-0.302093 </td><td style=\"text-align: right;\"> 0.490816 </td><td style=\"text-align: right;\">-0.493271 </td><td style=\"text-align: right;\">-0.585398 </td><td style=\"text-align: right;\"> 0.8064   </td><td style=\"text-align: right;\">-0.424099 </td><td style=\"text-align: right;\">-0.672412 </td><td style=\"text-align: right;\"> 0.236234 </td><td style=\"text-align: right;\"> 0.621226  </td><td style=\"text-align: right;\"> 0.421086  </td><td style=\"text-align: right;\">-0.957542 </td><td style=\"text-align: right;\"> 0.609662  </td><td style=\"text-align: right;\">-0.625019 </td><td style=\"text-align: right;\"> 0.188252  </td><td style=\"text-align: right;\"> 0.878188 </td><td style=\"text-align: right;\">-0.0257143</td><td style=\"text-align: right;\">-0.138875 </td><td style=\"text-align: right;\">-0.0223257 </td><td style=\"text-align: right;\"> 1.23374   </td><td style=\"text-align: right;\">-0.363303 </td><td style=\"text-align: right;\">-0.19214   </td><td style=\"text-align: right;\"> 0.637254 </td><td style=\"text-align: right;\"> 0.567913  </td><td style=\"text-align: right;\"> 0.199097 </td><td style=\"text-align: right;\">-0.825055 </td><td style=\"text-align: right;\"> 0.482516  </td><td style=\"text-align: right;\"> 0.0236314  </td><td style=\"text-align: right;\">-0.274883  </td><td style=\"text-align: right;\">-0.26622  </td><td style=\"text-align: right;\"> 0.389476 </td><td style=\"text-align: right;\">-0.254482 </td><td style=\"text-align: right;\"> 0.476774 </td><td style=\"text-align: right;\"> 0.806681 </td><td style=\"text-align: right;\">-0.515323  </td><td style=\"text-align: right;\">-0.268944 </td><td style=\"text-align: right;\">-0.521861 </td><td style=\"text-align: right;\">-0.0541904 </td><td style=\"text-align: right;\"> 0.0623078</td><td style=\"text-align: right;\">-0.427573  </td><td style=\"text-align: right;\"> 0.209428 </td><td style=\"text-align: right;\"> 0.675307  </td><td style=\"text-align: right;\">-0.156747 </td><td style=\"text-align: right;\">-0.488074  </td><td style=\"text-align: right;\"> 0.266841 </td><td style=\"text-align: right;\"> 0.216901  </td><td style=\"text-align: right;\">-0.365613   </td><td style=\"text-align: right;\">-0.483448  </td><td style=\"text-align: right;\">-0.16199   </td><td style=\"text-align: right;\">-0.311047  </td><td style=\"text-align: right;\">-0.877527  </td><td style=\"text-align: right;\">-0.30912  </td><td style=\"text-align: right;\">-0.48697  </td><td style=\"text-align: right;\"> 0.149168 </td><td style=\"text-align: right;\">-0.372397  </td><td style=\"text-align: right;\">-0.163269 </td><td style=\"text-align: right;\">-0.117403 </td><td style=\"text-align: right;\"> 0.138337 </td><td style=\"text-align: right;\">-0.19628  </td><td style=\"text-align: right;\"> 0.201152  </td><td style=\"text-align: right;\">-0.0601995</td><td style=\"text-align: right;\"> 0.192374  </td><td style=\"text-align: right;\">-0.52172  </td><td style=\"text-align: right;\">-0.127364 </td><td style=\"text-align: right;\">-0.232277 </td><td style=\"text-align: right;\">-0.0896376</td><td style=\"text-align: right;\">-0.125402  </td><td style=\"text-align: right;\"> 0.187321  </td><td style=\"text-align: right;\">-0.271664  </td><td style=\"text-align: right;\">-0.2616   </td><td style=\"text-align: right;\"> 0.0108175 </td><td style=\"text-align: right;\"> 0.43486   </td><td style=\"text-align: right;\">-0.319592  </td><td style=\"text-align: right;\"> 0.198224 </td><td style=\"text-align: right;\">-0.258672 </td><td style=\"text-align: right;\">-0.383842 </td><td style=\"text-align: right;\">-0.435208 </td><td style=\"text-align: right;\"> 0.323674  </td><td style=\"text-align: right;\">-0.708164  </td><td style=\"text-align: right;\">-0.422046 </td><td style=\"text-align: right;\">-0.207349  </td><td style=\"text-align: right;\">-0.780153 </td><td style=\"text-align: right;\"> 0.00302298</td><td style=\"text-align: right;\"> 0.213339  </td><td style=\"text-align: right;\"> 0.0179504  </td><td style=\"text-align: right;\"> 0.450774  </td><td style=\"text-align: right;\">-0.478498  </td><td style=\"text-align: right;\">-0.0366665 </td><td style=\"text-align: right;\"> 0.0296298  </td><td style=\"text-align: right;\"> 0.283827  </td><td style=\"text-align: right;\">-0.472738  </td><td style=\"text-align: right;\"> 0.0141913  </td><td style=\"text-align: right;\"> 0.275673 </td><td style=\"text-align: right;\"> 0.052553 </td><td style=\"text-align: right;\"> 0.255064 </td><td style=\"text-align: right;\"> 0.240547  </td><td style=\"text-align: right;\"> 0.15366    </td><td style=\"text-align: right;\">-0.170729  </td><td style=\"text-align: right;\"> 0.243725  </td><td style=\"text-align: right;\"> 0.588446  </td><td style=\"text-align: right;\"> 0.528715  </td><td style=\"text-align: right;\">-0.147671  </td><td style=\"text-align: right;\">-0.216204  </td><td style=\"text-align: right;\"> 0.56448   </td><td style=\"text-align: right;\">-0.525028  </td><td style=\"text-align: right;\"> 0.0715956  </td><td style=\"text-align: right;\"> 0.332453  </td><td style=\"text-align: right;\">-0.223248  </td><td style=\"text-align: right;\"> 0.61728   </td><td style=\"text-align: right;\"> 0.123985 </td><td style=\"text-align: right;\">-0.0749367 </td><td style=\"text-align: right;\"> 0.0996517</td><td style=\"text-align: right;\">-0.257484  </td><td style=\"text-align: right;\">-0.405051  </td><td style=\"text-align: right;\"> 0.293621 </td><td style=\"text-align: right;\">-0.227607  </td><td style=\"text-align: right;\">-0.427547 </td><td style=\"text-align: right;\">-0.384105  </td><td style=\"text-align: right;\"> 0.20133    </td><td style=\"text-align: right;\">-0.0139542 </td><td style=\"text-align: right;\">-0.396255  </td><td style=\"text-align: right;\"> 0.0760807</td><td style=\"text-align: right;\"> 0.15238   </td><td style=\"text-align: right;\"> 0.0874545 </td><td style=\"text-align: right;\"> 0.195867 </td><td style=\"text-align: right;\"> 0.241876  </td><td style=\"text-align: right;\"> 0.124269  </td><td style=\"text-align: right;\">-0.272356 </td><td style=\"text-align: right;\"> 0.188318  </td><td style=\"text-align: right;\"> 0.0350412 </td><td style=\"text-align: right;\"> 0.100087  </td><td style=\"text-align: right;\"> 0.0796334</td><td style=\"text-align: right;\">-0.349118  </td><td style=\"text-align: right;\"> 0.14185   </td><td style=\"text-align: right;\">-0.00669717</td><td style=\"text-align: right;\"> 0.19513   </td><td style=\"text-align: right;\"> 0.223768  </td><td style=\"text-align: right;\">-0.268808  </td><td style=\"text-align: right;\">-0.19858  </td><td style=\"text-align: right;\">-0.134069  </td><td style=\"text-align: right;\"> 0.213021  </td><td style=\"text-align: right;\">-0.0708481 </td><td style=\"text-align: right;\">-0.370438 </td><td style=\"text-align: right;\">-0.42775   </td><td style=\"text-align: right;\">-0.0108664</td><td style=\"text-align: right;\">-0.189859  </td><td style=\"text-align: right;\">-0.370499   </td><td style=\"text-align: right;\">-0.286406   </td><td style=\"text-align: right;\"> 0.192455  </td><td style=\"text-align: right;\"> 0.252574  </td><td style=\"text-align: right;\">-0.241866  </td><td style=\"text-align: right;\">-0.0577385</td><td style=\"text-align: right;\"> 0.207005  </td><td style=\"text-align: right;\">-0.373174  </td><td style=\"text-align: right;\">-0.254423 </td><td style=\"text-align: right;\"> 0.370247  </td><td style=\"text-align: right;\"> 0.0748705  </td><td style=\"text-align: right;\"> 0.00531612</td><td style=\"text-align: right;\"> 0.150201  </td></tr>\n<tr><td>SRR8552929</td><td style=\"text-align: right;\"> -6.50059</td><td style=\"text-align: right;\"> 5.03212</td><td style=\"text-align: right;\"> 9.89964    </td><td style=\"text-align: right;\">-1.75115   </td><td style=\"text-align: right;\">-1.99842 </td><td style=\"text-align: right;\"> 5.18436 </td><td style=\"text-align: right;\"> 5.72881 </td><td style=\"text-align: right;\">22.9759   </td><td style=\"text-align: right;\">-72.9113  </td><td style=\"text-align: right;\">-19.4345   </td><td style=\"text-align: right;\"> 3.5075   </td><td style=\"text-align: right;\"> 0.688388 </td><td style=\"text-align: right;\"> 1.69246  </td><td style=\"text-align: right;\">-0.351719</td><td style=\"text-align: right;\"> 0.807579 </td><td style=\"text-align: right;\"> 0.162097</td><td style=\"text-align: right;\"> 0.751626 </td><td style=\"text-align: right;\">-0.18388  </td><td style=\"text-align: right;\"> 0.114748 </td><td style=\"text-align: right;\">-0.708287</td><td style=\"text-align: right;\">-0.431597</td><td style=\"text-align: right;\"> 0.0908924</td><td style=\"text-align: right;\"> 0.351024 </td><td style=\"text-align: right;\">-0.106659 </td><td style=\"text-align: right;\">-0.333741  </td><td style=\"text-align: right;\">-0.275902 </td><td style=\"text-align: right;\">-0.0169099</td><td style=\"text-align: right;\"> 0.738175  </td><td style=\"text-align: right;\"> 0.298389</td><td style=\"text-align: right;\"> 0.173786</td><td style=\"text-align: right;\">-0.232006  </td><td style=\"text-align: right;\">-0.157514 </td><td style=\"text-align: right;\">-0.0104423</td><td style=\"text-align: right;\">-0.0416099</td><td style=\"text-align: right;\"> 0.00259742</td><td style=\"text-align: right;\"> 0.153628 </td><td style=\"text-align: right;\">-0.130673 </td><td style=\"text-align: right;\">-0.0629438</td><td style=\"text-align: right;\"> 0.103533 </td><td style=\"text-align: right;\"> 0.00953883</td><td style=\"text-align: right;\">-0.0284005 </td><td style=\"text-align: right;\"> 0.101688 </td><td style=\"text-align: right;\">-0.15913  </td><td style=\"text-align: right;\"> 0.126722 </td><td style=\"text-align: right;\">-0.0756605</td><td style=\"text-align: right;\">-0.0757435</td><td style=\"text-align: right;\"> 0.0441156</td><td style=\"text-align: right;\"> 0.0158992</td><td style=\"text-align: right;\"> 0.0966239</td><td style=\"text-align: right;\">-0.0160974 </td><td style=\"text-align: right;\">-0.00503431</td><td style=\"text-align: right;\"> 0.0116024</td><td style=\"text-align: right;\"> 0.0095455 </td><td style=\"text-align: right;\">-0.0067565</td><td style=\"text-align: right;\">-0.026261  </td><td style=\"text-align: right;\">-0.0215083</td><td style=\"text-align: right;\"> 0.0502305</td><td style=\"text-align: right;\">-0.0297334</td><td style=\"text-align: right;\"> 0.00990971</td><td style=\"text-align: right;\">-0.0598099 </td><td style=\"text-align: right;\"> 0.0232784</td><td style=\"text-align: right;\">-0.0248749 </td><td style=\"text-align: right;\">-0.0285802</td><td style=\"text-align: right;\"> 0.00209873</td><td style=\"text-align: right;\"> 0.0368059</td><td style=\"text-align: right;\"> 0.0434571</td><td style=\"text-align: right;\">-0.0579956 </td><td style=\"text-align: right;\">-0.000134279</td><td style=\"text-align: right;\"> 0.0298716 </td><td style=\"text-align: right;\">-0.0178984</td><td style=\"text-align: right;\"> 0.0093227</td><td style=\"text-align: right;\">-0.0204604</td><td style=\"text-align: right;\">-0.0540928</td><td style=\"text-align: right;\"> 0.0371086</td><td style=\"text-align: right;\"> 0.00754352</td><td style=\"text-align: right;\">-0.0336085</td><td style=\"text-align: right;\">-0.0019139</td><td style=\"text-align: right;\"> 0.00628899</td><td style=\"text-align: right;\">-0.0455008</td><td style=\"text-align: right;\"> 0.052359  </td><td style=\"text-align: right;\"> 0.0163493</td><td style=\"text-align: right;\"> 0.00218547</td><td style=\"text-align: right;\"> 0.0132377</td><td style=\"text-align: right;\"> 0.00211587</td><td style=\"text-align: right;\">-0.0146862</td><td style=\"text-align: right;\">-0.00559338</td><td style=\"text-align: right;\">-0.000155938</td><td style=\"text-align: right;\"> 0.00755395</td><td style=\"text-align: right;\"> 0.0033325 </td><td style=\"text-align: right;\"> 0.00209277</td><td style=\"text-align: right;\"> 0.00105389</td><td style=\"text-align: right;\">-0.0748952</td><td style=\"text-align: right;\"> 0.0101986</td><td style=\"text-align: right;\">-0.0145325</td><td style=\"text-align: right;\">-0.00125014</td><td style=\"text-align: right;\">-0.0258381</td><td style=\"text-align: right;\">-0.0540903</td><td style=\"text-align: right;\">-0.0410478</td><td style=\"text-align: right;\"> 0.0387674</td><td style=\"text-align: right;\"> 0.00351536</td><td style=\"text-align: right;\"> 0.0128107</td><td style=\"text-align: right;\"> 0.00557929</td><td style=\"text-align: right;\">-0.0619911</td><td style=\"text-align: right;\"> 0.0247265</td><td style=\"text-align: right;\"> 0.0154274</td><td style=\"text-align: right;\">-0.0321825</td><td style=\"text-align: right;\">-0.00951977</td><td style=\"text-align: right;\"> 0.00769412</td><td style=\"text-align: right;\">-0.0357834 </td><td style=\"text-align: right;\">-0.0591719</td><td style=\"text-align: right;\">-0.00457642</td><td style=\"text-align: right;\">-0.00606525</td><td style=\"text-align: right;\"> 0.00840811</td><td style=\"text-align: right;\"> 0.0210038</td><td style=\"text-align: right;\"> 0.004185 </td><td style=\"text-align: right;\">-0.014654 </td><td style=\"text-align: right;\"> 0.0225778</td><td style=\"text-align: right;\">-0.00183399</td><td style=\"text-align: right;\"> 0.00217674</td><td style=\"text-align: right;\"> 0.0351158</td><td style=\"text-align: right;\">-0.00135192</td><td style=\"text-align: right;\">-0.0150031</td><td style=\"text-align: right;\"> 0.0036849 </td><td style=\"text-align: right;\">-0.00310188</td><td style=\"text-align: right;\"> 0.000879287</td><td style=\"text-align: right;\"> 0.00355384</td><td style=\"text-align: right;\">-0.0084746 </td><td style=\"text-align: right;\">-0.00534059</td><td style=\"text-align: right;\">-0.0105895  </td><td style=\"text-align: right;\"> 0.00742139</td><td style=\"text-align: right;\"> 0.011533  </td><td style=\"text-align: right;\">-0.00614121 </td><td style=\"text-align: right;\">-0.0129047</td><td style=\"text-align: right;\"> 0.020875 </td><td style=\"text-align: right;\">-0.0049962</td><td style=\"text-align: right;\">-0.00231064</td><td style=\"text-align: right;\"> 0.00582987 </td><td style=\"text-align: right;\">-0.00690987</td><td style=\"text-align: right;\">-0.00203907</td><td style=\"text-align: right;\"> 0.00527454</td><td style=\"text-align: right;\"> 0.00045267</td><td style=\"text-align: right;\"> 0.00388553</td><td style=\"text-align: right;\">-0.0197361 </td><td style=\"text-align: right;\"> 0.00423608</td><td style=\"text-align: right;\"> 0.00979886</td><td style=\"text-align: right;\"> 0.000483858</td><td style=\"text-align: right;\">-0.00017943</td><td style=\"text-align: right;\">-0.00964616</td><td style=\"text-align: right;\"> 0.0194447 </td><td style=\"text-align: right;\"> 0.0148543</td><td style=\"text-align: right;\"> 0.00513786</td><td style=\"text-align: right;\">-0.0106696</td><td style=\"text-align: right;\">-0.00341618</td><td style=\"text-align: right;\"> 0.00174641</td><td style=\"text-align: right;\"> 0.0118982</td><td style=\"text-align: right;\"> 0.00116556</td><td style=\"text-align: right;\"> 0.0209835</td><td style=\"text-align: right;\"> 0.00243423</td><td style=\"text-align: right;\">-0.000339955</td><td style=\"text-align: right;\"> 0.00521808</td><td style=\"text-align: right;\">-0.00359017</td><td style=\"text-align: right;\">-0.0172559</td><td style=\"text-align: right;\">-0.00280436</td><td style=\"text-align: right;\">-0.00727958</td><td style=\"text-align: right;\"> 0.026531 </td><td style=\"text-align: right;\"> 0.00720347</td><td style=\"text-align: right;\"> 0.00123806</td><td style=\"text-align: right;\"> 0.0154357</td><td style=\"text-align: right;\"> 0.00556288</td><td style=\"text-align: right;\"> 0.00342277</td><td style=\"text-align: right;\"> 0.0102327 </td><td style=\"text-align: right;\">-0.0109282</td><td style=\"text-align: right;\">-0.00307871</td><td style=\"text-align: right;\">-0.00308189</td><td style=\"text-align: right;\">-0.00206439</td><td style=\"text-align: right;\"> 0.0103463 </td><td style=\"text-align: right;\">-0.00746865</td><td style=\"text-align: right;\">-0.00659294</td><td style=\"text-align: right;\"> 0.0021469</td><td style=\"text-align: right;\"> 0.00023555</td><td style=\"text-align: right;\"> 0.0107691 </td><td style=\"text-align: right;\">-0.00834449</td><td style=\"text-align: right;\"> 0.0171208</td><td style=\"text-align: right;\"> 0.00355487</td><td style=\"text-align: right;\"> 0.0104005</td><td style=\"text-align: right;\"> 0.00500246</td><td style=\"text-align: right;\"> 0.000461584</td><td style=\"text-align: right;\"> 0.000601585</td><td style=\"text-align: right;\"> 0.00443169</td><td style=\"text-align: right;\"> 0.016988  </td><td style=\"text-align: right;\">-0.00255609</td><td style=\"text-align: right;\"> 0.0107808</td><td style=\"text-align: right;\"> 0.00364382</td><td style=\"text-align: right;\">-0.00654571</td><td style=\"text-align: right;\">-0.0063882</td><td style=\"text-align: right;\">-0.00536978</td><td style=\"text-align: right;\"> 0.000630954</td><td style=\"text-align: right;\"> 0.0107065 </td><td style=\"text-align: right;\"> 0.0136769 </td></tr>\n<tr><td>ERR067629 </td><td style=\"text-align: right;\">-12.9479 </td><td style=\"text-align: right;\"> 4.52013</td><td style=\"text-align: right;\">-0.0727567  </td><td style=\"text-align: right;\"> 0.795501  </td><td style=\"text-align: right;\"> 5.60493 </td><td style=\"text-align: right;\">-3.83393 </td><td style=\"text-align: right;\">-0.123111</td><td style=\"text-align: right;\"> 0.276374 </td><td style=\"text-align: right;\"> -0.394928</td><td style=\"text-align: right;\">  1.5134   </td><td style=\"text-align: right;\"> 0.0998441</td><td style=\"text-align: right;\">-0.160441 </td><td style=\"text-align: right;\"> 0.875783 </td><td style=\"text-align: right;\"> 0.144141</td><td style=\"text-align: right;\"> 1.50295  </td><td style=\"text-align: right;\"> 0.662061</td><td style=\"text-align: right;\">-0.152918 </td><td style=\"text-align: right;\">-1.32294  </td><td style=\"text-align: right;\"> 0.494843 </td><td style=\"text-align: right;\"> 0.120914</td><td style=\"text-align: right;\"> 0.409421</td><td style=\"text-align: right;\"> 1.27984  </td><td style=\"text-align: right;\"> 0.89714  </td><td style=\"text-align: right;\">-0.4064   </td><td style=\"text-align: right;\"> 0.436947  </td><td style=\"text-align: right;\">-0.264961 </td><td style=\"text-align: right;\">-0.504652 </td><td style=\"text-align: right;\"> 0.0964939 </td><td style=\"text-align: right;\">-0.857363</td><td style=\"text-align: right;\"> 0.640224</td><td style=\"text-align: right;\"> 0.00723726</td><td style=\"text-align: right;\">-0.427967 </td><td style=\"text-align: right;\"> 0.128956 </td><td style=\"text-align: right;\">-0.386457 </td><td style=\"text-align: right;\">-0.294656  </td><td style=\"text-align: right;\">-0.138751 </td><td style=\"text-align: right;\">-0.556036 </td><td style=\"text-align: right;\">-0.0155012</td><td style=\"text-align: right;\">-0.478571 </td><td style=\"text-align: right;\"> 0.665948  </td><td style=\"text-align: right;\">-0.00757544</td><td style=\"text-align: right;\"> 0.0321201</td><td style=\"text-align: right;\">-0.430406 </td><td style=\"text-align: right;\">-0.53032  </td><td style=\"text-align: right;\"> 1.22734  </td><td style=\"text-align: right;\"> 0.12203  </td><td style=\"text-align: right;\"> 1.33503  </td><td style=\"text-align: right;\"> 0.968721 </td><td style=\"text-align: right;\">-0.417973 </td><td style=\"text-align: right;\"> 0.607955  </td><td style=\"text-align: right;\">-0.330774  </td><td style=\"text-align: right;\"> 0.561572 </td><td style=\"text-align: right;\"> 0.352208  </td><td style=\"text-align: right;\"> 1.5755   </td><td style=\"text-align: right;\">-0.707895  </td><td style=\"text-align: right;\">-0.909152 </td><td style=\"text-align: right;\"> 0.28725  </td><td style=\"text-align: right;\"> 0.0648046</td><td style=\"text-align: right;\">-0.0253563 </td><td style=\"text-align: right;\">-0.217064  </td><td style=\"text-align: right;\"> 0.413599 </td><td style=\"text-align: right;\"> 0.61586   </td><td style=\"text-align: right;\"> 0.537453 </td><td style=\"text-align: right;\"> 0.0908139 </td><td style=\"text-align: right;\">-0.675122 </td><td style=\"text-align: right;\">-0.489732 </td><td style=\"text-align: right;\"> 0.581519  </td><td style=\"text-align: right;\"> 0.330403   </td><td style=\"text-align: right;\">-0.240445  </td><td style=\"text-align: right;\"> 0.167285 </td><td style=\"text-align: right;\">-0.323837 </td><td style=\"text-align: right;\">-0.203957 </td><td style=\"text-align: right;\"> 0.662979 </td><td style=\"text-align: right;\">-0.2441   </td><td style=\"text-align: right;\"> 0.212523  </td><td style=\"text-align: right;\">-0.801479 </td><td style=\"text-align: right;\">-0.320418 </td><td style=\"text-align: right;\">-0.0492246 </td><td style=\"text-align: right;\"> 0.0482084</td><td style=\"text-align: right;\">-0.143322  </td><td style=\"text-align: right;\"> 0.540529 </td><td style=\"text-align: right;\"> 0.84252   </td><td style=\"text-align: right;\"> 0.304992 </td><td style=\"text-align: right;\"> 0.255836  </td><td style=\"text-align: right;\"> 0.296174 </td><td style=\"text-align: right;\">-0.203431  </td><td style=\"text-align: right;\"> 0.15144    </td><td style=\"text-align: right;\"> 0.0989564 </td><td style=\"text-align: right;\"> 0.231816  </td><td style=\"text-align: right;\">-0.0948375 </td><td style=\"text-align: right;\"> 0.383431  </td><td style=\"text-align: right;\">-0.130254 </td><td style=\"text-align: right;\"> 0.368513 </td><td style=\"text-align: right;\"> 0.10371  </td><td style=\"text-align: right;\"> 0.252825  </td><td style=\"text-align: right;\">-0.265766 </td><td style=\"text-align: right;\"> 0.268541 </td><td style=\"text-align: right;\"> 0.4523   </td><td style=\"text-align: right;\">-0.0431464</td><td style=\"text-align: right;\">-0.282415  </td><td style=\"text-align: right;\"> 0.455213 </td><td style=\"text-align: right;\">-0.159996  </td><td style=\"text-align: right;\"> 0.361028 </td><td style=\"text-align: right;\">-0.260988 </td><td style=\"text-align: right;\"> 0.186677 </td><td style=\"text-align: right;\"> 0.0308555</td><td style=\"text-align: right;\"> 0.137222  </td><td style=\"text-align: right;\">-0.0186495 </td><td style=\"text-align: right;\"> 0.273489  </td><td style=\"text-align: right;\">-0.342984 </td><td style=\"text-align: right;\"> 0.101656  </td><td style=\"text-align: right;\">-0.162863  </td><td style=\"text-align: right;\">-0.0422177 </td><td style=\"text-align: right;\"> 0.0131981</td><td style=\"text-align: right;\"> 0.0687778</td><td style=\"text-align: right;\">-0.845328 </td><td style=\"text-align: right;\">-0.289969 </td><td style=\"text-align: right;\"> 0.162009  </td><td style=\"text-align: right;\">-0.372335  </td><td style=\"text-align: right;\"> 0.472539 </td><td style=\"text-align: right;\"> 0.335047  </td><td style=\"text-align: right;\">-0.259656 </td><td style=\"text-align: right;\">-0.0743039 </td><td style=\"text-align: right;\"> 0.104449  </td><td style=\"text-align: right;\">-0.44302    </td><td style=\"text-align: right;\">-0.00990119</td><td style=\"text-align: right;\">-0.361591  </td><td style=\"text-align: right;\"> 0.0910314 </td><td style=\"text-align: right;\"> 0.184432   </td><td style=\"text-align: right;\">-0.366909  </td><td style=\"text-align: right;\"> 0.100612  </td><td style=\"text-align: right;\">-0.201271   </td><td style=\"text-align: right;\">-0.0203719</td><td style=\"text-align: right;\"> 0.0346376</td><td style=\"text-align: right;\">-0.0766412</td><td style=\"text-align: right;\"> 0.771028  </td><td style=\"text-align: right;\">-0.373069   </td><td style=\"text-align: right;\">-0.510017  </td><td style=\"text-align: right;\">-0.192733  </td><td style=\"text-align: right;\"> 0.511328  </td><td style=\"text-align: right;\">-0.358742  </td><td style=\"text-align: right;\"> 0.781616  </td><td style=\"text-align: right;\">-0.0907365 </td><td style=\"text-align: right;\">-0.162883  </td><td style=\"text-align: right;\"> 0.418575  </td><td style=\"text-align: right;\"> 0.385409   </td><td style=\"text-align: right;\"> 0.392492  </td><td style=\"text-align: right;\"> 0.235851  </td><td style=\"text-align: right;\"> 0.408559  </td><td style=\"text-align: right;\"> 0.663412 </td><td style=\"text-align: right;\">-0.288445  </td><td style=\"text-align: right;\">-0.388877 </td><td style=\"text-align: right;\">-0.377931  </td><td style=\"text-align: right;\"> 0.790468  </td><td style=\"text-align: right;\">-0.21487  </td><td style=\"text-align: right;\"> 0.369718  </td><td style=\"text-align: right;\"> 0.249138 </td><td style=\"text-align: right;\">-0.0841726 </td><td style=\"text-align: right;\"> 0.257572   </td><td style=\"text-align: right;\"> 0.43072   </td><td style=\"text-align: right;\">-0.0510586 </td><td style=\"text-align: right;\">-0.0270357</td><td style=\"text-align: right;\"> 0.427252  </td><td style=\"text-align: right;\"> 0.108473  </td><td style=\"text-align: right;\">-0.256147 </td><td style=\"text-align: right;\">-0.425715  </td><td style=\"text-align: right;\">-0.244946  </td><td style=\"text-align: right;\">-0.0475409</td><td style=\"text-align: right;\"> 0.134611  </td><td style=\"text-align: right;\">-0.35111   </td><td style=\"text-align: right;\">-0.00822583</td><td style=\"text-align: right;\">-0.169693 </td><td style=\"text-align: right;\">-0.156576  </td><td style=\"text-align: right;\"> 0.370779  </td><td style=\"text-align: right;\">-0.390898  </td><td style=\"text-align: right;\"> 0.140082  </td><td style=\"text-align: right;\">-0.15994   </td><td style=\"text-align: right;\">-0.218447  </td><td style=\"text-align: right;\">-0.174837 </td><td style=\"text-align: right;\">-0.127382  </td><td style=\"text-align: right;\"> 0.27608   </td><td style=\"text-align: right;\"> 0.102577  </td><td style=\"text-align: right;\"> 0.085631 </td><td style=\"text-align: right;\">-0.51676   </td><td style=\"text-align: right;\"> 0.410059 </td><td style=\"text-align: right;\"> 0.401514  </td><td style=\"text-align: right;\">-0.0918516  </td><td style=\"text-align: right;\">-0.368146   </td><td style=\"text-align: right;\"> 0.445533  </td><td style=\"text-align: right;\"> 0.517653  </td><td style=\"text-align: right;\"> 0.124488  </td><td style=\"text-align: right;\"> 0.10141  </td><td style=\"text-align: right;\"> 0.1146    </td><td style=\"text-align: right;\"> 0.217356  </td><td style=\"text-align: right;\"> 0.631302 </td><td style=\"text-align: right;\">-0.333418  </td><td style=\"text-align: right;\"> 0.342894   </td><td style=\"text-align: right;\">-0.226901  </td><td style=\"text-align: right;\">-0.293725  </td></tr>\n<tr><td>ERR067714 </td><td style=\"text-align: right;\"> -8.94528</td><td style=\"text-align: right;\">-5.01545</td><td style=\"text-align: right;\"> 0.00218169 </td><td style=\"text-align: right;\"> 0.19758   </td><td style=\"text-align: right;\"> 0.776913</td><td style=\"text-align: right;\">-3.34027 </td><td style=\"text-align: right;\"> 0.435418</td><td style=\"text-align: right;\">-0.418539 </td><td style=\"text-align: right;\"> -0.392206</td><td style=\"text-align: right;\">  0.0628038</td><td style=\"text-align: right;\"> 0.194703 </td><td style=\"text-align: right;\">-0.470089 </td><td style=\"text-align: right;\">-0.505175 </td><td style=\"text-align: right;\">-0.666116</td><td style=\"text-align: right;\">-1.32472  </td><td style=\"text-align: right;\">-1.18856 </td><td style=\"text-align: right;\">-0.0948413</td><td style=\"text-align: right;\"> 0.846526 </td><td style=\"text-align: right;\">-0.351893 </td><td style=\"text-align: right;\"> 0.994438</td><td style=\"text-align: right;\"> 0.709866</td><td style=\"text-align: right;\"> 0.0946708</td><td style=\"text-align: right;\"> 0.730704 </td><td style=\"text-align: right;\">-0.415959 </td><td style=\"text-align: right;\"> 0.20027   </td><td style=\"text-align: right;\">-0.0269342</td><td style=\"text-align: right;\">-0.0357076</td><td style=\"text-align: right;\"> 0.00894854</td><td style=\"text-align: right;\">-0.396809</td><td style=\"text-align: right;\">-0.561537</td><td style=\"text-align: right;\"> 0.0696797 </td><td style=\"text-align: right;\"> 1.07964  </td><td style=\"text-align: right;\">-1.27838  </td><td style=\"text-align: right;\">-0.177258 </td><td style=\"text-align: right;\">-0.92883   </td><td style=\"text-align: right;\">-0.129073 </td><td style=\"text-align: right;\">-0.399533 </td><td style=\"text-align: right;\"> 0.0544567</td><td style=\"text-align: right;\">-0.503208 </td><td style=\"text-align: right;\"> 0.225213  </td><td style=\"text-align: right;\">-0.125742  </td><td style=\"text-align: right;\">-0.401784 </td><td style=\"text-align: right;\"> 0.0836486</td><td style=\"text-align: right;\">-0.0663367</td><td style=\"text-align: right;\">-0.339606 </td><td style=\"text-align: right;\">-0.0227511</td><td style=\"text-align: right;\"> 0.314145 </td><td style=\"text-align: right;\">-0.698153 </td><td style=\"text-align: right;\">-0.384385 </td><td style=\"text-align: right;\">-0.482622  </td><td style=\"text-align: right;\"> 0.123586  </td><td style=\"text-align: right;\"> 0.035008 </td><td style=\"text-align: right;\"> 0.0553435 </td><td style=\"text-align: right;\"> 0.375374 </td><td style=\"text-align: right;\">-0.165647  </td><td style=\"text-align: right;\"> 0.576548 </td><td style=\"text-align: right;\">-0.148979 </td><td style=\"text-align: right;\">-0.522299 </td><td style=\"text-align: right;\"> 0.35583   </td><td style=\"text-align: right;\">-0.475503  </td><td style=\"text-align: right;\">-0.117024 </td><td style=\"text-align: right;\">-0.0363074 </td><td style=\"text-align: right;\"> 0.171169 </td><td style=\"text-align: right;\">-0.0971223 </td><td style=\"text-align: right;\"> 0.175799 </td><td style=\"text-align: right;\">-0.0940921</td><td style=\"text-align: right;\">-0.145786  </td><td style=\"text-align: right;\">-0.0449375  </td><td style=\"text-align: right;\">-0.0327391 </td><td style=\"text-align: right;\"> 0.266942 </td><td style=\"text-align: right;\"> 0.371082 </td><td style=\"text-align: right;\"> 0.148319 </td><td style=\"text-align: right;\">-0.192359 </td><td style=\"text-align: right;\"> 0.114621 </td><td style=\"text-align: right;\"> 0.0116713 </td><td style=\"text-align: right;\">-0.0226767</td><td style=\"text-align: right;\">-0.0395446</td><td style=\"text-align: right;\"> 0.123841  </td><td style=\"text-align: right;\"> 0.0915411</td><td style=\"text-align: right;\">-0.368156  </td><td style=\"text-align: right;\"> 0.142615 </td><td style=\"text-align: right;\"> 0.0449073 </td><td style=\"text-align: right;\">-0.0961354</td><td style=\"text-align: right;\">-0.285895  </td><td style=\"text-align: right;\">-0.399253 </td><td style=\"text-align: right;\"> 0.336092  </td><td style=\"text-align: right;\"> 0.151977   </td><td style=\"text-align: right;\"> 0.227483  </td><td style=\"text-align: right;\"> 0.1069    </td><td style=\"text-align: right;\">-0.141486  </td><td style=\"text-align: right;\">-0.397814  </td><td style=\"text-align: right;\">-0.352355 </td><td style=\"text-align: right;\">-0.152311 </td><td style=\"text-align: right;\">-0.125061 </td><td style=\"text-align: right;\">-0.030034  </td><td style=\"text-align: right;\"> 0.219326 </td><td style=\"text-align: right;\"> 0.22168  </td><td style=\"text-align: right;\">-0.274953 </td><td style=\"text-align: right;\"> 0.037017 </td><td style=\"text-align: right;\">-0.214727  </td><td style=\"text-align: right;\">-0.0662301</td><td style=\"text-align: right;\"> 0.107729  </td><td style=\"text-align: right;\"> 0.27112  </td><td style=\"text-align: right;\"> 0.0018463</td><td style=\"text-align: right;\"> 0.0442201</td><td style=\"text-align: right;\">-0.279706 </td><td style=\"text-align: right;\">-0.0151437 </td><td style=\"text-align: right;\">-0.0484053 </td><td style=\"text-align: right;\"> 0.0693774 </td><td style=\"text-align: right;\">-0.150624 </td><td style=\"text-align: right;\">-0.0293918 </td><td style=\"text-align: right;\"> 0.0167988 </td><td style=\"text-align: right;\">-0.0950179 </td><td style=\"text-align: right;\">-0.343762 </td><td style=\"text-align: right;\">-0.0134441</td><td style=\"text-align: right;\">-0.0923724</td><td style=\"text-align: right;\"> 0.0734659</td><td style=\"text-align: right;\">-0.1104    </td><td style=\"text-align: right;\">-0.0647773 </td><td style=\"text-align: right;\">-0.27454  </td><td style=\"text-align: right;\"> 0.16298   </td><td style=\"text-align: right;\"> 0.160289 </td><td style=\"text-align: right;\">-0.337939  </td><td style=\"text-align: right;\"> 0.134666  </td><td style=\"text-align: right;\"> 0.0826234  </td><td style=\"text-align: right;\">-0.0991061 </td><td style=\"text-align: right;\"> 0.00194032</td><td style=\"text-align: right;\">-0.0835894 </td><td style=\"text-align: right;\"> 0.0239177  </td><td style=\"text-align: right;\"> 0.1042    </td><td style=\"text-align: right;\"> 0.0224501 </td><td style=\"text-align: right;\"> 0.264522   </td><td style=\"text-align: right;\">-0.0986982</td><td style=\"text-align: right;\"> 0.0640312</td><td style=\"text-align: right;\">-0.155391 </td><td style=\"text-align: right;\"> 0.038349  </td><td style=\"text-align: right;\">-0.0327791  </td><td style=\"text-align: right;\"> 0.052411  </td><td style=\"text-align: right;\"> 0.0375473 </td><td style=\"text-align: right;\"> 0.042954  </td><td style=\"text-align: right;\">-0.334741  </td><td style=\"text-align: right;\"> 0.101777  </td><td style=\"text-align: right;\">-0.00269391</td><td style=\"text-align: right;\">-0.0725712 </td><td style=\"text-align: right;\"> 0.142811  </td><td style=\"text-align: right;\">-0.197656   </td><td style=\"text-align: right;\"> 0.226308  </td><td style=\"text-align: right;\"> 0.21958   </td><td style=\"text-align: right;\"> 0.104074  </td><td style=\"text-align: right;\"> 0.0606405</td><td style=\"text-align: right;\"> 0.151589  </td><td style=\"text-align: right;\">-0.0177989</td><td style=\"text-align: right;\">-0.0394543 </td><td style=\"text-align: right;\">-0.060618  </td><td style=\"text-align: right;\"> 0.034742 </td><td style=\"text-align: right;\"> 0.117939  </td><td style=\"text-align: right;\">-0.0518007</td><td style=\"text-align: right;\">-0.0837149 </td><td style=\"text-align: right;\">-0.0975527  </td><td style=\"text-align: right;\">-0.203868  </td><td style=\"text-align: right;\">-0.169478  </td><td style=\"text-align: right;\">-0.268492 </td><td style=\"text-align: right;\">-0.051744  </td><td style=\"text-align: right;\"> 0.0340075 </td><td style=\"text-align: right;\">-0.114194 </td><td style=\"text-align: right;\">-0.0014794 </td><td style=\"text-align: right;\"> 0.184438  </td><td style=\"text-align: right;\">-0.115449 </td><td style=\"text-align: right;\"> 0.0871521 </td><td style=\"text-align: right;\"> 0.125626  </td><td style=\"text-align: right;\">-0.0201496 </td><td style=\"text-align: right;\">-0.211015 </td><td style=\"text-align: right;\"> 0.370505  </td><td style=\"text-align: right;\"> 0.161568  </td><td style=\"text-align: right;\">-0.0331975 </td><td style=\"text-align: right;\"> 0.115279  </td><td style=\"text-align: right;\">-0.0729038 </td><td style=\"text-align: right;\"> 0.167561  </td><td style=\"text-align: right;\"> 0.0427467</td><td style=\"text-align: right;\">-0.238144  </td><td style=\"text-align: right;\"> 0.0151419 </td><td style=\"text-align: right;\">-0.158566  </td><td style=\"text-align: right;\">-0.0342529</td><td style=\"text-align: right;\">-0.140659  </td><td style=\"text-align: right;\"> 0.0779365</td><td style=\"text-align: right;\"> 0.0792503 </td><td style=\"text-align: right;\">-0.208821   </td><td style=\"text-align: right;\">-0.0337909  </td><td style=\"text-align: right;\"> 0.168655  </td><td style=\"text-align: right;\">-0.0670168 </td><td style=\"text-align: right;\">-0.0351762 </td><td style=\"text-align: right;\"> 0.178609 </td><td style=\"text-align: right;\">-0.0471835 </td><td style=\"text-align: right;\"> 0.136935  </td><td style=\"text-align: right;\">-0.0638909</td><td style=\"text-align: right;\">-0.146832  </td><td style=\"text-align: right;\"> 0.177575   </td><td style=\"text-align: right;\"> 0.0438678 </td><td style=\"text-align: right;\"> 0.0781435 </td></tr>\n<tr><td>SRR5065314</td><td style=\"text-align: right;\"> -8.61603</td><td style=\"text-align: right;\">-5.40221</td><td style=\"text-align: right;\"> 0.00811241 </td><td style=\"text-align: right;\">-0.470638  </td><td style=\"text-align: right;\">-0.436735</td><td style=\"text-align: right;\"> 2.80297 </td><td style=\"text-align: right;\">-0.717564</td><td style=\"text-align: right;\"> 0.0320249</td><td style=\"text-align: right;\">  0.384208</td><td style=\"text-align: right;\"> -0.915967 </td><td style=\"text-align: right;\"> 0.109527 </td><td style=\"text-align: right;\"> 0.47088  </td><td style=\"text-align: right;\"> 0.56927  </td><td style=\"text-align: right;\"> 0.160269</td><td style=\"text-align: right;\"> 1.68617  </td><td style=\"text-align: right;\"> 1.00034 </td><td style=\"text-align: right;\">-0.268822 </td><td style=\"text-align: right;\"> 0.0977931</td><td style=\"text-align: right;\"> 0.296411 </td><td style=\"text-align: right;\"> 0.619891</td><td style=\"text-align: right;\">-0.622163</td><td style=\"text-align: right;\"> 0.976312 </td><td style=\"text-align: right;\">-0.49164  </td><td style=\"text-align: right;\"> 0.403487 </td><td style=\"text-align: right;\">-0.389032  </td><td style=\"text-align: right;\"> 0.472982 </td><td style=\"text-align: right;\"> 1.40307  </td><td style=\"text-align: right;\">-0.0736759 </td><td style=\"text-align: right;\">-0.46472 </td><td style=\"text-align: right;\">-0.184554</td><td style=\"text-align: right;\"> 0.0479997 </td><td style=\"text-align: right;\">-0.334994 </td><td style=\"text-align: right;\"> 0.160773 </td><td style=\"text-align: right;\">-0.313563 </td><td style=\"text-align: right;\">-0.234564  </td><td style=\"text-align: right;\"> 0.0904426</td><td style=\"text-align: right;\"> 0.187123 </td><td style=\"text-align: right;\">-0.1894   </td><td style=\"text-align: right;\">-0.382194 </td><td style=\"text-align: right;\">-0.201534  </td><td style=\"text-align: right;\">-0.192287  </td><td style=\"text-align: right;\">-0.369397 </td><td style=\"text-align: right;\"> 0.24313  </td><td style=\"text-align: right;\"> 0.378067 </td><td style=\"text-align: right;\">-0.0988708</td><td style=\"text-align: right;\"> 0.0338374</td><td style=\"text-align: right;\"> 0.457246 </td><td style=\"text-align: right;\">-0.188525 </td><td style=\"text-align: right;\"> 0.658951 </td><td style=\"text-align: right;\">-0.130829  </td><td style=\"text-align: right;\"> 0.298092  </td><td style=\"text-align: right;\"> 0.200871 </td><td style=\"text-align: right;\">-0.00588034</td><td style=\"text-align: right;\">-0.0506975</td><td style=\"text-align: right;\"> 0.202035  </td><td style=\"text-align: right;\"> 0.0840065</td><td style=\"text-align: right;\">-0.336172 </td><td style=\"text-align: right;\">-0.217707 </td><td style=\"text-align: right;\"> 0.159621  </td><td style=\"text-align: right;\">-0.113108  </td><td style=\"text-align: right;\">-0.260194 </td><td style=\"text-align: right;\"> 0.210903  </td><td style=\"text-align: right;\">-0.297812 </td><td style=\"text-align: right;\"> 0.191484  </td><td style=\"text-align: right;\"> 0.329767 </td><td style=\"text-align: right;\"> 0.134989 </td><td style=\"text-align: right;\">-0.0103842 </td><td style=\"text-align: right;\"> 0.0685854  </td><td style=\"text-align: right;\">-0.00680479</td><td style=\"text-align: right;\"> 0.266239 </td><td style=\"text-align: right;\"> 0.0298477</td><td style=\"text-align: right;\">-0.0748851</td><td style=\"text-align: right;\">-0.226567 </td><td style=\"text-align: right;\"> 0.255102 </td><td style=\"text-align: right;\">-0.46267   </td><td style=\"text-align: right;\">-0.0558517</td><td style=\"text-align: right;\"> 0.335046 </td><td style=\"text-align: right;\">-0.145945  </td><td style=\"text-align: right;\"> 0.20236  </td><td style=\"text-align: right;\"> 0.304878  </td><td style=\"text-align: right;\">-0.078967 </td><td style=\"text-align: right;\"> 0.0183667 </td><td style=\"text-align: right;\"> 0.273161 </td><td style=\"text-align: right;\">-0.335248  </td><td style=\"text-align: right;\">-0.254011 </td><td style=\"text-align: right;\"> 0.118854  </td><td style=\"text-align: right;\"> 0.307712   </td><td style=\"text-align: right;\">-0.262988  </td><td style=\"text-align: right;\"> 0.00616952</td><td style=\"text-align: right;\"> 0.29753   </td><td style=\"text-align: right;\">-0.202918  </td><td style=\"text-align: right;\"> 0.468733 </td><td style=\"text-align: right;\">-0.188677 </td><td style=\"text-align: right;\">-0.11437  </td><td style=\"text-align: right;\"> 0.11525   </td><td style=\"text-align: right;\"> 0.48977  </td><td style=\"text-align: right;\"> 0.386582 </td><td style=\"text-align: right;\">-0.0465705</td><td style=\"text-align: right;\">-0.213999 </td><td style=\"text-align: right;\">-0.186912  </td><td style=\"text-align: right;\">-0.0642073</td><td style=\"text-align: right;\"> 0.258249  </td><td style=\"text-align: right;\"> 0.0956704</td><td style=\"text-align: right;\">-0.0400266</td><td style=\"text-align: right;\"> 0.295486 </td><td style=\"text-align: right;\">-0.194503 </td><td style=\"text-align: right;\"> 0.270661  </td><td style=\"text-align: right;\">-0.132432  </td><td style=\"text-align: right;\">-0.00319387</td><td style=\"text-align: right;\">-0.0266163</td><td style=\"text-align: right;\">-0.135375  </td><td style=\"text-align: right;\">-0.1325    </td><td style=\"text-align: right;\">-0.198468  </td><td style=\"text-align: right;\">-0.130475 </td><td style=\"text-align: right;\">-0.0800707</td><td style=\"text-align: right;\">-0.0386215</td><td style=\"text-align: right;\"> 0.249876 </td><td style=\"text-align: right;\">-0.126518  </td><td style=\"text-align: right;\"> 0.219047  </td><td style=\"text-align: right;\"> 0.0443893</td><td style=\"text-align: right;\"> 0.224987  </td><td style=\"text-align: right;\"> 0.300631 </td><td style=\"text-align: right;\">-0.0520516 </td><td style=\"text-align: right;\">-0.21036   </td><td style=\"text-align: right;\"> 0.354681   </td><td style=\"text-align: right;\"> 0.0235207 </td><td style=\"text-align: right;\"> 0.0676734 </td><td style=\"text-align: right;\">-0.0435437 </td><td style=\"text-align: right;\"> 0.000305147</td><td style=\"text-align: right;\"> 0.11257   </td><td style=\"text-align: right;\"> 0.0879637 </td><td style=\"text-align: right;\">-0.238431   </td><td style=\"text-align: right;\">-0.137048 </td><td style=\"text-align: right;\"> 0.119859 </td><td style=\"text-align: right;\"> 0.538576 </td><td style=\"text-align: right;\">-0.0492506 </td><td style=\"text-align: right;\"> 0.132892   </td><td style=\"text-align: right;\"> 0.171543  </td><td style=\"text-align: right;\">-0.207903  </td><td style=\"text-align: right;\">-0.220583  </td><td style=\"text-align: right;\">-0.0663057 </td><td style=\"text-align: right;\">-0.249994  </td><td style=\"text-align: right;\">-0.106164  </td><td style=\"text-align: right;\">-0.0968478 </td><td style=\"text-align: right;\">-0.0368319 </td><td style=\"text-align: right;\">-0.0663302  </td><td style=\"text-align: right;\"> 0.0632253 </td><td style=\"text-align: right;\"> 0.437415  </td><td style=\"text-align: right;\">-0.104386  </td><td style=\"text-align: right;\"> 0.335587 </td><td style=\"text-align: right;\">-0.24875   </td><td style=\"text-align: right;\">-0.0855293</td><td style=\"text-align: right;\"> 0.066421  </td><td style=\"text-align: right;\"> 0.119544  </td><td style=\"text-align: right;\"> 0.0120892</td><td style=\"text-align: right;\"> 0.0322334 </td><td style=\"text-align: right;\">-0.112484 </td><td style=\"text-align: right;\"> 0.199125  </td><td style=\"text-align: right;\">-0.284355   </td><td style=\"text-align: right;\">-0.180984  </td><td style=\"text-align: right;\"> 0.00111741</td><td style=\"text-align: right;\">-0.28127  </td><td style=\"text-align: right;\"> 0.0789765 </td><td style=\"text-align: right;\"> 0.0622286 </td><td style=\"text-align: right;\"> 0.100738 </td><td style=\"text-align: right;\">-0.213872  </td><td style=\"text-align: right;\"> 0.0294017 </td><td style=\"text-align: right;\">-0.0373952</td><td style=\"text-align: right;\">-0.237339  </td><td style=\"text-align: right;\"> 0.034477  </td><td style=\"text-align: right;\"> 0.103067  </td><td style=\"text-align: right;\"> 0.11292  </td><td style=\"text-align: right;\">-0.182185  </td><td style=\"text-align: right;\">-0.161504  </td><td style=\"text-align: right;\"> 0.0491328 </td><td style=\"text-align: right;\"> 0.532505  </td><td style=\"text-align: right;\"> 0.175996  </td><td style=\"text-align: right;\"> 0.078395  </td><td style=\"text-align: right;\">-0.0769586</td><td style=\"text-align: right;\">-0.0977332 </td><td style=\"text-align: right;\"> 0.0300075 </td><td style=\"text-align: right;\"> 0.148379  </td><td style=\"text-align: right;\">-0.277488 </td><td style=\"text-align: right;\">-0.140362  </td><td style=\"text-align: right;\"> 0.0533468</td><td style=\"text-align: right;\">-0.216524  </td><td style=\"text-align: right;\">-0.224543   </td><td style=\"text-align: right;\"> 0.13969    </td><td style=\"text-align: right;\"> 0.0212791 </td><td style=\"text-align: right;\"> 0.189716  </td><td style=\"text-align: right;\"> 0.263188  </td><td style=\"text-align: right;\">-0.333152 </td><td style=\"text-align: right;\"> 0.490811  </td><td style=\"text-align: right;\">-0.00826002</td><td style=\"text-align: right;\"> 0.250755 </td><td style=\"text-align: right;\">-0.0532916 </td><td style=\"text-align: right;\"> 0.420241   </td><td style=\"text-align: right;\">-0.003078  </td><td style=\"text-align: right;\"> 0.00691849</td></tr>\n<tr><td>ERR067659 </td><td style=\"text-align: right;\"> -9.48605</td><td style=\"text-align: right;\">-4.62876</td><td style=\"text-align: right;\">-0.0113746  </td><td style=\"text-align: right;\"> 0.00264897</td><td style=\"text-align: right;\"> 0.775464</td><td style=\"text-align: right;\">-3.74757 </td><td style=\"text-align: right;\"> 0.77578 </td><td style=\"text-align: right;\">-0.347808 </td><td style=\"text-align: right;\"> -0.456373</td><td style=\"text-align: right;\">  0.557025 </td><td style=\"text-align: right;\">-0.34515  </td><td style=\"text-align: right;\">-0.525534 </td><td style=\"text-align: right;\">-0.770694 </td><td style=\"text-align: right;\">-0.893606</td><td style=\"text-align: right;\">-1.36622  </td><td style=\"text-align: right;\">-0.886175</td><td style=\"text-align: right;\">-0.660253 </td><td style=\"text-align: right;\"> 0.680601 </td><td style=\"text-align: right;\"> 0.087117 </td><td style=\"text-align: right;\">-1.99732 </td><td style=\"text-align: right;\"> 0.109212</td><td style=\"text-align: right;\">-0.287926 </td><td style=\"text-align: right;\"> 0.0916569</td><td style=\"text-align: right;\">-0.337078 </td><td style=\"text-align: right;\"> 0.529247  </td><td style=\"text-align: right;\">-0.370455 </td><td style=\"text-align: right;\">-0.353317 </td><td style=\"text-align: right;\"> 0.0351915 </td><td style=\"text-align: right;\">-0.315187</td><td style=\"text-align: right;\">-1.04475 </td><td style=\"text-align: right;\"> 0.0678574 </td><td style=\"text-align: right;\"> 0.129865 </td><td style=\"text-align: right;\">-0.294966 </td><td style=\"text-align: right;\">-0.138945 </td><td style=\"text-align: right;\">-1.23803   </td><td style=\"text-align: right;\">-0.174998 </td><td style=\"text-align: right;\">-1.22771  </td><td style=\"text-align: right;\">-0.148812 </td><td style=\"text-align: right;\">-0.438866 </td><td style=\"text-align: right;\"> 0.67779   </td><td style=\"text-align: right;\"> 0.609984  </td><td style=\"text-align: right;\">-0.491248 </td><td style=\"text-align: right;\">-0.811174 </td><td style=\"text-align: right;\">-0.267217 </td><td style=\"text-align: right;\">-0.687741 </td><td style=\"text-align: right;\">-0.44685  </td><td style=\"text-align: right;\">-0.208941 </td><td style=\"text-align: right;\"> 0.598894 </td><td style=\"text-align: right;\">-0.0131963</td><td style=\"text-align: right;\">-0.506304  </td><td style=\"text-align: right;\"> 0.214687  </td><td style=\"text-align: right;\">-0.442467 </td><td style=\"text-align: right;\">-0.0567995 </td><td style=\"text-align: right;\"> 0.638434 </td><td style=\"text-align: right;\">-0.290937  </td><td style=\"text-align: right;\"> 0.225813 </td><td style=\"text-align: right;\">-0.770266 </td><td style=\"text-align: right;\">-0.177163 </td><td style=\"text-align: right;\"> 0.494052  </td><td style=\"text-align: right;\">-0.00251475</td><td style=\"text-align: right;\">-0.551776 </td><td style=\"text-align: right;\"> 0.555569  </td><td style=\"text-align: right;\">-0.672519 </td><td style=\"text-align: right;\"> 0.0681414 </td><td style=\"text-align: right;\"> 0.143526 </td><td style=\"text-align: right;\">-0.141077 </td><td style=\"text-align: right;\">-0.12622   </td><td style=\"text-align: right;\">-1.1825     </td><td style=\"text-align: right;\">-0.890815  </td><td style=\"text-align: right;\"> 0.809135 </td><td style=\"text-align: right;\">-0.0734005</td><td style=\"text-align: right;\">-0.352972 </td><td style=\"text-align: right;\">-0.23503  </td><td style=\"text-align: right;\"> 0.146524 </td><td style=\"text-align: right;\"> 0.391508  </td><td style=\"text-align: right;\"> 0.223599 </td><td style=\"text-align: right;\"> 0.208097 </td><td style=\"text-align: right;\">-0.505177  </td><td style=\"text-align: right;\"> 0.0281984</td><td style=\"text-align: right;\">-0.184417  </td><td style=\"text-align: right;\"> 0.462344 </td><td style=\"text-align: right;\">-0.3132    </td><td style=\"text-align: right;\"> 0.0922791</td><td style=\"text-align: right;\">-0.260115  </td><td style=\"text-align: right;\">-0.502435 </td><td style=\"text-align: right;\"> 0.635807  </td><td style=\"text-align: right;\">-0.18061    </td><td style=\"text-align: right;\">-0.559209  </td><td style=\"text-align: right;\"> 0.172449  </td><td style=\"text-align: right;\">-0.236082  </td><td style=\"text-align: right;\"> 0.294326  </td><td style=\"text-align: right;\">-0.0327853</td><td style=\"text-align: right;\">-0.110448 </td><td style=\"text-align: right;\"> 0.316669 </td><td style=\"text-align: right;\">-0.50329   </td><td style=\"text-align: right;\">-0.467994 </td><td style=\"text-align: right;\">-0.386507 </td><td style=\"text-align: right;\"> 0.128248 </td><td style=\"text-align: right;\">-0.195392 </td><td style=\"text-align: right;\"> 0.214672  </td><td style=\"text-align: right;\">-0.433561 </td><td style=\"text-align: right;\">-0.17302   </td><td style=\"text-align: right;\">-0.418322 </td><td style=\"text-align: right;\">-0.225325 </td><td style=\"text-align: right;\">-0.198205 </td><td style=\"text-align: right;\">-0.409893 </td><td style=\"text-align: right;\"> 0.0723651 </td><td style=\"text-align: right;\"> 0.0195491 </td><td style=\"text-align: right;\">-0.119501  </td><td style=\"text-align: right;\"> 0.53044  </td><td style=\"text-align: right;\">-0.208966  </td><td style=\"text-align: right;\">-0.0434626 </td><td style=\"text-align: right;\"> 0.335261  </td><td style=\"text-align: right;\">-0.0186331</td><td style=\"text-align: right;\">-0.197542 </td><td style=\"text-align: right;\"> 0.542854 </td><td style=\"text-align: right;\"> 0.431388 </td><td style=\"text-align: right;\">-0.0885179 </td><td style=\"text-align: right;\">-0.0761147 </td><td style=\"text-align: right;\"> 0.34833  </td><td style=\"text-align: right;\">-0.286945  </td><td style=\"text-align: right;\"> 0.121582 </td><td style=\"text-align: right;\"> 0.163274  </td><td style=\"text-align: right;\"> 0.202084  </td><td style=\"text-align: right;\"> 0.0408521  </td><td style=\"text-align: right;\">-0.0559559 </td><td style=\"text-align: right;\">-0.00372374</td><td style=\"text-align: right;\">-0.405219  </td><td style=\"text-align: right;\"> 0.0149087  </td><td style=\"text-align: right;\"> 0.191357  </td><td style=\"text-align: right;\">-0.0619767 </td><td style=\"text-align: right;\">-0.0499176  </td><td style=\"text-align: right;\"> 0.163253 </td><td style=\"text-align: right;\">-0.177005 </td><td style=\"text-align: right;\">-0.693782 </td><td style=\"text-align: right;\">-0.0374278 </td><td style=\"text-align: right;\">-0.000758044</td><td style=\"text-align: right;\"> 0.0458899 </td><td style=\"text-align: right;\"> 0.0892009 </td><td style=\"text-align: right;\">-0.0336944 </td><td style=\"text-align: right;\"> 0.027149  </td><td style=\"text-align: right;\">-0.236796  </td><td style=\"text-align: right;\"> 0.165388  </td><td style=\"text-align: right;\"> 0.328765  </td><td style=\"text-align: right;\">-0.420372  </td><td style=\"text-align: right;\">-0.0441485  </td><td style=\"text-align: right;\">-0.541111  </td><td style=\"text-align: right;\"> 0.364678  </td><td style=\"text-align: right;\">-0.200678  </td><td style=\"text-align: right;\">-0.325924 </td><td style=\"text-align: right;\"> 0.434868  </td><td style=\"text-align: right;\">-0.0713203</td><td style=\"text-align: right;\">-0.308079  </td><td style=\"text-align: right;\"> 0.546199  </td><td style=\"text-align: right;\"> 0.208701 </td><td style=\"text-align: right;\">-0.428515  </td><td style=\"text-align: right;\"> 0.3897   </td><td style=\"text-align: right;\">-0.268265  </td><td style=\"text-align: right;\"> 0.0722884  </td><td style=\"text-align: right;\">-0.242711  </td><td style=\"text-align: right;\">-0.154381  </td><td style=\"text-align: right;\">-0.478868 </td><td style=\"text-align: right;\"> 0.111516  </td><td style=\"text-align: right;\"> 0.110804  </td><td style=\"text-align: right;\"> 0.013939 </td><td style=\"text-align: right;\">-0.561829  </td><td style=\"text-align: right;\"> 0.421027  </td><td style=\"text-align: right;\"> 0.396893 </td><td style=\"text-align: right;\">-0.509855  </td><td style=\"text-align: right;\"> 0.0646768 </td><td style=\"text-align: right;\">-0.29089   </td><td style=\"text-align: right;\"> 0.16559  </td><td style=\"text-align: right;\">-0.521093  </td><td style=\"text-align: right;\"> 0.611326  </td><td style=\"text-align: right;\"> 0.237163  </td><td style=\"text-align: right;\"> 0.185881  </td><td style=\"text-align: right;\"> 0.254386  </td><td style=\"text-align: right;\"> 0.363215  </td><td style=\"text-align: right;\">-0.119303 </td><td style=\"text-align: right;\"> 0.496844  </td><td style=\"text-align: right;\"> 0.139088  </td><td style=\"text-align: right;\"> 0.331454  </td><td style=\"text-align: right;\"> 0.210057 </td><td style=\"text-align: right;\">-0.419926  </td><td style=\"text-align: right;\"> 0.236703 </td><td style=\"text-align: right;\">-0.185421  </td><td style=\"text-align: right;\"> 0.14139    </td><td style=\"text-align: right;\">-0.0706251  </td><td style=\"text-align: right;\">-0.118829  </td><td style=\"text-align: right;\"> 0.00907507</td><td style=\"text-align: right;\"> 0.220119  </td><td style=\"text-align: right;\"> 0.233469 </td><td style=\"text-align: right;\">-0.210597  </td><td style=\"text-align: right;\">-0.422977  </td><td style=\"text-align: right;\"> 0.278417 </td><td style=\"text-align: right;\">-0.125613  </td><td style=\"text-align: right;\">-0.117672   </td><td style=\"text-align: right;\"> 0.204266  </td><td style=\"text-align: right;\"> 0.100809  </td></tr>\n<tr><td>ERR067590 </td><td style=\"text-align: right;\"> -9.76658</td><td style=\"text-align: right;\">-5.5994 </td><td style=\"text-align: right;\">-3.89829e-05</td><td style=\"text-align: right;\"> 0.128426  </td><td style=\"text-align: right;\"> 0.275775</td><td style=\"text-align: right;\">-3.69459 </td><td style=\"text-align: right;\"> 0.934526</td><td style=\"text-align: right;\">-0.210841 </td><td style=\"text-align: right;\"> -0.167749</td><td style=\"text-align: right;\">  0.01654  </td><td style=\"text-align: right;\">-0.435993 </td><td style=\"text-align: right;\">-0.0865435</td><td style=\"text-align: right;\">-0.0988782</td><td style=\"text-align: right;\">-0.916727</td><td style=\"text-align: right;\">-1.00726  </td><td style=\"text-align: right;\">-0.965776</td><td style=\"text-align: right;\"> 0.394868 </td><td style=\"text-align: right;\"> 0.0572899</td><td style=\"text-align: right;\">-0.25157  </td><td style=\"text-align: right;\"> 0.346353</td><td style=\"text-align: right;\"> 0.402495</td><td style=\"text-align: right;\"> 0.564993 </td><td style=\"text-align: right;\"> 1.01356  </td><td style=\"text-align: right;\">-0.282266 </td><td style=\"text-align: right;\">-0.191537  </td><td style=\"text-align: right;\"> 0.143237 </td><td style=\"text-align: right;\"> 0.192089 </td><td style=\"text-align: right;\">-0.0401013 </td><td style=\"text-align: right;\"> 0.592642</td><td style=\"text-align: right;\"> 0.307771</td><td style=\"text-align: right;\">-0.210301  </td><td style=\"text-align: right;\"> 0.885181 </td><td style=\"text-align: right;\"> 0.623763 </td><td style=\"text-align: right;\">-1.24509  </td><td style=\"text-align: right;\"> 0.308801  </td><td style=\"text-align: right;\">-0.390058 </td><td style=\"text-align: right;\"> 0.0322479</td><td style=\"text-align: right;\">-0.378667 </td><td style=\"text-align: right;\">-0.171962 </td><td style=\"text-align: right;\">-0.388523  </td><td style=\"text-align: right;\">-0.203368  </td><td style=\"text-align: right;\"> 0.150018 </td><td style=\"text-align: right;\">-0.311775 </td><td style=\"text-align: right;\"> 0.716699 </td><td style=\"text-align: right;\">-0.34096  </td><td style=\"text-align: right;\">-0.123057 </td><td style=\"text-align: right;\"> 0.343106 </td><td style=\"text-align: right;\"> 0.0780912</td><td style=\"text-align: right;\"> 0.0999492</td><td style=\"text-align: right;\">-0.21739   </td><td style=\"text-align: right;\">-0.439137  </td><td style=\"text-align: right;\">-0.641553 </td><td style=\"text-align: right;\"> 0.63747   </td><td style=\"text-align: right;\"> 0.212651 </td><td style=\"text-align: right;\"> 0.00023834</td><td style=\"text-align: right;\"> 0.752072 </td><td style=\"text-align: right;\">-0.35732  </td><td style=\"text-align: right;\">-0.0844205</td><td style=\"text-align: right;\">-0.05655   </td><td style=\"text-align: right;\"> 0.486645  </td><td style=\"text-align: right;\">-0.144824 </td><td style=\"text-align: right;\"> 0.00930026</td><td style=\"text-align: right;\"> 0.509781 </td><td style=\"text-align: right;\"> 0.955677  </td><td style=\"text-align: right;\"> 0.156868 </td><td style=\"text-align: right;\"> 0.338637 </td><td style=\"text-align: right;\"> 0.235263  </td><td style=\"text-align: right;\"> 0.409853   </td><td style=\"text-align: right;\">-0.0224862 </td><td style=\"text-align: right;\"> 0.414458 </td><td style=\"text-align: right;\">-0.0496435</td><td style=\"text-align: right;\"> 0.25     </td><td style=\"text-align: right;\"> 0.0278119</td><td style=\"text-align: right;\"> 0.09181  </td><td style=\"text-align: right;\"> 0.325807  </td><td style=\"text-align: right;\"> 0.113944 </td><td style=\"text-align: right;\">-0.512569 </td><td style=\"text-align: right;\"> 0.211964  </td><td style=\"text-align: right;\">-0.40525  </td><td style=\"text-align: right;\">-0.00559174</td><td style=\"text-align: right;\">-0.335272 </td><td style=\"text-align: right;\">-0.0507388 </td><td style=\"text-align: right;\">-0.271236 </td><td style=\"text-align: right;\"> 0.506507  </td><td style=\"text-align: right;\">-0.0271158</td><td style=\"text-align: right;\"> 0.0993435 </td><td style=\"text-align: right;\">-0.264506   </td><td style=\"text-align: right;\"> 0.13633   </td><td style=\"text-align: right;\"> 0.0295806 </td><td style=\"text-align: right;\">-0.029975  </td><td style=\"text-align: right;\">-0.20447   </td><td style=\"text-align: right;\">-0.357801 </td><td style=\"text-align: right;\">-0.234231 </td><td style=\"text-align: right;\"> 0.271066 </td><td style=\"text-align: right;\"> 0.0340541 </td><td style=\"text-align: right;\"> 0.0197665</td><td style=\"text-align: right;\">-0.0858676</td><td style=\"text-align: right;\">-0.0685943</td><td style=\"text-align: right;\">-0.223353 </td><td style=\"text-align: right;\">-0.140029  </td><td style=\"text-align: right;\">-0.0177669</td><td style=\"text-align: right;\"> 0.13616   </td><td style=\"text-align: right;\">-0.0288363</td><td style=\"text-align: right;\">-0.144437 </td><td style=\"text-align: right;\">-0.216546 </td><td style=\"text-align: right;\">-0.481661 </td><td style=\"text-align: right;\">-0.241355  </td><td style=\"text-align: right;\"> 0.57967   </td><td style=\"text-align: right;\"> 0.381273  </td><td style=\"text-align: right;\"> 0.199381 </td><td style=\"text-align: right;\"> 0.0247126 </td><td style=\"text-align: right;\">-0.293661  </td><td style=\"text-align: right;\"> 0.0366443 </td><td style=\"text-align: right;\">-0.0894075</td><td style=\"text-align: right;\"> 0.284502 </td><td style=\"text-align: right;\"> 0.0516168</td><td style=\"text-align: right;\"> 0.392418 </td><td style=\"text-align: right;\"> 0.277646  </td><td style=\"text-align: right;\">-0.290867  </td><td style=\"text-align: right;\"> 0.181913 </td><td style=\"text-align: right;\">-0.253747  </td><td style=\"text-align: right;\">-0.172934 </td><td style=\"text-align: right;\"> 0.115745  </td><td style=\"text-align: right;\">-0.169049  </td><td style=\"text-align: right;\">-0.168836   </td><td style=\"text-align: right;\">-0.108469  </td><td style=\"text-align: right;\"> 0.060913  </td><td style=\"text-align: right;\"> 0.0477332 </td><td style=\"text-align: right;\"> 0.153886   </td><td style=\"text-align: right;\"> 0.17978   </td><td style=\"text-align: right;\">-0.390308  </td><td style=\"text-align: right;\">-0.000594149</td><td style=\"text-align: right;\">-0.0922742</td><td style=\"text-align: right;\"> 0.0948177</td><td style=\"text-align: right;\"> 0.1513   </td><td style=\"text-align: right;\"> 0.0629856 </td><td style=\"text-align: right;\">-0.0766572  </td><td style=\"text-align: right;\"> 0.0214414 </td><td style=\"text-align: right;\">-0.0950004 </td><td style=\"text-align: right;\"> 0.0877746 </td><td style=\"text-align: right;\"> 0.141019  </td><td style=\"text-align: right;\"> 0.0743689 </td><td style=\"text-align: right;\"> 0.0662412 </td><td style=\"text-align: right;\"> 0.520284  </td><td style=\"text-align: right;\">-0.303057  </td><td style=\"text-align: right;\"> 0.183541   </td><td style=\"text-align: right;\"> 0.166094  </td><td style=\"text-align: right;\"> 0.421861  </td><td style=\"text-align: right;\"> 0.136801  </td><td style=\"text-align: right;\">-0.11681  </td><td style=\"text-align: right;\">-0.163334  </td><td style=\"text-align: right;\">-0.0581083</td><td style=\"text-align: right;\">-0.158864  </td><td style=\"text-align: right;\"> 0.0991802 </td><td style=\"text-align: right;\">-0.157009 </td><td style=\"text-align: right;\"> 0.299469  </td><td style=\"text-align: right;\">-0.0443993</td><td style=\"text-align: right;\">-0.0668477 </td><td style=\"text-align: right;\">-0.0397008  </td><td style=\"text-align: right;\"> 0.0152228 </td><td style=\"text-align: right;\"> 0.0125098 </td><td style=\"text-align: right;\">-0.229027 </td><td style=\"text-align: right;\">-0.0256575 </td><td style=\"text-align: right;\">-0.152536  </td><td style=\"text-align: right;\"> 0.0809117</td><td style=\"text-align: right;\">-0.182133  </td><td style=\"text-align: right;\"> 0.0761649 </td><td style=\"text-align: right;\">-0.106114 </td><td style=\"text-align: right;\"> 0.112669  </td><td style=\"text-align: right;\"> 0.0769044 </td><td style=\"text-align: right;\"> 0.290035  </td><td style=\"text-align: right;\"> 0.082249 </td><td style=\"text-align: right;\">-0.161454  </td><td style=\"text-align: right;\">-0.23842   </td><td style=\"text-align: right;\"> 0.0490028 </td><td style=\"text-align: right;\"> 0.227777  </td><td style=\"text-align: right;\"> 0.0811296 </td><td style=\"text-align: right;\">-0.172135  </td><td style=\"text-align: right;\"> 0.198609 </td><td style=\"text-align: right;\">-0.048791  </td><td style=\"text-align: right;\"> 0.39733   </td><td style=\"text-align: right;\">-0.0440375 </td><td style=\"text-align: right;\">-0.302422 </td><td style=\"text-align: right;\"> 0.121435  </td><td style=\"text-align: right;\">-0.0814581</td><td style=\"text-align: right;\">-0.457707  </td><td style=\"text-align: right;\">-0.111481   </td><td style=\"text-align: right;\"> 0.157116   </td><td style=\"text-align: right;\">-0.261661  </td><td style=\"text-align: right;\">-0.0290202 </td><td style=\"text-align: right;\">-0.0832653 </td><td style=\"text-align: right;\">-0.15217  </td><td style=\"text-align: right;\"> 0.346027  </td><td style=\"text-align: right;\">-0.12647   </td><td style=\"text-align: right;\"> 0.101427 </td><td style=\"text-align: right;\">-0.0278872 </td><td style=\"text-align: right;\"> 0.0469565  </td><td style=\"text-align: right;\">-0.0606447 </td><td style=\"text-align: right;\"> 0.0924889 </td></tr>\n<tr><td>ERR688027 </td><td style=\"text-align: right;\"> -6.8708 </td><td style=\"text-align: right;\"> 2.68057</td><td style=\"text-align: right;\">-0.0355698  </td><td style=\"text-align: right;\">-0.699036  </td><td style=\"text-align: right;\"> 0.736729</td><td style=\"text-align: right;\"> 0.257921</td><td style=\"text-align: right;\"> 3.02569 </td><td style=\"text-align: right;\"> 1.1828   </td><td style=\"text-align: right;\">  0.413017</td><td style=\"text-align: right;\">  1.53433  </td><td style=\"text-align: right;\"> 5.12066  </td><td style=\"text-align: right;\">-1.7532   </td><td style=\"text-align: right;\">-0.738115 </td><td style=\"text-align: right;\">-2.14663 </td><td style=\"text-align: right;\">-0.683129 </td><td style=\"text-align: right;\">-0.654376</td><td style=\"text-align: right;\">-0.61325  </td><td style=\"text-align: right;\"> 0.185093 </td><td style=\"text-align: right;\"> 0.415841 </td><td style=\"text-align: right;\">-0.534862</td><td style=\"text-align: right;\">-0.220786</td><td style=\"text-align: right;\"> 1.42245  </td><td style=\"text-align: right;\"> 0.176689 </td><td style=\"text-align: right;\"> 0.0192469</td><td style=\"text-align: right;\"> 0.396607  </td><td style=\"text-align: right;\">-0.005357 </td><td style=\"text-align: right;\"> 1.40927  </td><td style=\"text-align: right;\">-0.0209309 </td><td style=\"text-align: right;\">-1.71154 </td><td style=\"text-align: right;\">-0.270967</td><td style=\"text-align: right;\"> 0.503112  </td><td style=\"text-align: right;\">-0.453672 </td><td style=\"text-align: right;\">-0.834217 </td><td style=\"text-align: right;\"> 1.10271  </td><td style=\"text-align: right;\"> 0.392462  </td><td style=\"text-align: right;\"> 1.47327  </td><td style=\"text-align: right;\"> 0.559773 </td><td style=\"text-align: right;\">-1.06503  </td><td style=\"text-align: right;\">-0.155041 </td><td style=\"text-align: right;\">-0.281089  </td><td style=\"text-align: right;\"> 0.336117  </td><td style=\"text-align: right;\"> 0.527712 </td><td style=\"text-align: right;\">-0.547592 </td><td style=\"text-align: right;\"> 0.625531 </td><td style=\"text-align: right;\">-0.584138 </td><td style=\"text-align: right;\">-0.408617 </td><td style=\"text-align: right;\"> 0.212724 </td><td style=\"text-align: right;\">-1.05129  </td><td style=\"text-align: right;\"> 0.307422 </td><td style=\"text-align: right;\"> 0.597414  </td><td style=\"text-align: right;\"> 0.308627  </td><td style=\"text-align: right;\"> 0.0839721</td><td style=\"text-align: right;\"> 1.0917    </td><td style=\"text-align: right;\">-0.797267 </td><td style=\"text-align: right;\"> 0.0857386 </td><td style=\"text-align: right;\"> 0.0500546</td><td style=\"text-align: right;\">-0.187399 </td><td style=\"text-align: right;\"> 0.159411 </td><td style=\"text-align: right;\">-0.0430745 </td><td style=\"text-align: right;\"> 0.0136178 </td><td style=\"text-align: right;\"> 0.29476  </td><td style=\"text-align: right;\">-0.168814  </td><td style=\"text-align: right;\">-0.2206   </td><td style=\"text-align: right;\"> 0.0783109 </td><td style=\"text-align: right;\">-0.132235 </td><td style=\"text-align: right;\"> 0.220012 </td><td style=\"text-align: right;\">-0.188318  </td><td style=\"text-align: right;\"> 0.24743    </td><td style=\"text-align: right;\"> 0.464853  </td><td style=\"text-align: right;\"> 0.0383091</td><td style=\"text-align: right;\">-0.686787 </td><td style=\"text-align: right;\"> 0.111268 </td><td style=\"text-align: right;\"> 0.0162829</td><td style=\"text-align: right;\"> 0.325926 </td><td style=\"text-align: right;\">-0.0904145 </td><td style=\"text-align: right;\"> 0.465747 </td><td style=\"text-align: right;\">-0.016556 </td><td style=\"text-align: right;\">-0.15027   </td><td style=\"text-align: right;\"> 0.207866 </td><td style=\"text-align: right;\"> 0.572747  </td><td style=\"text-align: right;\">-0.0418297</td><td style=\"text-align: right;\">-0.545091  </td><td style=\"text-align: right;\">-0.173507 </td><td style=\"text-align: right;\"> 0.15963   </td><td style=\"text-align: right;\"> 0.1852   </td><td style=\"text-align: right;\"> 0.314861  </td><td style=\"text-align: right;\">-0.299225   </td><td style=\"text-align: right;\"> 0.0272655 </td><td style=\"text-align: right;\">-0.134234  </td><td style=\"text-align: right;\"> 0.0170405 </td><td style=\"text-align: right;\"> 0.336794  </td><td style=\"text-align: right;\"> 0.288353 </td><td style=\"text-align: right;\">-0.139473 </td><td style=\"text-align: right;\"> 0.166308 </td><td style=\"text-align: right;\">-0.121751  </td><td style=\"text-align: right;\">-0.161998 </td><td style=\"text-align: right;\"> 0.0468824</td><td style=\"text-align: right;\">-0.132319 </td><td style=\"text-align: right;\"> 0.138868 </td><td style=\"text-align: right;\"> 0.0860348 </td><td style=\"text-align: right;\"> 0.200801 </td><td style=\"text-align: right;\"> 0.107458  </td><td style=\"text-align: right;\">-0.21358  </td><td style=\"text-align: right;\">-0.106988 </td><td style=\"text-align: right;\">-0.633656 </td><td style=\"text-align: right;\"> 0.121946 </td><td style=\"text-align: right;\">-0.123863  </td><td style=\"text-align: right;\">-0.320828  </td><td style=\"text-align: right;\">-0.344134  </td><td style=\"text-align: right;\"> 0.251929 </td><td style=\"text-align: right;\"> 0.0805143 </td><td style=\"text-align: right;\">-0.221949  </td><td style=\"text-align: right;\">-0.180121  </td><td style=\"text-align: right;\">-0.120502 </td><td style=\"text-align: right;\">-0.22436  </td><td style=\"text-align: right;\"> 0.204527 </td><td style=\"text-align: right;\"> 0.521209 </td><td style=\"text-align: right;\">-0.0929853 </td><td style=\"text-align: right;\">-0.116271  </td><td style=\"text-align: right;\"> 0.0938814</td><td style=\"text-align: right;\">-0.0186209 </td><td style=\"text-align: right;\">-0.122752 </td><td style=\"text-align: right;\">-0.0490904 </td><td style=\"text-align: right;\"> 0.221927  </td><td style=\"text-align: right;\"> 0.0744466  </td><td style=\"text-align: right;\"> 0.122014  </td><td style=\"text-align: right;\">-0.073049  </td><td style=\"text-align: right;\">-0.115816  </td><td style=\"text-align: right;\"> 0.0574372  </td><td style=\"text-align: right;\"> 0.277756  </td><td style=\"text-align: right;\">-0.00358919</td><td style=\"text-align: right;\"> 0.0481752  </td><td style=\"text-align: right;\">-0.341583 </td><td style=\"text-align: right;\"> 0.250432 </td><td style=\"text-align: right;\"> 0.0920894</td><td style=\"text-align: right;\"> 0.10257   </td><td style=\"text-align: right;\">-0.113817   </td><td style=\"text-align: right;\"> 0.10745   </td><td style=\"text-align: right;\"> 0.176046  </td><td style=\"text-align: right;\">-0.149467  </td><td style=\"text-align: right;\">-0.0509981 </td><td style=\"text-align: right;\"> 0.024196  </td><td style=\"text-align: right;\"> 0.00076316</td><td style=\"text-align: right;\">-0.0449122 </td><td style=\"text-align: right;\"> 0.091909  </td><td style=\"text-align: right;\">-0.0479243  </td><td style=\"text-align: right;\"> 0.214462  </td><td style=\"text-align: right;\"> 0.13844   </td><td style=\"text-align: right;\">-0.240763  </td><td style=\"text-align: right;\"> 0.269624 </td><td style=\"text-align: right;\">-0.194052  </td><td style=\"text-align: right;\">-0.209013 </td><td style=\"text-align: right;\"> 0.113906  </td><td style=\"text-align: right;\">-0.194578  </td><td style=\"text-align: right;\"> 0.140454 </td><td style=\"text-align: right;\">-0.1064    </td><td style=\"text-align: right;\">-0.581816 </td><td style=\"text-align: right;\">-0.131183  </td><td style=\"text-align: right;\">-0.349921   </td><td style=\"text-align: right;\">-0.168237  </td><td style=\"text-align: right;\">-0.0816458 </td><td style=\"text-align: right;\">-0.226236 </td><td style=\"text-align: right;\"> 0.150529  </td><td style=\"text-align: right;\"> 0.274294  </td><td style=\"text-align: right;\">-0.165284 </td><td style=\"text-align: right;\"> 0.00747436</td><td style=\"text-align: right;\">-0.0591628 </td><td style=\"text-align: right;\"> 0.0272055</td><td style=\"text-align: right;\">-0.0140462 </td><td style=\"text-align: right;\"> 0.0427684 </td><td style=\"text-align: right;\">-0.16886   </td><td style=\"text-align: right;\">-0.0207045</td><td style=\"text-align: right;\"> 0.186032  </td><td style=\"text-align: right;\">-0.264496  </td><td style=\"text-align: right;\"> 0.177216  </td><td style=\"text-align: right;\">-0.00905544</td><td style=\"text-align: right;\"> 0.0825891 </td><td style=\"text-align: right;\"> 0.246186  </td><td style=\"text-align: right;\"> 0.111854 </td><td style=\"text-align: right;\"> 0.448187  </td><td style=\"text-align: right;\"> 0.0607458 </td><td style=\"text-align: right;\">-0.189043  </td><td style=\"text-align: right;\"> 0.0269027</td><td style=\"text-align: right;\"> 0.299077  </td><td style=\"text-align: right;\">-0.141073 </td><td style=\"text-align: right;\">-0.0316477 </td><td style=\"text-align: right;\"> 0.048967   </td><td style=\"text-align: right;\"> 0.270196   </td><td style=\"text-align: right;\">-0.204264  </td><td style=\"text-align: right;\">-0.0493952 </td><td style=\"text-align: right;\">-0.116593  </td><td style=\"text-align: right;\"> 0.0616901</td><td style=\"text-align: right;\"> 0.229456  </td><td style=\"text-align: right;\"> 0.0879137 </td><td style=\"text-align: right;\">-0.0471718</td><td style=\"text-align: right;\">-0.0450974 </td><td style=\"text-align: right;\">-0.34514    </td><td style=\"text-align: right;\">-0.115519  </td><td style=\"text-align: right;\"> 0.108102  </td></tr>\n<tr><td>ERR3335727</td><td style=\"text-align: right;\"> -9.7002 </td><td style=\"text-align: right;\"> 2.01993</td><td style=\"text-align: right;\">-0.0419022  </td><td style=\"text-align: right;\">-1.78693   </td><td style=\"text-align: right;\">-0.868938</td><td style=\"text-align: right;\"> 4.90576 </td><td style=\"text-align: right;\"> 3.07665 </td><td style=\"text-align: right;\"> 1.46937  </td><td style=\"text-align: right;\">  0.497968</td><td style=\"text-align: right;\">  2.8248   </td><td style=\"text-align: right;\"> 4.23813  </td><td style=\"text-align: right;\">-0.6334   </td><td style=\"text-align: right;\"> 1.22995  </td><td style=\"text-align: right;\">-1.28486 </td><td style=\"text-align: right;\"> 1.02514  </td><td style=\"text-align: right;\">-0.576321</td><td style=\"text-align: right;\"> 1.38022  </td><td style=\"text-align: right;\"> 1.20001  </td><td style=\"text-align: right;\"> 0.389443 </td><td style=\"text-align: right;\">-1.77273 </td><td style=\"text-align: right;\">-1.24207 </td><td style=\"text-align: right;\"> 1.16477  </td><td style=\"text-align: right;\"> 0.697286 </td><td style=\"text-align: right;\">-0.368327 </td><td style=\"text-align: right;\">-0.00249318</td><td style=\"text-align: right;\">-0.127154 </td><td style=\"text-align: right;\">-0.250148 </td><td style=\"text-align: right;\"> 0.0167133 </td><td style=\"text-align: right;\"> 0.617982</td><td style=\"text-align: right;\"> 0.592714</td><td style=\"text-align: right;\">-0.570079  </td><td style=\"text-align: right;\">-0.0316759</td><td style=\"text-align: right;\"> 0.315347 </td><td style=\"text-align: right;\">-0.637864 </td><td style=\"text-align: right;\"> 0.943744  </td><td style=\"text-align: right;\">-0.95563  </td><td style=\"text-align: right;\"> 0.0187535</td><td style=\"text-align: right;\"> 0.840864 </td><td style=\"text-align: right;\"> 0.614452 </td><td style=\"text-align: right;\"> 0.703567  </td><td style=\"text-align: right;\"> 0.732973  </td><td style=\"text-align: right;\">-0.135743 </td><td style=\"text-align: right;\"> 0.614975 </td><td style=\"text-align: right;\">-0.575716 </td><td style=\"text-align: right;\">-0.0218175</td><td style=\"text-align: right;\"> 0.879477 </td><td style=\"text-align: right;\">-0.0555101</td><td style=\"text-align: right;\"> 0.987613 </td><td style=\"text-align: right;\"> 0.5341   </td><td style=\"text-align: right;\"> 0.544382  </td><td style=\"text-align: right;\"> 0.144836  </td><td style=\"text-align: right;\">-0.530193 </td><td style=\"text-align: right;\"> 0.55032   </td><td style=\"text-align: right;\"> 0.189941 </td><td style=\"text-align: right;\"> 0.568939  </td><td style=\"text-align: right;\"> 0.555888 </td><td style=\"text-align: right;\">-1.45468  </td><td style=\"text-align: right;\"> 0.100443 </td><td style=\"text-align: right;\"> 0.243123  </td><td style=\"text-align: right;\">-0.106879  </td><td style=\"text-align: right;\">-0.545287 </td><td style=\"text-align: right;\"> 0.300738  </td><td style=\"text-align: right;\"> 0.213071 </td><td style=\"text-align: right;\"> 0.418881  </td><td style=\"text-align: right;\"> 0.230577 </td><td style=\"text-align: right;\">-0.797578 </td><td style=\"text-align: right;\"> 0.00839976</td><td style=\"text-align: right;\">-0.514347   </td><td style=\"text-align: right;\">-0.397928  </td><td style=\"text-align: right;\"> 0.251805 </td><td style=\"text-align: right;\"> 0.0655922</td><td style=\"text-align: right;\">-0.284184 </td><td style=\"text-align: right;\">-0.244452 </td><td style=\"text-align: right;\"> 0.0890336</td><td style=\"text-align: right;\">-0.235954  </td><td style=\"text-align: right;\"> 0.0687547</td><td style=\"text-align: right;\"> 0.59685  </td><td style=\"text-align: right;\">-0.381562  </td><td style=\"text-align: right;\"> 0.217461 </td><td style=\"text-align: right;\">-0.115784  </td><td style=\"text-align: right;\">-0.220976 </td><td style=\"text-align: right;\"> 0.135589  </td><td style=\"text-align: right;\"> 0.380991 </td><td style=\"text-align: right;\">-0.376626  </td><td style=\"text-align: right;\"> 0.153256 </td><td style=\"text-align: right;\"> 0.124564  </td><td style=\"text-align: right;\">-0.0237586  </td><td style=\"text-align: right;\"> 0.156169  </td><td style=\"text-align: right;\">-0.0594366 </td><td style=\"text-align: right;\"> 0.0874143 </td><td style=\"text-align: right;\">-0.296594  </td><td style=\"text-align: right;\">-0.0797775</td><td style=\"text-align: right;\"> 0.115377 </td><td style=\"text-align: right;\">-0.17258  </td><td style=\"text-align: right;\">-0.20333   </td><td style=\"text-align: right;\">-0.390256 </td><td style=\"text-align: right;\"> 0.61364  </td><td style=\"text-align: right;\"> 0.208968 </td><td style=\"text-align: right;\"> 0.196587 </td><td style=\"text-align: right;\"> 0.462276  </td><td style=\"text-align: right;\">-0.519164 </td><td style=\"text-align: right;\"> 0.158059  </td><td style=\"text-align: right;\"> 0.155647 </td><td style=\"text-align: right;\">-0.12425  </td><td style=\"text-align: right;\"> 0.0731028</td><td style=\"text-align: right;\"> 0.142651 </td><td style=\"text-align: right;\">-0.130596  </td><td style=\"text-align: right;\"> 0.217428  </td><td style=\"text-align: right;\"> 0.325612  </td><td style=\"text-align: right;\"> 0.215072 </td><td style=\"text-align: right;\">-0.101754  </td><td style=\"text-align: right;\">-0.514854  </td><td style=\"text-align: right;\"> 0.0425049 </td><td style=\"text-align: right;\"> 0.430603 </td><td style=\"text-align: right;\">-0.568491 </td><td style=\"text-align: right;\">-0.265812 </td><td style=\"text-align: right;\">-0.560729 </td><td style=\"text-align: right;\"> 0.140233  </td><td style=\"text-align: right;\">-0.331596  </td><td style=\"text-align: right;\"> 0.399495 </td><td style=\"text-align: right;\"> 0.0114895 </td><td style=\"text-align: right;\">-0.380821 </td><td style=\"text-align: right;\"> 0.0857853 </td><td style=\"text-align: right;\"> 0.476789  </td><td style=\"text-align: right;\"> 0.117023   </td><td style=\"text-align: right;\"> 0.0347636 </td><td style=\"text-align: right;\">-0.321351  </td><td style=\"text-align: right;\"> 0.0941885 </td><td style=\"text-align: right;\">-0.13162    </td><td style=\"text-align: right;\">-0.303511  </td><td style=\"text-align: right;\">-0.215142  </td><td style=\"text-align: right;\">-0.122692   </td><td style=\"text-align: right;\"> 0.898417 </td><td style=\"text-align: right;\">-0.0212619</td><td style=\"text-align: right;\">-0.231751 </td><td style=\"text-align: right;\"> 0.00636333</td><td style=\"text-align: right;\">-0.107066   </td><td style=\"text-align: right;\">-0.302672  </td><td style=\"text-align: right;\"> 0.21904   </td><td style=\"text-align: right;\">-0.264316  </td><td style=\"text-align: right;\">-0.114049  </td><td style=\"text-align: right;\">-0.359548  </td><td style=\"text-align: right;\"> 0.043984  </td><td style=\"text-align: right;\">-0.417547  </td><td style=\"text-align: right;\">-0.0733333 </td><td style=\"text-align: right;\"> 0.219099   </td><td style=\"text-align: right;\"> 0.00445267</td><td style=\"text-align: right;\">-0.24492   </td><td style=\"text-align: right;\">-0.00254248</td><td style=\"text-align: right;\"> 0.270459 </td><td style=\"text-align: right;\"> 0.258728  </td><td style=\"text-align: right;\"> 0.0124197</td><td style=\"text-align: right;\"> 0.0574718 </td><td style=\"text-align: right;\"> 0.118086  </td><td style=\"text-align: right;\"> 0.100874 </td><td style=\"text-align: right;\">-0.287752  </td><td style=\"text-align: right;\"> 0.216107 </td><td style=\"text-align: right;\">-0.524942  </td><td style=\"text-align: right;\">-0.188604   </td><td style=\"text-align: right;\"> 0.222052  </td><td style=\"text-align: right;\">-0.288676  </td><td style=\"text-align: right;\"> 0.0389674</td><td style=\"text-align: right;\">-0.039381  </td><td style=\"text-align: right;\">-0.0241603 </td><td style=\"text-align: right;\"> 0.131161 </td><td style=\"text-align: right;\"> 0.149168  </td><td style=\"text-align: right;\">-0.50884   </td><td style=\"text-align: right;\"> 0.314479 </td><td style=\"text-align: right;\"> 0.325975  </td><td style=\"text-align: right;\">-0.0304763 </td><td style=\"text-align: right;\"> 0.597556  </td><td style=\"text-align: right;\">-0.0751168</td><td style=\"text-align: right;\"> 0.285042  </td><td style=\"text-align: right;\"> 0.404374  </td><td style=\"text-align: right;\"> 0.340443  </td><td style=\"text-align: right;\">-0.246579  </td><td style=\"text-align: right;\"> 0.248091  </td><td style=\"text-align: right;\"> 0.225155  </td><td style=\"text-align: right;\">-0.158595 </td><td style=\"text-align: right;\">-0.219442  </td><td style=\"text-align: right;\">-0.00982387</td><td style=\"text-align: right;\">-0.0913876 </td><td style=\"text-align: right;\"> 0.116182 </td><td style=\"text-align: right;\"> 0.0220935 </td><td style=\"text-align: right;\">-0.179899 </td><td style=\"text-align: right;\"> 0.118903  </td><td style=\"text-align: right;\"> 0.164548   </td><td style=\"text-align: right;\">-0.103457   </td><td style=\"text-align: right;\">-0.324     </td><td style=\"text-align: right;\">-0.194148  </td><td style=\"text-align: right;\"> 0.205753  </td><td style=\"text-align: right;\"> 0.277896 </td><td style=\"text-align: right;\">-0.429106  </td><td style=\"text-align: right;\"> 0.325799  </td><td style=\"text-align: right;\">-0.452503 </td><td style=\"text-align: right;\">-0.35914   </td><td style=\"text-align: right;\"> 0.0457975  </td><td style=\"text-align: right;\">-0.103766  </td><td style=\"text-align: right;\">-0.226946  </td></tr>\n<tr><td>ERR3335759</td><td style=\"text-align: right;\"> -8.54219</td><td style=\"text-align: right;\"> 1.20221</td><td style=\"text-align: right;\">-0.0337894  </td><td style=\"text-align: right;\">-1.70933   </td><td style=\"text-align: right;\">-1.31788 </td><td style=\"text-align: right;\"> 4.43432 </td><td style=\"text-align: right;\"> 2.78561 </td><td style=\"text-align: right;\"> 1.62459  </td><td style=\"text-align: right;\">  0.844757</td><td style=\"text-align: right;\">  1.30749  </td><td style=\"text-align: right;\"> 3.03594  </td><td style=\"text-align: right;\">-0.389582 </td><td style=\"text-align: right;\"> 1.38847  </td><td style=\"text-align: right;\">-0.790943</td><td style=\"text-align: right;\"> 0.411406 </td><td style=\"text-align: right;\">-0.215496</td><td style=\"text-align: right;\"> 0.0373483</td><td style=\"text-align: right;\"> 0.888375 </td><td style=\"text-align: right;\"> 0.217075 </td><td style=\"text-align: right;\">-1.25865 </td><td style=\"text-align: right;\">-0.840179</td><td style=\"text-align: right;\"> 0.762913 </td><td style=\"text-align: right;\"> 0.464845 </td><td style=\"text-align: right;\">-0.653663 </td><td style=\"text-align: right;\">-0.140936  </td><td style=\"text-align: right;\">-0.0993573</td><td style=\"text-align: right;\"> 0.698259 </td><td style=\"text-align: right;\">-0.0461487 </td><td style=\"text-align: right;\"> 0.244734</td><td style=\"text-align: right;\">-0.219995</td><td style=\"text-align: right;\"> 0.0686529 </td><td style=\"text-align: right;\">-0.408289 </td><td style=\"text-align: right;\">-0.0627849</td><td style=\"text-align: right;\">-0.532491 </td><td style=\"text-align: right;\"> 1.05035   </td><td style=\"text-align: right;\">-0.830271 </td><td style=\"text-align: right;\">-0.37178  </td><td style=\"text-align: right;\"> 0.551295 </td><td style=\"text-align: right;\">-0.0337151</td><td style=\"text-align: right;\"> 0.0254299 </td><td style=\"text-align: right;\">-0.739716  </td><td style=\"text-align: right;\">-0.237236 </td><td style=\"text-align: right;\">-0.268804 </td><td style=\"text-align: right;\"> 0.0528469</td><td style=\"text-align: right;\"> 0.253406 </td><td style=\"text-align: right;\">-0.314882 </td><td style=\"text-align: right;\"> 0.63836  </td><td style=\"text-align: right;\"> 0.479703 </td><td style=\"text-align: right;\">-0.512762 </td><td style=\"text-align: right;\"> 0.00980382</td><td style=\"text-align: right;\"> 0.0365693 </td><td style=\"text-align: right;\"> 0.283264 </td><td style=\"text-align: right;\"> 0.385486  </td><td style=\"text-align: right;\"> 0.844663 </td><td style=\"text-align: right;\">-0.722482  </td><td style=\"text-align: right;\"> 0.389155 </td><td style=\"text-align: right;\"> 0.518976 </td><td style=\"text-align: right;\"> 0.140026 </td><td style=\"text-align: right;\"> 0.367951  </td><td style=\"text-align: right;\"> 0.0578155 </td><td style=\"text-align: right;\">-0.237808 </td><td style=\"text-align: right;\"> 0.726078  </td><td style=\"text-align: right;\"> 0.0794338</td><td style=\"text-align: right;\">-0.396036  </td><td style=\"text-align: right;\"> 0.223692 </td><td style=\"text-align: right;\"> 0.564151 </td><td style=\"text-align: right;\"> 0.0105188 </td><td style=\"text-align: right;\">-0.751705   </td><td style=\"text-align: right;\">-0.127846  </td><td style=\"text-align: right;\"> 0.0994481</td><td style=\"text-align: right;\">-0.601196 </td><td style=\"text-align: right;\">-0.17901  </td><td style=\"text-align: right;\">-0.440456 </td><td style=\"text-align: right;\">-0.424434 </td><td style=\"text-align: right;\">-0.0342483 </td><td style=\"text-align: right;\">-0.281859 </td><td style=\"text-align: right;\"> 0.235901 </td><td style=\"text-align: right;\"> 0.18012   </td><td style=\"text-align: right;\"> 0.360096 </td><td style=\"text-align: right;\">-0.317282  </td><td style=\"text-align: right;\">-0.0694499</td><td style=\"text-align: right;\">-0.363567  </td><td style=\"text-align: right;\">-0.116735 </td><td style=\"text-align: right;\"> 0.340759  </td><td style=\"text-align: right;\">-0.673291 </td><td style=\"text-align: right;\"> 0.884106  </td><td style=\"text-align: right;\"> 0.606648   </td><td style=\"text-align: right;\"> 0.294978  </td><td style=\"text-align: right;\"> 0.175188  </td><td style=\"text-align: right;\">-0.245768  </td><td style=\"text-align: right;\"> 0.269212  </td><td style=\"text-align: right;\">-0.0200029</td><td style=\"text-align: right;\"> 0.124079 </td><td style=\"text-align: right;\"> 0.0252647</td><td style=\"text-align: right;\"> 0.21792   </td><td style=\"text-align: right;\"> 0.409602 </td><td style=\"text-align: right;\">-0.589638 </td><td style=\"text-align: right;\">-0.327337 </td><td style=\"text-align: right;\">-0.0520886</td><td style=\"text-align: right;\"> 0.411777  </td><td style=\"text-align: right;\"> 0.09315  </td><td style=\"text-align: right;\">-0.143922  </td><td style=\"text-align: right;\"> 0.38183  </td><td style=\"text-align: right;\"> 0.0916742</td><td style=\"text-align: right;\"> 0.201024 </td><td style=\"text-align: right;\">-0.10852  </td><td style=\"text-align: right;\"> 0.320168  </td><td style=\"text-align: right;\">-0.259112  </td><td style=\"text-align: right;\"> 0.39255   </td><td style=\"text-align: right;\">-0.172737 </td><td style=\"text-align: right;\"> 0.371132  </td><td style=\"text-align: right;\"> 0.460941  </td><td style=\"text-align: right;\">-0.0133471 </td><td style=\"text-align: right;\">-0.238938 </td><td style=\"text-align: right;\">-0.226956 </td><td style=\"text-align: right;\"> 0.297199 </td><td style=\"text-align: right;\">-0.314315 </td><td style=\"text-align: right;\"> 0.165405  </td><td style=\"text-align: right;\"> 0.0842257 </td><td style=\"text-align: right;\">-0.400583 </td><td style=\"text-align: right;\"> 0.151181  </td><td style=\"text-align: right;\"> 0.346786 </td><td style=\"text-align: right;\"> 0.275771  </td><td style=\"text-align: right;\">-0.433518  </td><td style=\"text-align: right;\">-0.234866   </td><td style=\"text-align: right;\">-0.367062  </td><td style=\"text-align: right;\"> 0.214556  </td><td style=\"text-align: right;\">-0.620324  </td><td style=\"text-align: right;\">-0.284036   </td><td style=\"text-align: right;\"> 0.230501  </td><td style=\"text-align: right;\"> 0.0543145 </td><td style=\"text-align: right;\"> 0.110878   </td><td style=\"text-align: right;\">-0.602834 </td><td style=\"text-align: right;\"> 0.455412 </td><td style=\"text-align: right;\"> 0.325825 </td><td style=\"text-align: right;\">-0.0291731 </td><td style=\"text-align: right;\"> 0.4177     </td><td style=\"text-align: right;\">-0.0487769 </td><td style=\"text-align: right;\"> 0.719916  </td><td style=\"text-align: right;\"> 0.091659  </td><td style=\"text-align: right;\">-0.0373595 </td><td style=\"text-align: right;\"> 0.0773591 </td><td style=\"text-align: right;\">-0.135434  </td><td style=\"text-align: right;\"> 0.0181273 </td><td style=\"text-align: right;\"> 0.0261117 </td><td style=\"text-align: right;\"> 0.14644    </td><td style=\"text-align: right;\">-0.0933808 </td><td style=\"text-align: right;\"> 0.105142  </td><td style=\"text-align: right;\"> 0.24001   </td><td style=\"text-align: right;\"> 0.0931343</td><td style=\"text-align: right;\"> 0.0627232 </td><td style=\"text-align: right;\"> 0.101432 </td><td style=\"text-align: right;\">-0.11545   </td><td style=\"text-align: right;\"> 0.102735  </td><td style=\"text-align: right;\">-0.0011381</td><td style=\"text-align: right;\"> 0.520417  </td><td style=\"text-align: right;\">-0.0511215</td><td style=\"text-align: right;\"> 0.347643  </td><td style=\"text-align: right;\"> 0.156714   </td><td style=\"text-align: right;\">-0.248581  </td><td style=\"text-align: right;\">-0.213454  </td><td style=\"text-align: right;\">-0.277386 </td><td style=\"text-align: right;\"> 0.193475  </td><td style=\"text-align: right;\"> 0.0239697 </td><td style=\"text-align: right;\"> 0.345145 </td><td style=\"text-align: right;\">-0.284584  </td><td style=\"text-align: right;\">-0.189322  </td><td style=\"text-align: right;\">-0.287148 </td><td style=\"text-align: right;\">-0.207969  </td><td style=\"text-align: right;\">-0.202163  </td><td style=\"text-align: right;\">-0.0796535 </td><td style=\"text-align: right;\">-0.105895 </td><td style=\"text-align: right;\">-0.229858  </td><td style=\"text-align: right;\">-0.236454  </td><td style=\"text-align: right;\">-0.246952  </td><td style=\"text-align: right;\"> 0.103366  </td><td style=\"text-align: right;\">-0.0597777 </td><td style=\"text-align: right;\">-0.110702  </td><td style=\"text-align: right;\"> 0.254327 </td><td style=\"text-align: right;\"> 0.00290837</td><td style=\"text-align: right;\"> 0.111981  </td><td style=\"text-align: right;\">-0.240961  </td><td style=\"text-align: right;\"> 0.0804205</td><td style=\"text-align: right;\">-0.203052  </td><td style=\"text-align: right;\"> 0.291348 </td><td style=\"text-align: right;\"> 0.380352  </td><td style=\"text-align: right;\"> 0.339571   </td><td style=\"text-align: right;\">-0.166293   </td><td style=\"text-align: right;\">-0.205874  </td><td style=\"text-align: right;\">-0.10269   </td><td style=\"text-align: right;\">-0.173863  </td><td style=\"text-align: right;\">-0.411589 </td><td style=\"text-align: right;\"> 0.0428641 </td><td style=\"text-align: right;\">-0.0847032 </td><td style=\"text-align: right;\"> 0.371689 </td><td style=\"text-align: right;\">-0.238893  </td><td style=\"text-align: right;\"> 0.530464   </td><td style=\"text-align: right;\"> 0.244679  </td><td style=\"text-align: right;\"> 0.389905  </td></tr>\n</tbody>\n</table>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 43,
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "execution_count": 43,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605467955506
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model development with the transformed PCA datasets"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_col = 'SampleID'\r\n",
        "nfolds = 5\r\n",
        "\r\n",
        "# Identify predictors and response columns\r\n",
        "predictor_cols = train_pca_df_frame.columns\r\n",
        "response_col = \"Resistance_Status\"\r\n",
        "\r\n",
        "predictor_cols.remove(response_col)\r\n"
      ],
      "outputs": [],
      "execution_count": 44,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605467959017
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For binary classification, response should be a factor\r\n",
        "train_pca_df_frame[response_col] = train_pca_df_frame[response_col].asfactor()\r\n",
        "test_pca_df_frame[response_col] = test_pca_df_frame[response_col].asfactor()\r\n",
        "\r\n",
        "x = predictor_cols\r\n",
        "y = response_col"
      ],
      "outputs": [],
      "execution_count": 45,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605467961005
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML models on transformed data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from h2o.automl import H2OAutoML\r\n",
        "\r\n",
        "# Run AutoML for 20 base models (limited to 1 hour max runtime by default)\r\n",
        "aml = H2OAutoML(max_models=20, seed=1234, stopping_metric= 'AUTO')\r\n",
        "aml.train(x=x, y=y, training_frame=train_pca_df_frame)\r\n",
        "\r\n",
        "# View the AutoML Leaderboard\r\n",
        "lb = aml.leaderboard\r\n",
        "lb.head(rows=lb.nrows)   \r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<table>\n<thead>\n<tr><th>model_id                                           </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th></tr>\n</thead>\n<tbody>\n<tr><td>StackedEnsemble_BestOfFamily_AutoML_20201108_044243</td><td style=\"text-align: right;\">0.898379</td><td style=\"text-align: right;\"> 0.385515</td><td style=\"text-align: right;\">0.939439</td><td style=\"text-align: right;\">              0.201463</td><td style=\"text-align: right;\">0.345492</td><td style=\"text-align: right;\">0.119365</td></tr>\n<tr><td>StackedEnsemble_AllModels_AutoML_20201108_044243   </td><td style=\"text-align: right;\">0.897125</td><td style=\"text-align: right;\"> 0.389261</td><td style=\"text-align: right;\">0.93964 </td><td style=\"text-align: right;\">              0.194425</td><td style=\"text-align: right;\">0.347953</td><td style=\"text-align: right;\">0.121071</td></tr>\n<tr><td>GBM_4_AutoML_20201108_044243                       </td><td style=\"text-align: right;\">0.884563</td><td style=\"text-align: right;\"> 0.412288</td><td style=\"text-align: right;\">0.930272</td><td style=\"text-align: right;\">              0.205892</td><td style=\"text-align: right;\">0.360915</td><td style=\"text-align: right;\">0.13026 </td></tr>\n<tr><td>GBM_grid__1_AutoML_20201108_044243_model_2         </td><td style=\"text-align: right;\">0.883757</td><td style=\"text-align: right;\"> 0.412247</td><td style=\"text-align: right;\">0.929666</td><td style=\"text-align: right;\">              0.212998</td><td style=\"text-align: right;\">0.358975</td><td style=\"text-align: right;\">0.128863</td></tr>\n<tr><td>GBM_2_AutoML_20201108_044243                       </td><td style=\"text-align: right;\">0.882101</td><td style=\"text-align: right;\"> 0.408096</td><td style=\"text-align: right;\">0.924653</td><td style=\"text-align: right;\">              0.190866</td><td style=\"text-align: right;\">0.356368</td><td style=\"text-align: right;\">0.126998</td></tr>\n<tr><td>GBM_grid__1_AutoML_20201108_044243_model_1         </td><td style=\"text-align: right;\">0.879994</td><td style=\"text-align: right;\"> 0.411873</td><td style=\"text-align: right;\">0.926902</td><td style=\"text-align: right;\">              0.219601</td><td style=\"text-align: right;\">0.360577</td><td style=\"text-align: right;\">0.130016</td></tr>\n<tr><td>GBM_3_AutoML_20201108_044243                       </td><td style=\"text-align: right;\">0.876952</td><td style=\"text-align: right;\"> 0.418408</td><td style=\"text-align: right;\">0.923052</td><td style=\"text-align: right;\">              0.212156</td><td style=\"text-align: right;\">0.363543</td><td style=\"text-align: right;\">0.132164</td></tr>\n<tr><td>GBM_1_AutoML_20201108_044243                       </td><td style=\"text-align: right;\">0.876497</td><td style=\"text-align: right;\"> 0.422203</td><td style=\"text-align: right;\">0.925008</td><td style=\"text-align: right;\">              0.222101</td><td style=\"text-align: right;\">0.365536</td><td style=\"text-align: right;\">0.133617</td></tr>\n<tr><td>GLM_1_AutoML_20201108_044243                       </td><td style=\"text-align: right;\">0.875757</td><td style=\"text-align: right;\"> 0.426938</td><td style=\"text-align: right;\">0.921075</td><td style=\"text-align: right;\">              0.228976</td><td style=\"text-align: right;\">0.368016</td><td style=\"text-align: right;\">0.135436</td></tr>\n<tr><td>XGBoost_grid__1_AutoML_20201108_044243_model_3     </td><td style=\"text-align: right;\">0.872385</td><td style=\"text-align: right;\"> 0.513561</td><td style=\"text-align: right;\">0.917598</td><td style=\"text-align: right;\">              0.220728</td><td style=\"text-align: right;\">0.371594</td><td style=\"text-align: right;\">0.138082</td></tr>\n<tr><td>GBM_5_AutoML_20201108_044243                       </td><td style=\"text-align: right;\">0.869842</td><td style=\"text-align: right;\"> 0.428889</td><td style=\"text-align: right;\">0.919382</td><td style=\"text-align: right;\">              0.206164</td><td style=\"text-align: right;\">0.368263</td><td style=\"text-align: right;\">0.135618</td></tr>\n<tr><td>XGBoost_grid__1_AutoML_20201108_044243_model_4     </td><td style=\"text-align: right;\">0.859046</td><td style=\"text-align: right;\"> 0.454019</td><td style=\"text-align: right;\">0.913158</td><td style=\"text-align: right;\">              0.264396</td><td style=\"text-align: right;\">0.377553</td><td style=\"text-align: right;\">0.142546</td></tr>\n<tr><td>XGBoost_grid__1_AutoML_20201108_044243_model_1     </td><td style=\"text-align: right;\">0.856996</td><td style=\"text-align: right;\"> 0.443175</td><td style=\"text-align: right;\">0.908054</td><td style=\"text-align: right;\">              0.249709</td><td style=\"text-align: right;\">0.375767</td><td style=\"text-align: right;\">0.141201</td></tr>\n<tr><td>XGBoost_3_AutoML_20201108_044243                   </td><td style=\"text-align: right;\">0.856359</td><td style=\"text-align: right;\"> 0.459651</td><td style=\"text-align: right;\">0.907647</td><td style=\"text-align: right;\">              0.229669</td><td style=\"text-align: right;\">0.379338</td><td style=\"text-align: right;\">0.143897</td></tr>\n<tr><td>DeepLearning_grid__2_AutoML_20201108_044243_model_1</td><td style=\"text-align: right;\">0.856299</td><td style=\"text-align: right;\"> 1.25953 </td><td style=\"text-align: right;\">0.899245</td><td style=\"text-align: right;\">              0.237114</td><td style=\"text-align: right;\">0.419033</td><td style=\"text-align: right;\">0.175589</td></tr>\n<tr><td>XGBoost_1_AutoML_20201108_044243                   </td><td style=\"text-align: right;\">0.855931</td><td style=\"text-align: right;\"> 0.454767</td><td style=\"text-align: right;\">0.910027</td><td style=\"text-align: right;\">              0.239397</td><td style=\"text-align: right;\">0.380238</td><td style=\"text-align: right;\">0.144581</td></tr>\n<tr><td>DRF_1_AutoML_20201108_044243                       </td><td style=\"text-align: right;\">0.8528  </td><td style=\"text-align: right;\"> 0.474152</td><td style=\"text-align: right;\">0.907583</td><td style=\"text-align: right;\">              0.245266</td><td style=\"text-align: right;\">0.390851</td><td style=\"text-align: right;\">0.152765</td></tr>\n<tr><td>XRT_1_AutoML_20201108_044243                       </td><td style=\"text-align: right;\">0.845461</td><td style=\"text-align: right;\"> 0.484405</td><td style=\"text-align: right;\">0.899942</td><td style=\"text-align: right;\">              0.2829  </td><td style=\"text-align: right;\">0.395608</td><td style=\"text-align: right;\">0.156505</td></tr>\n<tr><td>XGBoost_grid__1_AutoML_20201108_044243_model_2     </td><td style=\"text-align: right;\">0.845414</td><td style=\"text-align: right;\"> 0.46337 </td><td style=\"text-align: right;\">0.892877</td><td style=\"text-align: right;\">              0.235226</td><td style=\"text-align: right;\">0.381605</td><td style=\"text-align: right;\">0.145623</td></tr>\n<tr><td>XGBoost_2_AutoML_20201108_044243                   </td><td style=\"text-align: right;\">0.844431</td><td style=\"text-align: right;\"> 0.465161</td><td style=\"text-align: right;\">0.902156</td><td style=\"text-align: right;\">              0.226884</td><td style=\"text-align: right;\">0.383919</td><td style=\"text-align: right;\">0.147394</td></tr>\n<tr><td>DeepLearning_grid__1_AutoML_20201108_044243_model_1</td><td style=\"text-align: right;\">0.836792</td><td style=\"text-align: right;\"> 1.71017 </td><td style=\"text-align: right;\">0.880211</td><td style=\"text-align: right;\">              0.230702</td><td style=\"text-align: right;\">0.432594</td><td style=\"text-align: right;\">0.187138</td></tr>\n<tr><td>DeepLearning_1_AutoML_20201108_044243              </td><td style=\"text-align: right;\">0.80954 </td><td style=\"text-align: right;\"> 0.684416</td><td style=\"text-align: right;\">0.871226</td><td style=\"text-align: right;\">              0.318824</td><td style=\"text-align: right;\">0.429181</td><td style=\"text-align: right;\">0.184196</td></tr>\n</tbody>\n</table>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 62,
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "execution_count": 62,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604810955440
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_automl_model_ids = aml.leaderboard['model_id'].as_data_frame()['model_id'].tolist()\r\n",
        "\r\n",
        "for mdl_id in all_automl_model_ids:\r\n",
        "    print(mdl_id)\r\n",
        "    h2o.save_model(model= h2o.get_model(mdl_id), path= MODELS_LOCATION + \"pca300/aml_models\", force=True)\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StackedEnsemble_BestOfFamily_AutoML_20201108_044243\n",
            "StackedEnsemble_AllModels_AutoML_20201108_044243\n",
            "GBM_4_AutoML_20201108_044243\n",
            "GBM_grid__1_AutoML_20201108_044243_model_2\n",
            "GBM_2_AutoML_20201108_044243\n",
            "GBM_grid__1_AutoML_20201108_044243_model_1\n",
            "GBM_3_AutoML_20201108_044243\n",
            "GBM_1_AutoML_20201108_044243\n",
            "GLM_1_AutoML_20201108_044243\n",
            "XGBoost_grid__1_AutoML_20201108_044243_model_3\n",
            "GBM_5_AutoML_20201108_044243\n",
            "XGBoost_grid__1_AutoML_20201108_044243_model_4\n",
            "XGBoost_grid__1_AutoML_20201108_044243_model_1\n",
            "XGBoost_3_AutoML_20201108_044243\n",
            "DeepLearning_grid__2_AutoML_20201108_044243_model_1\n",
            "XGBoost_1_AutoML_20201108_044243\n",
            "DRF_1_AutoML_20201108_044243\n",
            "XRT_1_AutoML_20201108_044243\n",
            "XGBoost_grid__1_AutoML_20201108_044243_model_2\n",
            "XGBoost_2_AutoML_20201108_044243\n",
            "DeepLearning_grid__1_AutoML_20201108_044243_model_1\n",
            "DeepLearning_1_AutoML_20201108_044243\n"
          ]
        }
      ],
      "execution_count": 65,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604811260638
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive-Bayes Grid"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from h2o.grid.grid_search import H2OGridSearch\r\n",
        "from h2o.estimators import H2ONaiveBayesEstimator\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "hyper_params = {\r\n",
        "                \"laplace\": [0.1, 0.3, 0.6, 0.9, 1.0],\r\n",
        "                \"min_sdev\":[0.1, 0.3, 0.6, 0.9, 1.0],\r\n",
        "                \"eps_sdev\":[0.1, 0.3, 0.6, 0.9, 1.0],\r\n",
        "                \"min_prob\":[0.1, 0.3, 0.6, 0.9, 1.0],\r\n",
        "                \"eps_prob\":[0.1, 0.3, 0.6, 0.9, 1.0],\r\n",
        "                # \"compute_metrics\": [True, False]\r\n",
        "                }\r\n",
        "\r\n",
        "search_criteria = {\"strategy\": \"RandomDiscrete\", \r\n",
        "                   \"max_models\": MAX_MODELS}\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "base_model = H2ONaiveBayesEstimator(\r\n",
        "                                 nfolds=nfolds, \r\n",
        "                                 fold_assignment = \"random\",\r\n",
        "                                 keep_cross_validation_predictions = True,\r\n",
        "                                 seed=1234)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "nb_grid = H2OGridSearch(model=base_model,\r\n",
        "                     hyper_params=hyper_params,\r\n",
        "                     search_criteria=search_criteria)\r\n",
        "\r\n",
        "\r\n",
        "nb_grid.train(x=x, y=y, training_frame=train_pca_df_frame, validation_frame=test_pca_df_frame) \r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "naivebayes Grid Build progress: |█████████████████████████████████████████| 100%\n"
          ]
        }
      ],
      "execution_count": 69,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604812174035
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h2o.save_grid(MODELS_LOCATION + \"pca300/nb_grid\", nb_grid.grid_id)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 71,
          "data": {
            "text/plain": "'../../models/pca300/nb_grid/Grid_NaiveBayes_py_30_sid_bdfe_model_python_1604806499448_2178'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 71,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604812325298
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GLM Grid"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from h2o.grid.grid_search import H2OGridSearch\r\n",
        "from h2o.estimators import H2OGeneralizedLinearEstimator\r\n",
        "\r\n",
        "\r\n",
        "hyper_params = {\r\n",
        "# lambda //use self.lambda_\r\n",
        "# \"missing_values_handling\" : [\"mean_imputation\", \"skip\", \"plug_values\"],\r\n",
        "# 'standardize'\r\n",
        "\r\n",
        "\"alpha\" : [0, 0.3, 0.6, 0.9, 1],\r\n",
        "\"theta\" : [0, 0.3, 0.6, 0.9, 1],\r\n",
        "\"tweedie_link_power\" : [0, 0.3, 0.6, 0.9, 1, 3, 6, 9],\r\n",
        "\"tweedie_variance_power\" : [0, 0.3, 0.6, 0.9, 1, 3, 6, 9],\r\n",
        "}\r\n",
        "\r\n",
        "search_criteria = {\"strategy\": \"RandomDiscrete\", \r\n",
        "                   \"max_models\": MAX_MODELS}\r\n",
        "\r\n",
        "\r\n",
        "# Train and cross-validate a NB\r\n",
        "base_model = H2OGeneralizedLinearEstimator(\r\n",
        "                                family= \"binomial\",\r\n",
        "\r\n",
        "                                 nfolds=nfolds, \r\n",
        "                                 fold_assignment = \"random\",\r\n",
        "                                 keep_cross_validation_predictions = True,\r\n",
        "                                 seed=1234)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Train the grid\r\n",
        "glm_grid = H2OGridSearch(model=base_model,\r\n",
        "                     hyper_params=hyper_params,\r\n",
        "                     search_criteria=search_criteria)\r\n",
        "\r\n",
        "\r\n",
        "glm_grid.train(x=x, y=y, training_frame=train_pca_df_frame, validation_frame=test_pca_df_frame) \r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glm Grid Build progress: |████████████████████████████████████████████████| 100%\n"
          ]
        }
      ],
      "execution_count": 76,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604812648965
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h2o.save_grid(MODELS_LOCATION + \"pca300/glm_grid\", glm_grid.grid_id)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 77,
          "data": {
            "text/plain": "'../../models/pca300/glm_grid/Grid_GLM_py_30_sid_bdfe_model_python_1604806499448_2504'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 77,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604812669821
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GBM Grid"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from h2o.grid.grid_search import H2OGridSearch\r\n",
        "from h2o.estimators import H2OGradientBoostingEstimator\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "hyper_params = {\r\n",
        "'learn_rate': [0.1, 0.3, 0.6, 0.9],\r\n",
        "'learn_rate_annealing': [0.1, 0.3, 0.6, 0.9, 1],\r\n",
        "'distribution': ['bernoulli', 'multinomial'],\r\n",
        "'quantile_alpha':[0.1, 0.3, 0.5, 0.8, 1],\r\n",
        "'tweedie_power': [1.1, 1.5,1.9],\r\n",
        "'col_sample_rate': [0.1, 0.3, 0.7, 0.9],\r\n",
        "'balance_classes': [True, False],\r\n",
        "'ntrees': [10, 20, 50, 100, 150],\r\n",
        "'max_depth': [5, 10, 15, 20], # defaults to 20\r\n",
        "'sample_rate': [ 0.1, 0.3, 0.6, 0.9],\r\n",
        "'col_sample_rate_per_tree': [ 0.1, 0.3, 0.6, 0.8, 1],\r\n",
        "'col_sample_rate_change_per_level': [ 0.1, 0.3, 0.6, 0.8, 1, 1.3, 1.5, 1.7, 1.9],\r\n",
        "'histogram_type': [\"AUTO\", \"UniformAdaptive\", \"Random\", \"QuantilesGlobal\", \"RoundRobin\"]\r\n",
        "\r\n",
        "#'max_abs_leafnode_pred' # use default value\r\n",
        "#'class_sampling_factors',\r\n",
        "#'max_after_balance_size',\r\n",
        "#'min_rows', # defaults to 1\r\n",
        "#'nbins', # default is 20\r\n",
        "#'nbins_top_level', # requires too much tuning\r\n",
        "#'nbins_cats', # requires too much tuning\r\n",
        "#'r2_stopping',\r\n",
        "#'seed',\r\n",
        "#'build_tree_one_node',\r\n",
        "#'sample_rate_per_class':[ 0.1, 0.3, 0.6, 0.9],\r\n",
        "#'score_tree_interval',\r\n",
        "#'min_split_improvement',\r\n",
        "\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "search_criteria = {\"strategy\": \"RandomDiscrete\", \r\n",
        "                   \"max_models\": MAX_MODELS}\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "base_model = H2OGradientBoostingEstimator(\r\n",
        "\r\n",
        "\r\n",
        "                                 nfolds=nfolds, \r\n",
        "                                 fold_assignment = \"random\",\r\n",
        "                                 keep_cross_validation_predictions = True,\r\n",
        "                                 seed=1234\r\n",
        "                                 )\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Train the grid\r\n",
        "gbm_grid = H2OGridSearch(model=base_model,\r\n",
        "                     hyper_params=hyper_params,\r\n",
        "                     search_criteria=search_criteria,\r\n",
        "                     parallelism= 1)\r\n",
        "\r\n",
        "\r\n",
        "gbm_grid.train(x=x, y=y, training_frame=train_pca_df_frame, validation_frame=test_pca_df_frame) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gbm Grid Build progress: |████████████████████████████████████████████████| 100%\n"
          ]
        }
      ],
      "execution_count": 79,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604813007060
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h2o.save_grid(MODELS_LOCATION + \"pca300/gbm_grid\", gbm_grid.grid_id)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 80,
          "data": {
            "text/plain": "'../../models/pca300/gbm_grid/Grid_GBM_py_30_sid_bdfe_model_python_1604806499448_4444'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 80,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604813083261
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DRF Grid"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from h2o.grid.grid_search import H2OGridSearch\r\n",
        "from h2o.estimators import H2ORandomForestEstimator\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "hyper_params = {\r\n",
        "'mtries': [-1, 30, 60, 90, 150, 200],\r\n",
        "'balance_classes': [True, False],\r\n",
        "'ntrees': [10, 20, 50, 100, 150],\r\n",
        "'max_depth': [5, 10, 15, 20], # defaults to 20\r\n",
        "'sample_rate': [ 0.1, 0.3, 0.6, 0.9],\r\n",
        "'col_sample_rate_per_tree': [ 0.1, 0.3, 0.6, 0.8, 1],\r\n",
        "'col_sample_rate_change_per_level': [ 0.1, 0.3, 0.6, 0.8, 1, 1.3, 1.5, 1.7, 1.9],\r\n",
        "'histogram_type': [\"AUTO\", \"UniformAdaptive\", \"Random\", \"QuantilesGlobal\", \"RoundRobin\"]\r\n",
        "\r\n",
        "#'score_tree_interval',\r\n",
        "#'min_split_improvement',\r\n",
        "#'class_sampling_factors',\r\n",
        "#'max_after_balance_size',\r\n",
        "#'min_rows', # defaults to 1\r\n",
        "#'nbins', # default is 20\r\n",
        "#'nbins_top_level', # requires too much tuning\r\n",
        "#'nbins_cats', # requires too much tuning\r\n",
        "#'r2_stopping',\r\n",
        "#'seed',\r\n",
        "#'build_tree_one_node',\r\n",
        "#'sample_rate_per_class':[ 0.1, 0.9],\r\n",
        "}\r\n",
        "\r\n",
        "search_criteria = {\"strategy\": \"RandomDiscrete\", \r\n",
        "                   \"max_models\": MAX_MODELS}\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "base_model = H2ORandomForestEstimator(\r\n",
        "\r\n",
        "                                 nfolds=nfolds, \r\n",
        "                                 fold_assignment = \"random\",\r\n",
        "                                 keep_cross_validation_predictions = True,\r\n",
        "                                 seed=1234)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Train the grid\r\n",
        "drf_grid = H2OGridSearch(model=base_model,\r\n",
        "                     hyper_params=hyper_params,\r\n",
        "                     search_criteria=search_criteria,\r\n",
        "                     parallelism= 1)\r\n",
        "\r\n",
        "\r\n",
        "drf_grid.train(x=x, y=y, training_frame=train_pca_df_frame, validation_frame=test_pca_df_frame) \r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drf Grid Build progress: |████████████████████████████████████████████████| 100%\n"
          ]
        }
      ],
      "execution_count": 123,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604826026316
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h2o.save_grid(MODELS_LOCATION + \"pca300/drf_grid\", drf_grid.grid_id)\r\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 124,
          "data": {
            "text/plain": "'../../models/pca300/drf_grid/Grid_DRF_py_173_sid_9c98_model_python_1604825008375_8677'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 124,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604826124926
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DL Grid"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from h2o.grid.grid_search import H2OGridSearch\r\n",
        "from h2o.estimators import H2ODeepLearningEstimator\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "hyper_params = {\r\n",
        "#   'adaptive_rate',\r\n",
        "#   'categorical_encoding',\r\n",
        "#   'classification_stop',\r\n",
        "#   'class_sampling_factors',\r\n",
        "#   'col_major',\r\n",
        "#   'elastic_averaging_moving_rate',\r\n",
        "#   'elastic_averaging_regularization',\r\n",
        "#   'elastic_averaging',\r\n",
        "#   'epsilon',\r\n",
        "#   'fast_mode',\r\n",
        "#   'force_load_balance',\r\n",
        "#   'initial_biases',\r\n",
        "#   'initial_weights',\r\n",
        "#   'initial_weight_distribution',\r\n",
        "#   'initial_weight_scale',\r\n",
        "\r\n",
        "#   'max_after_balance_size',\r\n",
        "#   'max_categorical_features',\r\n",
        "#   'max_w2',\r\n",
        "#   'missing_values_handling',\r\n",
        "#   'momentum_ramp',\r\n",
        "#   'momentum_stable',\r\n",
        "#   'momentum_start',\r\n",
        "#   'nesterov_accelerated_gradient',\r\n",
        "#   'overwrite_with_best_model',\r\n",
        "#   'quantile_alpha',\r\n",
        "#   'quiet_mode',\r\n",
        "#   'rate_annealing',\r\n",
        "#   'rate_decay',\r\n",
        "#   'rate',\r\n",
        "#   'regression_stop',\r\n",
        "#   'replicate_training_data',\r\n",
        "#   'reproducible',\r\n",
        "#   'score_duty_cycle',\r\n",
        "#   'score_interval',\r\n",
        "#   'score_training_samples',\r\n",
        "#   'score_validation_samples',\r\n",
        "#   'score_validation_sampling',\r\n",
        "#   'seed',\r\n",
        "#   'shuffle_training_data',\r\n",
        "#   'single_node_mode',\r\n",
        "#   'sparsity_beta',\r\n",
        "#   'target_ratio_comm_to_comp',\r\n",
        "#   'train_samples_per_iteration',\r\n",
        "#   'tweedie_power',\r\n",
        "#   'use_all_factor_levels',\r\n",
        "#   'variable_importances ',\r\n",
        "\r\n",
        "# \"hidden_dropout_ratios\": [0, 0.1, 0.2, [0.5, 0.5], [0.5, 0.5]]  ,\r\n",
        "              \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "              'l1': [0, 1e-5, 1e-2],\r\n",
        "              'l2': [0, 1e-5, 1e-2],\r\n",
        "              'sparse': [ True, False],\r\n",
        "              'balance_classes': [ True, False],\r\n",
        "       \t      'average_activation': [0, 0.5, 1, 3, 5, 7, 10],\r\n",
        "\t            'epochs': [10, 20, 30],\r\n",
        "              \"activation\" : ['Rectifier', 'RectifierWithDropout', 'TanHWithDropout', 'TanH', 'Maxout', 'MaxoutWithDropout'] ,\r\n",
        "              'distribution': ['bernoulli', 'multinomial'],\r\n",
        "              \r\n",
        "              \"hidden\": [[10, 10, 10], [50], [500, 500], [500, 500, 500]]  ,\r\n",
        "              \"input_dropout_ratio\":[0, 0.10, 0.15, 0.20]  ,\r\n",
        "              \"rho\" : [0.95, 0.90] ,\r\n",
        "              \"standardize\" : [True, False] ,\r\n",
        "              'loss': ['Automatic', 'Quadratic', 'CrossEntropy'],\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "search_criteria = {\"strategy\": \"RandomDiscrete\", \r\n",
        "                   \"max_models\": MAX_MODELS}\r\n",
        "\r\n",
        " \r\n",
        "\r\n",
        "base_model = H2ODeepLearningEstimator(\r\n",
        "\r\n",
        "                                        keep_cross_validation_predictions = True,\r\n",
        "                                        nfolds= nfolds,\r\n",
        "                                        fold_assignment = \"random\",\r\n",
        "                                        seed=1234)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Train the grid\r\n",
        "dl_grid = H2OGridSearch(model=base_model,\r\n",
        "                     hyper_params=hyper_params,\r\n",
        "                     search_criteria=search_criteria)\r\n",
        "\r\n",
        "\r\n",
        "dl_grid.train(x=x, y=y, training_frame=train_pca_df_frame, validation_frame=test_pca_df_frame)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deeplearning Grid Build progress: |███████████████████████████████████████| 100%\n"
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605368437831
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h2o.save_grid(MODELS_LOCATION + \"PCA300/dl_grid\", dl_grid.grid_id)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "'../../models/PCA300/dl_grid_LATEST/Grid_DeepLearning_py_3_sid_b60c_model_python_1605362597414_758'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605371464759
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGB Grid"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from h2o.grid.grid_search import H2OGridSearch\r\n",
        "from h2o.estimators import H2OXGBoostEstimator\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "hyper_params = {\r\n",
        " 'distribution': ['bernoulli', 'multinomial'],\r\n",
        " 'categorical_encoding': ['auto',  'binary',  'label_encoder'],\r\n",
        " 'ntrees': [10, 50, 70, 100],\r\n",
        " 'booster': ['gbtree', 'gblinear', 'dart'], \r\n",
        " 'col_sample_rate': [0.1, 0.3, 0.6, 0.8, 1], \r\n",
        " 'colsample_bylevel': [0.1, 0.3, 0.6, 0.8, 1], \r\n",
        " 'colsample_bytree': [0.1, 0.3, 0.6, 0.8, 1], \r\n",
        " 'learn_rate': [0.1, 0.3, 0.6, 0.8, 1], \r\n",
        "#  'grow_policy': ['lossguide'], \r\n",
        " 'max_depth': [0, 3, 6], \r\n",
        " 'normalize_type': ['tree', 'forest'], \r\n",
        " 'sample_type': ['uniform', 'weighted'], \r\n",
        " 'sample_rate': [0.1, 0.3, 0.6, 0.8, 1], \r\n",
        "#  'tree_method': ['auto', 'exact', 'approx', 'hist'], \r\n",
        " 'tweedie_power': [1.2, 1.5, 1.8],\r\n",
        "\r\n",
        "# 'max_abs_leafnode_pred'\r\n",
        "# 'min_split_improvement',  \r\n",
        "# 'max_bins', \r\n",
        "# 'max_delta_step', \r\n",
        "# 'max_leaves', \r\n",
        "# 'min_rows':  \r\n",
        "# 'one_drop', \r\n",
        "# 'rate_drop', \r\n",
        "# 'reg_alpha', \r\n",
        "# 'reg_lambda', \r\n",
        "# 'skip_drop', \r\n",
        "# 'num_leaves'\r\n",
        "\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "search_criteria = {\"strategy\": \"RandomDiscrete\", \r\n",
        "                   \"max_models\": MAX_MODELS}\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "base_model = H2OXGBoostEstimator(grow_policy= 'lossguide',\r\n",
        "                                tree_method='hist',\r\n",
        "\r\n",
        "                              keep_cross_validation_predictions = True,\r\n",
        "                              nfolds= nfolds,\r\n",
        "                              fold_assignment = \"random\",\r\n",
        "                              seed=1234)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Train the grid\r\n",
        "xgb_grid = H2OGridSearch(model=base_model,\r\n",
        "                     hyper_params=hyper_params,\r\n",
        "                     search_criteria=search_criteria)\r\n",
        "\r\n",
        "\r\n",
        "xgb_grid.train(x=x, y=y, training_frame=train_pca_df_frame, validation_frame=test_pca_df_frame) \r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xgboost Grid Build progress: |████████████████████████████████████████████| 100%\n",
            "Errors/Warnings building gridsearch model\n",
            "\n",
            "Hyper-parameter: booster, dart\n",
            "Hyper-parameter: categorical_encoding, Binary\n",
            "Hyper-parameter: col_sample_rate, 1.0\n",
            "Hyper-parameter: colsample_bylevel, 0.3\n",
            "Hyper-parameter: colsample_bytree, 0.1\n",
            "Hyper-parameter: distribution, multinomial\n",
            "Hyper-parameter: learn_rate, 1.0\n",
            "Hyper-parameter: max_depth, 0\n",
            "Hyper-parameter: normalize_type, forest\n",
            "Hyper-parameter: ntrees, 100\n",
            "Hyper-parameter: sample_rate, 0.3\n",
            "Hyper-parameter: sample_type, weighted\n",
            "Hyper-parameter: tweedie_power, 1.5\n",
            "failure_details: Cannot perform booster operation: updater is inactive on node /127.0.0.1:54321\n",
            "failure_stack_traces: java.lang.IllegalStateException: Cannot perform booster operation: updater is inactive on node /127.0.0.1:54321\n",
            "\tat ml.dmlc.xgboost4j.java.XGBoostUpdater.invoke(XGBoostUpdater.java:108)\n",
            "\tat ml.dmlc.xgboost4j.java.XGBoostUpdater.doUpdate(XGBoostUpdater.java:178)\n",
            "\tat ml.dmlc.xgboost4j.java.XGBoostUpdateTask.execute(XGBoostUpdateTask.java:19)\n",
            "\tat ml.dmlc.xgboost4j.java.AbstractXGBoostTask.setupLocal(AbstractXGBoostTask.java:35)\n",
            "\tat water.MRTask.setupLocal0(MRTask.java:566)\n",
            "\tat water.MRTask.dfork(MRTask.java:416)\n",
            "\tat water.MRTask.doAll(MRTask.java:408)\n",
            "\tat water.MRTask.doAllNodes(MRTask.java:421)\n",
            "\tat ml.dmlc.xgboost4j.java.AbstractXGBoostTask.run(AbstractXGBoostTask.java:46)\n",
            "\tat hex.tree.xgboost.XGBoost$XGBoostDriver.scoreAndBuildTrees(XGBoost.java:466)\n",
            "\tat hex.tree.xgboost.XGBoost$XGBoostDriver.buildModelImpl(XGBoost.java:390)\n",
            "\tat hex.tree.xgboost.XGBoost$XGBoostDriver.buildModel(XGBoost.java:337)\n",
            "\tat hex.tree.xgboost.XGBoost$XGBoostDriver.computeImpl(XGBoost.java:327)\n",
            "\tat hex.ModelBuilder$Driver.compute2(ModelBuilder.java:248)\n",
            "\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1557)\n",
            "\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n",
            "\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n",
            "\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n",
            "\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n",
            "\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n",
            "\n",
            "\n",
            "Hyper-parameter: booster, dart\n",
            "Hyper-parameter: categorical_encoding, LabelEncoder\n",
            "Hyper-parameter: col_sample_rate, 0.6\n",
            "Hyper-parameter: colsample_bylevel, 0.6\n",
            "Hyper-parameter: colsample_bytree, 0.6\n",
            "Hyper-parameter: distribution, bernoulli\n",
            "Hyper-parameter: learn_rate, 0.8\n",
            "Hyper-parameter: max_depth, 0\n",
            "Hyper-parameter: normalize_type, tree\n",
            "Hyper-parameter: ntrees, 50\n",
            "Hyper-parameter: sample_rate, 0.6\n",
            "Hyper-parameter: sample_type, weighted\n",
            "Hyper-parameter: tweedie_power, 1.8\n",
            "failure_details: Cannot perform booster operation: updater is inactive on node /127.0.0.1:54321\n",
            "failure_stack_traces: java.lang.IllegalStateException: Cannot perform booster operation: updater is inactive on node /127.0.0.1:54321\n",
            "\tat ml.dmlc.xgboost4j.java.XGBoostUpdater.invoke(XGBoostUpdater.java:108)\n",
            "\tat ml.dmlc.xgboost4j.java.XGBoostUpdater.doUpdate(XGBoostUpdater.java:178)\n",
            "\tat ml.dmlc.xgboost4j.java.XGBoostUpdateTask.execute(XGBoostUpdateTask.java:19)\n",
            "\tat ml.dmlc.xgboost4j.java.AbstractXGBoostTask.setupLocal(AbstractXGBoostTask.java:35)\n",
            "\tat water.MRTask.setupLocal0(MRTask.java:566)\n",
            "\tat water.MRTask.dfork(MRTask.java:416)\n",
            "\tat water.MRTask.doAll(MRTask.java:408)\n",
            "\tat water.MRTask.doAllNodes(MRTask.java:421)\n",
            "\tat ml.dmlc.xgboost4j.java.AbstractXGBoostTask.run(AbstractXGBoostTask.java:46)\n",
            "\tat hex.tree.xgboost.XGBoost$XGBoostDriver.scoreAndBuildTrees(XGBoost.java:466)\n",
            "\tat hex.tree.xgboost.XGBoost$XGBoostDriver.buildModelImpl(XGBoost.java:390)\n",
            "\tat hex.tree.xgboost.XGBoost$XGBoostDriver.buildModel(XGBoost.java:337)\n",
            "\tat hex.tree.xgboost.XGBoost$XGBoostDriver.computeImpl(XGBoost.java:327)\n",
            "\tat hex.ModelBuilder$Driver.compute2(ModelBuilder.java:248)\n",
            "\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1557)\n",
            "\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n",
            "\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n",
            "\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n",
            "\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n",
            "\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n",
            "\n",
            "\n",
            "Hyper-parameter: booster, gbtree\n",
            "Hyper-parameter: categorical_encoding, AUTO\n",
            "Hyper-parameter: col_sample_rate, 1.0\n",
            "Hyper-parameter: colsample_bylevel, 0.6\n",
            "Hyper-parameter: colsample_bytree, 0.3\n",
            "Hyper-parameter: distribution, bernoulli\n",
            "Hyper-parameter: learn_rate, 0.3\n",
            "Hyper-parameter: max_depth, 0\n",
            "Hyper-parameter: normalize_type, tree\n",
            "Hyper-parameter: ntrees, 100\n",
            "Hyper-parameter: sample_rate, 0.1\n",
            "Hyper-parameter: sample_type, uniform\n",
            "Hyper-parameter: tweedie_power, 1.2\n",
            "failure_details: Cannot perform booster operation: updater is inactive on node /127.0.0.1:54321\n",
            "failure_stack_traces: java.lang.IllegalStateException: Cannot perform booster operation: updater is inactive on node /127.0.0.1:54321\n",
            "\tat ml.dmlc.xgboost4j.java.XGBoostUpdater.invoke(XGBoostUpdater.java:108)\n",
            "\tat ml.dmlc.xgboost4j.java.XGBoostUpdater.doUpdate(XGBoostUpdater.java:178)\n",
            "\tat ml.dmlc.xgboost4j.java.XGBoostUpdateTask.execute(XGBoostUpdateTask.java:19)\n",
            "\tat ml.dmlc.xgboost4j.java.AbstractXGBoostTask.setupLocal(AbstractXGBoostTask.java:35)\n",
            "\tat water.MRTask.setupLocal0(MRTask.java:566)\n",
            "\tat water.MRTask.dfork(MRTask.java:416)\n",
            "\tat water.MRTask.doAll(MRTask.java:408)\n",
            "\tat water.MRTask.doAllNodes(MRTask.java:421)\n",
            "\tat ml.dmlc.xgboost4j.java.AbstractXGBoostTask.run(AbstractXGBoostTask.java:46)\n",
            "\tat hex.tree.xgboost.XGBoost$XGBoostDriver.scoreAndBuildTrees(XGBoost.java:466)\n",
            "\tat hex.tree.xgboost.XGBoost$XGBoostDriver.buildModelImpl(XGBoost.java:390)\n",
            "\tat hex.tree.xgboost.XGBoost$XGBoostDriver.buildModel(XGBoost.java:337)\n",
            "\tat hex.tree.xgboost.XGBoost$XGBoostDriver.computeImpl(XGBoost.java:327)\n",
            "\tat hex.ModelBuilder$Driver.compute2(ModelBuilder.java:248)\n",
            "\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1557)\n",
            "\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n",
            "\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n",
            "\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n",
            "\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n",
            "\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "execution_count": 118,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604825368612
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h2o.save_grid(MODELS_LOCATION + \"pca300/xgb_grid\", xgb_grid.grid_id)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 120,
          "data": {
            "text/plain": "'../../models/pca300/xgb_grid/Grid_XGBoost_py_173_sid_9c98_model_python_1604825008375_1'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 120,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604825382978
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Stackend Ensemble using the best models from the grids"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_grid = h2o.load_grid(MODELS_LOCATION + \"pca300/nb_grid/Grid_NaiveBayes_py_30_sid_bdfe_model_python_1604806499448_2178\")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "glm_grid = h2o.load_grid(MODELS_LOCATION + \"pca300/glm_grid/Grid_GLM_py_30_sid_bdfe_model_python_1604806499448_2504\")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "gbm_grid = h2o.load_grid(MODELS_LOCATION + \"pca300/gbm_grid/Grid_GBM_py_30_sid_bdfe_model_python_1604806499448_4444\")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "xgb_grid = h2o.load_grid(MODELS_LOCATION + \"pca300/xgb_grid/Grid_XGBoost_py_173_sid_9c98_model_python_1604825008375_1\")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "dl_grid = h2o.load_grid(MODELS_LOCATION + \"pca300/dl_grid/Grid_DeepLearning_py_3_sid_b60c_model_python_1605362597414_758\")\r\n",
        "\r\n",
        "\r\n",
        "drf_grid = h2o.load_grid(MODELS_LOCATION + \"pca300/drf_grid/Grid_DRF_py_173_sid_9c98_model_python_1604825008375_8677\")\r\n"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605460382036
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select best models from the grids based on performance on the test data\r\n",
        "\r\n",
        "def best_model_from_grid (model_grid):\r\n",
        "\r\n",
        "    sorted_grid = model_grid.get_grid(sort_by='auc', decreasing=True)\r\n",
        "\r\n",
        "    for mdl in sorted_grid:\r\n",
        "        print(\"Modeld ID: \", mdl.model_id)\r\n",
        "\r\n",
        "        # print('Train data AUC: ', mdl.model_performance(train=True).auc()) # same result with model_performance()\r\n",
        "        print('Default Test data AUC: ', mdl.model_performance(valid=True).auc())    \r\n",
        "        print('Default Test data AUCPR: ', mdl.model_performance(valid=True).aucpr())    \r\n",
        "\r\n",
        "        print('Default Cross-validation AUC: ', mdl.model_performance(xval=True).auc())\r\n",
        "        print('Default Cross-validation AUCPR: ', mdl.model_performance(xval=True).aucpr())\r\n",
        "        print(\"\\n--------------------\\n\")\r\n",
        "\r\n",
        "    print(\"\\n@@@@@@@@@@@@@@@@@@@@@@@\\n\")\r\n",
        "    return sorted_grid[0]\r\n"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605460382097
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_nb_model = best_model_from_grid(nb_grid)\r\n",
        "best_glm_model = best_model_from_grid(glm_grid)\r\n",
        "best_gbm_model = best_model_from_grid(gbm_grid)\r\n",
        "best_xgb_model= best_model_from_grid(xgb_grid)\r\n",
        "best_dl_model= best_model_from_grid(dl_grid)\r\n",
        "best_drf_model= best_model_from_grid(drf_grid)\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modeld ID:  Grid_NaiveBayes_py_30_sid_bdfe_model_python_1604806499448_2178_model_3\n",
            "Default Test data AUC:  0.5736287073002505\n",
            "Default Test data AUCPR:  0.722796224545721\n",
            "Default Cross-validation AUC:  0.62177304964539\n",
            "Default Cross-validation AUCPR:  0.7463032863986705\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_NaiveBayes_py_30_sid_bdfe_model_python_1604806499448_2178_model_10\n",
            "Default Test data AUC:  0.5484717029077576\n",
            "Default Test data AUCPR:  0.7123235647071509\n",
            "Default Cross-validation AUC:  0.5759293735224587\n",
            "Default Cross-validation AUCPR:  0.6842246540548909\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_NaiveBayes_py_30_sid_bdfe_model_python_1604806499448_2178_model_9\n",
            "Default Test data AUC:  0.5590354666569862\n",
            "Default Test data AUCPR:  0.7002563536407302\n",
            "Default Cross-validation AUC:  0.5701713947990544\n",
            "Default Cross-validation AUCPR:  0.7105505892531342\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_NaiveBayes_py_30_sid_bdfe_model_python_1604806499448_2178_model_7\n",
            "Default Test data AUC:  0.5320361563872654\n",
            "Default Test data AUCPR:  0.707325077533424\n",
            "Default Cross-validation AUC:  0.5394060283687943\n",
            "Default Cross-validation AUCPR:  0.6829883264851554\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_NaiveBayes_py_30_sid_bdfe_model_python_1604806499448_2178_model_4\n",
            "Default Test data AUC:  0.5149381057828438\n",
            "Default Test data AUCPR:  0.674797115684899\n",
            "Default Cross-validation AUC:  0.5199423758865248\n",
            "Default Cross-validation AUCPR:  0.6718191012843986\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_NaiveBayes_py_30_sid_bdfe_model_python_1604806499448_2178_model_5\n",
            "Default Test data AUC:  0.5180237412422406\n",
            "Default Test data AUCPR:  0.6906664433624456\n",
            "Default Cross-validation AUC:  0.4947104018912529\n",
            "Default Cross-validation AUCPR:  0.6374350512034186\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_NaiveBayes_py_30_sid_bdfe_model_python_1604806499448_2178_model_6\n",
            "Default Test data AUC:  0.4901168911315207\n",
            "Default Test data AUCPR:  0.68834210257479\n",
            "Default Cross-validation AUC:  0.4929255319148936\n",
            "Default Cross-validation AUCPR:  0.6363421060102182\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_NaiveBayes_py_30_sid_bdfe_model_python_1604806499448_2178_model_1\n",
            "Default Test data AUC:  0.5\n",
            "Default Test data AUCPR:  0.6746506986027944\n",
            "Default Cross-validation AUC:  0.4831131796690307\n",
            "Default Cross-validation AUCPR:  0.641963388575653\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_NaiveBayes_py_30_sid_bdfe_model_python_1604806499448_2178_model_2\n",
            "Default Test data AUC:  0.5\n",
            "Default Test data AUCPR:  0.6746506986027944\n",
            "Default Cross-validation AUC:  0.4831131796690307\n",
            "Default Cross-validation AUCPR:  0.641963388575653\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_NaiveBayes_py_30_sid_bdfe_model_python_1604806499448_2178_model_8\n",
            "Default Test data AUC:  0.5\n",
            "Default Test data AUCPR:  0.6746506986027944\n",
            "Default Cross-validation AUC:  0.4831131796690307\n",
            "Default Cross-validation AUCPR:  0.641963388575653\n",
            "\n",
            "--------------------\n",
            "\n",
            "\n",
            "@@@@@@@@@@@@@@@@@@@@@@@\n",
            "\n",
            "Modeld ID:  Grid_GLM_py_30_sid_bdfe_model_python_1604806499448_2504_model_2\n",
            "Default Test data AUC:  0.6266381094130032\n",
            "Default Test data AUCPR:  0.7515512182825628\n",
            "Default Cross-validation AUC:  0.8693484042553191\n",
            "Default Cross-validation AUCPR:  0.9206885107574454\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_GLM_py_30_sid_bdfe_model_python_1604806499448_2504_model_6\n",
            "Default Test data AUC:  0.6266381094130032\n",
            "Default Test data AUCPR:  0.7515512182825628\n",
            "Default Cross-validation AUC:  0.8693484042553191\n",
            "Default Cross-validation AUCPR:  0.9206885107574454\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_GLM_py_30_sid_bdfe_model_python_1604806499448_2504_model_3\n",
            "Default Test data AUC:  0.5863251896758268\n",
            "Default Test data AUCPR:  0.7123711533205923\n",
            "Default Cross-validation AUC:  0.8570907210401891\n",
            "Default Cross-validation AUCPR:  0.8962271232275381\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_GLM_py_30_sid_bdfe_model_python_1604806499448_2504_model_7\n",
            "Default Test data AUC:  0.5863251896758268\n",
            "Default Test data AUCPR:  0.7123711533205923\n",
            "Default Cross-validation AUC:  0.8570907210401891\n",
            "Default Cross-validation AUCPR:  0.8962271232275381\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_GLM_py_30_sid_bdfe_model_python_1604806499448_2504_model_1\n",
            "Default Test data AUC:  0.591788579518641\n",
            "Default Test data AUCPR:  0.7168702488556923\n",
            "Default Cross-validation AUC:  0.8549231678486997\n",
            "Default Cross-validation AUCPR:  0.893730528947243\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_GLM_py_30_sid_bdfe_model_python_1604806499448_2504_model_10\n",
            "Default Test data AUC:  0.591788579518641\n",
            "Default Test data AUCPR:  0.7168702488556923\n",
            "Default Cross-validation AUC:  0.8549231678486997\n",
            "Default Cross-validation AUCPR:  0.893730528947243\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_GLM_py_30_sid_bdfe_model_python_1604806499448_2504_model_4\n",
            "Default Test data AUC:  0.591788579518641\n",
            "Default Test data AUCPR:  0.7168702488556923\n",
            "Default Cross-validation AUC:  0.8549231678486997\n",
            "Default Cross-validation AUCPR:  0.893730528947243\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_GLM_py_30_sid_bdfe_model_python_1604806499448_2504_model_5\n",
            "Default Test data AUC:  0.591788579518641\n",
            "Default Test data AUCPR:  0.7168702488556923\n",
            "Default Cross-validation AUC:  0.8549231678486997\n",
            "Default Cross-validation AUCPR:  0.893730528947243\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_GLM_py_30_sid_bdfe_model_python_1604806499448_2504_model_8\n",
            "Default Test data AUC:  0.591788579518641\n",
            "Default Test data AUCPR:  0.7168702488556923\n",
            "Default Cross-validation AUC:  0.8549231678486997\n",
            "Default Cross-validation AUCPR:  0.893730528947243\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_GLM_py_30_sid_bdfe_model_python_1604806499448_2504_model_9\n",
            "Default Test data AUC:  0.591788579518641\n",
            "Default Test data AUCPR:  0.7168702488556923\n",
            "Default Cross-validation AUC:  0.8549231678486997\n",
            "Default Cross-validation AUCPR:  0.893730528947243\n",
            "\n",
            "--------------------\n",
            "\n",
            "\n",
            "@@@@@@@@@@@@@@@@@@@@@@@\n",
            "\n",
            "Modeld ID:  Grid_GBM_py_30_sid_bdfe_model_python_1604806499448_4444_model_5\n",
            "Default Test data AUC:  0.5621574037100229\n",
            "Default Test data AUCPR:  0.7342422655997748\n",
            "Default Cross-validation AUC:  0.8782254728132387\n",
            "Default Cross-validation AUCPR:  0.9117333177488975\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_GBM_py_30_sid_bdfe_model_python_1604806499448_4444_model_7\n",
            "Default Test data AUC:  0.5911714524267615\n",
            "Default Test data AUCPR:  0.7543769573104404\n",
            "Default Cross-validation AUC:  0.8044193262411348\n",
            "Default Cross-validation AUCPR:  0.8828104770819434\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_GBM_py_30_sid_bdfe_model_python_1604806499448_4444_model_3\n",
            "Default Test data AUC:  0.5650524558028097\n",
            "Default Test data AUCPR:  0.7059262799195561\n",
            "Default Cross-validation AUC:  0.7986805555555556\n",
            "Default Cross-validation AUCPR:  0.867315768349834\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_GBM_py_30_sid_bdfe_model_python_1604806499448_4444_model_1\n",
            "Default Test data AUC:  0.5493520165535267\n",
            "Default Test data AUCPR:  0.7040377715788042\n",
            "Default Cross-validation AUC:  0.797191193853428\n",
            "Default Cross-validation AUCPR:  0.8726856025971447\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_GBM_py_30_sid_bdfe_model_python_1604806499448_4444_model_10\n",
            "Default Test data AUC:  0.5104820851635387\n",
            "Default Test data AUCPR:  0.6999949148168211\n",
            "Default Cross-validation AUC:  0.7670227541371158\n",
            "Default Cross-validation AUCPR:  0.8346180931988019\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_GBM_py_30_sid_bdfe_model_python_1604806499448_4444_model_6\n",
            "Default Test data AUC:  0.6056830144843358\n",
            "Default Test data AUCPR:  0.7618816164994612\n",
            "Default Cross-validation AUC:  0.7251226359338062\n",
            "Default Cross-validation AUCPR:  0.8019681140716669\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_GBM_py_30_sid_bdfe_model_python_1604806499448_4444_model_9\n",
            "Default Test data AUC:  0.5600791374741352\n",
            "Default Test data AUCPR:  0.7417224976322403\n",
            "Default Cross-validation AUC:  0.6983333333333333\n",
            "Default Cross-validation AUCPR:  0.7898803717471761\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_GBM_py_30_sid_bdfe_model_python_1604806499448_4444_model_4\n",
            "Default Test data AUC:  0.4968780629469634\n",
            "Default Test data AUCPR:  0.6840605335031601\n",
            "Default Cross-validation AUC:  0.6692996453900709\n",
            "Default Cross-validation AUCPR:  0.7800891842461939\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_GBM_py_30_sid_bdfe_model_python_1604806499448_4444_model_2\n",
            "Default Test data AUC:  0.5485624568918576\n",
            "Default Test data AUCPR:  0.6953869210230089\n",
            "Default Cross-validation AUC:  0.6555067966903073\n",
            "Default Cross-validation AUCPR:  0.7521405906346205\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_GBM_py_30_sid_bdfe_model_python_1604806499448_4444_model_8\n",
            "Default Test data AUC:  0.5015972701201582\n",
            "Default Test data AUCPR:  0.6641705612072644\n",
            "Default Cross-validation AUC:  0.5941193853427896\n",
            "Default Cross-validation AUCPR:  0.7078480055102175\n",
            "\n",
            "--------------------\n",
            "\n",
            "\n",
            "@@@@@@@@@@@@@@@@@@@@@@@\n",
            "\n",
            "Modeld ID:  Grid_XGBoost_py_173_sid_9c98_model_python_1604825008375_1_model_1\n",
            "Default Test data AUC:  0.6006189421715613\n",
            "Default Test data AUCPR:  0.757982161501983\n",
            "Default Cross-validation AUC:  0.8880614657210402\n",
            "Default Cross-validation AUCPR:  0.9298853306000129\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_XGBoost_py_173_sid_9c98_model_python_1604825008375_1_model_5\n",
            "Default Test data AUC:  0.6373833811304316\n",
            "Default Test data AUCPR:  0.7748548483987819\n",
            "Default Cross-validation AUC:  0.870196513002364\n",
            "Default Cross-validation AUCPR:  0.9182560753525744\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_XGBoost_py_173_sid_9c98_model_python_1604825008375_1_model_10\n",
            "Default Test data AUC:  0.5815696809089919\n",
            "Default Test data AUCPR:  0.7375729038675836\n",
            "Default Cross-validation AUC:  0.8111790780141844\n",
            "Default Cross-validation AUCPR:  0.875342293499504\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_XGBoost_py_173_sid_9c98_model_python_1604825008375_1_model_3\n",
            "Default Test data AUC:  0.6144952263404363\n",
            "Default Test data AUCPR:  0.7634580813387875\n",
            "Default Cross-validation AUC:  0.8105023640661938\n",
            "Default Cross-validation AUCPR:  0.8743426454795941\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_XGBoost_py_173_sid_9c98_model_python_1604825008375_1_model_4\n",
            "Default Test data AUC:  0.6177714451664428\n",
            "Default Test data AUCPR:  0.764129489835918\n",
            "Default Cross-validation AUC:  0.8090750591016548\n",
            "Default Cross-validation AUCPR:  0.8741350674711706\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_XGBoost_py_173_sid_9c98_model_python_1604825008375_1_model_6\n",
            "Default Test data AUC:  0.6000744182669618\n",
            "Default Test data AUCPR:  0.736903633999404\n",
            "Default Cross-validation AUC:  0.7280053191489362\n",
            "Default Cross-validation AUCPR:  0.8211763724670733\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_XGBoost_py_173_sid_9c98_model_python_1604825008375_1_model_2\n",
            "Default Test data AUC:  0.532371946128435\n",
            "Default Test data AUCPR:  0.6897493739316475\n",
            "Default Cross-validation AUC:  0.7035800827423168\n",
            "Default Cross-validation AUCPR:  0.7991183385997647\n",
            "\n",
            "--------------------\n",
            "\n",
            "\n",
            "@@@@@@@@@@@@@@@@@@@@@@@\n",
            "\n",
            "Modeld ID:  Grid_DeepLearning_py_3_sid_b60c_model_python_1605362597414_758_model_5\n",
            "Default Test data AUC:  0.6312847133989182\n",
            "Default Test data AUCPR:  0.7804867860351187\n",
            "Default Cross-validation AUC:  0.8736111111111111\n",
            "Default Cross-validation AUCPR:  0.9222555417769538\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_DeepLearning_py_3_sid_b60c_model_python_1605362597414_758_model_9\n",
            "Default Test data AUC:  0.6440901005554144\n",
            "Default Test data AUCPR:  0.7702323387778022\n",
            "Default Cross-validation AUC:  0.8547916666666666\n",
            "Default Cross-validation AUCPR:  0.9060445923140601\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_DeepLearning_py_3_sid_b60c_model_python_1605362597414_758_model_3\n",
            "Default Test data AUC:  0.6306948125022689\n",
            "Default Test data AUCPR:  0.7542601978583798\n",
            "Default Cross-validation AUC:  0.8536052009456264\n",
            "Default Cross-validation AUCPR:  0.905387474639246\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_DeepLearning_py_3_sid_b60c_model_python_1605362597414_758_model_2\n",
            "Default Test data AUC:  0.5976694376883145\n",
            "Default Test data AUCPR:  0.7620697914279121\n",
            "Default Cross-validation AUC:  0.8387174940898344\n",
            "Default Cross-validation AUCPR:  0.8934394867894748\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_DeepLearning_py_3_sid_b60c_model_python_1605362597414_758_model_8\n",
            "Default Test data AUC:  0.6135513849057973\n",
            "Default Test data AUCPR:  0.7562079654636168\n",
            "Default Cross-validation AUC:  0.8291829196217494\n",
            "Default Cross-validation AUCPR:  0.8897291806733669\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_DeepLearning_py_3_sid_b60c_model_python_1605362597414_758_model_7\n",
            "Default Test data AUC:  0.5948560641812176\n",
            "Default Test data AUCPR:  0.717706114608065\n",
            "Default Cross-validation AUC:  0.8281043144208038\n",
            "Default Cross-validation AUCPR:  0.8814089855031274\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_DeepLearning_py_3_sid_b60c_model_python_1605362597414_758_model_4\n",
            "Default Test data AUC:  0.6513231930881767\n",
            "Default Test data AUCPR:  0.771860804472994\n",
            "Default Cross-validation AUC:  0.7714568557919622\n",
            "Default Cross-validation AUCPR:  0.8638169616902509\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_DeepLearning_py_3_sid_b60c_model_python_1605362597414_758_model_1\n",
            "Default Test data AUC:  0.6269829745525829\n",
            "Default Test data AUCPR:  0.7623296430172621\n",
            "Default Cross-validation AUC:  0.6530422576832151\n",
            "Default Cross-validation AUCPR:  0.7725882631259251\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_DeepLearning_py_3_sid_b60c_model_python_1605362597414_758_model_10\n",
            "Default Test data AUC:  0.5\n",
            "Default Test data AUCPR:  0.6746506986027944\n",
            "Default Cross-validation AUC:  0.5872960992907802\n",
            "Default Cross-validation AUCPR:  0.7482558648957338\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_DeepLearning_py_3_sid_b60c_model_python_1605362597414_758_model_6\n",
            "Default Test data AUC:  0.5\n",
            "Default Test data AUCPR:  0.6746506986027944\n",
            "Default Cross-validation AUC:  0.4935328014184397\n",
            "Default Cross-validation AUCPR:  0.6517516457626242\n",
            "\n",
            "--------------------\n",
            "\n",
            "\n",
            "@@@@@@@@@@@@@@@@@@@@@@@\n",
            "\n",
            "Modeld ID:  Grid_DRF_py_173_sid_9c98_model_python_1604825008375_8677_model_5\n",
            "Default Test data AUC:  0.5821051294151813\n",
            "Default Test data AUCPR:  0.7520371662557974\n",
            "Default Cross-validation AUC:  0.8844089834515367\n",
            "Default Cross-validation AUCPR:  0.9292240110585137\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_DRF_py_173_sid_9c98_model_python_1604825008375_8677_model_7\n",
            "Default Test data AUC:  0.5827857842959306\n",
            "Default Test data AUCPR:  0.7503998063297266\n",
            "Default Cross-validation AUC:  0.8731914893617022\n",
            "Default Cross-validation AUCPR:  0.9252970368944919\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_DRF_py_173_sid_9c98_model_python_1604825008375_8677_model_6\n",
            "Default Test data AUC:  0.5775674302101862\n",
            "Default Test data AUCPR:  0.7441007584662777\n",
            "Default Cross-validation AUC:  0.8658348108747045\n",
            "Default Cross-validation AUCPR:  0.9146143851385142\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_DRF_py_173_sid_9c98_model_python_1604825008375_8677_model_2\n",
            "Default Test data AUC:  0.5770955094928668\n",
            "Default Test data AUCPR:  0.748800319841249\n",
            "Default Cross-validation AUC:  0.8519119385342789\n",
            "Default Cross-validation AUCPR:  0.9069872633627765\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_DRF_py_173_sid_9c98_model_python_1604825008375_8677_model_8\n",
            "Default Test data AUC:  0.5849820307111482\n",
            "Default Test data AUCPR:  0.7594751443978316\n",
            "Default Cross-validation AUC:  0.8505673758865249\n",
            "Default Cross-validation AUCPR:  0.9011700452611322\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_DRF_py_173_sid_9c98_model_python_1604825008375_8677_model_10\n",
            "Default Test data AUC:  0.5915435437615711\n",
            "Default Test data AUCPR:  0.7494350743502506\n",
            "Default Cross-validation AUC:  0.8329373522458628\n",
            "Default Cross-validation AUCPR:  0.8953810623184211\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_DRF_py_173_sid_9c98_model_python_1604825008375_8677_model_4\n",
            "Default Test data AUC:  0.5773677714451665\n",
            "Default Test data AUCPR:  0.746395521499641\n",
            "Default Cross-validation AUC:  0.8284293735224587\n",
            "Default Cross-validation AUCPR:  0.888035602758361\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_DRF_py_173_sid_9c98_model_python_1604825008375_8677_model_1\n",
            "Default Test data AUC:  0.5668040076959379\n",
            "Default Test data AUCPR:  0.7307154403277908\n",
            "Default Cross-validation AUC:  0.7938371749408983\n",
            "Default Cross-validation AUCPR:  0.8683331042352752\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_DRF_py_173_sid_9c98_model_python_1604825008375_8677_model_9\n",
            "Default Test data AUC:  0.5979053980469743\n",
            "Default Test data AUCPR:  0.7634623112748247\n",
            "Default Cross-validation AUC:  0.786846926713948\n",
            "Default Cross-validation AUCPR:  0.8613930267125789\n",
            "\n",
            "--------------------\n",
            "\n",
            "Modeld ID:  Grid_DRF_py_173_sid_9c98_model_python_1604825008375_8677_model_3\n",
            "Default Test data AUC:  0.6031509783279486\n",
            "Default Test data AUCPR:  0.742750777213124\n",
            "Default Cross-validation AUC:  0.7450723995271867\n",
            "Default Cross-validation AUCPR:  0.8329935230794867\n",
            "\n",
            "--------------------\n",
            "\n",
            "\n",
            "@@@@@@@@@@@@@@@@@@@@@@@\n",
            "\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605460389265
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "def extract_params_from_model(actual_params_dict, extra_params = [], additional_keys = {}):\r\n",
        "    final_params = actual_params_dict\r\n",
        "\r\n",
        "    columns_to_be_removed =   [\r\n",
        "                                'model_id',\r\n",
        "                                'validation_frame',\r\n",
        "                                'response_column',\r\n",
        "                                'ignored_columns',\r\n",
        "                                'training_frame',\r\n",
        "                                *extra_params\r\n",
        "]\r\n",
        "\r\n",
        "    for col_name in columns_to_be_removed:\r\n",
        "        del  final_params[col_name]\r\n",
        "\r\n",
        "    return {**final_params, **additional_keys}"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605460389719
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from h2o.estimators import H2ONaiveBayesEstimator\r\n",
        "\r\n",
        "top_nb = H2ONaiveBayesEstimator(**extract_params_from_model(best_nb_model.actual_params))\r\n",
        "\r\n",
        "top_nb.train(x=x, y=y, training_frame=train_pca_df_frame, validation_frame=test_pca_df_frame)\r\n",
        "\r\n",
        "# h2o.save_model(top_nb, MODELS_LOCATION + \"PCA300/top_nb\")\r\n",
        "\r\n",
        "print('AUC on test_pca_df_frame data: ', top_nb.model_performance(valid=True).auc(), \"\\n\\n============================\")\r\n",
        "\r\n",
        "top_nb.model_performance"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "naivebayes Model Build progress: |████████████████████████████████████████| 100%\n",
            "AUC on test_pca_df_frame data:  0.5736650088938905 \n",
            "\n",
            "============================\n",
            "Model Details\n",
            "=============\n",
            "H2ONaiveBayesEstimator :  Naive Bayes\n",
            "Model Key:  NaiveBayes_model_python_1605467917228_1\n",
            "\n",
            "\n",
            "Model Summary: \n",
            "\n",
            "\n",
            "ModelMetricsBinomial: naivebayes\n",
            "** Reported on train data. **\n",
            "\n",
            "MSE: 0.23176875895186294\n",
            "RMSE: 0.4814236792596132\n",
            "LogLoss: 0.8090609556633163\n",
            "Mean Per-Class Error: 0.3141134751773049\n",
            "AUC: 0.7467124704491725\n",
            "AUCPR: 0.8338461959696989\n",
            "Gini: 0.4934249408983451\n",
            "\n",
            "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.06978097423895066: \n",
            "\n",
            "Maximum Metrics: Maximum metrics at their respective thresholds\n",
            "\n",
            "Gains/Lift Table: Avg response rate: 65.41 %, avg score: 57.53 %\n",
            "\n",
            "\n",
            "ModelMetricsBinomial: naivebayes\n",
            "** Reported on validation data. **\n",
            "\n",
            "MSE: 0.35348622076185887\n",
            "RMSE: 0.5945470719479315\n",
            "LogLoss: 1.2712951498433689\n",
            "Mean Per-Class Error: 0.43942171561331544\n",
            "AUC: 0.5736650088938905\n",
            "AUCPR: 0.7243829622084862\n",
            "Gini: 0.147330017787781\n",
            "\n",
            "Confusion Matrix (Act/Pred) for max f1 @ threshold = 1.882199883640578e-05: \n",
            "\n",
            "Maximum Metrics: Maximum metrics at their respective thresholds\n",
            "\n",
            "Gains/Lift Table: Avg response rate: 67.47 %, avg score: 48.41 %\n",
            "\n",
            "\n",
            "ModelMetricsBinomial: naivebayes\n",
            "** Reported on cross-validation data. **\n",
            "\n",
            "MSE: 0.3187324803753368"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "     number_of_response_levels  min_apriori_probability  \\\n0                          2.0                 0.346022   \n\n   max_apriori_probability  \n0                 0.653978  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>number_of_response_levels</th>\n      <th>min_apriori_probability</th>\n      <th>max_apriori_probability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>2.0</td>\n      <td>0.346022</td>\n      <td>0.653978</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RMSE: 0.5645639736782155\n",
            "LogLoss: 1.2753938215212923\n",
            "Mean Per-Class Error: 0.41355348699763594\n",
            "AUC: 0.62177304964539\n",
            "AUCPR: 0.7463032863986705\n",
            "Gini: 0.24354609929078008\n",
            "\n",
            "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.00026154732736230425: \n",
            "\n",
            "Maximum Metrics: Maximum metrics at their respective thresholds\n",
            "\n",
            "Gains/Lift Table: Avg response rate: 65.41 %, avg score: 58.42 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "              0       1   Error             Rate\n0      0  148.0   275.0  0.6501    (275.0/423.0)\n1      1   62.0   738.0  0.0775     (62.0/800.0)\n2  Total  210.0  1013.0  0.2756   (337.0/1223.0)",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>148.0</td>\n      <td>275.0</td>\n      <td>0.6501</td>\n      <td>(275.0/423.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>62.0</td>\n      <td>738.0</td>\n      <td>0.0775</td>\n      <td>(62.0/800.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>210.0</td>\n      <td>1013.0</td>\n      <td>0.2756</td>\n      <td>(337.0/1223.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                         metric  threshold       value    idx\n0                        max f1   0.069781    0.814120  354.0\n1                        max f2   0.000378    0.904364  399.0\n2                  max f0point5   0.320159    0.779862  264.0\n3                  max accuracy   0.135834    0.730989  326.0\n4                 max precision   0.999263    0.960000    1.0\n5                    max recall   0.000378    1.000000  399.0\n6               max specificity   0.999880    0.997636    0.0\n7              max absolute_mcc   0.179494    0.371467  311.0\n8    max min_per_class_accuracy   0.563942    0.683215  189.0\n9   max mean_per_class_accuracy   0.699184    0.685887  145.0\n10                      max tns   0.999880  422.000000    0.0\n11                      max fns   0.999880  779.000000    0.0\n12                      max fps   0.000378  423.000000  399.0\n13                      max tps   0.000378  800.000000  399.0\n14                      max tnr   0.999880    0.997636    0.0\n15                      max fnr   0.999880    0.973750    0.0\n16                      max fpr   0.000378    1.000000  399.0\n17                      max tpr   0.000378    1.000000  399.0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.069781</td>\n      <td>0.814120</td>\n      <td>354.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.000378</td>\n      <td>0.904364</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.320159</td>\n      <td>0.779862</td>\n      <td>264.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.135834</td>\n      <td>0.730989</td>\n      <td>326.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>0.999263</td>\n      <td>0.960000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.000378</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>0.999880</td>\n      <td>0.997636</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.179494</td>\n      <td>0.371467</td>\n      <td>311.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.563942</td>\n      <td>0.683215</td>\n      <td>189.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.699184</td>\n      <td>0.685887</td>\n      <td>145.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>0.999880</td>\n      <td>422.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>0.999880</td>\n      <td>779.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.000378</td>\n      <td>423.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.000378</td>\n      <td>800.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>0.999880</td>\n      <td>0.997636</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>0.999880</td>\n      <td>0.973750</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.000378</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.000378</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "      group  cumulative_data_fraction  lower_threshold      lift  \\\n0         1                  0.010630         0.999884  1.411154   \n1         2                  0.020442         0.999515  1.401354   \n2         3                  0.030253         0.999176  1.528750   \n3         4                  0.040065         0.998847  1.528750   \n4         5                  0.050695         0.998293  1.411154   \n5         6                  0.100572         0.994998  1.328258   \n6         7                  0.150450         0.986820  1.328258   \n7         8                  0.200327         0.972453  1.228012   \n8         9                  0.300082         0.926313  1.265605   \n9        10                  0.399836         0.844079  1.140297   \n10       11                  0.500409         0.680641  1.168313   \n11       12                  0.600164         0.468491  0.977398   \n12       13                  0.699918         0.255103  0.927275   \n13       14                  0.799673         0.094874  0.839559   \n14       15                  0.899428         0.021975  0.651598   \n15       16                  1.000000         0.000068  0.360437   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0          1.411154       0.923077  0.999963                  0.923077   \n1          1.406450       0.916667  0.999722                  0.920000   \n2          1.446115       1.000000  0.999405                  0.945946   \n3          1.466352       1.000000  0.999075                  0.959184   \n4          1.454778       0.923077  0.998601                  0.951613   \n5          1.392033       0.868852  0.996639                  0.910569   \n6          1.370890       0.868852  0.991332                  0.896739   \n7          1.335316       0.803279  0.981436                  0.873469   \n8          1.312142       0.827869  0.952795                  0.858311   \n9          1.269269       0.745902  0.889900                  0.830266   \n10         1.248979       0.764228  0.765484                  0.816993   \n11         1.203839       0.639344  0.572908                  0.787466   \n12         1.164422       0.606557  0.358007                  0.761682   \n13         1.123897       0.549180  0.168650                  0.735174   \n14         1.071515       0.426230  0.053418                  0.700909   \n15         1.000000       0.235772  0.007576                  0.654129   \n\n    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n0           0.999963       0.01500                  0.01500  41.115385   \n1           0.999847       0.01375                  0.02875  40.135417   \n2           0.999704       0.01500                  0.04375  52.875000   \n3           0.999550       0.01500                  0.05875  52.875000   \n4           0.999351       0.01500                  0.07375  41.115385   \n5           0.998006       0.06625                  0.14000  32.825820   \n6           0.995793       0.06625                  0.20625  32.825820   \n7           0.992219       0.06125                  0.26750  22.801230   \n8           0.979113       0.12625                  0.39375  26.560451   \n9           0.956855       0.11375                  0.50750  14.029713   \n10          0.918393       0.11750                  0.62500  16.831301   \n11          0.860969       0.09750                  0.72250  -2.260246   \n12          0.789285       0.09250                  0.81500  -7.272541   \n13          0.711865       0.08375                  0.89875 -16.044057   \n14          0.638837       0.06500                  0.96375 -34.840164   \n15          0.575350       0.03625                  1.00000 -63.956301   \n\n    cumulative_gain  \n0         41.115385  \n1         40.645000  \n2         44.611486  \n3         46.635204  \n4         45.477823  \n5         39.203252  \n6         37.088995  \n7         33.531633  \n8         31.214237  \n9         26.926892  \n10        24.897876  \n11        20.383856  \n12        16.442173  \n13        12.389698  \n14         7.151477  \n15         0.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.010630</td>\n      <td>0.999884</td>\n      <td>1.411154</td>\n      <td>1.411154</td>\n      <td>0.923077</td>\n      <td>0.999963</td>\n      <td>0.923077</td>\n      <td>0.999963</td>\n      <td>0.01500</td>\n      <td>0.01500</td>\n      <td>41.115385</td>\n      <td>41.115385</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.020442</td>\n      <td>0.999515</td>\n      <td>1.401354</td>\n      <td>1.406450</td>\n      <td>0.916667</td>\n      <td>0.999722</td>\n      <td>0.920000</td>\n      <td>0.999847</td>\n      <td>0.01375</td>\n      <td>0.02875</td>\n      <td>40.135417</td>\n      <td>40.645000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.030253</td>\n      <td>0.999176</td>\n      <td>1.528750</td>\n      <td>1.446115</td>\n      <td>1.000000</td>\n      <td>0.999405</td>\n      <td>0.945946</td>\n      <td>0.999704</td>\n      <td>0.01500</td>\n      <td>0.04375</td>\n      <td>52.875000</td>\n      <td>44.611486</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.040065</td>\n      <td>0.998847</td>\n      <td>1.528750</td>\n      <td>1.466352</td>\n      <td>1.000000</td>\n      <td>0.999075</td>\n      <td>0.959184</td>\n      <td>0.999550</td>\n      <td>0.01500</td>\n      <td>0.05875</td>\n      <td>52.875000</td>\n      <td>46.635204</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>0.050695</td>\n      <td>0.998293</td>\n      <td>1.411154</td>\n      <td>1.454778</td>\n      <td>0.923077</td>\n      <td>0.998601</td>\n      <td>0.951613</td>\n      <td>0.999351</td>\n      <td>0.01500</td>\n      <td>0.07375</td>\n      <td>41.115385</td>\n      <td>45.477823</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>6</td>\n      <td>0.100572</td>\n      <td>0.994998</td>\n      <td>1.328258</td>\n      <td>1.392033</td>\n      <td>0.868852</td>\n      <td>0.996639</td>\n      <td>0.910569</td>\n      <td>0.998006</td>\n      <td>0.06625</td>\n      <td>0.14000</td>\n      <td>32.825820</td>\n      <td>39.203252</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>0.150450</td>\n      <td>0.986820</td>\n      <td>1.328258</td>\n      <td>1.370890</td>\n      <td>0.868852</td>\n      <td>0.991332</td>\n      <td>0.896739</td>\n      <td>0.995793</td>\n      <td>0.06625</td>\n      <td>0.20625</td>\n      <td>32.825820</td>\n      <td>37.088995</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>8</td>\n      <td>0.200327</td>\n      <td>0.972453</td>\n      <td>1.228012</td>\n      <td>1.335316</td>\n      <td>0.803279</td>\n      <td>0.981436</td>\n      <td>0.873469</td>\n      <td>0.992219</td>\n      <td>0.06125</td>\n      <td>0.26750</td>\n      <td>22.801230</td>\n      <td>33.531633</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>9</td>\n      <td>0.300082</td>\n      <td>0.926313</td>\n      <td>1.265605</td>\n      <td>1.312142</td>\n      <td>0.827869</td>\n      <td>0.952795</td>\n      <td>0.858311</td>\n      <td>0.979113</td>\n      <td>0.12625</td>\n      <td>0.39375</td>\n      <td>26.560451</td>\n      <td>31.214237</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>10</td>\n      <td>0.399836</td>\n      <td>0.844079</td>\n      <td>1.140297</td>\n      <td>1.269269</td>\n      <td>0.745902</td>\n      <td>0.889900</td>\n      <td>0.830266</td>\n      <td>0.956855</td>\n      <td>0.11375</td>\n      <td>0.50750</td>\n      <td>14.029713</td>\n      <td>26.926892</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>11</td>\n      <td>0.500409</td>\n      <td>0.680641</td>\n      <td>1.168313</td>\n      <td>1.248979</td>\n      <td>0.764228</td>\n      <td>0.765484</td>\n      <td>0.816993</td>\n      <td>0.918393</td>\n      <td>0.11750</td>\n      <td>0.62500</td>\n      <td>16.831301</td>\n      <td>24.897876</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>12</td>\n      <td>0.600164</td>\n      <td>0.468491</td>\n      <td>0.977398</td>\n      <td>1.203839</td>\n      <td>0.639344</td>\n      <td>0.572908</td>\n      <td>0.787466</td>\n      <td>0.860969</td>\n      <td>0.09750</td>\n      <td>0.72250</td>\n      <td>-2.260246</td>\n      <td>20.383856</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>13</td>\n      <td>0.699918</td>\n      <td>0.255103</td>\n      <td>0.927275</td>\n      <td>1.164422</td>\n      <td>0.606557</td>\n      <td>0.358007</td>\n      <td>0.761682</td>\n      <td>0.789285</td>\n      <td>0.09250</td>\n      <td>0.81500</td>\n      <td>-7.272541</td>\n      <td>16.442173</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>14</td>\n      <td>0.799673</td>\n      <td>0.094874</td>\n      <td>0.839559</td>\n      <td>1.123897</td>\n      <td>0.549180</td>\n      <td>0.168650</td>\n      <td>0.735174</td>\n      <td>0.711865</td>\n      <td>0.08375</td>\n      <td>0.89875</td>\n      <td>-16.044057</td>\n      <td>12.389698</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>15</td>\n      <td>0.899428</td>\n      <td>0.021975</td>\n      <td>0.651598</td>\n      <td>1.071515</td>\n      <td>0.426230</td>\n      <td>0.053418</td>\n      <td>0.700909</td>\n      <td>0.638837</td>\n      <td>0.06500</td>\n      <td>0.96375</td>\n      <td>-34.840164</td>\n      <td>7.151477</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>16</td>\n      <td>1.000000</td>\n      <td>0.000068</td>\n      <td>0.360437</td>\n      <td>1.000000</td>\n      <td>0.235772</td>\n      <td>0.007576</td>\n      <td>0.654129</td>\n      <td>0.575350</td>\n      <td>0.03625</td>\n      <td>1.00000</td>\n      <td>-63.956301</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "            0      1   Error            Rate\n0      0  0.0  163.0     1.0   (163.0/163.0)\n1      1  0.0  338.0     0.0     (0.0/338.0)\n2  Total  0.0  501.0  0.3253   (163.0/501.0)",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>163.0</td>\n      <td>1.0</td>\n      <td>(163.0/163.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>338.0</td>\n      <td>0.0</td>\n      <td>(0.0/338.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>0.0</td>\n      <td>501.0</td>\n      <td>0.3253</td>\n      <td>(163.0/501.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                         metric  threshold       value    idx\n0                        max f1   0.000019    0.805721  399.0\n1                        max f2   0.000019    0.912035  399.0\n2                  max f0point5   0.033002    0.731707  358.0\n3                  max accuracy   0.004415    0.678643  389.0\n4                 max precision   0.999972    1.000000    0.0\n5                    max recall   0.000019    1.000000  399.0\n6               max specificity   0.999972    1.000000    0.0\n7              max absolute_mcc   0.072467    0.137092  329.0\n8    max min_per_class_accuracy   0.435723    0.553254  214.0\n9   max mean_per_class_accuracy   0.630219    0.560578  168.0\n10                      max tns   0.999972  163.000000    0.0\n11                      max fns   0.999972  337.000000    0.0\n12                      max fps   0.000019  163.000000  399.0\n13                      max tps   0.000019  338.000000  399.0\n14                      max tnr   0.999972    1.000000    0.0\n15                      max fnr   0.999972    0.997041    0.0\n16                      max fpr   0.000019    1.000000  399.0\n17                      max tpr   0.000019    1.000000  399.0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.000019</td>\n      <td>0.805721</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.000019</td>\n      <td>0.912035</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.033002</td>\n      <td>0.731707</td>\n      <td>358.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.004415</td>\n      <td>0.678643</td>\n      <td>389.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>0.999972</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.000019</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>0.999972</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.072467</td>\n      <td>0.137092</td>\n      <td>329.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.435723</td>\n      <td>0.553254</td>\n      <td>214.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.630219</td>\n      <td>0.560578</td>\n      <td>168.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>0.999972</td>\n      <td>163.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>0.999972</td>\n      <td>337.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.000019</td>\n      <td>163.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.000019</td>\n      <td>338.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>0.999972</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>0.999972</td>\n      <td>0.997041</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.000019</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.000019</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "      group  cumulative_data_fraction  lower_threshold      lift  \\\n0         1                  0.011976         0.999151  0.988166   \n1         2                  0.021956         0.997826  1.185799   \n2         3                  0.031936         0.996729  1.185799   \n3         4                  0.041916         0.995198  1.482249   \n4         5                  0.053892         0.992816  0.988166   \n5         6                  0.101796         0.982072  1.049926   \n6         7                  0.151697         0.960561  1.067219   \n7         8                  0.201597         0.915961  1.126509   \n8         9                  0.301397         0.793827  1.096864   \n9        10                  0.401198         0.645576  1.037574   \n10       11                  0.500998         0.455959  1.037574   \n11       12                  0.600798         0.305265  0.889349   \n12       13                  0.700599         0.145351  1.067219   \n13       14                  0.800399         0.061849  1.007929   \n14       15                  0.900200         0.014352  0.889349   \n15       16                  1.000000         0.000018  0.770769   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0          0.988166       0.666667  0.999484                  0.666667   \n1          1.077999       0.800000  0.998375                  0.727273   \n2          1.111686       0.800000  0.997253                  0.750000   \n3          1.199915       1.000000  0.995839                  0.809524   \n4          1.152860       0.666667  0.993714                  0.777778   \n5          1.104420       0.708333  0.987526                  0.745098   \n6          1.092183       0.720000  0.972885                  0.736842   \n7          1.100680       0.760000  0.940022                  0.742574   \n8          1.099416       0.740000  0.858133                  0.741722   \n9          1.084033       0.700000  0.724299                  0.731343   \n10         1.074778       0.700000  0.562622                  0.725100   \n11         1.043976       0.600000  0.379646                  0.704319   \n12         1.047287       0.720000  0.214842                  0.706553   \n13         1.042379       0.680000  0.100026                  0.703242   \n14         1.025414       0.600000  0.035928                  0.691796   \n15         1.000000       0.520000  0.006091                  0.674651   \n\n    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n0           0.999484      0.011834                 0.011834  -1.183432   \n1           0.998980      0.011834                 0.023669  18.579882   \n2           0.998440      0.011834                 0.035503  18.579882   \n3           0.997821      0.014793                 0.050296  48.224852   \n4           0.996908      0.011834                 0.062130  -1.183432   \n5           0.992493      0.050296                 0.112426   4.992604   \n6           0.986043      0.053254                 0.165680   6.721893   \n7           0.974652      0.056213                 0.221893  12.650888   \n8           0.936069      0.109467                 0.331361   9.686391   \n9           0.883390      0.103550                 0.434911   3.757396   \n10          0.819492      0.103550                 0.538462   3.757396   \n11          0.746428      0.088757                 0.627219 -11.065089   \n12          0.670703      0.106509                 0.733728   6.721893   \n13          0.599547      0.100592                 0.834320   0.792899   \n14          0.537061      0.088757                 0.923077 -11.065089   \n15          0.484070      0.076923                 1.000000 -22.923077   \n\n    cumulative_gain  \n0         -1.183432  \n1          7.799892  \n2         11.168639  \n3         19.991547  \n4         15.285996  \n5         10.442047  \n6          9.218312  \n7         10.067959  \n8          9.941612  \n9          8.403250  \n10         7.477781  \n11         4.397570  \n12         4.728670  \n13         4.237926  \n14         2.541361  \n15         0.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.011976</td>\n      <td>0.999151</td>\n      <td>0.988166</td>\n      <td>0.988166</td>\n      <td>0.666667</td>\n      <td>0.999484</td>\n      <td>0.666667</td>\n      <td>0.999484</td>\n      <td>0.011834</td>\n      <td>0.011834</td>\n      <td>-1.183432</td>\n      <td>-1.183432</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.021956</td>\n      <td>0.997826</td>\n      <td>1.185799</td>\n      <td>1.077999</td>\n      <td>0.800000</td>\n      <td>0.998375</td>\n      <td>0.727273</td>\n      <td>0.998980</td>\n      <td>0.011834</td>\n      <td>0.023669</td>\n      <td>18.579882</td>\n      <td>7.799892</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.031936</td>\n      <td>0.996729</td>\n      <td>1.185799</td>\n      <td>1.111686</td>\n      <td>0.800000</td>\n      <td>0.997253</td>\n      <td>0.750000</td>\n      <td>0.998440</td>\n      <td>0.011834</td>\n      <td>0.035503</td>\n      <td>18.579882</td>\n      <td>11.168639</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.041916</td>\n      <td>0.995198</td>\n      <td>1.482249</td>\n      <td>1.199915</td>\n      <td>1.000000</td>\n      <td>0.995839</td>\n      <td>0.809524</td>\n      <td>0.997821</td>\n      <td>0.014793</td>\n      <td>0.050296</td>\n      <td>48.224852</td>\n      <td>19.991547</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>0.053892</td>\n      <td>0.992816</td>\n      <td>0.988166</td>\n      <td>1.152860</td>\n      <td>0.666667</td>\n      <td>0.993714</td>\n      <td>0.777778</td>\n      <td>0.996908</td>\n      <td>0.011834</td>\n      <td>0.062130</td>\n      <td>-1.183432</td>\n      <td>15.285996</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>6</td>\n      <td>0.101796</td>\n      <td>0.982072</td>\n      <td>1.049926</td>\n      <td>1.104420</td>\n      <td>0.708333</td>\n      <td>0.987526</td>\n      <td>0.745098</td>\n      <td>0.992493</td>\n      <td>0.050296</td>\n      <td>0.112426</td>\n      <td>4.992604</td>\n      <td>10.442047</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>0.151697</td>\n      <td>0.960561</td>\n      <td>1.067219</td>\n      <td>1.092183</td>\n      <td>0.720000</td>\n      <td>0.972885</td>\n      <td>0.736842</td>\n      <td>0.986043</td>\n      <td>0.053254</td>\n      <td>0.165680</td>\n      <td>6.721893</td>\n      <td>9.218312</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>8</td>\n      <td>0.201597</td>\n      <td>0.915961</td>\n      <td>1.126509</td>\n      <td>1.100680</td>\n      <td>0.760000</td>\n      <td>0.940022</td>\n      <td>0.742574</td>\n      <td>0.974652</td>\n      <td>0.056213</td>\n      <td>0.221893</td>\n      <td>12.650888</td>\n      <td>10.067959</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>9</td>\n      <td>0.301397</td>\n      <td>0.793827</td>\n      <td>1.096864</td>\n      <td>1.099416</td>\n      <td>0.740000</td>\n      <td>0.858133</td>\n      <td>0.741722</td>\n      <td>0.936069</td>\n      <td>0.109467</td>\n      <td>0.331361</td>\n      <td>9.686391</td>\n      <td>9.941612</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>10</td>\n      <td>0.401198</td>\n      <td>0.645576</td>\n      <td>1.037574</td>\n      <td>1.084033</td>\n      <td>0.700000</td>\n      <td>0.724299</td>\n      <td>0.731343</td>\n      <td>0.883390</td>\n      <td>0.103550</td>\n      <td>0.434911</td>\n      <td>3.757396</td>\n      <td>8.403250</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>11</td>\n      <td>0.500998</td>\n      <td>0.455959</td>\n      <td>1.037574</td>\n      <td>1.074778</td>\n      <td>0.700000</td>\n      <td>0.562622</td>\n      <td>0.725100</td>\n      <td>0.819492</td>\n      <td>0.103550</td>\n      <td>0.538462</td>\n      <td>3.757396</td>\n      <td>7.477781</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>12</td>\n      <td>0.600798</td>\n      <td>0.305265</td>\n      <td>0.889349</td>\n      <td>1.043976</td>\n      <td>0.600000</td>\n      <td>0.379646</td>\n      <td>0.704319</td>\n      <td>0.746428</td>\n      <td>0.088757</td>\n      <td>0.627219</td>\n      <td>-11.065089</td>\n      <td>4.397570</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>13</td>\n      <td>0.700599</td>\n      <td>0.145351</td>\n      <td>1.067219</td>\n      <td>1.047287</td>\n      <td>0.720000</td>\n      <td>0.214842</td>\n      <td>0.706553</td>\n      <td>0.670703</td>\n      <td>0.106509</td>\n      <td>0.733728</td>\n      <td>6.721893</td>\n      <td>4.728670</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>14</td>\n      <td>0.800399</td>\n      <td>0.061849</td>\n      <td>1.007929</td>\n      <td>1.042379</td>\n      <td>0.680000</td>\n      <td>0.100026</td>\n      <td>0.703242</td>\n      <td>0.599547</td>\n      <td>0.100592</td>\n      <td>0.834320</td>\n      <td>0.792899</td>\n      <td>4.237926</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>15</td>\n      <td>0.900200</td>\n      <td>0.014352</td>\n      <td>0.889349</td>\n      <td>1.025414</td>\n      <td>0.600000</td>\n      <td>0.035928</td>\n      <td>0.691796</td>\n      <td>0.537061</td>\n      <td>0.088757</td>\n      <td>0.923077</td>\n      <td>-11.065089</td>\n      <td>2.541361</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>16</td>\n      <td>1.000000</td>\n      <td>0.000018</td>\n      <td>0.770769</td>\n      <td>1.000000</td>\n      <td>0.520000</td>\n      <td>0.006091</td>\n      <td>0.674651</td>\n      <td>0.484070</td>\n      <td>0.076923</td>\n      <td>1.000000</td>\n      <td>-22.923077</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "            0       1   Error             Rate\n0      0  0.0   423.0     1.0    (423.0/423.0)\n1      1  0.0   800.0     0.0      (0.0/800.0)\n2  Total  0.0  1223.0  0.3459   (423.0/1223.0)",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>423.0</td>\n      <td>1.0</td>\n      <td>(423.0/423.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>800.0</td>\n      <td>0.0</td>\n      <td>(0.0/800.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>0.0</td>\n      <td>1223.0</td>\n      <td>0.3459</td>\n      <td>(423.0/1223.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                         metric  threshold       value    idx\n0                        max f1   0.000262    0.790905  399.0\n1                        max f2   0.000262    0.904364  399.0\n2                  max f0point5   0.069536    0.726111  351.0\n3                  max accuracy   0.028679    0.674571  371.0\n4                 max precision   0.999896    0.868421    0.0\n5                    max recall   0.000262    1.000000  399.0\n6               max specificity   0.999896    0.988180    0.0\n7              max absolute_mcc   0.028679    0.191441  371.0\n8    max min_per_class_accuracy   0.677169    0.572500  155.0\n9   max mean_per_class_accuracy   0.545321    0.586447  197.0\n10                      max tns   0.999896  418.000000    0.0\n11                      max fns   0.999896  767.000000    0.0\n12                      max fps   0.000262  423.000000  399.0\n13                      max tps   0.000262  800.000000  399.0\n14                      max tnr   0.999896    0.988180    0.0\n15                      max fnr   0.999896    0.958750    0.0\n16                      max fpr   0.000262    1.000000  399.0\n17                      max tpr   0.000262    1.000000  399.0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.000262</td>\n      <td>0.790905</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.000262</td>\n      <td>0.904364</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.069536</td>\n      <td>0.726111</td>\n      <td>351.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.028679</td>\n      <td>0.674571</td>\n      <td>371.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>0.999896</td>\n      <td>0.868421</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.000262</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>0.999896</td>\n      <td>0.988180</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.028679</td>\n      <td>0.191441</td>\n      <td>371.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.677169</td>\n      <td>0.572500</td>\n      <td>155.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.545321</td>\n      <td>0.586447</td>\n      <td>197.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>0.999896</td>\n      <td>418.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>0.999896</td>\n      <td>767.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.000262</td>\n      <td>423.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.000262</td>\n      <td>800.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>0.999896</td>\n      <td>0.988180</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>0.999896</td>\n      <td>0.958750</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.000262</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.000262</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "      group  cumulative_data_fraction  lower_threshold      lift  \\\n0         1                  0.010630         0.999964  1.175962   \n1         2                  0.020442         0.999885  1.528750   \n2         3                  0.030253         0.999742  1.401354   \n3         4                  0.040065         0.999622  1.146562   \n4         5                  0.050695         0.999470  1.411154   \n5         6                  0.100572         0.997892  1.202951   \n6         7                  0.150450         0.995142  1.077643   \n7         8                  0.200327         0.988102  1.177889   \n8         9                  0.300082         0.955576  1.127766   \n9        10                  0.399836         0.872114  0.964867   \n10       11                  0.500409         0.724054  1.068882   \n11       12                  0.600164         0.493700  1.014990   \n12       13                  0.699918         0.220413  0.939805   \n13       14                  0.799673         0.078218  1.014990   \n14       15                  0.899428         0.012923  0.801967   \n15       16                  1.000000         0.000009  0.671159   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0          1.175962       0.769231  0.999988                  0.769231   \n1          1.345300       1.000000  0.999930                  0.880000   \n2          1.363480       0.916667  0.999825                  0.891892   \n3          1.310357       0.750000  0.999685                  0.857143   \n4          1.331492       0.923077  0.999541                  0.870968   \n5          1.267744       0.786885  0.998813                  0.829268   \n6          1.204721       0.704918  0.996485                  0.788043   \n7          1.198041       0.770492  0.991979                  0.783673   \n8          1.174680       0.737705  0.976113                  0.768392   \n9          1.122334       0.631148  0.919737                  0.734151   \n10         1.111591       0.699187  0.809394                  0.727124   \n11         1.095535       0.663934  0.607225                  0.716621   \n12         1.073340       0.614754  0.354122                  0.702103   \n13         1.066061       0.663934  0.138178                  0.697342   \n14         1.036770       0.524590  0.039012                  0.678182   \n15         1.000000       0.439024  0.004251                  0.654129   \n\n    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n0           0.999988       0.01250                  0.01250  17.596154   \n1           0.999960       0.01500                  0.02750  52.875000   \n2           0.999916       0.01375                  0.04125  40.135417   \n3           0.999860       0.01125                  0.05250  14.656250   \n4           0.999793       0.01500                  0.06750  41.115385   \n5           0.999307       0.06000                  0.12750  20.295082   \n6           0.998371       0.05375                  0.18125   7.764344   \n7           0.996780       0.05875                  0.24000  17.788934   \n8           0.989910       0.11250                  0.35250  12.776639   \n9           0.972402       0.09625                  0.44875  -3.513320   \n10          0.939641       0.10750                  0.55625   6.888211   \n11          0.884389       0.10125                  0.65750   1.498975   \n12          0.808814       0.09375                  0.75125  -6.019467   \n13          0.725156       0.10125                  0.85250   1.498975   \n14          0.649056       0.08000                  0.93250 -19.803279   \n15          0.584206       0.06750                  1.00000 -32.884146   \n\n    cumulative_gain  \n0         17.596154  \n1         34.530000  \n2         36.347973  \n3         31.035714  \n4         33.149194  \n5         26.774390  \n6         20.472147  \n7         19.804082  \n8         17.467984  \n9         12.233384  \n10        11.159109  \n11         9.553474  \n12         7.333966  \n13         6.606084  \n14         3.677045  \n15         0.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.010630</td>\n      <td>0.999964</td>\n      <td>1.175962</td>\n      <td>1.175962</td>\n      <td>0.769231</td>\n      <td>0.999988</td>\n      <td>0.769231</td>\n      <td>0.999988</td>\n      <td>0.01250</td>\n      <td>0.01250</td>\n      <td>17.596154</td>\n      <td>17.596154</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.020442</td>\n      <td>0.999885</td>\n      <td>1.528750</td>\n      <td>1.345300</td>\n      <td>1.000000</td>\n      <td>0.999930</td>\n      <td>0.880000</td>\n      <td>0.999960</td>\n      <td>0.01500</td>\n      <td>0.02750</td>\n      <td>52.875000</td>\n      <td>34.530000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.030253</td>\n      <td>0.999742</td>\n      <td>1.401354</td>\n      <td>1.363480</td>\n      <td>0.916667</td>\n      <td>0.999825</td>\n      <td>0.891892</td>\n      <td>0.999916</td>\n      <td>0.01375</td>\n      <td>0.04125</td>\n      <td>40.135417</td>\n      <td>36.347973</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.040065</td>\n      <td>0.999622</td>\n      <td>1.146562</td>\n      <td>1.310357</td>\n      <td>0.750000</td>\n      <td>0.999685</td>\n      <td>0.857143</td>\n      <td>0.999860</td>\n      <td>0.01125</td>\n      <td>0.05250</td>\n      <td>14.656250</td>\n      <td>31.035714</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>0.050695</td>\n      <td>0.999470</td>\n      <td>1.411154</td>\n      <td>1.331492</td>\n      <td>0.923077</td>\n      <td>0.999541</td>\n      <td>0.870968</td>\n      <td>0.999793</td>\n      <td>0.01500</td>\n      <td>0.06750</td>\n      <td>41.115385</td>\n      <td>33.149194</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>6</td>\n      <td>0.100572</td>\n      <td>0.997892</td>\n      <td>1.202951</td>\n      <td>1.267744</td>\n      <td>0.786885</td>\n      <td>0.998813</td>\n      <td>0.829268</td>\n      <td>0.999307</td>\n      <td>0.06000</td>\n      <td>0.12750</td>\n      <td>20.295082</td>\n      <td>26.774390</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>0.150450</td>\n      <td>0.995142</td>\n      <td>1.077643</td>\n      <td>1.204721</td>\n      <td>0.704918</td>\n      <td>0.996485</td>\n      <td>0.788043</td>\n      <td>0.998371</td>\n      <td>0.05375</td>\n      <td>0.18125</td>\n      <td>7.764344</td>\n      <td>20.472147</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>8</td>\n      <td>0.200327</td>\n      <td>0.988102</td>\n      <td>1.177889</td>\n      <td>1.198041</td>\n      <td>0.770492</td>\n      <td>0.991979</td>\n      <td>0.783673</td>\n      <td>0.996780</td>\n      <td>0.05875</td>\n      <td>0.24000</td>\n      <td>17.788934</td>\n      <td>19.804082</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>9</td>\n      <td>0.300082</td>\n      <td>0.955576</td>\n      <td>1.127766</td>\n      <td>1.174680</td>\n      <td>0.737705</td>\n      <td>0.976113</td>\n      <td>0.768392</td>\n      <td>0.989910</td>\n      <td>0.11250</td>\n      <td>0.35250</td>\n      <td>12.776639</td>\n      <td>17.467984</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>10</td>\n      <td>0.399836</td>\n      <td>0.872114</td>\n      <td>0.964867</td>\n      <td>1.122334</td>\n      <td>0.631148</td>\n      <td>0.919737</td>\n      <td>0.734151</td>\n      <td>0.972402</td>\n      <td>0.09625</td>\n      <td>0.44875</td>\n      <td>-3.513320</td>\n      <td>12.233384</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>11</td>\n      <td>0.500409</td>\n      <td>0.724054</td>\n      <td>1.068882</td>\n      <td>1.111591</td>\n      <td>0.699187</td>\n      <td>0.809394</td>\n      <td>0.727124</td>\n      <td>0.939641</td>\n      <td>0.10750</td>\n      <td>0.55625</td>\n      <td>6.888211</td>\n      <td>11.159109</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>12</td>\n      <td>0.600164</td>\n      <td>0.493700</td>\n      <td>1.014990</td>\n      <td>1.095535</td>\n      <td>0.663934</td>\n      <td>0.607225</td>\n      <td>0.716621</td>\n      <td>0.884389</td>\n      <td>0.10125</td>\n      <td>0.65750</td>\n      <td>1.498975</td>\n      <td>9.553474</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>13</td>\n      <td>0.699918</td>\n      <td>0.220413</td>\n      <td>0.939805</td>\n      <td>1.073340</td>\n      <td>0.614754</td>\n      <td>0.354122</td>\n      <td>0.702103</td>\n      <td>0.808814</td>\n      <td>0.09375</td>\n      <td>0.75125</td>\n      <td>-6.019467</td>\n      <td>7.333966</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>14</td>\n      <td>0.799673</td>\n      <td>0.078218</td>\n      <td>1.014990</td>\n      <td>1.066061</td>\n      <td>0.663934</td>\n      <td>0.138178</td>\n      <td>0.697342</td>\n      <td>0.725156</td>\n      <td>0.10125</td>\n      <td>0.85250</td>\n      <td>1.498975</td>\n      <td>6.606084</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>15</td>\n      <td>0.899428</td>\n      <td>0.012923</td>\n      <td>0.801967</td>\n      <td>1.036770</td>\n      <td>0.524590</td>\n      <td>0.039012</td>\n      <td>0.678182</td>\n      <td>0.649056</td>\n      <td>0.08000</td>\n      <td>0.93250</td>\n      <td>-19.803279</td>\n      <td>3.677045</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>16</td>\n      <td>1.000000</td>\n      <td>0.000009</td>\n      <td>0.671159</td>\n      <td>1.000000</td>\n      <td>0.439024</td>\n      <td>0.004251</td>\n      <td>0.654129</td>\n      <td>0.584206</td>\n      <td>0.06750</td>\n      <td>1.00000</td>\n      <td>-32.884146</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Cross-Validation Metrics Summary: \n",
            "\n",
            "See the whole table with table.as_data_frame()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                                    mean           sd   cv_1_valid  \\\n0                  accuracy    0.6813875  0.032319296    0.7108434   \n1                       auc    0.6512176  0.020242797    0.6659452   \n2                     aucpr    0.7582092  0.026206708    0.7725955   \n3                       err   0.31861252  0.032319296   0.28915662   \n4                 err_count         78.0     9.027735         72.0   \n5                  f0point5    0.7236188  0.027202625    0.7522124   \n6                        f1    0.8002306  0.015225069    0.8095238   \n7                        f2    0.8958176  0.012522429   0.87628865   \n8            lift_top_group    1.4234031   0.20615338    1.5090909   \n9                   logloss    1.2761745    0.1843319    1.1700575   \n10      max_per_class_error   0.87064785   0.12570904   0.71428573   \n11                      mcc   0.27236786  0.033709124    0.2863477   \n12  mean_per_class_accuracy    0.5517067   0.04909224   0.60649353   \n13     mean_per_class_error    0.4482933   0.04909224    0.3935065   \n14                      mse   0.31911555  0.054569524   0.30913097   \n15                   pr_auc    0.7582092  0.026206708    0.7725955   \n16                precision    0.6804082  0.033164605    0.7183099   \n17                       r2  -0.41328508     0.251438  -0.38285926   \n18                   recall   0.97406125  0.030491687   0.92727274   \n19                     rmse    0.5633418  0.046924848   0.55599546   \n\n    cv_2_valid   cv_3_valid  cv_4_valid  cv_5_valid  \n0   0.63095236    0.6987448   0.6680498   0.6983471  \n1   0.64347064    0.6209906  0.67228264  0.65339893  \n2    0.7343244   0.73981434    0.797079  0.74723285  \n3    0.3690476   0.30125523  0.33195022  0.30165288  \n4         93.0         72.0        80.0        73.0  \n5   0.68123394   0.73913044  0.71555555   0.7299618  \n6   0.77372265    0.8095238  0.80099505   0.8073879  \n7    0.8952703    0.8947368  0.90960455   0.9031877  \n8    1.0566038    1.5031446   1.4968944    1.551282  \n9    1.3332363    1.5758824   1.1597352   1.1419615  \n10         1.0        0.825         1.0  0.81395346  \n11         NaN     0.233918         NaN   0.2968379  \n12         0.5   0.56863207         0.5   0.5834079  \n13         0.5   0.43136793         0.5  0.41659212  \n14  0.30073154    0.4096822   0.2621607  0.31387228  \n15   0.7343244   0.73981434    0.797079  0.74723285  \n16  0.63095236   0.69863015   0.6680498  0.68609864  \n17  -0.2915165  -0.83973724   -0.182186  -0.3701264  \n18         1.0    0.9622642         1.0   0.9807692  \n19   0.5483899   0.64006424   0.5120163  0.56024307  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>mean</th>\n      <th>sd</th>\n      <th>cv_1_valid</th>\n      <th>cv_2_valid</th>\n      <th>cv_3_valid</th>\n      <th>cv_4_valid</th>\n      <th>cv_5_valid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>accuracy</td>\n      <td>0.6813875</td>\n      <td>0.032319296</td>\n      <td>0.7108434</td>\n      <td>0.63095236</td>\n      <td>0.6987448</td>\n      <td>0.6680498</td>\n      <td>0.6983471</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>auc</td>\n      <td>0.6512176</td>\n      <td>0.020242797</td>\n      <td>0.6659452</td>\n      <td>0.64347064</td>\n      <td>0.6209906</td>\n      <td>0.67228264</td>\n      <td>0.65339893</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>aucpr</td>\n      <td>0.7582092</td>\n      <td>0.026206708</td>\n      <td>0.7725955</td>\n      <td>0.7343244</td>\n      <td>0.73981434</td>\n      <td>0.797079</td>\n      <td>0.74723285</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>err</td>\n      <td>0.31861252</td>\n      <td>0.032319296</td>\n      <td>0.28915662</td>\n      <td>0.3690476</td>\n      <td>0.30125523</td>\n      <td>0.33195022</td>\n      <td>0.30165288</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>err_count</td>\n      <td>78.0</td>\n      <td>9.027735</td>\n      <td>72.0</td>\n      <td>93.0</td>\n      <td>72.0</td>\n      <td>80.0</td>\n      <td>73.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>f0point5</td>\n      <td>0.7236188</td>\n      <td>0.027202625</td>\n      <td>0.7522124</td>\n      <td>0.68123394</td>\n      <td>0.73913044</td>\n      <td>0.71555555</td>\n      <td>0.7299618</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>f1</td>\n      <td>0.8002306</td>\n      <td>0.015225069</td>\n      <td>0.8095238</td>\n      <td>0.77372265</td>\n      <td>0.8095238</td>\n      <td>0.80099505</td>\n      <td>0.8073879</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>f2</td>\n      <td>0.8958176</td>\n      <td>0.012522429</td>\n      <td>0.87628865</td>\n      <td>0.8952703</td>\n      <td>0.8947368</td>\n      <td>0.90960455</td>\n      <td>0.9031877</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>lift_top_group</td>\n      <td>1.4234031</td>\n      <td>0.20615338</td>\n      <td>1.5090909</td>\n      <td>1.0566038</td>\n      <td>1.5031446</td>\n      <td>1.4968944</td>\n      <td>1.551282</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>logloss</td>\n      <td>1.2761745</td>\n      <td>0.1843319</td>\n      <td>1.1700575</td>\n      <td>1.3332363</td>\n      <td>1.5758824</td>\n      <td>1.1597352</td>\n      <td>1.1419615</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max_per_class_error</td>\n      <td>0.87064785</td>\n      <td>0.12570904</td>\n      <td>0.71428573</td>\n      <td>1.0</td>\n      <td>0.825</td>\n      <td>1.0</td>\n      <td>0.81395346</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>mcc</td>\n      <td>0.27236786</td>\n      <td>0.033709124</td>\n      <td>0.2863477</td>\n      <td>NaN</td>\n      <td>0.233918</td>\n      <td>NaN</td>\n      <td>0.2968379</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>mean_per_class_accuracy</td>\n      <td>0.5517067</td>\n      <td>0.04909224</td>\n      <td>0.60649353</td>\n      <td>0.5</td>\n      <td>0.56863207</td>\n      <td>0.5</td>\n      <td>0.5834079</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>mean_per_class_error</td>\n      <td>0.4482933</td>\n      <td>0.04909224</td>\n      <td>0.3935065</td>\n      <td>0.5</td>\n      <td>0.43136793</td>\n      <td>0.5</td>\n      <td>0.41659212</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>mse</td>\n      <td>0.31911555</td>\n      <td>0.054569524</td>\n      <td>0.30913097</td>\n      <td>0.30073154</td>\n      <td>0.4096822</td>\n      <td>0.2621607</td>\n      <td>0.31387228</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>pr_auc</td>\n      <td>0.7582092</td>\n      <td>0.026206708</td>\n      <td>0.7725955</td>\n      <td>0.7343244</td>\n      <td>0.73981434</td>\n      <td>0.797079</td>\n      <td>0.74723285</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>precision</td>\n      <td>0.6804082</td>\n      <td>0.033164605</td>\n      <td>0.7183099</td>\n      <td>0.63095236</td>\n      <td>0.69863015</td>\n      <td>0.6680498</td>\n      <td>0.68609864</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>r2</td>\n      <td>-0.41328508</td>\n      <td>0.251438</td>\n      <td>-0.38285926</td>\n      <td>-0.2915165</td>\n      <td>-0.83973724</td>\n      <td>-0.182186</td>\n      <td>-0.3701264</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>recall</td>\n      <td>0.97406125</td>\n      <td>0.030491687</td>\n      <td>0.92727274</td>\n      <td>1.0</td>\n      <td>0.9622642</td>\n      <td>1.0</td>\n      <td>0.9807692</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>rmse</td>\n      <td>0.5633418</td>\n      <td>0.046924848</td>\n      <td>0.55599546</td>\n      <td>0.5483899</td>\n      <td>0.64006424</td>\n      <td>0.5120163</td>\n      <td>0.56024307</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 46,
          "data": {
            "text/plain": "<bound method ModelBase.model_performance of >"
          },
          "metadata": {}
        }
      ],
      "execution_count": 46,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605467980010
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from h2o.estimators import H2OGeneralizedLinearEstimator\r\n",
        "\r\n",
        "top_glm = H2OGeneralizedLinearEstimator(**extract_params_from_model(best_glm_model.actual_params, ['lambda']))\r\n",
        "\r\n",
        "top_glm.train(x=x, y=y, training_frame=train_pca_df_frame, validation_frame=test_pca_df_frame)\r\n",
        "\r\n",
        "# h2o.save_model(top_glm, MODELS_LOCATION + \"PCA300/top_glm\")\r\n",
        "\r\n",
        "\r\n",
        "print('AUC on test_pca_df_frame data: ', top_glm.model_performance(valid=True).auc(), \"\\n\\n============================\")\r\n",
        "\r\n",
        "top_glm.model_performance"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glm Model Build progress: |███████████████████████████████████████████████| 100%\n",
            "AUC on test_pca_df_frame data:  0.6266381094130032 \n",
            "\n",
            "============================\n",
            "Model Details\n",
            "=============\n",
            "H2OGeneralizedLinearEstimator :  Generalized Linear Modeling\n",
            "Model Key:  GLM_model_python_1605467917228_20\n",
            "\n",
            "\n",
            "GLM Model: summary\n",
            "\n",
            "\n",
            "ModelMetricsBinomialGLM: glm\n",
            "** Reported on train data. **\n",
            "\n",
            "MSE: 0.06737869858143082\n",
            "RMSE: 0.2595740714736948\n",
            "LogLoss: 0.23465203622551015\n",
            "Null degrees of freedom: 1222\n",
            "Residual degrees of freedom: 922\n",
            "Null deviance: 1577.310356148988\n",
            "Residual deviance: 573.958880607598\n",
            "AIC: 1175.958880607598\n",
            "AUC: 0.9708421985815603\n",
            "AUCPR: 0.9839626762765715\n",
            "Gini: 0.9416843971631206\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "       family   link              regularization  number_of_predictors_total  \\\n0    binomial  logit  Ridge ( lambda = 0.01677 )                         300   \n\n  number_of_active_predictors  number_of_iterations training_frame  \n0                         300                     5  py_7_sid_80ae  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>family</th>\n      <th>link</th>\n      <th>regularization</th>\n      <th>number_of_predictors_total</th>\n      <th>number_of_active_predictors</th>\n      <th>number_of_iterations</th>\n      <th>training_frame</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>binomial</td>\n      <td>logit</td>\n      <td>Ridge ( lambda = 0.01677 )</td>\n      <td>300</td>\n      <td>300</td>\n      <td>5</td>\n      <td>py_7_sid_80ae</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5308632131207871: \n",
            "\n",
            "Maximum Metrics: Maximum metrics at their respective thresholds\n",
            "\n",
            "Gains/Lift Table: Avg response rate: 65.41 %, avg score: 65.41 %\n",
            "\n",
            "\n",
            "ModelMetricsBinomialGLM: glm\n",
            "** Reported on validation data. **\n",
            "\n",
            "MSE: 0.25607792452539224\n",
            "RMSE: 0.5060414257008928\n",
            "LogLoss: 0.9472698917241775\n",
            "Null degrees of freedom: 500\n",
            "Residual degrees of freedom: 200\n",
            "Null deviance: 633.0394016859412\n",
            "Residual deviance: 2383.229676671357\n",
            "AIC: 2985.229676671357\n",
            "AUC: 0.6266381094130032\n",
            "AUCPR: 0.7515512182825628\n",
            "Gini: 0.2532762188260065\n",
            "\n",
            "Confusion Matrix (Act/Pred) for max f1 @ threshold = 1.7755963216651885e-34: \n",
            "\n",
            "Maximum Metrics: Maximum metrics at their respective thresholds\n",
            "\n",
            "Gains/Lift Table: Avg response rate: 67.47 %, avg score: 64.06 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "              0      1   Error             Rate\n0      0  366.0   57.0  0.1348     (57.0/423.0)\n1      1   45.0  755.0  0.0563     (45.0/800.0)\n2  Total  411.0  812.0  0.0834   (102.0/1223.0)",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>366.0</td>\n      <td>57.0</td>\n      <td>0.1348</td>\n      <td>(57.0/423.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>45.0</td>\n      <td>755.0</td>\n      <td>0.0563</td>\n      <td>(45.0/800.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>411.0</td>\n      <td>812.0</td>\n      <td>0.0834</td>\n      <td>(102.0/1223.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                         metric  threshold       value    idx\n0                        max f1   0.530863    0.936725  219.0\n1                        max f2   0.350370    0.953659  270.0\n2                  max f0point5   0.708890    0.953228  167.0\n3                  max accuracy   0.642200    0.916599  188.0\n4                 max precision   0.999739    1.000000    0.0\n5                    max recall   0.113270    1.000000  347.0\n6               max specificity   0.999739    1.000000    0.0\n7              max absolute_mcc   0.642200    0.822160  188.0\n8    max min_per_class_accuracy   0.627963    0.912530  193.0\n9   max mean_per_class_accuracy   0.642200    0.919539  188.0\n10                      max tns   0.999739  423.000000    0.0\n11                      max fns   0.999739  784.000000    0.0\n12                      max fps   0.000207  423.000000  399.0\n13                      max tps   0.113270  800.000000  347.0\n14                      max tnr   0.999739    1.000000    0.0\n15                      max fnr   0.999739    0.980000    0.0\n16                      max fpr   0.000207    1.000000  399.0\n17                      max tpr   0.113270    1.000000  347.0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.530863</td>\n      <td>0.936725</td>\n      <td>219.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.350370</td>\n      <td>0.953659</td>\n      <td>270.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.708890</td>\n      <td>0.953228</td>\n      <td>167.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.642200</td>\n      <td>0.916599</td>\n      <td>188.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>0.999739</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.113270</td>\n      <td>1.000000</td>\n      <td>347.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>0.999739</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.642200</td>\n      <td>0.822160</td>\n      <td>188.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.627963</td>\n      <td>0.912530</td>\n      <td>193.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.642200</td>\n      <td>0.919539</td>\n      <td>188.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>0.999739</td>\n      <td>423.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>0.999739</td>\n      <td>784.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.000207</td>\n      <td>423.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.113270</td>\n      <td>800.000000</td>\n      <td>347.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>0.999739</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>0.999739</td>\n      <td>0.980000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.000207</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.113270</td>\n      <td>1.000000</td>\n      <td>347.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "      group  cumulative_data_fraction  lower_threshold      lift  \\\n0         1                  0.010630         0.999616  1.528750   \n1         2                  0.020442         0.998603  1.528750   \n2         3                  0.030253         0.997103  1.528750   \n3         4                  0.040065         0.995161  1.528750   \n4         5                  0.050695         0.993913  1.528750   \n5         6                  0.100572         0.987903  1.528750   \n6         7                  0.150450         0.979469  1.528750   \n7         8                  0.200327         0.969746  1.528750   \n8         9                  0.300082         0.945710  1.503689   \n9        10                  0.399836         0.898344  1.491158   \n10       11                  0.500409         0.823264  1.479035   \n11       12                  0.600164         0.678715  1.353320   \n12       13                  0.699918         0.423889  0.726783   \n13       14                  0.799673         0.229252  0.288207   \n14       15                  0.899428         0.077290  0.100246   \n15       16                  1.000000         0.000207  0.000000   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0          1.528750       1.000000  0.999787                  1.000000   \n1          1.528750       1.000000  0.999156                  1.000000   \n2          1.528750       1.000000  0.997897                  1.000000   \n3          1.528750       1.000000  0.996197                  1.000000   \n4          1.528750       1.000000  0.994620                  1.000000   \n5          1.528750       1.000000  0.991093                  1.000000   \n6          1.528750       1.000000  0.983049                  1.000000   \n7          1.528750       1.000000  0.975220                  1.000000   \n8          1.520419       0.983607  0.957797                  0.994550   \n9          1.513119       0.975410  0.922858                  0.989775   \n10         1.506268       0.967480  0.863465                  0.985294   \n11         1.480846       0.885246  0.758413                  0.968665   \n12         1.373375       0.475410  0.562245                  0.898364   \n13         1.238006       0.188525  0.324006                  0.809816   \n14         1.111818       0.065574  0.140127                  0.727273   \n15         1.000000       0.000000  0.039440                  0.654129   \n\n    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n0           0.999787       0.01625                  0.01625   52.875000   \n1           0.999484       0.01500                  0.03125   52.875000   \n2           0.998970       0.01500                  0.04625   52.875000   \n3           0.998291       0.01500                  0.06125   52.875000   \n4           0.997521       0.01625                  0.07750   52.875000   \n5           0.994333       0.07625                  0.15375   52.875000   \n6           0.990592       0.07625                  0.23000   52.875000   \n7           0.986765       0.07625                  0.30625   52.875000   \n8           0.977135       0.15000                  0.45625   50.368852   \n9           0.963594       0.14875                  0.60500   49.115779   \n10          0.943470       0.14875                  0.75375   47.903455   \n11          0.912711       0.13500                  0.88875   35.331967   \n12          0.862761       0.07250                  0.96125  -27.321721   \n13          0.795555       0.02875                  0.99000  -71.179303   \n14          0.722862       0.01000                  1.00000  -89.975410   \n15          0.654128       0.00000                  1.00000 -100.000000   \n\n    cumulative_gain  \n0         52.875000  \n1         52.875000  \n2         52.875000  \n3         52.875000  \n4         52.875000  \n5         52.875000  \n6         52.875000  \n7         52.875000  \n8         52.041894  \n9         51.311861  \n10        50.626838  \n11        48.084639  \n12        37.337471  \n13        23.800613  \n14        11.181818  \n15         0.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.010630</td>\n      <td>0.999616</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>0.999787</td>\n      <td>1.000000</td>\n      <td>0.999787</td>\n      <td>0.01625</td>\n      <td>0.01625</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.020442</td>\n      <td>0.998603</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>0.999156</td>\n      <td>1.000000</td>\n      <td>0.999484</td>\n      <td>0.01500</td>\n      <td>0.03125</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.030253</td>\n      <td>0.997103</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>0.997897</td>\n      <td>1.000000</td>\n      <td>0.998970</td>\n      <td>0.01500</td>\n      <td>0.04625</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.040065</td>\n      <td>0.995161</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>0.996197</td>\n      <td>1.000000</td>\n      <td>0.998291</td>\n      <td>0.01500</td>\n      <td>0.06125</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>0.050695</td>\n      <td>0.993913</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>0.994620</td>\n      <td>1.000000</td>\n      <td>0.997521</td>\n      <td>0.01625</td>\n      <td>0.07750</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>6</td>\n      <td>0.100572</td>\n      <td>0.987903</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>0.991093</td>\n      <td>1.000000</td>\n      <td>0.994333</td>\n      <td>0.07625</td>\n      <td>0.15375</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>0.150450</td>\n      <td>0.979469</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>0.983049</td>\n      <td>1.000000</td>\n      <td>0.990592</td>\n      <td>0.07625</td>\n      <td>0.23000</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>8</td>\n      <td>0.200327</td>\n      <td>0.969746</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>0.975220</td>\n      <td>1.000000</td>\n      <td>0.986765</td>\n      <td>0.07625</td>\n      <td>0.30625</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>9</td>\n      <td>0.300082</td>\n      <td>0.945710</td>\n      <td>1.503689</td>\n      <td>1.520419</td>\n      <td>0.983607</td>\n      <td>0.957797</td>\n      <td>0.994550</td>\n      <td>0.977135</td>\n      <td>0.15000</td>\n      <td>0.45625</td>\n      <td>50.368852</td>\n      <td>52.041894</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>10</td>\n      <td>0.399836</td>\n      <td>0.898344</td>\n      <td>1.491158</td>\n      <td>1.513119</td>\n      <td>0.975410</td>\n      <td>0.922858</td>\n      <td>0.989775</td>\n      <td>0.963594</td>\n      <td>0.14875</td>\n      <td>0.60500</td>\n      <td>49.115779</td>\n      <td>51.311861</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>11</td>\n      <td>0.500409</td>\n      <td>0.823264</td>\n      <td>1.479035</td>\n      <td>1.506268</td>\n      <td>0.967480</td>\n      <td>0.863465</td>\n      <td>0.985294</td>\n      <td>0.943470</td>\n      <td>0.14875</td>\n      <td>0.75375</td>\n      <td>47.903455</td>\n      <td>50.626838</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>12</td>\n      <td>0.600164</td>\n      <td>0.678715</td>\n      <td>1.353320</td>\n      <td>1.480846</td>\n      <td>0.885246</td>\n      <td>0.758413</td>\n      <td>0.968665</td>\n      <td>0.912711</td>\n      <td>0.13500</td>\n      <td>0.88875</td>\n      <td>35.331967</td>\n      <td>48.084639</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>13</td>\n      <td>0.699918</td>\n      <td>0.423889</td>\n      <td>0.726783</td>\n      <td>1.373375</td>\n      <td>0.475410</td>\n      <td>0.562245</td>\n      <td>0.898364</td>\n      <td>0.862761</td>\n      <td>0.07250</td>\n      <td>0.96125</td>\n      <td>-27.321721</td>\n      <td>37.337471</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>14</td>\n      <td>0.799673</td>\n      <td>0.229252</td>\n      <td>0.288207</td>\n      <td>1.238006</td>\n      <td>0.188525</td>\n      <td>0.324006</td>\n      <td>0.809816</td>\n      <td>0.795555</td>\n      <td>0.02875</td>\n      <td>0.99000</td>\n      <td>-71.179303</td>\n      <td>23.800613</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>15</td>\n      <td>0.899428</td>\n      <td>0.077290</td>\n      <td>0.100246</td>\n      <td>1.111818</td>\n      <td>0.065574</td>\n      <td>0.140127</td>\n      <td>0.727273</td>\n      <td>0.722862</td>\n      <td>0.01000</td>\n      <td>1.00000</td>\n      <td>-89.975410</td>\n      <td>11.181818</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>16</td>\n      <td>1.000000</td>\n      <td>0.000207</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.039440</td>\n      <td>0.654129</td>\n      <td>0.654128</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>-100.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "            0      1   Error            Rate\n0      0  0.0  163.0     1.0   (163.0/163.0)\n1      1  0.0  338.0     0.0     (0.0/338.0)\n2  Total  0.0  501.0  0.3253   (163.0/501.0)",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>163.0</td>\n      <td>1.0</td>\n      <td>(163.0/163.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>338.0</td>\n      <td>0.0</td>\n      <td>(0.0/338.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>0.0</td>\n      <td>501.0</td>\n      <td>0.3253</td>\n      <td>(163.0/501.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                         metric     threshold       value    idx\n0                        max f1  1.775596e-34    0.805721  399.0\n1                        max f2  1.775596e-34    0.912035  399.0\n2                  max f0point5  7.193462e-01    0.744361  180.0\n3                  max accuracy  5.300331e-02    0.678643  384.0\n4                 max precision  8.944720e-01    0.832117   89.0\n5                    max recall  1.775596e-34    1.000000  399.0\n6               max specificity  9.999816e-01    0.987730    0.0\n7              max absolute_mcc  7.274565e-01    0.262032  176.0\n8    max min_per_class_accuracy  6.789091e-01    0.612426  199.0\n9   max mean_per_class_accuracy  7.274565e-01    0.639743  176.0\n10                      max tns  9.999816e-01  161.000000    0.0\n11                      max fns  9.999816e-01  337.000000    0.0\n12                      max fps  8.439892e-03  163.000000  395.0\n13                      max tps  1.775596e-34  338.000000  399.0\n14                      max tnr  9.999816e-01    0.987730    0.0\n15                      max fnr  9.999816e-01    0.997041    0.0\n16                      max fpr  8.439892e-03    1.000000  395.0\n17                      max tpr  1.775596e-34    1.000000  399.0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>1.775596e-34</td>\n      <td>0.805721</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>1.775596e-34</td>\n      <td>0.912035</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>7.193462e-01</td>\n      <td>0.744361</td>\n      <td>180.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>5.300331e-02</td>\n      <td>0.678643</td>\n      <td>384.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>8.944720e-01</td>\n      <td>0.832117</td>\n      <td>89.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>1.775596e-34</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>9.999816e-01</td>\n      <td>0.987730</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>7.274565e-01</td>\n      <td>0.262032</td>\n      <td>176.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>6.789091e-01</td>\n      <td>0.612426</td>\n      <td>199.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>7.274565e-01</td>\n      <td>0.639743</td>\n      <td>176.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>9.999816e-01</td>\n      <td>161.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>9.999816e-01</td>\n      <td>337.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>8.439892e-03</td>\n      <td>163.000000</td>\n      <td>395.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>1.775596e-34</td>\n      <td>338.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>9.999816e-01</td>\n      <td>0.987730</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>9.999816e-01</td>\n      <td>0.997041</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>8.439892e-03</td>\n      <td>1.000000</td>\n      <td>395.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>1.775596e-34</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "      group  cumulative_data_fraction  lower_threshold      lift  \\\n0         1                  0.011976     9.993451e-01  0.741124   \n1         2                  0.021956     9.942697e-01  1.482249   \n2         3                  0.031936     9.906410e-01  0.889349   \n3         4                  0.041916     9.865676e-01  1.185799   \n4         5                  0.051896     9.830744e-01  1.482249   \n5         6                  0.101796     9.663331e-01  1.126509   \n6         7                  0.151697     9.474713e-01  1.363669   \n7         8                  0.201597     9.352137e-01  1.185799   \n8         9                  0.301397     8.765075e-01  1.245089   \n9        10                  0.401198     8.087037e-01  1.037574   \n10       11                  0.500998     7.178550e-01  1.185799   \n11       12                  0.602794     6.154637e-01  0.697529   \n12       13                  0.700599     4.934618e-01  0.756249   \n13       14                  0.800399     3.358252e-01  0.978284   \n14       15                  0.900200     1.369725e-01  0.889349   \n15       16                  1.000000     1.775596e-34  0.800414   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0          0.741124       0.500000  0.999707                  0.500000   \n1          1.077999       1.000000  0.995651                  0.727273   \n2          1.019046       0.600000  0.992628                  0.687500   \n3          1.058749       0.800000  0.988036                  0.714286   \n4          1.140191       1.000000  0.984516                  0.769231   \n5          1.133484       0.760000  0.974368                  0.764706   \n6          1.209203       0.920000  0.956715                  0.815789   \n7          1.203410       0.800000  0.940910                  0.811881   \n8          1.217211       0.840000  0.905349                  0.821192   \n9          1.172525       0.700000  0.848144                  0.791045   \n10         1.175169       0.800000  0.756387                  0.792829   \n11         1.094508       0.470588  0.661910                  0.738411   \n12         1.047287       0.510204  0.557423                  0.706553   \n13         1.038683       0.660000  0.426580                  0.700748   \n14         1.022127       0.600000  0.237362                  0.689579   \n15         1.000000       0.540000  0.071469                  0.674651   \n\n    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n0           0.999707      0.008876                 0.008876 -25.887574   \n1           0.997863      0.014793                 0.023669  48.224852   \n2           0.996227      0.008876                 0.032544 -11.065089   \n3           0.994277      0.011834                 0.044379  18.579882   \n4           0.992400      0.014793                 0.059172  48.224852   \n5           0.983561      0.056213                 0.115385  12.650888   \n6           0.974730      0.068047                 0.183432  36.366864   \n7           0.966359      0.059172                 0.242604  18.579882   \n8           0.946157      0.124260                 0.366864  24.508876   \n9           0.921775      0.103550                 0.470414   3.757396   \n10          0.888830      0.118343                 0.588757  18.579882   \n11          0.850509      0.071006                 0.659763 -30.247128   \n12          0.809594      0.073964                 0.733728 -24.375075   \n13          0.761836      0.097633                 0.831361  -2.171598   \n14          0.703690      0.088757                 0.920118 -11.065089   \n15          0.640595      0.079882                 1.000000 -19.958580   \n\n    cumulative_gain  \n0        -25.887574  \n1          7.799892  \n2          1.904586  \n3          5.874894  \n4         14.019117  \n5         13.348416  \n6         20.920274  \n7         20.340969  \n8         21.721071  \n9         17.252495  \n10        17.516915  \n11         9.450801  \n12         4.728670  \n13         3.868288  \n14         2.212703  \n15         0.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.011976</td>\n      <td>9.993451e-01</td>\n      <td>0.741124</td>\n      <td>0.741124</td>\n      <td>0.500000</td>\n      <td>0.999707</td>\n      <td>0.500000</td>\n      <td>0.999707</td>\n      <td>0.008876</td>\n      <td>0.008876</td>\n      <td>-25.887574</td>\n      <td>-25.887574</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.021956</td>\n      <td>9.942697e-01</td>\n      <td>1.482249</td>\n      <td>1.077999</td>\n      <td>1.000000</td>\n      <td>0.995651</td>\n      <td>0.727273</td>\n      <td>0.997863</td>\n      <td>0.014793</td>\n      <td>0.023669</td>\n      <td>48.224852</td>\n      <td>7.799892</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.031936</td>\n      <td>9.906410e-01</td>\n      <td>0.889349</td>\n      <td>1.019046</td>\n      <td>0.600000</td>\n      <td>0.992628</td>\n      <td>0.687500</td>\n      <td>0.996227</td>\n      <td>0.008876</td>\n      <td>0.032544</td>\n      <td>-11.065089</td>\n      <td>1.904586</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.041916</td>\n      <td>9.865676e-01</td>\n      <td>1.185799</td>\n      <td>1.058749</td>\n      <td>0.800000</td>\n      <td>0.988036</td>\n      <td>0.714286</td>\n      <td>0.994277</td>\n      <td>0.011834</td>\n      <td>0.044379</td>\n      <td>18.579882</td>\n      <td>5.874894</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>0.051896</td>\n      <td>9.830744e-01</td>\n      <td>1.482249</td>\n      <td>1.140191</td>\n      <td>1.000000</td>\n      <td>0.984516</td>\n      <td>0.769231</td>\n      <td>0.992400</td>\n      <td>0.014793</td>\n      <td>0.059172</td>\n      <td>48.224852</td>\n      <td>14.019117</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>6</td>\n      <td>0.101796</td>\n      <td>9.663331e-01</td>\n      <td>1.126509</td>\n      <td>1.133484</td>\n      <td>0.760000</td>\n      <td>0.974368</td>\n      <td>0.764706</td>\n      <td>0.983561</td>\n      <td>0.056213</td>\n      <td>0.115385</td>\n      <td>12.650888</td>\n      <td>13.348416</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>0.151697</td>\n      <td>9.474713e-01</td>\n      <td>1.363669</td>\n      <td>1.209203</td>\n      <td>0.920000</td>\n      <td>0.956715</td>\n      <td>0.815789</td>\n      <td>0.974730</td>\n      <td>0.068047</td>\n      <td>0.183432</td>\n      <td>36.366864</td>\n      <td>20.920274</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>8</td>\n      <td>0.201597</td>\n      <td>9.352137e-01</td>\n      <td>1.185799</td>\n      <td>1.203410</td>\n      <td>0.800000</td>\n      <td>0.940910</td>\n      <td>0.811881</td>\n      <td>0.966359</td>\n      <td>0.059172</td>\n      <td>0.242604</td>\n      <td>18.579882</td>\n      <td>20.340969</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>9</td>\n      <td>0.301397</td>\n      <td>8.765075e-01</td>\n      <td>1.245089</td>\n      <td>1.217211</td>\n      <td>0.840000</td>\n      <td>0.905349</td>\n      <td>0.821192</td>\n      <td>0.946157</td>\n      <td>0.124260</td>\n      <td>0.366864</td>\n      <td>24.508876</td>\n      <td>21.721071</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>10</td>\n      <td>0.401198</td>\n      <td>8.087037e-01</td>\n      <td>1.037574</td>\n      <td>1.172525</td>\n      <td>0.700000</td>\n      <td>0.848144</td>\n      <td>0.791045</td>\n      <td>0.921775</td>\n      <td>0.103550</td>\n      <td>0.470414</td>\n      <td>3.757396</td>\n      <td>17.252495</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>11</td>\n      <td>0.500998</td>\n      <td>7.178550e-01</td>\n      <td>1.185799</td>\n      <td>1.175169</td>\n      <td>0.800000</td>\n      <td>0.756387</td>\n      <td>0.792829</td>\n      <td>0.888830</td>\n      <td>0.118343</td>\n      <td>0.588757</td>\n      <td>18.579882</td>\n      <td>17.516915</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>12</td>\n      <td>0.602794</td>\n      <td>6.154637e-01</td>\n      <td>0.697529</td>\n      <td>1.094508</td>\n      <td>0.470588</td>\n      <td>0.661910</td>\n      <td>0.738411</td>\n      <td>0.850509</td>\n      <td>0.071006</td>\n      <td>0.659763</td>\n      <td>-30.247128</td>\n      <td>9.450801</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>13</td>\n      <td>0.700599</td>\n      <td>4.934618e-01</td>\n      <td>0.756249</td>\n      <td>1.047287</td>\n      <td>0.510204</td>\n      <td>0.557423</td>\n      <td>0.706553</td>\n      <td>0.809594</td>\n      <td>0.073964</td>\n      <td>0.733728</td>\n      <td>-24.375075</td>\n      <td>4.728670</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>14</td>\n      <td>0.800399</td>\n      <td>3.358252e-01</td>\n      <td>0.978284</td>\n      <td>1.038683</td>\n      <td>0.660000</td>\n      <td>0.426580</td>\n      <td>0.700748</td>\n      <td>0.761836</td>\n      <td>0.097633</td>\n      <td>0.831361</td>\n      <td>-2.171598</td>\n      <td>3.868288</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>15</td>\n      <td>0.900200</td>\n      <td>1.369725e-01</td>\n      <td>0.889349</td>\n      <td>1.022127</td>\n      <td>0.600000</td>\n      <td>0.237362</td>\n      <td>0.689579</td>\n      <td>0.703690</td>\n      <td>0.088757</td>\n      <td>0.920118</td>\n      <td>-11.065089</td>\n      <td>2.212703</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>16</td>\n      <td>1.000000</td>\n      <td>1.775596e-34</td>\n      <td>0.800414</td>\n      <td>1.000000</td>\n      <td>0.540000</td>\n      <td>0.071469</td>\n      <td>0.674651</td>\n      <td>0.640595</td>\n      <td>0.079882</td>\n      <td>1.000000</td>\n      <td>-19.958580</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "ModelMetricsBinomialGLM: glm\n",
            "** Reported on cross-validation data. **\n",
            "\n",
            "MSE: 0.1395447128968992\n",
            "RMSE: 0.3735568402491102\n",
            "LogLoss: 0.4527805055290165\n",
            "Null degrees of freedom: 1222\n",
            "Residual degrees of freedom: 922\n",
            "Null deviance: 1577.9471491067366\n",
            "Residual deviance: 1107.5011165239741\n",
            "AIC: 1709.5011165239741\n",
            "AUC: 0.8693484042553191\n",
            "AUCPR: 0.9206885107574454\n",
            "Gini: 0.7386968085106382\n",
            "\n",
            "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5371233996347867: \n",
            "\n",
            "Maximum Metrics: Maximum metrics at their respective thresholds\n",
            "\n",
            "Gains/Lift Table: Avg response rate: 65.41 %, avg score: 66.03 %\n",
            "\n",
            "\n",
            "Cross-Validation Metrics Summary: \n",
            "\n",
            "See the whole table with table.as_data_frame()\n",
            "\n",
            "Scoring History: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "              0      1   Error             Rate\n0      0  290.0  133.0  0.3144    (133.0/423.0)\n1      1  102.0  698.0  0.1275    (102.0/800.0)\n2  Total  392.0  831.0  0.1922   (235.0/1223.0)",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>290.0</td>\n      <td>133.0</td>\n      <td>0.3144</td>\n      <td>(133.0/423.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>102.0</td>\n      <td>698.0</td>\n      <td>0.1275</td>\n      <td>(102.0/800.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>392.0</td>\n      <td>831.0</td>\n      <td>0.1922</td>\n      <td>(235.0/1223.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                         metric  threshold       value    idx\n0                        max f1   0.537123    0.855917  218.0\n1                        max f2   0.119758    0.910047  344.0\n2                  max f0point5   0.735585    0.868885  152.0\n3                  max accuracy   0.550566    0.808667  213.0\n4                 max precision   0.999730    1.000000    0.0\n5                    max recall   0.000151    1.000000  399.0\n6               max specificity   0.999730    1.000000    0.0\n7              max absolute_mcc   0.694445    0.583450  170.0\n8    max min_per_class_accuracy   0.702083    0.798750  167.0\n9   max mean_per_class_accuracy   0.735585    0.801497  152.0\n10                      max tns   0.999730  423.000000    0.0\n11                      max fns   0.999730  790.000000    0.0\n12                      max fps   0.000151  423.000000  399.0\n13                      max tps   0.000151  800.000000  399.0\n14                      max tnr   0.999730    1.000000    0.0\n15                      max fnr   0.999730    0.987500    0.0\n16                      max fpr   0.000151    1.000000  399.0\n17                      max tpr   0.000151    1.000000  399.0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.537123</td>\n      <td>0.855917</td>\n      <td>218.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.119758</td>\n      <td>0.910047</td>\n      <td>344.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.735585</td>\n      <td>0.868885</td>\n      <td>152.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.550566</td>\n      <td>0.808667</td>\n      <td>213.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>0.999730</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.000151</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>0.999730</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.694445</td>\n      <td>0.583450</td>\n      <td>170.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.702083</td>\n      <td>0.798750</td>\n      <td>167.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.735585</td>\n      <td>0.801497</td>\n      <td>152.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>0.999730</td>\n      <td>423.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>0.999730</td>\n      <td>790.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.000151</td>\n      <td>423.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.000151</td>\n      <td>800.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>0.999730</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>0.999730</td>\n      <td>0.987500</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.000151</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.000151</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "      group  cumulative_data_fraction  lower_threshold      lift  \\\n0         1                  0.010630         0.998523  1.411154   \n1         2                  0.020442         0.997224  1.401354   \n2         3                  0.030253         0.996328  1.528750   \n3         4                  0.040065         0.994908  1.528750   \n4         5                  0.050695         0.993039  1.411154   \n5         6                  0.100572         0.984540  1.528750   \n6         7                  0.150450         0.975300  1.478627   \n7         8                  0.200327         0.963804  1.478627   \n8         9                  0.300082         0.929459  1.453566   \n9        10                  0.399836         0.872848  1.303197   \n10       11                  0.500409         0.792277  1.280173   \n11       12                  0.600164         0.686784  1.065113   \n12       13                  0.699918         0.494666  0.739314   \n13       14                  0.799673         0.281606  0.588945   \n14       15                  0.899428         0.094618  0.350861   \n15       16                  1.000000         0.000060  0.248577   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0          1.411154       0.923077  0.999516                  0.923077   \n1          1.406450       0.916667  0.998027                  0.920000   \n2          1.446115       1.000000  0.996829                  0.945946   \n3          1.466352       1.000000  0.995508                  0.959184   \n4          1.454778       0.923077  0.993942                  0.951613   \n5          1.491463       1.000000  0.988600                  0.975610   \n6          1.487208       0.967213  0.980045                  0.972826   \n7          1.485071       0.967213  0.969176                  0.971429   \n8          1.474598       0.950820  0.948175                  0.964578   \n9          1.431835       0.852459  0.903500                  0.936605   \n10         1.401354       0.837398  0.837360                  0.916667   \n11         1.345467       0.696721  0.739974                  0.880109   \n12         1.259076       0.483607  0.593596                  0.823598   \n13         1.175481       0.385246  0.387120                  0.768916   \n14         1.084023       0.229508  0.180079                  0.709091   \n15         1.000000       0.162602  0.046484                  0.654129   \n\n    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n0           0.999516       0.01500                  0.01500  41.115385   \n1           0.998801       0.01375                  0.02875  40.135417   \n2           0.998162       0.01500                  0.04375  52.875000   \n3           0.997512       0.01500                  0.05875  52.875000   \n4           0.996763       0.01500                  0.07375  41.115385   \n5           0.992715       0.07625                  0.15000  52.875000   \n6           0.988515       0.07375                  0.22375  47.862705   \n7           0.983700       0.07375                  0.29750  47.862705   \n8           0.971890       0.14500                  0.44250  45.356557   \n9           0.954828       0.13000                  0.57250  30.319672   \n10          0.931219       0.12875                  0.70125  28.017276   \n11          0.899432       0.10625                  0.80750   6.511270   \n12          0.855843       0.07375                  0.88125 -26.068648   \n13          0.797372       0.05875                  0.94000 -41.105533   \n14          0.728909       0.03500                  0.97500 -64.913934   \n15          0.660276       0.02500                  1.00000 -75.142276   \n\n    cumulative_gain  \n0         41.115385  \n1         40.645000  \n2         44.611486  \n3         46.635204  \n4         45.477823  \n5         49.146341  \n6         48.720788  \n7         48.507143  \n8         47.459809  \n9         43.183538  \n10        40.135417  \n11        34.546662  \n12        25.907564  \n13        17.548057  \n14         8.402273  \n15         0.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.010630</td>\n      <td>0.998523</td>\n      <td>1.411154</td>\n      <td>1.411154</td>\n      <td>0.923077</td>\n      <td>0.999516</td>\n      <td>0.923077</td>\n      <td>0.999516</td>\n      <td>0.01500</td>\n      <td>0.01500</td>\n      <td>41.115385</td>\n      <td>41.115385</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.020442</td>\n      <td>0.997224</td>\n      <td>1.401354</td>\n      <td>1.406450</td>\n      <td>0.916667</td>\n      <td>0.998027</td>\n      <td>0.920000</td>\n      <td>0.998801</td>\n      <td>0.01375</td>\n      <td>0.02875</td>\n      <td>40.135417</td>\n      <td>40.645000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.030253</td>\n      <td>0.996328</td>\n      <td>1.528750</td>\n      <td>1.446115</td>\n      <td>1.000000</td>\n      <td>0.996829</td>\n      <td>0.945946</td>\n      <td>0.998162</td>\n      <td>0.01500</td>\n      <td>0.04375</td>\n      <td>52.875000</td>\n      <td>44.611486</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.040065</td>\n      <td>0.994908</td>\n      <td>1.528750</td>\n      <td>1.466352</td>\n      <td>1.000000</td>\n      <td>0.995508</td>\n      <td>0.959184</td>\n      <td>0.997512</td>\n      <td>0.01500</td>\n      <td>0.05875</td>\n      <td>52.875000</td>\n      <td>46.635204</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>0.050695</td>\n      <td>0.993039</td>\n      <td>1.411154</td>\n      <td>1.454778</td>\n      <td>0.923077</td>\n      <td>0.993942</td>\n      <td>0.951613</td>\n      <td>0.996763</td>\n      <td>0.01500</td>\n      <td>0.07375</td>\n      <td>41.115385</td>\n      <td>45.477823</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>6</td>\n      <td>0.100572</td>\n      <td>0.984540</td>\n      <td>1.528750</td>\n      <td>1.491463</td>\n      <td>1.000000</td>\n      <td>0.988600</td>\n      <td>0.975610</td>\n      <td>0.992715</td>\n      <td>0.07625</td>\n      <td>0.15000</td>\n      <td>52.875000</td>\n      <td>49.146341</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>0.150450</td>\n      <td>0.975300</td>\n      <td>1.478627</td>\n      <td>1.487208</td>\n      <td>0.967213</td>\n      <td>0.980045</td>\n      <td>0.972826</td>\n      <td>0.988515</td>\n      <td>0.07375</td>\n      <td>0.22375</td>\n      <td>47.862705</td>\n      <td>48.720788</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>8</td>\n      <td>0.200327</td>\n      <td>0.963804</td>\n      <td>1.478627</td>\n      <td>1.485071</td>\n      <td>0.967213</td>\n      <td>0.969176</td>\n      <td>0.971429</td>\n      <td>0.983700</td>\n      <td>0.07375</td>\n      <td>0.29750</td>\n      <td>47.862705</td>\n      <td>48.507143</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>9</td>\n      <td>0.300082</td>\n      <td>0.929459</td>\n      <td>1.453566</td>\n      <td>1.474598</td>\n      <td>0.950820</td>\n      <td>0.948175</td>\n      <td>0.964578</td>\n      <td>0.971890</td>\n      <td>0.14500</td>\n      <td>0.44250</td>\n      <td>45.356557</td>\n      <td>47.459809</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>10</td>\n      <td>0.399836</td>\n      <td>0.872848</td>\n      <td>1.303197</td>\n      <td>1.431835</td>\n      <td>0.852459</td>\n      <td>0.903500</td>\n      <td>0.936605</td>\n      <td>0.954828</td>\n      <td>0.13000</td>\n      <td>0.57250</td>\n      <td>30.319672</td>\n      <td>43.183538</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>11</td>\n      <td>0.500409</td>\n      <td>0.792277</td>\n      <td>1.280173</td>\n      <td>1.401354</td>\n      <td>0.837398</td>\n      <td>0.837360</td>\n      <td>0.916667</td>\n      <td>0.931219</td>\n      <td>0.12875</td>\n      <td>0.70125</td>\n      <td>28.017276</td>\n      <td>40.135417</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>12</td>\n      <td>0.600164</td>\n      <td>0.686784</td>\n      <td>1.065113</td>\n      <td>1.345467</td>\n      <td>0.696721</td>\n      <td>0.739974</td>\n      <td>0.880109</td>\n      <td>0.899432</td>\n      <td>0.10625</td>\n      <td>0.80750</td>\n      <td>6.511270</td>\n      <td>34.546662</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>13</td>\n      <td>0.699918</td>\n      <td>0.494666</td>\n      <td>0.739314</td>\n      <td>1.259076</td>\n      <td>0.483607</td>\n      <td>0.593596</td>\n      <td>0.823598</td>\n      <td>0.855843</td>\n      <td>0.07375</td>\n      <td>0.88125</td>\n      <td>-26.068648</td>\n      <td>25.907564</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>14</td>\n      <td>0.799673</td>\n      <td>0.281606</td>\n      <td>0.588945</td>\n      <td>1.175481</td>\n      <td>0.385246</td>\n      <td>0.387120</td>\n      <td>0.768916</td>\n      <td>0.797372</td>\n      <td>0.05875</td>\n      <td>0.94000</td>\n      <td>-41.105533</td>\n      <td>17.548057</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>15</td>\n      <td>0.899428</td>\n      <td>0.094618</td>\n      <td>0.350861</td>\n      <td>1.084023</td>\n      <td>0.229508</td>\n      <td>0.180079</td>\n      <td>0.709091</td>\n      <td>0.728909</td>\n      <td>0.03500</td>\n      <td>0.97500</td>\n      <td>-64.913934</td>\n      <td>8.402273</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>16</td>\n      <td>1.000000</td>\n      <td>0.000060</td>\n      <td>0.248577</td>\n      <td>1.000000</td>\n      <td>0.162602</td>\n      <td>0.046484</td>\n      <td>0.654129</td>\n      <td>0.660276</td>\n      <td>0.02500</td>\n      <td>1.00000</td>\n      <td>-75.142276</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                                   mean           sd  cv_1_valid  cv_2_valid  \\\n0                  accuracy   0.8160008  0.021070773   0.7871486   0.8373016   \n1                       auc   0.8698101  0.015944941  0.84415585   0.8861838   \n2                     aucpr  0.92141294  0.018122284   0.8909563   0.9269646   \n3                       err  0.18399917  0.021070773   0.2128514  0.16269842   \n4                 err_count        45.0    5.2440443        53.0        41.0   \n5                  f0point5   0.8489646  0.028703708   0.8145766   0.8882907   \n6                        f1  0.86426866   0.01006933   0.8515406  0.86557376   \n7                        f2   0.8812137  0.021759702   0.8920188   0.8439898   \n8            lift_top_group   1.4284575   0.23887382   1.0060606   1.5849056   \n9                   logloss  0.45273125   0.03007873  0.49771476   0.4211145   \n10      max_per_class_error  0.33949107  0.118501484  0.47619048  0.16981132   \n11                      mcc   0.5833133   0.06423936    0.500812  0.66434956   \n12  mean_per_class_accuracy   0.7789316   0.04571704   0.7225108   0.8398255   \n13     mean_per_class_error  0.22106838   0.04571704   0.2774892  0.16017447   \n14                      mse   0.1395134  0.008161301  0.15205601  0.13344538   \n15            null_deviance   315.58942   11.1641865   318.47858   332.80194   \n16                   pr_auc  0.92141294  0.018122284   0.8909563   0.9269646   \n17                precision   0.8396076  0.043236114   0.7916667   0.9041096   \n18                       r2   0.3823241  0.040417697  0.31979617  0.42690775   \n19                   recall  0.89349955    0.0373235  0.92121214   0.8301887   \n\n    cv_3_valid  cv_4_valid  cv_5_valid  \n0    0.8033473   0.8340249   0.8181818  \n1    0.8792453   0.8706522  0.86881334  \n2   0.93958586  0.92370063  0.92585725  \n3   0.19665273  0.16597511  0.18181819  \n4         47.0        40.0        44.0  \n5    0.8304892   0.8639053    0.847561  \n6    0.8613569   0.8795181    0.863354  \n7   0.89460784   0.8957055  0.87974685  \n8    1.5031446   1.4968944    1.551282  \n9   0.43569115  0.44234762   0.4667883  \n10       0.425      0.3125   0.3139535  \n11  0.53980726   0.6165101  0.59508747  \n12   0.7466195  0.79716617   0.7885361  \n13   0.2533805  0.20283385  0.21146393  \n14  0.13846648  0.13148622  0.14211294  \n15   304.91693    306.6569    315.0928  \n16  0.93958586  0.92370063  0.92585725  \n17   0.8111111   0.8538012   0.8373494  \n18  0.37819624  0.40707675  0.37964353  \n19    0.918239   0.9068323  0.89102566  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>mean</th>\n      <th>sd</th>\n      <th>cv_1_valid</th>\n      <th>cv_2_valid</th>\n      <th>cv_3_valid</th>\n      <th>cv_4_valid</th>\n      <th>cv_5_valid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>accuracy</td>\n      <td>0.8160008</td>\n      <td>0.021070773</td>\n      <td>0.7871486</td>\n      <td>0.8373016</td>\n      <td>0.8033473</td>\n      <td>0.8340249</td>\n      <td>0.8181818</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>auc</td>\n      <td>0.8698101</td>\n      <td>0.015944941</td>\n      <td>0.84415585</td>\n      <td>0.8861838</td>\n      <td>0.8792453</td>\n      <td>0.8706522</td>\n      <td>0.86881334</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>aucpr</td>\n      <td>0.92141294</td>\n      <td>0.018122284</td>\n      <td>0.8909563</td>\n      <td>0.9269646</td>\n      <td>0.93958586</td>\n      <td>0.92370063</td>\n      <td>0.92585725</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>err</td>\n      <td>0.18399917</td>\n      <td>0.021070773</td>\n      <td>0.2128514</td>\n      <td>0.16269842</td>\n      <td>0.19665273</td>\n      <td>0.16597511</td>\n      <td>0.18181819</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>err_count</td>\n      <td>45.0</td>\n      <td>5.2440443</td>\n      <td>53.0</td>\n      <td>41.0</td>\n      <td>47.0</td>\n      <td>40.0</td>\n      <td>44.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>f0point5</td>\n      <td>0.8489646</td>\n      <td>0.028703708</td>\n      <td>0.8145766</td>\n      <td>0.8882907</td>\n      <td>0.8304892</td>\n      <td>0.8639053</td>\n      <td>0.847561</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>f1</td>\n      <td>0.86426866</td>\n      <td>0.01006933</td>\n      <td>0.8515406</td>\n      <td>0.86557376</td>\n      <td>0.8613569</td>\n      <td>0.8795181</td>\n      <td>0.863354</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>f2</td>\n      <td>0.8812137</td>\n      <td>0.021759702</td>\n      <td>0.8920188</td>\n      <td>0.8439898</td>\n      <td>0.89460784</td>\n      <td>0.8957055</td>\n      <td>0.87974685</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>lift_top_group</td>\n      <td>1.4284575</td>\n      <td>0.23887382</td>\n      <td>1.0060606</td>\n      <td>1.5849056</td>\n      <td>1.5031446</td>\n      <td>1.4968944</td>\n      <td>1.551282</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>logloss</td>\n      <td>0.45273125</td>\n      <td>0.03007873</td>\n      <td>0.49771476</td>\n      <td>0.4211145</td>\n      <td>0.43569115</td>\n      <td>0.44234762</td>\n      <td>0.4667883</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max_per_class_error</td>\n      <td>0.33949107</td>\n      <td>0.118501484</td>\n      <td>0.47619048</td>\n      <td>0.16981132</td>\n      <td>0.425</td>\n      <td>0.3125</td>\n      <td>0.3139535</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>mcc</td>\n      <td>0.5833133</td>\n      <td>0.06423936</td>\n      <td>0.500812</td>\n      <td>0.66434956</td>\n      <td>0.53980726</td>\n      <td>0.6165101</td>\n      <td>0.59508747</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>mean_per_class_accuracy</td>\n      <td>0.7789316</td>\n      <td>0.04571704</td>\n      <td>0.7225108</td>\n      <td>0.8398255</td>\n      <td>0.7466195</td>\n      <td>0.79716617</td>\n      <td>0.7885361</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>mean_per_class_error</td>\n      <td>0.22106838</td>\n      <td>0.04571704</td>\n      <td>0.2774892</td>\n      <td>0.16017447</td>\n      <td>0.2533805</td>\n      <td>0.20283385</td>\n      <td>0.21146393</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>mse</td>\n      <td>0.1395134</td>\n      <td>0.008161301</td>\n      <td>0.15205601</td>\n      <td>0.13344538</td>\n      <td>0.13846648</td>\n      <td>0.13148622</td>\n      <td>0.14211294</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>null_deviance</td>\n      <td>315.58942</td>\n      <td>11.1641865</td>\n      <td>318.47858</td>\n      <td>332.80194</td>\n      <td>304.91693</td>\n      <td>306.6569</td>\n      <td>315.0928</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>pr_auc</td>\n      <td>0.92141294</td>\n      <td>0.018122284</td>\n      <td>0.8909563</td>\n      <td>0.9269646</td>\n      <td>0.93958586</td>\n      <td>0.92370063</td>\n      <td>0.92585725</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>precision</td>\n      <td>0.8396076</td>\n      <td>0.043236114</td>\n      <td>0.7916667</td>\n      <td>0.9041096</td>\n      <td>0.8111111</td>\n      <td>0.8538012</td>\n      <td>0.8373494</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>r2</td>\n      <td>0.3823241</td>\n      <td>0.040417697</td>\n      <td>0.31979617</td>\n      <td>0.42690775</td>\n      <td>0.37819624</td>\n      <td>0.40707675</td>\n      <td>0.37964353</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>recall</td>\n      <td>0.89349955</td>\n      <td>0.0373235</td>\n      <td>0.92121214</td>\n      <td>0.8301887</td>\n      <td>0.918239</td>\n      <td>0.9068323</td>\n      <td>0.89102566</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "               timestamp    duration  iterations  negative_log_likelihood  \\\n0    2020-11-15 19:19:41   0.000 sec           0               788.655178   \n1    2020-11-15 19:19:41   0.120 sec           1               378.294602   \n2    2020-11-15 19:19:41   0.153 sec           2               312.852395   \n3    2020-11-15 19:19:41   0.185 sec           3               291.179150   \n4    2020-11-15 19:19:41   0.216 sec           4               287.185359   \n5    2020-11-15 19:19:41   0.246 sec           5               286.979440   \n\n   objective  \n0   0.644853  \n1   0.328072  \n2   0.292164  \n3   0.286272  \n4   0.285953  \n5   0.285951  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>timestamp</th>\n      <th>duration</th>\n      <th>iterations</th>\n      <th>negative_log_likelihood</th>\n      <th>objective</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>2020-11-15 19:19:41</td>\n      <td>0.000 sec</td>\n      <td>0</td>\n      <td>788.655178</td>\n      <td>0.644853</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2020-11-15 19:19:41</td>\n      <td>0.120 sec</td>\n      <td>1</td>\n      <td>378.294602</td>\n      <td>0.328072</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>2020-11-15 19:19:41</td>\n      <td>0.153 sec</td>\n      <td>2</td>\n      <td>312.852395</td>\n      <td>0.292164</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>2020-11-15 19:19:41</td>\n      <td>0.185 sec</td>\n      <td>3</td>\n      <td>291.179150</td>\n      <td>0.286272</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>2020-11-15 19:19:41</td>\n      <td>0.216 sec</td>\n      <td>4</td>\n      <td>287.185359</td>\n      <td>0.285953</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>2020-11-15 19:19:41</td>\n      <td>0.246 sec</td>\n      <td>5</td>\n      <td>286.979440</td>\n      <td>0.285951</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 47,
          "data": {
            "text/plain": "<bound method ModelBase.model_performance of >"
          },
          "metadata": {}
        }
      ],
      "execution_count": 47,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605467983997
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from h2o.estimators import H2OGradientBoostingEstimator\r\n",
        "\r\n",
        "top_gbm = H2OGradientBoostingEstimator(**extract_params_from_model(best_gbm_model.actual_params))\r\n",
        "\r\n",
        "top_gbm.train(x=x, y=y, training_frame=train_pca_df_frame, validation_frame=test_pca_df_frame)\r\n",
        "\r\n",
        "# h2o.save_model(top_gbm, MODELS_LOCATION + \"PCA300/top_gbm\")\r\n",
        "\r\n",
        "\r\n",
        "print('AUC on test_pca_df_frame data: ', top_gbm.model_performance(valid=True).auc(), \"\\n\\n============================\")\r\n",
        "\r\n",
        "top_gbm.model_performance"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
            "AUC on test_pca_df_frame data:  0.5569935020147384 \n",
            "\n",
            "============================\n",
            "Model Details\n",
            "=============\n",
            "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
            "Model Key:  GBM_model_python_1605450290525_39\n",
            "\n",
            "\n",
            "Model Summary: \n",
            "\n",
            "\n",
            "ModelMetricsBinomial: gbm\n",
            "** Reported on train data. **\n",
            "\n",
            "MSE: 2.015691192817385e-33\n",
            "RMSE: 4.4896449668290976e-17\n",
            "LogLoss: 9.622538071158348e-18\n",
            "Mean Per-Class Error: 0.0\n",
            "AUC: 1.0\n",
            "AUCPR: 1.0\n",
            "Gini: 1.0\n",
            "\n",
            "Confusion Matrix (Act/Pred) for max f1 @ threshold = 1.0: \n",
            "\n",
            "Maximum Metrics: Maximum metrics at their respective thresholds\n",
            "\n",
            "Gains/Lift Table: Avg response rate: 65.41 %, avg score: 65.41 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "     number_of_trees  number_of_internal_trees  model_size_in_bytes  \\\n0              150.0                     150.0              80462.0   \n\n   min_depth  max_depth  mean_depth  min_leaves  max_leaves  mean_leaves  \n0        1.0       10.0    7.686667         2.0        87.0     37.97333  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>number_of_trees</th>\n      <th>number_of_internal_trees</th>\n      <th>model_size_in_bytes</th>\n      <th>min_depth</th>\n      <th>max_depth</th>\n      <th>mean_depth</th>\n      <th>min_leaves</th>\n      <th>max_leaves</th>\n      <th>mean_leaves</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>150.0</td>\n      <td>150.0</td>\n      <td>80462.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>7.686667</td>\n      <td>2.0</td>\n      <td>87.0</td>\n      <td>37.97333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "              0      1 Error           Rate\n0      0  423.0    0.0   0.0    (0.0/423.0)\n1      1    0.0  800.0   0.0    (0.0/800.0)\n2  Total  423.0  800.0   0.0   (0.0/1223.0)",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>423.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>(0.0/423.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>800.0</td>\n      <td>0.0</td>\n      <td>(0.0/800.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>423.0</td>\n      <td>800.0</td>\n      <td>0.0</td>\n      <td>(0.0/1223.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                         metric     threshold  value    idx\n0                        max f1  1.000000e+00    1.0    0.0\n1                        max f2  1.000000e+00    1.0    0.0\n2                  max f0point5  1.000000e+00    1.0    0.0\n3                  max accuracy  1.000000e+00    1.0    0.0\n4                 max precision  1.000000e+00    1.0    0.0\n5                    max recall  1.000000e+00    1.0    0.0\n6               max specificity  1.000000e+00    1.0    0.0\n7              max absolute_mcc  1.000000e+00    1.0    0.0\n8    max min_per_class_accuracy  1.000000e+00    1.0    0.0\n9   max mean_per_class_accuracy  1.000000e+00    1.0    0.0\n10                      max tns  1.000000e+00  423.0    0.0\n11                      max fns  1.000000e+00    0.0    0.0\n12                      max fps  1.000000e-19  423.0  368.0\n13                      max tps  1.000000e+00  800.0    0.0\n14                      max tnr  1.000000e+00    1.0    0.0\n15                      max fnr  1.000000e+00    0.0    0.0\n16                      max fpr  1.000000e-19    1.0  368.0\n17                      max tpr  1.000000e+00    1.0    0.0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>1.000000e+00</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>1.000000e+00</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>1.000000e+00</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>1.000000e+00</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>1.000000e+00</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>1.000000e+00</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>1.000000e+00</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>1.000000e+00</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>1.000000e+00</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>1.000000e+00</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>1.000000e+00</td>\n      <td>423.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>1.000000e+00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>1.000000e-19</td>\n      <td>423.0</td>\n      <td>368.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>1.000000e+00</td>\n      <td>800.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>1.000000e+00</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>1.000000e+00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>1.000000e-19</td>\n      <td>1.0</td>\n      <td>368.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>1.000000e+00</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "     group  cumulative_data_fraction  lower_threshold      lift  \\\n0        1                  0.616517     1.000000e+00  1.528750   \n1        2                  0.699918     2.087403e-17  0.689436   \n2        3                  0.799673     3.586533e-18  0.000000   \n3        4                  0.899428     5.047307e-19  0.000000   \n4        5                  1.000000     1.000000e-19  0.000000   \n\n   cumulative_lift  response_rate         score  cumulative_response_rate  \\\n0         1.528750        1.00000  1.000000e+00                  1.000000   \n1         1.428738        0.45098  4.509804e-01                  0.934579   \n2         1.250511        0.00000  9.679615e-18                  0.817996   \n3         1.111818        0.00000  1.630406e-18                  0.727273   \n4         1.000000        0.00000  1.859889e-19                  0.654129   \n\n   cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n0          1.000000        0.9425                   0.9425   52.875000   \n1          0.934579        0.0575                   1.0000  -31.056373   \n2          0.817996        0.0000                   1.0000 -100.000000   \n3          0.727273        0.0000                   1.0000 -100.000000   \n4          0.654129        0.0000                   1.0000 -100.000000   \n\n   cumulative_gain  \n0        52.875000  \n1        42.873832  \n2        25.051125  \n3        11.181818  \n4         0.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.616517</td>\n      <td>1.000000e+00</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.00000</td>\n      <td>1.000000e+00</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.9425</td>\n      <td>0.9425</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.699918</td>\n      <td>2.087403e-17</td>\n      <td>0.689436</td>\n      <td>1.428738</td>\n      <td>0.45098</td>\n      <td>4.509804e-01</td>\n      <td>0.934579</td>\n      <td>0.934579</td>\n      <td>0.0575</td>\n      <td>1.0000</td>\n      <td>-31.056373</td>\n      <td>42.873832</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.799673</td>\n      <td>3.586533e-18</td>\n      <td>0.000000</td>\n      <td>1.250511</td>\n      <td>0.00000</td>\n      <td>9.679615e-18</td>\n      <td>0.817996</td>\n      <td>0.817996</td>\n      <td>0.0000</td>\n      <td>1.0000</td>\n      <td>-100.000000</td>\n      <td>25.051125</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.899428</td>\n      <td>5.047307e-19</td>\n      <td>0.000000</td>\n      <td>1.111818</td>\n      <td>0.00000</td>\n      <td>1.630406e-18</td>\n      <td>0.727273</td>\n      <td>0.727273</td>\n      <td>0.0000</td>\n      <td>1.0000</td>\n      <td>-100.000000</td>\n      <td>11.181818</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>1.000000</td>\n      <td>1.000000e-19</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.00000</td>\n      <td>1.859889e-19</td>\n      <td>0.654129</td>\n      <td>0.654129</td>\n      <td>0.0000</td>\n      <td>1.0000</td>\n      <td>-100.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "ModelMetricsBinomial: gbm\n",
            "** Reported on validation data. **\n",
            "\n",
            "MSE: 0.386094728377163\n",
            "RMSE: 0.621365213362611\n",
            "LogLoss: 4.44770804705716\n",
            "Mean Per-Class Error: 0.4255000544523905\n",
            "AUC: 0.5569935020147384\n",
            "AUCPR: 0.7182021038974806\n",
            "Gini: 0.11398700402947681\n",
            "\n",
            "Confusion Matrix (Act/Pred) for max f1 @ threshold = 5.997054880112864e-11: \n",
            "\n",
            "Maximum Metrics: Maximum metrics at their respective thresholds\n",
            "\n",
            "Gains/Lift Table: Avg response rate: 67.47 %, avg score: 75.33 %\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "            0      1   Error            Rate\n0      0  4.0  159.0  0.9755   (159.0/163.0)\n1      1  0.0  338.0     0.0     (0.0/338.0)\n2  Total  4.0  497.0  0.3174   (159.0/501.0)",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>4.0</td>\n      <td>159.0</td>\n      <td>0.9755</td>\n      <td>(159.0/163.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>338.0</td>\n      <td>0.0</td>\n      <td>(0.0/338.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>4.0</td>\n      <td>497.0</td>\n      <td>0.3174</td>\n      <td>(159.0/501.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                         metric     threshold       value    idx\n0                        max f1  5.997055e-11    0.809581  311.0\n1                        max f2  5.997055e-11    0.914008  311.0\n2                  max f0point5  6.125291e-08    0.727432  300.0\n3                  max accuracy  1.197387e-09    0.682635  309.0\n4                 max precision  9.999999e-01    0.750000    2.0\n5                    max recall  5.997055e-11    1.000000  311.0\n6               max specificity  1.000000e+00    0.773006    0.0\n7              max absolute_mcc  9.999592e-01    0.139661   58.0\n8    max min_per_class_accuracy  9.998663e-01    0.564417   76.0\n9   max mean_per_class_accuracy  9.999592e-01    0.574500   58.0\n10                      max tns  1.000000e+00  126.000000    0.0\n11                      max fns  1.000000e+00  229.000000    0.0\n12                      max fps  2.832764e-14  163.000000  315.0\n13                      max tps  5.997055e-11  338.000000  311.0\n14                      max tnr  1.000000e+00    0.773006    0.0\n15                      max fnr  1.000000e+00    0.677515    0.0\n16                      max fpr  2.832764e-14    1.000000  315.0\n17                      max tpr  5.997055e-11    1.000000  311.0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>5.997055e-11</td>\n      <td>0.809581</td>\n      <td>311.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>5.997055e-11</td>\n      <td>0.914008</td>\n      <td>311.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>6.125291e-08</td>\n      <td>0.727432</td>\n      <td>300.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>1.197387e-09</td>\n      <td>0.682635</td>\n      <td>309.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>9.999999e-01</td>\n      <td>0.750000</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>5.997055e-11</td>\n      <td>1.000000</td>\n      <td>311.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>1.000000e+00</td>\n      <td>0.773006</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>9.999592e-01</td>\n      <td>0.139661</td>\n      <td>58.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>9.998663e-01</td>\n      <td>0.564417</td>\n      <td>76.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>9.999592e-01</td>\n      <td>0.574500</td>\n      <td>58.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>1.000000e+00</td>\n      <td>126.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>1.000000e+00</td>\n      <td>229.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>2.832764e-14</td>\n      <td>163.000000</td>\n      <td>315.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>5.997055e-11</td>\n      <td>338.000000</td>\n      <td>311.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>1.000000e+00</td>\n      <td>0.773006</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>1.000000e+00</td>\n      <td>0.677515</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>2.832764e-14</td>\n      <td>1.000000</td>\n      <td>315.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>5.997055e-11</td>\n      <td>1.000000</td>\n      <td>311.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "      group  cumulative_data_fraction  lower_threshold      lift  \\\n0         1                  0.033932     1.000000e+00  1.220675   \n1         2                  0.041916     1.000000e+00  1.111686   \n2         3                  0.051896     1.000000e+00  1.482249   \n3         4                  0.101796     1.000000e+00  1.185799   \n4         5                  0.151697     1.000000e+00  0.948639   \n5         6                  0.201597     1.000000e+00  1.126509   \n6         7                  0.301397     1.000000e+00  1.096864   \n7         8                  0.401198     9.999982e-01  1.007929   \n8         9                  0.500998     9.999435e-01  1.067219   \n9        10                  0.600798     9.961731e-01  0.830059   \n10       11                  0.700599     9.074671e-01  0.800414   \n11       12                  0.800399     1.208526e-01  0.830059   \n12       13                  0.900200     2.483908e-04  1.126509   \n13       14                  1.000000     2.832764e-14  0.978284   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0          1.220675       0.823529  1.000000                  0.823529   \n1          1.199915       0.750000  1.000000                  0.809524   \n2          1.254210       1.000000  1.000000                  0.846154   \n3          1.220675       0.800000  1.000000                  0.823529   \n4          1.131190       0.640000  1.000000                  0.763158   \n5          1.130031       0.760000  1.000000                  0.762376   \n6          1.119049       0.740000  1.000000                  0.754967   \n7          1.091407       0.680000  1.000000                  0.736318   \n8          1.086589       0.720000  0.999980                  0.733068   \n9          1.043976       0.560000  0.998915                  0.704319   \n10         1.009280       0.540000  0.970440                  0.680912   \n11         0.986934       0.560000  0.534798                  0.665835   \n12         1.002408       0.760000  0.024323                  0.676275   \n13         1.000000       0.660000  0.000018                  0.674651   \n\n    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n0           1.000000      0.041420                 0.041420  22.067525   \n1           1.000000      0.008876                 0.050296  11.168639   \n2           1.000000      0.014793                 0.065089  48.224852   \n3           1.000000      0.059172                 0.124260  18.579882   \n4           1.000000      0.047337                 0.171598  -5.136095   \n5           1.000000      0.056213                 0.227811  12.650888   \n6           1.000000      0.109467                 0.337278   9.686391   \n7           1.000000      0.100592                 0.437870   0.792899   \n8           0.999996      0.106509                 0.544379   6.721893   \n9           0.999816      0.082840                 0.627219 -16.994083   \n10          0.995632      0.079882                 0.707101 -19.958580   \n11          0.938171      0.082840                 0.789941 -16.994083   \n12          0.836858      0.112426                 0.902367  12.650888   \n13          0.753341      0.097633                 1.000000  -2.171598   \n\n    cumulative_gain  \n0         22.067525  \n1         19.991547  \n2         25.421029  \n3         22.067525  \n4         13.118966  \n5         13.003105  \n6         11.904855  \n7          9.140687  \n8          8.658856  \n9          4.397570  \n10         0.928033  \n11        -1.306645  \n12         0.240754  \n13         0.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.033932</td>\n      <td>1.000000e+00</td>\n      <td>1.220675</td>\n      <td>1.220675</td>\n      <td>0.823529</td>\n      <td>1.000000</td>\n      <td>0.823529</td>\n      <td>1.000000</td>\n      <td>0.041420</td>\n      <td>0.041420</td>\n      <td>22.067525</td>\n      <td>22.067525</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.041916</td>\n      <td>1.000000e+00</td>\n      <td>1.111686</td>\n      <td>1.199915</td>\n      <td>0.750000</td>\n      <td>1.000000</td>\n      <td>0.809524</td>\n      <td>1.000000</td>\n      <td>0.008876</td>\n      <td>0.050296</td>\n      <td>11.168639</td>\n      <td>19.991547</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.051896</td>\n      <td>1.000000e+00</td>\n      <td>1.482249</td>\n      <td>1.254210</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.846154</td>\n      <td>1.000000</td>\n      <td>0.014793</td>\n      <td>0.065089</td>\n      <td>48.224852</td>\n      <td>25.421029</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.101796</td>\n      <td>1.000000e+00</td>\n      <td>1.185799</td>\n      <td>1.220675</td>\n      <td>0.800000</td>\n      <td>1.000000</td>\n      <td>0.823529</td>\n      <td>1.000000</td>\n      <td>0.059172</td>\n      <td>0.124260</td>\n      <td>18.579882</td>\n      <td>22.067525</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>0.151697</td>\n      <td>1.000000e+00</td>\n      <td>0.948639</td>\n      <td>1.131190</td>\n      <td>0.640000</td>\n      <td>1.000000</td>\n      <td>0.763158</td>\n      <td>1.000000</td>\n      <td>0.047337</td>\n      <td>0.171598</td>\n      <td>-5.136095</td>\n      <td>13.118966</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>6</td>\n      <td>0.201597</td>\n      <td>1.000000e+00</td>\n      <td>1.126509</td>\n      <td>1.130031</td>\n      <td>0.760000</td>\n      <td>1.000000</td>\n      <td>0.762376</td>\n      <td>1.000000</td>\n      <td>0.056213</td>\n      <td>0.227811</td>\n      <td>12.650888</td>\n      <td>13.003105</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>0.301397</td>\n      <td>1.000000e+00</td>\n      <td>1.096864</td>\n      <td>1.119049</td>\n      <td>0.740000</td>\n      <td>1.000000</td>\n      <td>0.754967</td>\n      <td>1.000000</td>\n      <td>0.109467</td>\n      <td>0.337278</td>\n      <td>9.686391</td>\n      <td>11.904855</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>8</td>\n      <td>0.401198</td>\n      <td>9.999982e-01</td>\n      <td>1.007929</td>\n      <td>1.091407</td>\n      <td>0.680000</td>\n      <td>1.000000</td>\n      <td>0.736318</td>\n      <td>1.000000</td>\n      <td>0.100592</td>\n      <td>0.437870</td>\n      <td>0.792899</td>\n      <td>9.140687</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>9</td>\n      <td>0.500998</td>\n      <td>9.999435e-01</td>\n      <td>1.067219</td>\n      <td>1.086589</td>\n      <td>0.720000</td>\n      <td>0.999980</td>\n      <td>0.733068</td>\n      <td>0.999996</td>\n      <td>0.106509</td>\n      <td>0.544379</td>\n      <td>6.721893</td>\n      <td>8.658856</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>10</td>\n      <td>0.600798</td>\n      <td>9.961731e-01</td>\n      <td>0.830059</td>\n      <td>1.043976</td>\n      <td>0.560000</td>\n      <td>0.998915</td>\n      <td>0.704319</td>\n      <td>0.999816</td>\n      <td>0.082840</td>\n      <td>0.627219</td>\n      <td>-16.994083</td>\n      <td>4.397570</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>11</td>\n      <td>0.700599</td>\n      <td>9.074671e-01</td>\n      <td>0.800414</td>\n      <td>1.009280</td>\n      <td>0.540000</td>\n      <td>0.970440</td>\n      <td>0.680912</td>\n      <td>0.995632</td>\n      <td>0.079882</td>\n      <td>0.707101</td>\n      <td>-19.958580</td>\n      <td>0.928033</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>12</td>\n      <td>0.800399</td>\n      <td>1.208526e-01</td>\n      <td>0.830059</td>\n      <td>0.986934</td>\n      <td>0.560000</td>\n      <td>0.534798</td>\n      <td>0.665835</td>\n      <td>0.938171</td>\n      <td>0.082840</td>\n      <td>0.789941</td>\n      <td>-16.994083</td>\n      <td>-1.306645</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>13</td>\n      <td>0.900200</td>\n      <td>2.483908e-04</td>\n      <td>1.126509</td>\n      <td>1.002408</td>\n      <td>0.760000</td>\n      <td>0.024323</td>\n      <td>0.676275</td>\n      <td>0.836858</td>\n      <td>0.112426</td>\n      <td>0.902367</td>\n      <td>12.650888</td>\n      <td>0.240754</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>14</td>\n      <td>1.000000</td>\n      <td>2.832764e-14</td>\n      <td>0.978284</td>\n      <td>1.000000</td>\n      <td>0.660000</td>\n      <td>0.000018</td>\n      <td>0.674651</td>\n      <td>0.753341</td>\n      <td>0.097633</td>\n      <td>1.000000</td>\n      <td>-2.171598</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ModelMetricsBinomial: gbm\n",
            "** Reported on cross-validation data. **\n",
            "\n",
            "MSE: 0.16866504419297862\n",
            "RMSE: 0.4106885001956819\n",
            "LogLoss: 1.9557627576485224\n",
            "Mean Per-Class Error: 0.18732121749408992\n",
            "AUC: 0.8782254728132387\n",
            "AUCPR: 0.9117333177488975\n",
            "Gini: 0.7564509456264774\n",
            "\n",
            "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.32318228841095886: \n",
            "\n",
            "Maximum Metrics: Maximum metrics at their respective thresholds\n",
            "\n",
            "Gains/Lift Table: Avg response rate: 65.41 %, avg score: 71.99 %\n",
            "\n",
            "\n",
            "Cross-Validation Metrics Summary: \n",
            "\n",
            "See the whole table with table.as_data_frame()\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "              0      1   Error             Rate\n0      0  268.0  155.0  0.3664    (155.0/423.0)\n1      1   65.0  735.0  0.0813     (65.0/800.0)\n2  Total  333.0  890.0  0.1799   (220.0/1223.0)",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>268.0</td>\n      <td>155.0</td>\n      <td>0.3664</td>\n      <td>(155.0/423.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>65.0</td>\n      <td>735.0</td>\n      <td>0.0813</td>\n      <td>(65.0/800.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>333.0</td>\n      <td>890.0</td>\n      <td>0.1799</td>\n      <td>(220.0/1223.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                         metric     threshold       value    idx\n0                        max f1  3.231823e-01    0.869822  238.0\n1                        max f2  9.540450e-05    0.924430  356.0\n2                  max f0point5  9.999822e-01    0.876678   45.0\n3                  max accuracy  9.800485e-01    0.827473  167.0\n4                 max precision  1.000000e+00    0.937615    0.0\n5                    max recall  2.398012e-09    1.000000  399.0\n6               max specificity  1.000000e+00    0.919622    0.0\n7              max absolute_mcc  9.800485e-01    0.615008  167.0\n8    max min_per_class_accuracy  9.998924e-01    0.807500   76.0\n9   max mean_per_class_accuracy  9.999822e-01    0.812679   45.0\n10                      max tns  1.000000e+00  389.000000    0.0\n11                      max fns  1.000000e+00  289.000000    0.0\n12                      max fps  2.398012e-09  423.000000  399.0\n13                      max tps  2.398012e-09  800.000000  399.0\n14                      max tnr  1.000000e+00    0.919622    0.0\n15                      max fnr  1.000000e+00    0.361250    0.0\n16                      max fpr  2.398012e-09    1.000000  399.0\n17                      max tpr  2.398012e-09    1.000000  399.0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>3.231823e-01</td>\n      <td>0.869822</td>\n      <td>238.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>9.540450e-05</td>\n      <td>0.924430</td>\n      <td>356.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>9.999822e-01</td>\n      <td>0.876678</td>\n      <td>45.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>9.800485e-01</td>\n      <td>0.827473</td>\n      <td>167.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>1.000000e+00</td>\n      <td>0.937615</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>2.398012e-09</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>1.000000e+00</td>\n      <td>0.919622</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>9.800485e-01</td>\n      <td>0.615008</td>\n      <td>167.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>9.998924e-01</td>\n      <td>0.807500</td>\n      <td>76.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>9.999822e-01</td>\n      <td>0.812679</td>\n      <td>45.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>1.000000e+00</td>\n      <td>389.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>1.000000e+00</td>\n      <td>289.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>2.398012e-09</td>\n      <td>423.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>2.398012e-09</td>\n      <td>800.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>1.000000e+00</td>\n      <td>0.919622</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>1.000000e+00</td>\n      <td>0.361250</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>2.398012e-09</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>2.398012e-09</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "      group  cumulative_data_fraction  lower_threshold      lift  \\\n0         1                  0.065413     1.000000e+00  1.490531   \n1         2                  0.103025     1.000000e+00  1.495516   \n2         3                  0.150450     1.000000e+00  1.476034   \n3         4                  0.200327     1.000000e+00  1.478627   \n4         5                  0.300082     1.000000e+00  1.403443   \n5         6                  0.399836     1.000000e+00  1.441035   \n6         7                  0.500409     9.999993e-01  1.242886   \n7         8                  0.600164     9.998290e-01  1.065113   \n8         9                  0.699918     8.250288e-01  0.852090   \n9        10                  0.799673     5.303647e-04  0.651598   \n10       11                  0.899428     1.270028e-08  0.263145   \n11       12                  1.000000     1.632584e-18  0.111860   \n\n    cumulative_lift  response_rate         score  cumulative_response_rate  \\\n0          1.490531       0.975000  1.000000e+00                  0.975000   \n1          1.492351       0.978261  1.000000e+00                  0.976190   \n2          1.487208       0.965517  1.000000e+00                  0.972826   \n3          1.485071       0.967213  1.000000e+00                  0.971429   \n4          1.457936       0.918033  1.000000e+00                  0.953678   \n5          1.453719       0.942623  1.000000e+00                  0.950920   \n6          1.411346       0.813008  9.999999e-01                  0.923203   \n7          1.353798       0.696721  9.999755e-01                  0.885559   \n8          1.282293       0.557377  9.734470e-01                  0.838785   \n9          1.203617       0.426230  2.269344e-01                  0.787321   \n10         1.099310       0.172131  6.356409e-05                  0.719091   \n11         1.000000       0.073171  1.140950e-09                  0.654129   \n\n    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n0           1.000000       0.09750                  0.09750  49.053125   \n1           1.000000       0.05625                  0.15375  49.551630   \n2           1.000000       0.07000                  0.22375  47.603448   \n3           1.000000       0.07375                  0.29750  47.862705   \n4           1.000000       0.14000                  0.43750  40.344262   \n5           1.000000       0.14375                  0.58125  44.103484   \n6           1.000000       0.12500                  0.70625  24.288618   \n7           0.999996       0.10625                  0.81250   6.511270   \n8           0.996212       0.08500                  0.89750 -14.790984   \n9           0.900249       0.06500                  0.96250 -34.840164   \n10          0.800410       0.02625                  0.98875 -73.685451   \n11          0.719911       0.01125                  1.00000 -88.814024   \n\n    cumulative_gain  \n0         49.053125  \n1         49.235119  \n2         48.720788  \n3         48.507143  \n4         45.793597  \n5         45.371933  \n6         41.134600  \n7         35.379768  \n8         28.229264  \n9         20.361708  \n10         9.931023  \n11         0.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.065413</td>\n      <td>1.000000e+00</td>\n      <td>1.490531</td>\n      <td>1.490531</td>\n      <td>0.975000</td>\n      <td>1.000000e+00</td>\n      <td>0.975000</td>\n      <td>1.000000</td>\n      <td>0.09750</td>\n      <td>0.09750</td>\n      <td>49.053125</td>\n      <td>49.053125</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.103025</td>\n      <td>1.000000e+00</td>\n      <td>1.495516</td>\n      <td>1.492351</td>\n      <td>0.978261</td>\n      <td>1.000000e+00</td>\n      <td>0.976190</td>\n      <td>1.000000</td>\n      <td>0.05625</td>\n      <td>0.15375</td>\n      <td>49.551630</td>\n      <td>49.235119</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.150450</td>\n      <td>1.000000e+00</td>\n      <td>1.476034</td>\n      <td>1.487208</td>\n      <td>0.965517</td>\n      <td>1.000000e+00</td>\n      <td>0.972826</td>\n      <td>1.000000</td>\n      <td>0.07000</td>\n      <td>0.22375</td>\n      <td>47.603448</td>\n      <td>48.720788</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.200327</td>\n      <td>1.000000e+00</td>\n      <td>1.478627</td>\n      <td>1.485071</td>\n      <td>0.967213</td>\n      <td>1.000000e+00</td>\n      <td>0.971429</td>\n      <td>1.000000</td>\n      <td>0.07375</td>\n      <td>0.29750</td>\n      <td>47.862705</td>\n      <td>48.507143</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>0.300082</td>\n      <td>1.000000e+00</td>\n      <td>1.403443</td>\n      <td>1.457936</td>\n      <td>0.918033</td>\n      <td>1.000000e+00</td>\n      <td>0.953678</td>\n      <td>1.000000</td>\n      <td>0.14000</td>\n      <td>0.43750</td>\n      <td>40.344262</td>\n      <td>45.793597</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>6</td>\n      <td>0.399836</td>\n      <td>1.000000e+00</td>\n      <td>1.441035</td>\n      <td>1.453719</td>\n      <td>0.942623</td>\n      <td>1.000000e+00</td>\n      <td>0.950920</td>\n      <td>1.000000</td>\n      <td>0.14375</td>\n      <td>0.58125</td>\n      <td>44.103484</td>\n      <td>45.371933</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>0.500409</td>\n      <td>9.999993e-01</td>\n      <td>1.242886</td>\n      <td>1.411346</td>\n      <td>0.813008</td>\n      <td>9.999999e-01</td>\n      <td>0.923203</td>\n      <td>1.000000</td>\n      <td>0.12500</td>\n      <td>0.70625</td>\n      <td>24.288618</td>\n      <td>41.134600</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>8</td>\n      <td>0.600164</td>\n      <td>9.998290e-01</td>\n      <td>1.065113</td>\n      <td>1.353798</td>\n      <td>0.696721</td>\n      <td>9.999755e-01</td>\n      <td>0.885559</td>\n      <td>0.999996</td>\n      <td>0.10625</td>\n      <td>0.81250</td>\n      <td>6.511270</td>\n      <td>35.379768</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>9</td>\n      <td>0.699918</td>\n      <td>8.250288e-01</td>\n      <td>0.852090</td>\n      <td>1.282293</td>\n      <td>0.557377</td>\n      <td>9.734470e-01</td>\n      <td>0.838785</td>\n      <td>0.996212</td>\n      <td>0.08500</td>\n      <td>0.89750</td>\n      <td>-14.790984</td>\n      <td>28.229264</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>10</td>\n      <td>0.799673</td>\n      <td>5.303647e-04</td>\n      <td>0.651598</td>\n      <td>1.203617</td>\n      <td>0.426230</td>\n      <td>2.269344e-01</td>\n      <td>0.787321</td>\n      <td>0.900249</td>\n      <td>0.06500</td>\n      <td>0.96250</td>\n      <td>-34.840164</td>\n      <td>20.361708</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>11</td>\n      <td>0.899428</td>\n      <td>1.270028e-08</td>\n      <td>0.263145</td>\n      <td>1.099310</td>\n      <td>0.172131</td>\n      <td>6.356409e-05</td>\n      <td>0.719091</td>\n      <td>0.800410</td>\n      <td>0.02625</td>\n      <td>0.98875</td>\n      <td>-73.685451</td>\n      <td>9.931023</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>12</td>\n      <td>1.000000</td>\n      <td>1.632584e-18</td>\n      <td>0.111860</td>\n      <td>1.000000</td>\n      <td>0.073171</td>\n      <td>1.140950e-09</td>\n      <td>0.654129</td>\n      <td>0.719911</td>\n      <td>0.01125</td>\n      <td>1.00000</td>\n      <td>-88.814024</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                                   mean           sd  cv_1_valid  cv_2_valid  \\\n0                  accuracy    0.831843   0.01859163  0.82329315   0.8055556   \n1                       auc   0.8775816  0.011729488  0.87460315   0.8894299   \n2                     aucpr   0.9119413  0.011119945   0.9171611  0.92475086   \n3                       err    0.168157   0.01859163  0.17670682  0.19444445   \n4                 err_count        41.2    5.4037023        44.0        49.0   \n5                  f0point5   0.8503556  0.027037434   0.8513053  0.81124073   \n6                        f1   0.8790338  0.012038547    0.872093  0.86197186   \n7                        f2  0.91066444  0.022579378   0.8939213  0.91947114   \n8            lift_top_group   1.4909613    0.0676803   1.5090909   1.5849056   \n9                   logloss   1.9550341   0.08839667   1.9753071   2.0436678   \n10      max_per_class_error  0.36070678  0.103437215   0.3452381   0.4623656   \n11                      mcc  0.62282103  0.039857086   0.5930234   0.5802296   \n12  mean_per_class_accuracy  0.78647846  0.034584176   0.7819264   0.7499493   \n13     mean_per_class_error  0.21352157  0.034584176  0.21807359  0.25005072   \n14                      mse  0.16851825  0.008485014  0.17579463   0.1789323   \n15                   pr_auc   0.9119413  0.011119945   0.9171611  0.92475086   \n16                precision    0.832654  0.038396414  0.83798885  0.78061223   \n17                       r2   0.2544202   0.03044994  0.21360438  0.23156036   \n18                   recall  0.93366367   0.03909115  0.90909094   0.9622642   \n19                     rmse  0.41040608  0.010313331   0.4192787   0.4230039   \n\n    cv_3_valid  cv_4_valid  cv_5_valid  \n0   0.83682007   0.8381743   0.8553719  \n1    0.8612421   0.8740295  0.88860315  \n2   0.89485925   0.9091185   0.9138167  \n3   0.16317992  0.16182573   0.1446281  \n4         39.0        39.0        35.0  \n5   0.86412394  0.84126985  0.88383836  \n6   0.88145894   0.8907563   0.8888889  \n7    0.8995037   0.9464286  0.89399743  \n8    1.5031446   1.4033386   1.4543269  \n9    2.0313797   1.8631929   1.8616235  \n10      0.3125      0.4625  0.22093023  \n11   0.6242338   0.6345227  0.68209577  \n12   0.7997248   0.7625388  0.83825284  \n13  0.20027515  0.23746118  0.16174717  \n14  0.16356316  0.15891518  0.16538592  \n15  0.89485925   0.9091185   0.9138167  \n16  0.85294116  0.81122446   0.8805031  \n17  0.26549596  0.28338882   0.2780515  \n18   0.9119497   0.9875776   0.8974359  \n19  0.40442944  0.39864165  0.40667668  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>mean</th>\n      <th>sd</th>\n      <th>cv_1_valid</th>\n      <th>cv_2_valid</th>\n      <th>cv_3_valid</th>\n      <th>cv_4_valid</th>\n      <th>cv_5_valid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>accuracy</td>\n      <td>0.831843</td>\n      <td>0.01859163</td>\n      <td>0.82329315</td>\n      <td>0.8055556</td>\n      <td>0.83682007</td>\n      <td>0.8381743</td>\n      <td>0.8553719</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>auc</td>\n      <td>0.8775816</td>\n      <td>0.011729488</td>\n      <td>0.87460315</td>\n      <td>0.8894299</td>\n      <td>0.8612421</td>\n      <td>0.8740295</td>\n      <td>0.88860315</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>aucpr</td>\n      <td>0.9119413</td>\n      <td>0.011119945</td>\n      <td>0.9171611</td>\n      <td>0.92475086</td>\n      <td>0.89485925</td>\n      <td>0.9091185</td>\n      <td>0.9138167</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>err</td>\n      <td>0.168157</td>\n      <td>0.01859163</td>\n      <td>0.17670682</td>\n      <td>0.19444445</td>\n      <td>0.16317992</td>\n      <td>0.16182573</td>\n      <td>0.1446281</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>err_count</td>\n      <td>41.2</td>\n      <td>5.4037023</td>\n      <td>44.0</td>\n      <td>49.0</td>\n      <td>39.0</td>\n      <td>39.0</td>\n      <td>35.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>f0point5</td>\n      <td>0.8503556</td>\n      <td>0.027037434</td>\n      <td>0.8513053</td>\n      <td>0.81124073</td>\n      <td>0.86412394</td>\n      <td>0.84126985</td>\n      <td>0.88383836</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>f1</td>\n      <td>0.8790338</td>\n      <td>0.012038547</td>\n      <td>0.872093</td>\n      <td>0.86197186</td>\n      <td>0.88145894</td>\n      <td>0.8907563</td>\n      <td>0.8888889</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>f2</td>\n      <td>0.91066444</td>\n      <td>0.022579378</td>\n      <td>0.8939213</td>\n      <td>0.91947114</td>\n      <td>0.8995037</td>\n      <td>0.9464286</td>\n      <td>0.89399743</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>lift_top_group</td>\n      <td>1.4909613</td>\n      <td>0.0676803</td>\n      <td>1.5090909</td>\n      <td>1.5849056</td>\n      <td>1.5031446</td>\n      <td>1.4033386</td>\n      <td>1.4543269</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>logloss</td>\n      <td>1.9550341</td>\n      <td>0.08839667</td>\n      <td>1.9753071</td>\n      <td>2.0436678</td>\n      <td>2.0313797</td>\n      <td>1.8631929</td>\n      <td>1.8616235</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max_per_class_error</td>\n      <td>0.36070678</td>\n      <td>0.103437215</td>\n      <td>0.3452381</td>\n      <td>0.4623656</td>\n      <td>0.3125</td>\n      <td>0.4625</td>\n      <td>0.22093023</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>mcc</td>\n      <td>0.62282103</td>\n      <td>0.039857086</td>\n      <td>0.5930234</td>\n      <td>0.5802296</td>\n      <td>0.6242338</td>\n      <td>0.6345227</td>\n      <td>0.68209577</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>mean_per_class_accuracy</td>\n      <td>0.78647846</td>\n      <td>0.034584176</td>\n      <td>0.7819264</td>\n      <td>0.7499493</td>\n      <td>0.7997248</td>\n      <td>0.7625388</td>\n      <td>0.83825284</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>mean_per_class_error</td>\n      <td>0.21352157</td>\n      <td>0.034584176</td>\n      <td>0.21807359</td>\n      <td>0.25005072</td>\n      <td>0.20027515</td>\n      <td>0.23746118</td>\n      <td>0.16174717</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>mse</td>\n      <td>0.16851825</td>\n      <td>0.008485014</td>\n      <td>0.17579463</td>\n      <td>0.1789323</td>\n      <td>0.16356316</td>\n      <td>0.15891518</td>\n      <td>0.16538592</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>pr_auc</td>\n      <td>0.9119413</td>\n      <td>0.011119945</td>\n      <td>0.9171611</td>\n      <td>0.92475086</td>\n      <td>0.89485925</td>\n      <td>0.9091185</td>\n      <td>0.9138167</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>precision</td>\n      <td>0.832654</td>\n      <td>0.038396414</td>\n      <td>0.83798885</td>\n      <td>0.78061223</td>\n      <td>0.85294116</td>\n      <td>0.81122446</td>\n      <td>0.8805031</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>r2</td>\n      <td>0.2544202</td>\n      <td>0.03044994</td>\n      <td>0.21360438</td>\n      <td>0.23156036</td>\n      <td>0.26549596</td>\n      <td>0.28338882</td>\n      <td>0.2780515</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>recall</td>\n      <td>0.93366367</td>\n      <td>0.03909115</td>\n      <td>0.90909094</td>\n      <td>0.9622642</td>\n      <td>0.9119497</td>\n      <td>0.9875776</td>\n      <td>0.8974359</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>rmse</td>\n      <td>0.41040608</td>\n      <td>0.010313331</td>\n      <td>0.4192787</td>\n      <td>0.4230039</td>\n      <td>0.40442944</td>\n      <td>0.39864165</td>\n      <td>0.40667668</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scoring History: \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                timestamp           duration  number_of_trees  training_rmse  \\\n0     2020-11-15 17:14:59   1 min 45.931 sec              0.0   4.756513e-01   \n1     2020-11-15 17:15:01   1 min 48.157 sec              1.0   3.162353e-01   \n2     2020-11-15 17:15:01   1 min 48.403 sec              2.0   2.189493e-01   \n3     2020-11-15 17:15:02   1 min 48.768 sec              3.0   1.457040e-01   \n4     2020-11-15 17:15:02   1 min 49.070 sec              4.0   1.078160e-01   \n5     2020-11-15 17:15:02   1 min 49.324 sec              5.0   7.338120e-02   \n6     2020-11-15 17:15:02   1 min 49.631 sec              6.0   4.622081e-02   \n7     2020-11-15 17:15:03   1 min 49.983 sec              7.0   2.640568e-02   \n8     2020-11-15 17:15:03   1 min 50.288 sec              8.0   1.873358e-02   \n9     2020-11-15 17:15:03   1 min 50.567 sec              9.0   1.189123e-02   \n10    2020-11-15 17:15:04   1 min 50.941 sec             10.0   8.161421e-03   \n11    2020-11-15 17:15:04   1 min 51.241 sec             11.0   7.865222e-03   \n12    2020-11-15 17:15:04   1 min 51.489 sec             12.0   3.982023e-03   \n13    2020-11-15 17:15:08   1 min 55.632 sec             29.0   3.963193e-06   \n14    2020-11-15 17:15:13   1 min 59.830 sec             44.0   1.265216e-08   \n15    2020-11-15 17:15:17   2 min  4.007 sec             59.0   2.240176e-11   \n16    2020-11-15 17:15:21   2 min  8.062 sec             72.0   1.833331e-13   \n17    2020-11-15 17:15:25   2 min 12.214 sec             87.0   3.571879e-16   \n18    2020-11-15 17:15:28   2 min 15.576 sec            150.0   4.489645e-17   \n\n    training_logloss  training_auc  training_pr_auc  training_lift  \\\n0       6.448530e-01      0.500000         0.654129       1.000000   \n1       3.413688e-01      0.936668         0.963593       1.519784   \n2       1.935571e-01      0.987368         0.993094       1.528750   \n3       1.069637e-01      0.997986         0.998838       1.528750   \n4       6.884595e-02      0.999622         0.999798       1.528750   \n5       4.307819e-02      0.999713         0.999847       1.528750   \n6       2.621180e-02      0.999997         0.999998       1.528750   \n7       1.501857e-02      1.000000         1.000000       1.528750   \n8       9.755299e-03      1.000000         1.000000       1.528750   \n9       6.746149e-03      1.000000         1.000000       1.528750   \n10      4.397734e-03      1.000000         1.000000       1.528750   \n11      3.003800e-03      1.000000         1.000000       1.528750   \n12      1.813033e-03      1.000000         1.000000       1.528750   \n13      1.923108e-06      1.000000         1.000000       1.528750   \n14      5.461971e-09      1.000000         1.000000       1.528750   \n15      1.264277e-11      1.000000         1.000000       1.528750   \n16      6.061763e-14      1.000000         1.000000       1.528750   \n17      1.774723e-16      1.000000         1.000000       1.528750   \n18      9.622538e-18      1.000000         1.000000       1.528750   \n\n    training_classification_error  validation_rmse  validation_logloss  \\\n0                        0.345871         0.468954            0.631776   \n1                        0.138185         0.503058            0.728740   \n2                        0.045789         0.536939            0.882639   \n3                        0.018806         0.537076            0.923506   \n4                        0.007359         0.528007            0.936873   \n5                        0.001635         0.535525            0.984352   \n6                        0.000818         0.546897            1.056714   \n7                        0.000000         0.556110            1.126048   \n8                        0.000000         0.566971            1.183291   \n9                        0.000000         0.568130            1.203292   \n10                       0.000000         0.566834            1.226132   \n11                       0.000000         0.572155            1.263443   \n12                       0.000000         0.571731            1.263830   \n13                       0.000000         0.571734            1.940986   \n14                       0.000000         0.596219            2.728159   \n15                       0.000000         0.596385            3.196985   \n16                       0.000000         0.602415            3.748583   \n17                       0.000000         0.612782            4.368708   \n18                       0.000000         0.621365            4.447708   \n\n    validation_auc  validation_pr_auc  validation_lift  \\\n0         0.500000           0.674651         1.000000   \n1         0.601735           0.740769         1.160629   \n2         0.565343           0.734887         1.482249   \n3         0.580816           0.742031         1.482249   \n4         0.605138           0.745152         0.988166   \n5         0.602144           0.741490         0.741124   \n6         0.587305           0.744102         1.235207   \n7         0.581352           0.742909         1.235207   \n8         0.572767           0.743397         1.235207   \n9         0.572730           0.749955         1.235207   \n10        0.575725           0.751956         1.482249   \n11        0.570588           0.752325         1.482249   \n12        0.574736           0.752917         1.482249   \n13        0.570080           0.736045         1.482249   \n14        0.538226           0.715054         1.235207   \n15        0.551494           0.717989         1.235207   \n16        0.545867           0.711511         1.235207   \n17        0.545459           0.711099         1.185799   \n18        0.556994           0.718202         1.220675   \n\n    validation_classification_error  \n0                          0.325349  \n1                          0.325349  \n2                          0.323353  \n3                          0.325349  \n4                          0.325349  \n5                          0.325349  \n6                          0.325349  \n7                          0.325349  \n8                          0.325349  \n9                          0.325349  \n10                         0.325349  \n11                         0.325349  \n12                         0.323353  \n13                         0.321357  \n14                         0.319361  \n15                         0.315369  \n16                         0.315369  \n17                         0.313373  \n18                         0.317365  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>timestamp</th>\n      <th>duration</th>\n      <th>number_of_trees</th>\n      <th>training_rmse</th>\n      <th>training_logloss</th>\n      <th>training_auc</th>\n      <th>training_pr_auc</th>\n      <th>training_lift</th>\n      <th>training_classification_error</th>\n      <th>validation_rmse</th>\n      <th>validation_logloss</th>\n      <th>validation_auc</th>\n      <th>validation_pr_auc</th>\n      <th>validation_lift</th>\n      <th>validation_classification_error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>2020-11-15 17:14:59</td>\n      <td>1 min 45.931 sec</td>\n      <td>0.0</td>\n      <td>4.756513e-01</td>\n      <td>6.448530e-01</td>\n      <td>0.500000</td>\n      <td>0.654129</td>\n      <td>1.000000</td>\n      <td>0.345871</td>\n      <td>0.468954</td>\n      <td>0.631776</td>\n      <td>0.500000</td>\n      <td>0.674651</td>\n      <td>1.000000</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2020-11-15 17:15:01</td>\n      <td>1 min 48.157 sec</td>\n      <td>1.0</td>\n      <td>3.162353e-01</td>\n      <td>3.413688e-01</td>\n      <td>0.936668</td>\n      <td>0.963593</td>\n      <td>1.519784</td>\n      <td>0.138185</td>\n      <td>0.503058</td>\n      <td>0.728740</td>\n      <td>0.601735</td>\n      <td>0.740769</td>\n      <td>1.160629</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>2020-11-15 17:15:01</td>\n      <td>1 min 48.403 sec</td>\n      <td>2.0</td>\n      <td>2.189493e-01</td>\n      <td>1.935571e-01</td>\n      <td>0.987368</td>\n      <td>0.993094</td>\n      <td>1.528750</td>\n      <td>0.045789</td>\n      <td>0.536939</td>\n      <td>0.882639</td>\n      <td>0.565343</td>\n      <td>0.734887</td>\n      <td>1.482249</td>\n      <td>0.323353</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>2020-11-15 17:15:02</td>\n      <td>1 min 48.768 sec</td>\n      <td>3.0</td>\n      <td>1.457040e-01</td>\n      <td>1.069637e-01</td>\n      <td>0.997986</td>\n      <td>0.998838</td>\n      <td>1.528750</td>\n      <td>0.018806</td>\n      <td>0.537076</td>\n      <td>0.923506</td>\n      <td>0.580816</td>\n      <td>0.742031</td>\n      <td>1.482249</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>2020-11-15 17:15:02</td>\n      <td>1 min 49.070 sec</td>\n      <td>4.0</td>\n      <td>1.078160e-01</td>\n      <td>6.884595e-02</td>\n      <td>0.999622</td>\n      <td>0.999798</td>\n      <td>1.528750</td>\n      <td>0.007359</td>\n      <td>0.528007</td>\n      <td>0.936873</td>\n      <td>0.605138</td>\n      <td>0.745152</td>\n      <td>0.988166</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>2020-11-15 17:15:02</td>\n      <td>1 min 49.324 sec</td>\n      <td>5.0</td>\n      <td>7.338120e-02</td>\n      <td>4.307819e-02</td>\n      <td>0.999713</td>\n      <td>0.999847</td>\n      <td>1.528750</td>\n      <td>0.001635</td>\n      <td>0.535525</td>\n      <td>0.984352</td>\n      <td>0.602144</td>\n      <td>0.741490</td>\n      <td>0.741124</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>2020-11-15 17:15:02</td>\n      <td>1 min 49.631 sec</td>\n      <td>6.0</td>\n      <td>4.622081e-02</td>\n      <td>2.621180e-02</td>\n      <td>0.999997</td>\n      <td>0.999998</td>\n      <td>1.528750</td>\n      <td>0.000818</td>\n      <td>0.546897</td>\n      <td>1.056714</td>\n      <td>0.587305</td>\n      <td>0.744102</td>\n      <td>1.235207</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>2020-11-15 17:15:03</td>\n      <td>1 min 49.983 sec</td>\n      <td>7.0</td>\n      <td>2.640568e-02</td>\n      <td>1.501857e-02</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.528750</td>\n      <td>0.000000</td>\n      <td>0.556110</td>\n      <td>1.126048</td>\n      <td>0.581352</td>\n      <td>0.742909</td>\n      <td>1.235207</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>2020-11-15 17:15:03</td>\n      <td>1 min 50.288 sec</td>\n      <td>8.0</td>\n      <td>1.873358e-02</td>\n      <td>9.755299e-03</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.528750</td>\n      <td>0.000000</td>\n      <td>0.566971</td>\n      <td>1.183291</td>\n      <td>0.572767</td>\n      <td>0.743397</td>\n      <td>1.235207</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>2020-11-15 17:15:03</td>\n      <td>1 min 50.567 sec</td>\n      <td>9.0</td>\n      <td>1.189123e-02</td>\n      <td>6.746149e-03</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.528750</td>\n      <td>0.000000</td>\n      <td>0.568130</td>\n      <td>1.203292</td>\n      <td>0.572730</td>\n      <td>0.749955</td>\n      <td>1.235207</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>2020-11-15 17:15:04</td>\n      <td>1 min 50.941 sec</td>\n      <td>10.0</td>\n      <td>8.161421e-03</td>\n      <td>4.397734e-03</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.528750</td>\n      <td>0.000000</td>\n      <td>0.566834</td>\n      <td>1.226132</td>\n      <td>0.575725</td>\n      <td>0.751956</td>\n      <td>1.482249</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>2020-11-15 17:15:04</td>\n      <td>1 min 51.241 sec</td>\n      <td>11.0</td>\n      <td>7.865222e-03</td>\n      <td>3.003800e-03</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.528750</td>\n      <td>0.000000</td>\n      <td>0.572155</td>\n      <td>1.263443</td>\n      <td>0.570588</td>\n      <td>0.752325</td>\n      <td>1.482249</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>2020-11-15 17:15:04</td>\n      <td>1 min 51.489 sec</td>\n      <td>12.0</td>\n      <td>3.982023e-03</td>\n      <td>1.813033e-03</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.528750</td>\n      <td>0.000000</td>\n      <td>0.571731</td>\n      <td>1.263830</td>\n      <td>0.574736</td>\n      <td>0.752917</td>\n      <td>1.482249</td>\n      <td>0.323353</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>2020-11-15 17:15:08</td>\n      <td>1 min 55.632 sec</td>\n      <td>29.0</td>\n      <td>3.963193e-06</td>\n      <td>1.923108e-06</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.528750</td>\n      <td>0.000000</td>\n      <td>0.571734</td>\n      <td>1.940986</td>\n      <td>0.570080</td>\n      <td>0.736045</td>\n      <td>1.482249</td>\n      <td>0.321357</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>2020-11-15 17:15:13</td>\n      <td>1 min 59.830 sec</td>\n      <td>44.0</td>\n      <td>1.265216e-08</td>\n      <td>5.461971e-09</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.528750</td>\n      <td>0.000000</td>\n      <td>0.596219</td>\n      <td>2.728159</td>\n      <td>0.538226</td>\n      <td>0.715054</td>\n      <td>1.235207</td>\n      <td>0.319361</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>2020-11-15 17:15:17</td>\n      <td>2 min  4.007 sec</td>\n      <td>59.0</td>\n      <td>2.240176e-11</td>\n      <td>1.264277e-11</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.528750</td>\n      <td>0.000000</td>\n      <td>0.596385</td>\n      <td>3.196985</td>\n      <td>0.551494</td>\n      <td>0.717989</td>\n      <td>1.235207</td>\n      <td>0.315369</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td></td>\n      <td>2020-11-15 17:15:21</td>\n      <td>2 min  8.062 sec</td>\n      <td>72.0</td>\n      <td>1.833331e-13</td>\n      <td>6.061763e-14</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.528750</td>\n      <td>0.000000</td>\n      <td>0.602415</td>\n      <td>3.748583</td>\n      <td>0.545867</td>\n      <td>0.711511</td>\n      <td>1.235207</td>\n      <td>0.315369</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td></td>\n      <td>2020-11-15 17:15:25</td>\n      <td>2 min 12.214 sec</td>\n      <td>87.0</td>\n      <td>3.571879e-16</td>\n      <td>1.774723e-16</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.528750</td>\n      <td>0.000000</td>\n      <td>0.612782</td>\n      <td>4.368708</td>\n      <td>0.545459</td>\n      <td>0.711099</td>\n      <td>1.185799</td>\n      <td>0.313373</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td></td>\n      <td>2020-11-15 17:15:28</td>\n      <td>2 min 15.576 sec</td>\n      <td>150.0</td>\n      <td>4.489645e-17</td>\n      <td>9.622538e-18</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.528750</td>\n      <td>0.000000</td>\n      <td>0.621365</td>\n      <td>4.447708</td>\n      <td>0.556994</td>\n      <td>0.718202</td>\n      <td>1.220675</td>\n      <td>0.317365</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable Importances: \n",
            "\n",
            "See the whole table with table.as_data_frame()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "   variable  relative_importance  scaled_importance  percentage\n0      PC14            35.467583           1.000000    0.135559\n1      PC11            16.497795           0.465151    0.063055\n2       PC8             9.303946           0.262323    0.035560\n3      PC69             8.890472           0.250665    0.033980\n4      PC20             7.806957           0.220115    0.029839\n5       PC2             7.707667           0.217316    0.029459\n6       PC5             7.509401           0.211726    0.028701\n7       PC3             7.465839           0.210498    0.028535\n8     PC111             6.293296           0.177438    0.024053\n9     PC128             6.280142           0.177067    0.024003\n10      PC4             5.694570           0.160557    0.021765\n11    PC218             4.972324           0.140193    0.019005\n12      PC7             4.649944           0.131104    0.017772\n13     PC97             4.283659           0.120777    0.016372\n14     PC27             3.937489           0.111017    0.015049\n15     PC13             3.929464           0.110790    0.015019\n16     PC44             3.922213           0.110586    0.014991\n17     PC55             3.897375           0.109886    0.014896\n18    PC129             3.311144           0.093357    0.012655\n19     PC94             2.901412           0.081805    0.011089",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variable</th>\n      <th>relative_importance</th>\n      <th>scaled_importance</th>\n      <th>percentage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>PC14</td>\n      <td>35.467583</td>\n      <td>1.000000</td>\n      <td>0.135559</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>PC11</td>\n      <td>16.497795</td>\n      <td>0.465151</td>\n      <td>0.063055</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PC8</td>\n      <td>9.303946</td>\n      <td>0.262323</td>\n      <td>0.035560</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>PC69</td>\n      <td>8.890472</td>\n      <td>0.250665</td>\n      <td>0.033980</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>PC20</td>\n      <td>7.806957</td>\n      <td>0.220115</td>\n      <td>0.029839</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>PC2</td>\n      <td>7.707667</td>\n      <td>0.217316</td>\n      <td>0.029459</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>PC5</td>\n      <td>7.509401</td>\n      <td>0.211726</td>\n      <td>0.028701</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>PC3</td>\n      <td>7.465839</td>\n      <td>0.210498</td>\n      <td>0.028535</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>PC111</td>\n      <td>6.293296</td>\n      <td>0.177438</td>\n      <td>0.024053</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>PC128</td>\n      <td>6.280142</td>\n      <td>0.177067</td>\n      <td>0.024003</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>PC4</td>\n      <td>5.694570</td>\n      <td>0.160557</td>\n      <td>0.021765</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>PC218</td>\n      <td>4.972324</td>\n      <td>0.140193</td>\n      <td>0.019005</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>PC7</td>\n      <td>4.649944</td>\n      <td>0.131104</td>\n      <td>0.017772</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>PC97</td>\n      <td>4.283659</td>\n      <td>0.120777</td>\n      <td>0.016372</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>PC27</td>\n      <td>3.937489</td>\n      <td>0.111017</td>\n      <td>0.015049</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>PC13</td>\n      <td>3.929464</td>\n      <td>0.110790</td>\n      <td>0.015019</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>PC44</td>\n      <td>3.922213</td>\n      <td>0.110586</td>\n      <td>0.014991</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>PC55</td>\n      <td>3.897375</td>\n      <td>0.109886</td>\n      <td>0.014896</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>PC129</td>\n      <td>3.311144</td>\n      <td>0.093357</td>\n      <td>0.012655</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>PC94</td>\n      <td>2.901412</td>\n      <td>0.081805</td>\n      <td>0.011089</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "<bound method ModelBase.model_performance of >"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605460531426
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from h2o.estimators import H2OXGBoostEstimator\r\n",
        "\r\n",
        "top_xgb = H2OXGBoostEstimator(**extract_params_from_model(best_xgb_model.actual_params))\r\n",
        "\r\n",
        "top_xgb.train(x=x, y=y, training_frame=train_pca_df_frame, validation_frame=test_pca_df_frame)\r\n",
        "\r\n",
        "# h2o.save_model(top_xgb, MODELS_LOCATION + \"PCA300/top_xgb\")\r\n",
        "\r\n",
        "\r\n",
        "print('AUC on test_pca_df_frame data: ', top_xgb.model_performance(valid= True).auc(), \"\\n\\n============================\")\r\n",
        "\r\n",
        "top_xgb.model_performance"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xgboost Model Build progress: |███████████████████████████████████████████| 100%\n",
            "AUC on test_pca_df_frame data:  0.6006189421715613 \n",
            "\n",
            "============================\n",
            "Model Details\n",
            "=============\n",
            "H2OXGBoostEstimator :  XGBoost\n",
            "Model Key:  XGBoost_model_python_1605450290525_256\n",
            "\n",
            "\n",
            "Model Summary: \n",
            "\n",
            "\n",
            "ModelMetricsBinomial: xgboost\n",
            "** Reported on train data. **\n",
            "\n",
            "MSE: 0.0033808608330304197\n",
            "RMSE: 0.05814517033280081\n",
            "LogLoss: 0.04830052729085686\n",
            "Mean Per-Class Error: 0.0\n",
            "AUC: 1.0\n",
            "AUCPR: 1.0\n",
            "Gini: 1.0\n",
            "\n",
            "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8332616090774536: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "     number_of_trees\n0               70.0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>number_of_trees</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>70.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "              0      1 Error           Rate\n0      0  423.0    0.0   0.0    (0.0/423.0)\n1      1    0.0  800.0   0.0    (0.0/800.0)\n2  Total  423.0  800.0   0.0   (0.0/1223.0)",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>423.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>(0.0/423.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>800.0</td>\n      <td>0.0</td>\n      <td>(0.0/800.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>423.0</td>\n      <td>800.0</td>\n      <td>0.0</td>\n      <td>(0.0/1223.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Maximum Metrics: Maximum metrics at their respective thresholds\n",
            "\n",
            "Gains/Lift Table: Avg response rate: 65.41 %, avg score: 65.33 %\n",
            "\n",
            "\n",
            "ModelMetricsBinomial: xgboost\n",
            "** Reported on validation data. **\n",
            "\n",
            "MSE: 0.24513856243186335\n",
            "RMSE: 0.4951146962390264\n",
            "LogLoss: 0.7253855637689238\n",
            "Mean Per-Class Error: 0.4032199513558645\n",
            "AUC: 0.6006189421715613\n",
            "AUCPR: 0.757982161501983\n",
            "Gini: 0.20123788434312262\n",
            "\n",
            "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.06184113025665283: \n",
            "\n",
            "Maximum Metrics: Maximum metrics at their respective thresholds\n",
            "\n",
            "Gains/Lift Table: Avg response rate: 67.47 %, avg score: 70.81 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                         metric  threshold      value    idx\n0                        max f1   0.833262    1.00000  211.0\n1                        max f2   0.833262    1.00000  211.0\n2                  max f0point5   0.833262    1.00000  211.0\n3                  max accuracy   0.833262    1.00000  211.0\n4                 max precision   0.996885    1.00000    0.0\n5                    max recall   0.833262    1.00000  211.0\n6               max specificity   0.996885    1.00000    0.0\n7              max absolute_mcc   0.833262    1.00000  211.0\n8    max min_per_class_accuracy   0.833262    1.00000  211.0\n9   max mean_per_class_accuracy   0.833262    1.00000  211.0\n10                      max tns   0.996885  423.00000    0.0\n11                      max fns   0.996885  799.00000    0.0\n12                      max fps   0.014052  423.00000  399.0\n13                      max tps   0.833262  800.00000  211.0\n14                      max tnr   0.996885    1.00000    0.0\n15                      max fnr   0.996885    0.99875    0.0\n16                      max fpr   0.014052    1.00000  399.0\n17                      max tpr   0.833262    1.00000  211.0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.833262</td>\n      <td>1.00000</td>\n      <td>211.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.833262</td>\n      <td>1.00000</td>\n      <td>211.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.833262</td>\n      <td>1.00000</td>\n      <td>211.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.833262</td>\n      <td>1.00000</td>\n      <td>211.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>0.996885</td>\n      <td>1.00000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.833262</td>\n      <td>1.00000</td>\n      <td>211.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>0.996885</td>\n      <td>1.00000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.833262</td>\n      <td>1.00000</td>\n      <td>211.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.833262</td>\n      <td>1.00000</td>\n      <td>211.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.833262</td>\n      <td>1.00000</td>\n      <td>211.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>0.996885</td>\n      <td>423.00000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>0.996885</td>\n      <td>799.00000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.014052</td>\n      <td>423.00000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.833262</td>\n      <td>800.00000</td>\n      <td>211.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>0.996885</td>\n      <td>1.00000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>0.996885</td>\n      <td>0.99875</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.014052</td>\n      <td>1.00000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.833262</td>\n      <td>1.00000</td>\n      <td>211.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "      group  cumulative_data_fraction  lower_threshold      lift  \\\n0         1                  0.010630         0.993755  1.528750   \n1         2                  0.020442         0.992838  1.528750   \n2         3                  0.030253         0.991498  1.528750   \n3         4                  0.040065         0.990777  1.528750   \n4         5                  0.050695         0.990105  1.528750   \n5         6                  0.100572         0.986664  1.528750   \n6         7                  0.150450         0.984156  1.528750   \n7         8                  0.200327         0.980479  1.528750   \n8         9                  0.300082         0.973543  1.528750   \n9        10                  0.399836         0.963129  1.528750   \n10       11                  0.500409         0.949958  1.528750   \n11       12                  0.600164         0.925196  1.528750   \n12       13                  0.699918         0.116726  0.827029   \n13       14                  0.799673         0.059845  0.000000   \n14       15                  0.899428         0.037587  0.000000   \n15       16                  1.000000         0.014052  0.000000   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0          1.528750       1.000000  0.994982                  1.000000   \n1          1.528750       1.000000  0.993361                  1.000000   \n2          1.528750       1.000000  0.992257                  1.000000   \n3          1.528750       1.000000  0.991211                  1.000000   \n4          1.528750       1.000000  0.990415                  1.000000   \n5          1.528750       1.000000  0.988356                  1.000000   \n6          1.528750       1.000000  0.985409                  1.000000   \n7          1.528750       1.000000  0.982317                  1.000000   \n8          1.528750       1.000000  0.977050                  1.000000   \n9          1.528750       1.000000  0.968153                  1.000000   \n10         1.528750       1.000000  0.957031                  1.000000   \n11         1.528750       1.000000  0.939748                  1.000000   \n12         1.428738       0.540984  0.556255                  0.934579   \n13         1.250511       0.000000  0.083720                  0.817996   \n14         1.111818       0.000000  0.048611                  0.727273   \n15         1.000000       0.000000  0.027621                  0.654129   \n\n    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n0           0.994982       0.01625                  0.01625   52.875000   \n1           0.994204       0.01500                  0.03125   52.875000   \n2           0.993572       0.01500                  0.04625   52.875000   \n3           0.992994       0.01500                  0.06125   52.875000   \n4           0.992453       0.01625                  0.07750   52.875000   \n5           0.990421       0.07625                  0.15375   52.875000   \n6           0.988760       0.07625                  0.23000   52.875000   \n7           0.987155       0.07625                  0.30625   52.875000   \n8           0.983796       0.15250                  0.45875   52.875000   \n9           0.979893       0.15250                  0.61125   52.875000   \n10          0.975298       0.15375                  0.76500   52.875000   \n11          0.969389       0.15250                  0.91750   52.875000   \n12          0.910508       0.08250                  1.00000  -17.297131   \n13          0.807371       0.00000                  1.00000 -100.000000   \n14          0.723218       0.00000                  1.00000 -100.000000   \n15          0.653260       0.00000                  1.00000 -100.000000   \n\n    cumulative_gain  \n0         52.875000  \n1         52.875000  \n2         52.875000  \n3         52.875000  \n4         52.875000  \n5         52.875000  \n6         52.875000  \n7         52.875000  \n8         52.875000  \n9         52.875000  \n10        52.875000  \n11        52.875000  \n12        42.873832  \n13        25.051125  \n14        11.181818  \n15         0.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.010630</td>\n      <td>0.993755</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>0.994982</td>\n      <td>1.000000</td>\n      <td>0.994982</td>\n      <td>0.01625</td>\n      <td>0.01625</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.020442</td>\n      <td>0.992838</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>0.993361</td>\n      <td>1.000000</td>\n      <td>0.994204</td>\n      <td>0.01500</td>\n      <td>0.03125</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.030253</td>\n      <td>0.991498</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>0.992257</td>\n      <td>1.000000</td>\n      <td>0.993572</td>\n      <td>0.01500</td>\n      <td>0.04625</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.040065</td>\n      <td>0.990777</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>0.991211</td>\n      <td>1.000000</td>\n      <td>0.992994</td>\n      <td>0.01500</td>\n      <td>0.06125</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>0.050695</td>\n      <td>0.990105</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>0.990415</td>\n      <td>1.000000</td>\n      <td>0.992453</td>\n      <td>0.01625</td>\n      <td>0.07750</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>6</td>\n      <td>0.100572</td>\n      <td>0.986664</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>0.988356</td>\n      <td>1.000000</td>\n      <td>0.990421</td>\n      <td>0.07625</td>\n      <td>0.15375</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>0.150450</td>\n      <td>0.984156</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>0.985409</td>\n      <td>1.000000</td>\n      <td>0.988760</td>\n      <td>0.07625</td>\n      <td>0.23000</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>8</td>\n      <td>0.200327</td>\n      <td>0.980479</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>0.982317</td>\n      <td>1.000000</td>\n      <td>0.987155</td>\n      <td>0.07625</td>\n      <td>0.30625</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>9</td>\n      <td>0.300082</td>\n      <td>0.973543</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>0.977050</td>\n      <td>1.000000</td>\n      <td>0.983796</td>\n      <td>0.15250</td>\n      <td>0.45875</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>10</td>\n      <td>0.399836</td>\n      <td>0.963129</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>0.968153</td>\n      <td>1.000000</td>\n      <td>0.979893</td>\n      <td>0.15250</td>\n      <td>0.61125</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>11</td>\n      <td>0.500409</td>\n      <td>0.949958</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>0.957031</td>\n      <td>1.000000</td>\n      <td>0.975298</td>\n      <td>0.15375</td>\n      <td>0.76500</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>12</td>\n      <td>0.600164</td>\n      <td>0.925196</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>0.939748</td>\n      <td>1.000000</td>\n      <td>0.969389</td>\n      <td>0.15250</td>\n      <td>0.91750</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>13</td>\n      <td>0.699918</td>\n      <td>0.116726</td>\n      <td>0.827029</td>\n      <td>1.428738</td>\n      <td>0.540984</td>\n      <td>0.556255</td>\n      <td>0.934579</td>\n      <td>0.910508</td>\n      <td>0.08250</td>\n      <td>1.00000</td>\n      <td>-17.297131</td>\n      <td>42.873832</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>14</td>\n      <td>0.799673</td>\n      <td>0.059845</td>\n      <td>0.000000</td>\n      <td>1.250511</td>\n      <td>0.000000</td>\n      <td>0.083720</td>\n      <td>0.817996</td>\n      <td>0.807371</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>-100.000000</td>\n      <td>25.051125</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>15</td>\n      <td>0.899428</td>\n      <td>0.037587</td>\n      <td>0.000000</td>\n      <td>1.111818</td>\n      <td>0.000000</td>\n      <td>0.048611</td>\n      <td>0.727273</td>\n      <td>0.723218</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>-100.000000</td>\n      <td>11.181818</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>16</td>\n      <td>1.000000</td>\n      <td>0.014052</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.027621</td>\n      <td>0.654129</td>\n      <td>0.653260</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>-100.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "            0      1   Error            Rate\n0      0  0.0  163.0     1.0   (163.0/163.0)\n1      1  0.0  338.0     0.0     (0.0/338.0)\n2  Total  0.0  501.0  0.3253   (163.0/501.0)",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>163.0</td>\n      <td>1.0</td>\n      <td>(163.0/163.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>338.0</td>\n      <td>0.0</td>\n      <td>(0.0/338.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>0.0</td>\n      <td>501.0</td>\n      <td>0.3253</td>\n      <td>(163.0/501.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                         metric  threshold       value    idx\n0                        max f1   0.061841    0.805721  399.0\n1                        max f2   0.061841    0.912035  399.0\n2                  max f0point5   0.349946    0.730842  343.0\n3                  max accuracy   0.061841    0.674651  399.0\n4                 max precision   0.995495    1.000000    0.0\n5                    max recall   0.061841    1.000000  399.0\n6               max specificity   0.995495    1.000000    0.0\n7              max absolute_mcc   0.866196    0.190725  118.0\n8    max min_per_class_accuracy   0.759645    0.568047  186.0\n9   max mean_per_class_accuracy   0.866196    0.596780  118.0\n10                      max tns   0.995495  163.000000    0.0\n11                      max fns   0.995495  337.000000    0.0\n12                      max fps   0.096281  163.000000  396.0\n13                      max tps   0.061841  338.000000  399.0\n14                      max tnr   0.995495    1.000000    0.0\n15                      max fnr   0.995495    0.997041    0.0\n16                      max fpr   0.096281    1.000000  396.0\n17                      max tpr   0.061841    1.000000  399.0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.061841</td>\n      <td>0.805721</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.061841</td>\n      <td>0.912035</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.349946</td>\n      <td>0.730842</td>\n      <td>343.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.061841</td>\n      <td>0.674651</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>0.995495</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.061841</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>0.995495</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.866196</td>\n      <td>0.190725</td>\n      <td>118.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.759645</td>\n      <td>0.568047</td>\n      <td>186.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.866196</td>\n      <td>0.596780</td>\n      <td>118.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>0.995495</td>\n      <td>163.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>0.995495</td>\n      <td>337.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.096281</td>\n      <td>163.000000</td>\n      <td>396.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.061841</td>\n      <td>338.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>0.995495</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>0.995495</td>\n      <td>0.997041</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.096281</td>\n      <td>1.000000</td>\n      <td>396.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.061841</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "      group  cumulative_data_fraction  lower_threshold      lift  \\\n0         1                  0.011976         0.988995  1.482249   \n1         2                  0.021956         0.985476  0.889349   \n2         3                  0.031936         0.980057  1.482249   \n3         4                  0.041916         0.977705  0.889349   \n4         5                  0.051896         0.974306  1.482249   \n5         6                  0.101796         0.956100  1.126509   \n6         7                  0.151697         0.941595  1.245089   \n7         8                  0.201597         0.919802  1.185799   \n8         9                  0.301397         0.882816  1.096864   \n9        10                  0.401198         0.838573  1.007929   \n10       11                  0.500998         0.771878  1.037574   \n11       12                  0.600798         0.709230  0.800414   \n12       13                  0.700599         0.617023  0.770769   \n13       14                  0.800399         0.509008  1.185799   \n14       15                  0.900200         0.307938  0.889349   \n15       16                  1.000000         0.061841  0.800414   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0          1.482249           1.00  0.991787                  1.000000   \n1          1.212749           0.60  0.987282                  0.818182   \n2          1.296967           1.00  0.982329                  0.875000   \n3          1.199915           0.60  0.978471                  0.809524   \n4          1.254210           1.00  0.975998                  0.846154   \n5          1.191612           0.76  0.964057                  0.803922   \n6          1.209203           0.84  0.948843                  0.815789   \n7          1.203410           0.80  0.930159                  0.811881   \n8          1.168130           0.74  0.901427                  0.788079   \n9          1.128279           0.68  0.861915                  0.761194   \n10         1.110210           0.70  0.806606                  0.749004   \n11         1.058749           0.54  0.740312                  0.714286   \n12         1.017726           0.52  0.660737                  0.686610   \n13         1.038683           0.80  0.560820                  0.700748   \n14         1.022127           0.60  0.430207                  0.689579   \n15         1.000000           0.54  0.200451                  0.674651   \n\n    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n0           0.991787      0.017751                 0.017751  48.224852   \n1           0.989739      0.008876                 0.026627 -11.065089   \n2           0.987424      0.014793                 0.041420  48.224852   \n3           0.985292      0.008876                 0.050296 -11.065089   \n4           0.983505      0.014793                 0.065089  48.224852   \n5           0.973972      0.056213                 0.121302  12.650888   \n6           0.965706      0.062130                 0.183432  24.508876   \n7           0.956907      0.059172                 0.242604  18.579882   \n8           0.938536      0.109467                 0.352071   9.686391   \n9           0.919476      0.100592                 0.452663   0.792899   \n10          0.896992      0.103550                 0.556213   3.757396   \n11          0.870966      0.079882                 0.636095 -19.958580   \n12          0.841018      0.076923                 0.713018 -22.923077   \n13          0.806081      0.118343                 0.831361  18.579882   \n14          0.764410      0.088757                 0.920118 -11.065089   \n15          0.708126      0.079882                 1.000000 -19.958580   \n\n    cumulative_gain  \n0         48.224852  \n1         21.274879  \n2         29.696746  \n3         19.991547  \n4         25.421029  \n5         19.161156  \n6         20.920274  \n7         20.340969  \n8         16.812963  \n9         12.827872  \n10        11.021005  \n11         5.874894  \n12         1.772619  \n13         3.868288  \n14         2.212703  \n15         0.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.011976</td>\n      <td>0.988995</td>\n      <td>1.482249</td>\n      <td>1.482249</td>\n      <td>1.00</td>\n      <td>0.991787</td>\n      <td>1.000000</td>\n      <td>0.991787</td>\n      <td>0.017751</td>\n      <td>0.017751</td>\n      <td>48.224852</td>\n      <td>48.224852</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.021956</td>\n      <td>0.985476</td>\n      <td>0.889349</td>\n      <td>1.212749</td>\n      <td>0.60</td>\n      <td>0.987282</td>\n      <td>0.818182</td>\n      <td>0.989739</td>\n      <td>0.008876</td>\n      <td>0.026627</td>\n      <td>-11.065089</td>\n      <td>21.274879</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.031936</td>\n      <td>0.980057</td>\n      <td>1.482249</td>\n      <td>1.296967</td>\n      <td>1.00</td>\n      <td>0.982329</td>\n      <td>0.875000</td>\n      <td>0.987424</td>\n      <td>0.014793</td>\n      <td>0.041420</td>\n      <td>48.224852</td>\n      <td>29.696746</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.041916</td>\n      <td>0.977705</td>\n      <td>0.889349</td>\n      <td>1.199915</td>\n      <td>0.60</td>\n      <td>0.978471</td>\n      <td>0.809524</td>\n      <td>0.985292</td>\n      <td>0.008876</td>\n      <td>0.050296</td>\n      <td>-11.065089</td>\n      <td>19.991547</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>0.051896</td>\n      <td>0.974306</td>\n      <td>1.482249</td>\n      <td>1.254210</td>\n      <td>1.00</td>\n      <td>0.975998</td>\n      <td>0.846154</td>\n      <td>0.983505</td>\n      <td>0.014793</td>\n      <td>0.065089</td>\n      <td>48.224852</td>\n      <td>25.421029</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>6</td>\n      <td>0.101796</td>\n      <td>0.956100</td>\n      <td>1.126509</td>\n      <td>1.191612</td>\n      <td>0.76</td>\n      <td>0.964057</td>\n      <td>0.803922</td>\n      <td>0.973972</td>\n      <td>0.056213</td>\n      <td>0.121302</td>\n      <td>12.650888</td>\n      <td>19.161156</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>0.151697</td>\n      <td>0.941595</td>\n      <td>1.245089</td>\n      <td>1.209203</td>\n      <td>0.84</td>\n      <td>0.948843</td>\n      <td>0.815789</td>\n      <td>0.965706</td>\n      <td>0.062130</td>\n      <td>0.183432</td>\n      <td>24.508876</td>\n      <td>20.920274</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>8</td>\n      <td>0.201597</td>\n      <td>0.919802</td>\n      <td>1.185799</td>\n      <td>1.203410</td>\n      <td>0.80</td>\n      <td>0.930159</td>\n      <td>0.811881</td>\n      <td>0.956907</td>\n      <td>0.059172</td>\n      <td>0.242604</td>\n      <td>18.579882</td>\n      <td>20.340969</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>9</td>\n      <td>0.301397</td>\n      <td>0.882816</td>\n      <td>1.096864</td>\n      <td>1.168130</td>\n      <td>0.74</td>\n      <td>0.901427</td>\n      <td>0.788079</td>\n      <td>0.938536</td>\n      <td>0.109467</td>\n      <td>0.352071</td>\n      <td>9.686391</td>\n      <td>16.812963</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>10</td>\n      <td>0.401198</td>\n      <td>0.838573</td>\n      <td>1.007929</td>\n      <td>1.128279</td>\n      <td>0.68</td>\n      <td>0.861915</td>\n      <td>0.761194</td>\n      <td>0.919476</td>\n      <td>0.100592</td>\n      <td>0.452663</td>\n      <td>0.792899</td>\n      <td>12.827872</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>11</td>\n      <td>0.500998</td>\n      <td>0.771878</td>\n      <td>1.037574</td>\n      <td>1.110210</td>\n      <td>0.70</td>\n      <td>0.806606</td>\n      <td>0.749004</td>\n      <td>0.896992</td>\n      <td>0.103550</td>\n      <td>0.556213</td>\n      <td>3.757396</td>\n      <td>11.021005</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>12</td>\n      <td>0.600798</td>\n      <td>0.709230</td>\n      <td>0.800414</td>\n      <td>1.058749</td>\n      <td>0.54</td>\n      <td>0.740312</td>\n      <td>0.714286</td>\n      <td>0.870966</td>\n      <td>0.079882</td>\n      <td>0.636095</td>\n      <td>-19.958580</td>\n      <td>5.874894</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>13</td>\n      <td>0.700599</td>\n      <td>0.617023</td>\n      <td>0.770769</td>\n      <td>1.017726</td>\n      <td>0.52</td>\n      <td>0.660737</td>\n      <td>0.686610</td>\n      <td>0.841018</td>\n      <td>0.076923</td>\n      <td>0.713018</td>\n      <td>-22.923077</td>\n      <td>1.772619</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>14</td>\n      <td>0.800399</td>\n      <td>0.509008</td>\n      <td>1.185799</td>\n      <td>1.038683</td>\n      <td>0.80</td>\n      <td>0.560820</td>\n      <td>0.700748</td>\n      <td>0.806081</td>\n      <td>0.118343</td>\n      <td>0.831361</td>\n      <td>18.579882</td>\n      <td>3.868288</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>15</td>\n      <td>0.900200</td>\n      <td>0.307938</td>\n      <td>0.889349</td>\n      <td>1.022127</td>\n      <td>0.60</td>\n      <td>0.430207</td>\n      <td>0.689579</td>\n      <td>0.764410</td>\n      <td>0.088757</td>\n      <td>0.920118</td>\n      <td>-11.065089</td>\n      <td>2.212703</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>16</td>\n      <td>1.000000</td>\n      <td>0.061841</td>\n      <td>0.800414</td>\n      <td>1.000000</td>\n      <td>0.54</td>\n      <td>0.200451</td>\n      <td>0.674651</td>\n      <td>0.708126</td>\n      <td>0.079882</td>\n      <td>1.000000</td>\n      <td>-19.958580</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "ModelMetricsBinomial: xgboost\n",
            "** Reported on cross-validation data. **\n",
            "\n",
            "MSE: 0.126513604609309\n",
            "RMSE: 0.35568750977411195\n",
            "LogLoss: 0.4026131330710863\n",
            "Mean Per-Class Error: 0.18774083924349871\n",
            "AUC: 0.8880614657210402\n",
            "AUCPR: 0.9298853306000129\n",
            "Gini: 0.7761229314420803\n",
            "\n",
            "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6205197870731354: \n",
            "\n",
            "Maximum Metrics: Maximum metrics at their respective thresholds\n",
            "\n",
            "Gains/Lift Table: Avg response rate: 65.41 %, avg score: 69.56 %\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "              0      1   Error             Rate\n0      0  307.0  116.0  0.2742    (116.0/423.0)\n1      1   81.0  719.0  0.1013     (81.0/800.0)\n2  Total  388.0  835.0  0.1611   (197.0/1223.0)",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>307.0</td>\n      <td>116.0</td>\n      <td>0.2742</td>\n      <td>(116.0/423.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>81.0</td>\n      <td>719.0</td>\n      <td>0.1013</td>\n      <td>(81.0/800.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>388.0</td>\n      <td>835.0</td>\n      <td>0.1611</td>\n      <td>(197.0/1223.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                         metric  threshold       value    idx\n0                        max f1   0.620520    0.879511  205.0\n1                        max f2   0.241455    0.922605  318.0\n2                  max f0point5   0.780233    0.872881  141.0\n3                  max accuracy   0.620520    0.838921  205.0\n4                 max precision   0.995584    1.000000    0.0\n5                    max recall   0.022781    1.000000  398.0\n6               max specificity   0.995584    1.000000    0.0\n7              max absolute_mcc   0.620520    0.638265  205.0\n8    max min_per_class_accuracy   0.743228    0.806147  157.0\n9   max mean_per_class_accuracy   0.620520    0.812259  205.0\n10                      max tns   0.995584  423.000000    0.0\n11                      max fns   0.995584  798.000000    0.0\n12                      max fps   0.021227  423.000000  399.0\n13                      max tps   0.022781  800.000000  398.0\n14                      max tnr   0.995584    1.000000    0.0\n15                      max fnr   0.995584    0.997500    0.0\n16                      max fpr   0.021227    1.000000  399.0\n17                      max tpr   0.022781    1.000000  398.0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.620520</td>\n      <td>0.879511</td>\n      <td>205.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.241455</td>\n      <td>0.922605</td>\n      <td>318.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.780233</td>\n      <td>0.872881</td>\n      <td>141.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.620520</td>\n      <td>0.838921</td>\n      <td>205.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>0.995584</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.022781</td>\n      <td>1.000000</td>\n      <td>398.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>0.995584</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.620520</td>\n      <td>0.638265</td>\n      <td>205.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.743228</td>\n      <td>0.806147</td>\n      <td>157.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.620520</td>\n      <td>0.812259</td>\n      <td>205.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>0.995584</td>\n      <td>423.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>0.995584</td>\n      <td>798.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.021227</td>\n      <td>423.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.022781</td>\n      <td>800.000000</td>\n      <td>398.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>0.995584</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>0.995584</td>\n      <td>0.997500</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.021227</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.022781</td>\n      <td>1.000000</td>\n      <td>398.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "      group  cumulative_data_fraction  lower_threshold      lift  \\\n0         1                  0.010630         0.992334  1.528750   \n1         2                  0.020442         0.990809  1.401354   \n2         3                  0.030253         0.989421  1.528750   \n3         4                  0.040065         0.987439  1.528750   \n4         5                  0.050695         0.986476  1.528750   \n5         6                  0.100572         0.978343  1.503689   \n6         7                  0.150450         0.970047  1.478627   \n7         8                  0.200327         0.960739  1.503689   \n8         9                  0.300082         0.937027  1.428504   \n9        10                  0.399836         0.897359  1.328258   \n10       11                  0.500409         0.835142  1.242886   \n11       12                  0.600164         0.737403  1.127766   \n12       13                  0.699918         0.585166  0.964867   \n13       14                  0.799673         0.347572  0.513760   \n14       15                  0.899428         0.151209  0.288207   \n15       16                  1.000000         0.021227  0.111860   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0          1.528750       1.000000  0.993334                  1.000000   \n1          1.467600       0.916667  0.991453                  0.960000   \n2          1.487432       1.000000  0.990086                  0.972973   \n3          1.497551       1.000000  0.988567                  0.979592   \n4          1.504093       1.000000  0.986994                  0.983871   \n5          1.503892       0.983607  0.982372                  0.983740   \n6          1.495516       0.967213  0.974051                  0.978261   \n7          1.497551       0.983607  0.965573                  0.979592   \n8          1.474598       0.934426  0.948186                  0.964578   \n9          1.438088       0.868852  0.919391                  0.940695   \n10         1.398856       0.813008  0.866688                  0.915033   \n11         1.353798       0.737705  0.789530                  0.885559   \n12         1.298366       0.631148  0.668575                  0.849299   \n13         1.200491       0.336066  0.477624                  0.785276   \n14         1.099310       0.188525  0.244151                  0.719091   \n15         1.000000       0.073171  0.087266                  0.654129   \n\n    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n0           0.993334       0.01625                  0.01625  52.875000   \n1           0.992431       0.01375                  0.03000  40.135417   \n2           0.991671       0.01500                  0.04500  52.875000   \n3           0.990911       0.01500                  0.06000  52.875000   \n4           0.990089       0.01625                  0.07625  52.875000   \n5           0.986262       0.07500                  0.15125  50.368852   \n6           0.982214       0.07375                  0.22500  47.862705   \n7           0.978071       0.07500                  0.30000  50.368852   \n8           0.968136       0.14250                  0.44250  42.850410   \n9           0.955975       0.13250                  0.57500  32.825820   \n10          0.938030       0.12500                  0.70000  24.288618   \n11          0.913347       0.11250                  0.81250  12.776639   \n12          0.878462       0.09625                  0.90875  -3.513320   \n13          0.828459       0.05125                  0.96000 -48.623975   \n14          0.763654       0.02875                  0.98875 -71.179303   \n15          0.695628       0.01125                  1.00000 -88.814024   \n\n    cumulative_gain  \n0         52.875000  \n1         46.760000  \n2         48.743243  \n3         49.755102  \n4         50.409274  \n5         50.389228  \n6         49.551630  \n7         49.755102  \n8         47.459809  \n9         43.808793  \n10        39.885621  \n11        35.379768  \n12        29.836595  \n13        20.049080  \n14         9.931023  \n15         0.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.010630</td>\n      <td>0.992334</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>0.993334</td>\n      <td>1.000000</td>\n      <td>0.993334</td>\n      <td>0.01625</td>\n      <td>0.01625</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.020442</td>\n      <td>0.990809</td>\n      <td>1.401354</td>\n      <td>1.467600</td>\n      <td>0.916667</td>\n      <td>0.991453</td>\n      <td>0.960000</td>\n      <td>0.992431</td>\n      <td>0.01375</td>\n      <td>0.03000</td>\n      <td>40.135417</td>\n      <td>46.760000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.030253</td>\n      <td>0.989421</td>\n      <td>1.528750</td>\n      <td>1.487432</td>\n      <td>1.000000</td>\n      <td>0.990086</td>\n      <td>0.972973</td>\n      <td>0.991671</td>\n      <td>0.01500</td>\n      <td>0.04500</td>\n      <td>52.875000</td>\n      <td>48.743243</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.040065</td>\n      <td>0.987439</td>\n      <td>1.528750</td>\n      <td>1.497551</td>\n      <td>1.000000</td>\n      <td>0.988567</td>\n      <td>0.979592</td>\n      <td>0.990911</td>\n      <td>0.01500</td>\n      <td>0.06000</td>\n      <td>52.875000</td>\n      <td>49.755102</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>0.050695</td>\n      <td>0.986476</td>\n      <td>1.528750</td>\n      <td>1.504093</td>\n      <td>1.000000</td>\n      <td>0.986994</td>\n      <td>0.983871</td>\n      <td>0.990089</td>\n      <td>0.01625</td>\n      <td>0.07625</td>\n      <td>52.875000</td>\n      <td>50.409274</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>6</td>\n      <td>0.100572</td>\n      <td>0.978343</td>\n      <td>1.503689</td>\n      <td>1.503892</td>\n      <td>0.983607</td>\n      <td>0.982372</td>\n      <td>0.983740</td>\n      <td>0.986262</td>\n      <td>0.07500</td>\n      <td>0.15125</td>\n      <td>50.368852</td>\n      <td>50.389228</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>0.150450</td>\n      <td>0.970047</td>\n      <td>1.478627</td>\n      <td>1.495516</td>\n      <td>0.967213</td>\n      <td>0.974051</td>\n      <td>0.978261</td>\n      <td>0.982214</td>\n      <td>0.07375</td>\n      <td>0.22500</td>\n      <td>47.862705</td>\n      <td>49.551630</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>8</td>\n      <td>0.200327</td>\n      <td>0.960739</td>\n      <td>1.503689</td>\n      <td>1.497551</td>\n      <td>0.983607</td>\n      <td>0.965573</td>\n      <td>0.979592</td>\n      <td>0.978071</td>\n      <td>0.07500</td>\n      <td>0.30000</td>\n      <td>50.368852</td>\n      <td>49.755102</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>9</td>\n      <td>0.300082</td>\n      <td>0.937027</td>\n      <td>1.428504</td>\n      <td>1.474598</td>\n      <td>0.934426</td>\n      <td>0.948186</td>\n      <td>0.964578</td>\n      <td>0.968136</td>\n      <td>0.14250</td>\n      <td>0.44250</td>\n      <td>42.850410</td>\n      <td>47.459809</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>10</td>\n      <td>0.399836</td>\n      <td>0.897359</td>\n      <td>1.328258</td>\n      <td>1.438088</td>\n      <td>0.868852</td>\n      <td>0.919391</td>\n      <td>0.940695</td>\n      <td>0.955975</td>\n      <td>0.13250</td>\n      <td>0.57500</td>\n      <td>32.825820</td>\n      <td>43.808793</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>11</td>\n      <td>0.500409</td>\n      <td>0.835142</td>\n      <td>1.242886</td>\n      <td>1.398856</td>\n      <td>0.813008</td>\n      <td>0.866688</td>\n      <td>0.915033</td>\n      <td>0.938030</td>\n      <td>0.12500</td>\n      <td>0.70000</td>\n      <td>24.288618</td>\n      <td>39.885621</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>12</td>\n      <td>0.600164</td>\n      <td>0.737403</td>\n      <td>1.127766</td>\n      <td>1.353798</td>\n      <td>0.737705</td>\n      <td>0.789530</td>\n      <td>0.885559</td>\n      <td>0.913347</td>\n      <td>0.11250</td>\n      <td>0.81250</td>\n      <td>12.776639</td>\n      <td>35.379768</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>13</td>\n      <td>0.699918</td>\n      <td>0.585166</td>\n      <td>0.964867</td>\n      <td>1.298366</td>\n      <td>0.631148</td>\n      <td>0.668575</td>\n      <td>0.849299</td>\n      <td>0.878462</td>\n      <td>0.09625</td>\n      <td>0.90875</td>\n      <td>-3.513320</td>\n      <td>29.836595</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>14</td>\n      <td>0.799673</td>\n      <td>0.347572</td>\n      <td>0.513760</td>\n      <td>1.200491</td>\n      <td>0.336066</td>\n      <td>0.477624</td>\n      <td>0.785276</td>\n      <td>0.828459</td>\n      <td>0.05125</td>\n      <td>0.96000</td>\n      <td>-48.623975</td>\n      <td>20.049080</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>15</td>\n      <td>0.899428</td>\n      <td>0.151209</td>\n      <td>0.288207</td>\n      <td>1.099310</td>\n      <td>0.188525</td>\n      <td>0.244151</td>\n      <td>0.719091</td>\n      <td>0.763654</td>\n      <td>0.02875</td>\n      <td>0.98875</td>\n      <td>-71.179303</td>\n      <td>9.931023</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>16</td>\n      <td>1.000000</td>\n      <td>0.021227</td>\n      <td>0.111860</td>\n      <td>1.000000</td>\n      <td>0.073171</td>\n      <td>0.087266</td>\n      <td>0.654129</td>\n      <td>0.695628</td>\n      <td>0.01125</td>\n      <td>1.00000</td>\n      <td>-88.814024</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Metrics Summary: \n",
            "\n",
            "See the whole table with table.as_data_frame()\n",
            "\n",
            "Scoring History: \n",
            "\n",
            "See the whole table with table.as_data_frame()\n",
            "\n",
            "Variable Importances: \n",
            "\n",
            "See the whole table with table.as_data_frame()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                                   mean            sd  cv_1_valid  cv_2_valid  \\\n0                  accuracy   0.8439114   0.009800501   0.8514056   0.8293651   \n1                       auc   0.8873135   0.010410762    0.891342    0.897207   \n2                     aucpr  0.93073946   0.012864572  0.94105965   0.9394219   \n3                       err  0.15608859   0.009800501  0.14859438  0.17063493   \n4                 err_count        38.2     2.9495761        37.0        43.0   \n5                  f0point5  0.86003184  0.0130484775  0.87456846  0.85005903   \n6                        f1  0.88680804  0.0096642515   0.8914956  0.87009066   \n7                        f2   0.9156609   0.020263776  0.90909094   0.8910891   \n8            lift_top_group   1.5290636    0.03780725   1.5090909   1.5849056   \n9                   logloss  0.40265596   0.009278146  0.39286137  0.40253487   \n10      max_per_class_error  0.33334628    0.07112779   0.2857143  0.30107528   \n11                      mcc   0.6479294   0.019078607  0.66005164  0.62674123   \n12  mean_per_class_accuracy   0.8014227   0.021955615   0.8177489   0.8022925   \n13     mean_per_class_error  0.19857728   0.021955615  0.18225108  0.19770744   \n14                      mse   0.1264941  0.0029697428  0.12417467  0.12958266   \n15                   pr_auc  0.93073946   0.012864572  0.94105965   0.9394219   \n16                precision   0.8432131   0.019281898   0.8636364   0.8372093   \n17                       r2  0.44025895   0.005029392  0.44451994  0.44349653   \n18                   recall  0.93619174   0.030560225  0.92121214   0.9056604   \n19                     rmse  0.35564056  0.0041671083  0.35238427   0.3599759   \n\n     cv_3_valid   cv_4_valid  cv_5_valid  \n0     0.8493724    0.8381743   0.8512397  \n1     0.8889151   0.86964285   0.8894603  \n2     0.9393698   0.91347164   0.9203742  \n3    0.15062761   0.16182573  0.14876033  \n4          36.0         39.0        36.0  \n5    0.85858583    0.8449946   0.8719512  \n6     0.8947368   0.88951844  0.88819873  \n7    0.93406594   0.93899524   0.9050633  \n8     1.5031446    1.4968944    1.551282  \n9     0.3960655    0.4050471  0.41677105  \n10        0.375       0.4375  0.26744187  \n11    0.6542707    0.6290906   0.6694926  \n12    0.7936321    0.7688276   0.8246124  \n13   0.20636792   0.23117235  0.17538759  \n14  0.123956524  0.124892786  0.12986383  \n15    0.9393698   0.91347164   0.9203742  \n16    0.8360656    0.8177083   0.8614458  \n17    0.4433553   0.43680918   0.4331138  \n18    0.9622642    0.9751553   0.9166667  \n19    0.3520746   0.35340172  0.36036623  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>mean</th>\n      <th>sd</th>\n      <th>cv_1_valid</th>\n      <th>cv_2_valid</th>\n      <th>cv_3_valid</th>\n      <th>cv_4_valid</th>\n      <th>cv_5_valid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>accuracy</td>\n      <td>0.8439114</td>\n      <td>0.009800501</td>\n      <td>0.8514056</td>\n      <td>0.8293651</td>\n      <td>0.8493724</td>\n      <td>0.8381743</td>\n      <td>0.8512397</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>auc</td>\n      <td>0.8873135</td>\n      <td>0.010410762</td>\n      <td>0.891342</td>\n      <td>0.897207</td>\n      <td>0.8889151</td>\n      <td>0.86964285</td>\n      <td>0.8894603</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>aucpr</td>\n      <td>0.93073946</td>\n      <td>0.012864572</td>\n      <td>0.94105965</td>\n      <td>0.9394219</td>\n      <td>0.9393698</td>\n      <td>0.91347164</td>\n      <td>0.9203742</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>err</td>\n      <td>0.15608859</td>\n      <td>0.009800501</td>\n      <td>0.14859438</td>\n      <td>0.17063493</td>\n      <td>0.15062761</td>\n      <td>0.16182573</td>\n      <td>0.14876033</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>err_count</td>\n      <td>38.2</td>\n      <td>2.9495761</td>\n      <td>37.0</td>\n      <td>43.0</td>\n      <td>36.0</td>\n      <td>39.0</td>\n      <td>36.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>f0point5</td>\n      <td>0.86003184</td>\n      <td>0.0130484775</td>\n      <td>0.87456846</td>\n      <td>0.85005903</td>\n      <td>0.85858583</td>\n      <td>0.8449946</td>\n      <td>0.8719512</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>f1</td>\n      <td>0.88680804</td>\n      <td>0.0096642515</td>\n      <td>0.8914956</td>\n      <td>0.87009066</td>\n      <td>0.8947368</td>\n      <td>0.88951844</td>\n      <td>0.88819873</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>f2</td>\n      <td>0.9156609</td>\n      <td>0.020263776</td>\n      <td>0.90909094</td>\n      <td>0.8910891</td>\n      <td>0.93406594</td>\n      <td>0.93899524</td>\n      <td>0.9050633</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>lift_top_group</td>\n      <td>1.5290636</td>\n      <td>0.03780725</td>\n      <td>1.5090909</td>\n      <td>1.5849056</td>\n      <td>1.5031446</td>\n      <td>1.4968944</td>\n      <td>1.551282</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>logloss</td>\n      <td>0.40265596</td>\n      <td>0.009278146</td>\n      <td>0.39286137</td>\n      <td>0.40253487</td>\n      <td>0.3960655</td>\n      <td>0.4050471</td>\n      <td>0.41677105</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max_per_class_error</td>\n      <td>0.33334628</td>\n      <td>0.07112779</td>\n      <td>0.2857143</td>\n      <td>0.30107528</td>\n      <td>0.375</td>\n      <td>0.4375</td>\n      <td>0.26744187</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>mcc</td>\n      <td>0.6479294</td>\n      <td>0.019078607</td>\n      <td>0.66005164</td>\n      <td>0.62674123</td>\n      <td>0.6542707</td>\n      <td>0.6290906</td>\n      <td>0.6694926</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>mean_per_class_accuracy</td>\n      <td>0.8014227</td>\n      <td>0.021955615</td>\n      <td>0.8177489</td>\n      <td>0.8022925</td>\n      <td>0.7936321</td>\n      <td>0.7688276</td>\n      <td>0.8246124</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>mean_per_class_error</td>\n      <td>0.19857728</td>\n      <td>0.021955615</td>\n      <td>0.18225108</td>\n      <td>0.19770744</td>\n      <td>0.20636792</td>\n      <td>0.23117235</td>\n      <td>0.17538759</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>mse</td>\n      <td>0.1264941</td>\n      <td>0.0029697428</td>\n      <td>0.12417467</td>\n      <td>0.12958266</td>\n      <td>0.123956524</td>\n      <td>0.124892786</td>\n      <td>0.12986383</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>pr_auc</td>\n      <td>0.93073946</td>\n      <td>0.012864572</td>\n      <td>0.94105965</td>\n      <td>0.9394219</td>\n      <td>0.9393698</td>\n      <td>0.91347164</td>\n      <td>0.9203742</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>precision</td>\n      <td>0.8432131</td>\n      <td>0.019281898</td>\n      <td>0.8636364</td>\n      <td>0.8372093</td>\n      <td>0.8360656</td>\n      <td>0.8177083</td>\n      <td>0.8614458</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>r2</td>\n      <td>0.44025895</td>\n      <td>0.005029392</td>\n      <td>0.44451994</td>\n      <td>0.44349653</td>\n      <td>0.4433553</td>\n      <td>0.43680918</td>\n      <td>0.4331138</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>recall</td>\n      <td>0.93619174</td>\n      <td>0.030560225</td>\n      <td>0.92121214</td>\n      <td>0.9056604</td>\n      <td>0.9622642</td>\n      <td>0.9751553</td>\n      <td>0.9166667</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>rmse</td>\n      <td>0.35564056</td>\n      <td>0.0041671083</td>\n      <td>0.35238427</td>\n      <td>0.3599759</td>\n      <td>0.3520746</td>\n      <td>0.35340172</td>\n      <td>0.36036623</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                timestamp    duration  number_of_trees  training_rmse  \\\n0     2020-11-15 17:15:45  15.984 sec              0.0       0.500000   \n1     2020-11-15 17:15:45  16.171 sec              1.0       0.475108   \n2     2020-11-15 17:15:45  16.214 sec              2.0       0.453779   \n3     2020-11-15 17:15:46  16.266 sec              3.0       0.430273   \n4     2020-11-15 17:15:46  16.361 sec              4.0       0.405544   \n5     2020-11-15 17:15:46  16.407 sec              5.0       0.387562   \n6     2020-11-15 17:15:46  16.457 sec              6.0       0.370697   \n7     2020-11-15 17:15:46  16.514 sec              7.0       0.355001   \n8     2020-11-15 17:15:46  16.564 sec              8.0       0.341396   \n9     2020-11-15 17:15:46  16.621 sec              9.0       0.328628   \n10    2020-11-15 17:15:46  16.671 sec             10.0       0.317421   \n11    2020-11-15 17:15:46  16.718 sec             11.0       0.309168   \n12    2020-11-15 17:15:46  16.786 sec             12.0       0.298017   \n13    2020-11-15 17:15:46  16.850 sec             13.0       0.287860   \n14    2020-11-15 17:15:46  16.906 sec             14.0       0.278006   \n15    2020-11-15 17:15:46  16.962 sec             15.0       0.268490   \n16    2020-11-15 17:15:46  17.023 sec             16.0       0.262262   \n17    2020-11-15 17:15:46  17.102 sec             17.0       0.250550   \n18    2020-11-15 17:15:46  17.176 sec             18.0       0.243133   \n19    2020-11-15 17:15:47  17.243 sec             19.0       0.237383   \n\n    training_logloss  training_auc  training_pr_auc  training_lift  \\\n0           0.693147      0.500000         0.654129       1.000000   \n1           0.644499      0.893283         0.934619       1.520209   \n2           0.604356      0.934603         0.961879       1.528750   \n3           0.561689      0.965932         0.981046       1.528750   \n4           0.518412      0.981142         0.990292       1.528750   \n5           0.487536      0.982431         0.990796       1.528750   \n6           0.459064      0.984969         0.991893       1.528750   \n7           0.433188      0.987351         0.993140       1.528750   \n8           0.410832      0.988654         0.993790       1.528750   \n9           0.390355      0.991099         0.995128       1.528750   \n10          0.372369      0.992686         0.996057       1.528750   \n11          0.358571      0.993168         0.996369       1.528750   \n12          0.341027      0.994218         0.996979       1.528750   \n13          0.325120      0.995066         0.997361       1.528750   \n14          0.310059      0.996288         0.998014       1.528750   \n15          0.295897      0.997320         0.998585       1.528750   \n16          0.286050      0.997364         0.998603       1.528750   \n17          0.269401      0.998329         0.999120       1.528750   \n18          0.258780      0.998843         0.999392       1.528750   \n19          0.249938      0.999085         0.999517       1.528750   \n\n    training_classification_error  validation_rmse  validation_logloss  \\\n0                        0.345871         0.500000            0.693147   \n1                        0.147997         0.494108            0.681405   \n2                        0.117743         0.491526            0.676212   \n3                        0.083401         0.491490            0.676070   \n4                        0.062142         0.493391            0.679803   \n5                        0.060507         0.491797            0.676621   \n6                        0.052330         0.491912            0.676842   \n7                        0.044154         0.490928            0.674643   \n8                        0.044154         0.491934            0.677117   \n9                        0.039248         0.493176            0.679863   \n10                       0.036795         0.488912            0.671263   \n11                       0.036795         0.488986            0.671631   \n12                       0.032706         0.487721            0.669002   \n13                       0.028618         0.489893            0.673915   \n14                       0.024530         0.489704            0.673841   \n15                       0.024530         0.488970            0.672491   \n16                       0.022077         0.487714            0.670187   \n17                       0.017989         0.488228            0.671728   \n18                       0.015536         0.485485            0.665859   \n19                       0.014718         0.485455            0.666119   \n\n    validation_auc  validation_pr_auc  validation_lift  \\\n0         0.500000           0.674651         1.000000   \n1         0.569636           0.739420         1.283141   \n2         0.524122           0.718283         1.338805   \n3         0.516436           0.702038         1.296967   \n4         0.488529           0.676933         1.164624   \n5         0.493085           0.678748         1.212749   \n6         0.487467           0.676611         1.212749   \n7         0.498167           0.688697         1.212749   \n8         0.496288           0.681667         1.235207   \n9         0.497640           0.681109         1.058749   \n10        0.515864           0.695958         0.988166   \n11        0.519621           0.698344         0.988166   \n12        0.532327           0.707309         0.988166   \n13        0.530058           0.705822         0.988166   \n14        0.531410           0.705833         0.988166   \n15        0.537409           0.709221         0.988166   \n16        0.544170           0.712653         0.988166   \n17        0.543471           0.711558         0.988166   \n18        0.551666           0.717244         1.235207   \n19        0.552674           0.718537         0.988166   \n\n    validation_classification_error  \n0                          0.325349  \n1                          0.325349  \n2                          0.321357  \n3                          0.321357  \n4                          0.319361  \n5                          0.321357  \n6                          0.315369  \n7                          0.317365  \n8                          0.323353  \n9                          0.323353  \n10                         0.325349  \n11                         0.323353  \n12                         0.323353  \n13                         0.321357  \n14                         0.323353  \n15                         0.323353  \n16                         0.323353  \n17                         0.321357  \n18                         0.323353  \n19                         0.321357  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>timestamp</th>\n      <th>duration</th>\n      <th>number_of_trees</th>\n      <th>training_rmse</th>\n      <th>training_logloss</th>\n      <th>training_auc</th>\n      <th>training_pr_auc</th>\n      <th>training_lift</th>\n      <th>training_classification_error</th>\n      <th>validation_rmse</th>\n      <th>validation_logloss</th>\n      <th>validation_auc</th>\n      <th>validation_pr_auc</th>\n      <th>validation_lift</th>\n      <th>validation_classification_error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>2020-11-15 17:15:45</td>\n      <td>15.984 sec</td>\n      <td>0.0</td>\n      <td>0.500000</td>\n      <td>0.693147</td>\n      <td>0.500000</td>\n      <td>0.654129</td>\n      <td>1.000000</td>\n      <td>0.345871</td>\n      <td>0.500000</td>\n      <td>0.693147</td>\n      <td>0.500000</td>\n      <td>0.674651</td>\n      <td>1.000000</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2020-11-15 17:15:45</td>\n      <td>16.171 sec</td>\n      <td>1.0</td>\n      <td>0.475108</td>\n      <td>0.644499</td>\n      <td>0.893283</td>\n      <td>0.934619</td>\n      <td>1.520209</td>\n      <td>0.147997</td>\n      <td>0.494108</td>\n      <td>0.681405</td>\n      <td>0.569636</td>\n      <td>0.739420</td>\n      <td>1.283141</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>2020-11-15 17:15:45</td>\n      <td>16.214 sec</td>\n      <td>2.0</td>\n      <td>0.453779</td>\n      <td>0.604356</td>\n      <td>0.934603</td>\n      <td>0.961879</td>\n      <td>1.528750</td>\n      <td>0.117743</td>\n      <td>0.491526</td>\n      <td>0.676212</td>\n      <td>0.524122</td>\n      <td>0.718283</td>\n      <td>1.338805</td>\n      <td>0.321357</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>2020-11-15 17:15:46</td>\n      <td>16.266 sec</td>\n      <td>3.0</td>\n      <td>0.430273</td>\n      <td>0.561689</td>\n      <td>0.965932</td>\n      <td>0.981046</td>\n      <td>1.528750</td>\n      <td>0.083401</td>\n      <td>0.491490</td>\n      <td>0.676070</td>\n      <td>0.516436</td>\n      <td>0.702038</td>\n      <td>1.296967</td>\n      <td>0.321357</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>2020-11-15 17:15:46</td>\n      <td>16.361 sec</td>\n      <td>4.0</td>\n      <td>0.405544</td>\n      <td>0.518412</td>\n      <td>0.981142</td>\n      <td>0.990292</td>\n      <td>1.528750</td>\n      <td>0.062142</td>\n      <td>0.493391</td>\n      <td>0.679803</td>\n      <td>0.488529</td>\n      <td>0.676933</td>\n      <td>1.164624</td>\n      <td>0.319361</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>2020-11-15 17:15:46</td>\n      <td>16.407 sec</td>\n      <td>5.0</td>\n      <td>0.387562</td>\n      <td>0.487536</td>\n      <td>0.982431</td>\n      <td>0.990796</td>\n      <td>1.528750</td>\n      <td>0.060507</td>\n      <td>0.491797</td>\n      <td>0.676621</td>\n      <td>0.493085</td>\n      <td>0.678748</td>\n      <td>1.212749</td>\n      <td>0.321357</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>2020-11-15 17:15:46</td>\n      <td>16.457 sec</td>\n      <td>6.0</td>\n      <td>0.370697</td>\n      <td>0.459064</td>\n      <td>0.984969</td>\n      <td>0.991893</td>\n      <td>1.528750</td>\n      <td>0.052330</td>\n      <td>0.491912</td>\n      <td>0.676842</td>\n      <td>0.487467</td>\n      <td>0.676611</td>\n      <td>1.212749</td>\n      <td>0.315369</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>2020-11-15 17:15:46</td>\n      <td>16.514 sec</td>\n      <td>7.0</td>\n      <td>0.355001</td>\n      <td>0.433188</td>\n      <td>0.987351</td>\n      <td>0.993140</td>\n      <td>1.528750</td>\n      <td>0.044154</td>\n      <td>0.490928</td>\n      <td>0.674643</td>\n      <td>0.498167</td>\n      <td>0.688697</td>\n      <td>1.212749</td>\n      <td>0.317365</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>2020-11-15 17:15:46</td>\n      <td>16.564 sec</td>\n      <td>8.0</td>\n      <td>0.341396</td>\n      <td>0.410832</td>\n      <td>0.988654</td>\n      <td>0.993790</td>\n      <td>1.528750</td>\n      <td>0.044154</td>\n      <td>0.491934</td>\n      <td>0.677117</td>\n      <td>0.496288</td>\n      <td>0.681667</td>\n      <td>1.235207</td>\n      <td>0.323353</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>2020-11-15 17:15:46</td>\n      <td>16.621 sec</td>\n      <td>9.0</td>\n      <td>0.328628</td>\n      <td>0.390355</td>\n      <td>0.991099</td>\n      <td>0.995128</td>\n      <td>1.528750</td>\n      <td>0.039248</td>\n      <td>0.493176</td>\n      <td>0.679863</td>\n      <td>0.497640</td>\n      <td>0.681109</td>\n      <td>1.058749</td>\n      <td>0.323353</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>2020-11-15 17:15:46</td>\n      <td>16.671 sec</td>\n      <td>10.0</td>\n      <td>0.317421</td>\n      <td>0.372369</td>\n      <td>0.992686</td>\n      <td>0.996057</td>\n      <td>1.528750</td>\n      <td>0.036795</td>\n      <td>0.488912</td>\n      <td>0.671263</td>\n      <td>0.515864</td>\n      <td>0.695958</td>\n      <td>0.988166</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>2020-11-15 17:15:46</td>\n      <td>16.718 sec</td>\n      <td>11.0</td>\n      <td>0.309168</td>\n      <td>0.358571</td>\n      <td>0.993168</td>\n      <td>0.996369</td>\n      <td>1.528750</td>\n      <td>0.036795</td>\n      <td>0.488986</td>\n      <td>0.671631</td>\n      <td>0.519621</td>\n      <td>0.698344</td>\n      <td>0.988166</td>\n      <td>0.323353</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>2020-11-15 17:15:46</td>\n      <td>16.786 sec</td>\n      <td>12.0</td>\n      <td>0.298017</td>\n      <td>0.341027</td>\n      <td>0.994218</td>\n      <td>0.996979</td>\n      <td>1.528750</td>\n      <td>0.032706</td>\n      <td>0.487721</td>\n      <td>0.669002</td>\n      <td>0.532327</td>\n      <td>0.707309</td>\n      <td>0.988166</td>\n      <td>0.323353</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>2020-11-15 17:15:46</td>\n      <td>16.850 sec</td>\n      <td>13.0</td>\n      <td>0.287860</td>\n      <td>0.325120</td>\n      <td>0.995066</td>\n      <td>0.997361</td>\n      <td>1.528750</td>\n      <td>0.028618</td>\n      <td>0.489893</td>\n      <td>0.673915</td>\n      <td>0.530058</td>\n      <td>0.705822</td>\n      <td>0.988166</td>\n      <td>0.321357</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>2020-11-15 17:15:46</td>\n      <td>16.906 sec</td>\n      <td>14.0</td>\n      <td>0.278006</td>\n      <td>0.310059</td>\n      <td>0.996288</td>\n      <td>0.998014</td>\n      <td>1.528750</td>\n      <td>0.024530</td>\n      <td>0.489704</td>\n      <td>0.673841</td>\n      <td>0.531410</td>\n      <td>0.705833</td>\n      <td>0.988166</td>\n      <td>0.323353</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>2020-11-15 17:15:46</td>\n      <td>16.962 sec</td>\n      <td>15.0</td>\n      <td>0.268490</td>\n      <td>0.295897</td>\n      <td>0.997320</td>\n      <td>0.998585</td>\n      <td>1.528750</td>\n      <td>0.024530</td>\n      <td>0.488970</td>\n      <td>0.672491</td>\n      <td>0.537409</td>\n      <td>0.709221</td>\n      <td>0.988166</td>\n      <td>0.323353</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td></td>\n      <td>2020-11-15 17:15:46</td>\n      <td>17.023 sec</td>\n      <td>16.0</td>\n      <td>0.262262</td>\n      <td>0.286050</td>\n      <td>0.997364</td>\n      <td>0.998603</td>\n      <td>1.528750</td>\n      <td>0.022077</td>\n      <td>0.487714</td>\n      <td>0.670187</td>\n      <td>0.544170</td>\n      <td>0.712653</td>\n      <td>0.988166</td>\n      <td>0.323353</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td></td>\n      <td>2020-11-15 17:15:46</td>\n      <td>17.102 sec</td>\n      <td>17.0</td>\n      <td>0.250550</td>\n      <td>0.269401</td>\n      <td>0.998329</td>\n      <td>0.999120</td>\n      <td>1.528750</td>\n      <td>0.017989</td>\n      <td>0.488228</td>\n      <td>0.671728</td>\n      <td>0.543471</td>\n      <td>0.711558</td>\n      <td>0.988166</td>\n      <td>0.321357</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td></td>\n      <td>2020-11-15 17:15:46</td>\n      <td>17.176 sec</td>\n      <td>18.0</td>\n      <td>0.243133</td>\n      <td>0.258780</td>\n      <td>0.998843</td>\n      <td>0.999392</td>\n      <td>1.528750</td>\n      <td>0.015536</td>\n      <td>0.485485</td>\n      <td>0.665859</td>\n      <td>0.551666</td>\n      <td>0.717244</td>\n      <td>1.235207</td>\n      <td>0.323353</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td></td>\n      <td>2020-11-15 17:15:47</td>\n      <td>17.243 sec</td>\n      <td>19.0</td>\n      <td>0.237383</td>\n      <td>0.249938</td>\n      <td>0.999085</td>\n      <td>0.999517</td>\n      <td>1.528750</td>\n      <td>0.014718</td>\n      <td>0.485455</td>\n      <td>0.666119</td>\n      <td>0.552674</td>\n      <td>0.718537</td>\n      <td>0.988166</td>\n      <td>0.321357</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "   variable  relative_importance  scaled_importance  percentage\n0      PC14           688.135315           1.000000    0.091193\n1       PC4           246.798950           0.358649    0.032706\n2      PC20           236.119598           0.343130    0.031291\n3       PC7           228.511597           0.332074    0.030283\n4       PC2           203.115204           0.295168    0.026917\n5      PC27           202.068222           0.293646    0.026778\n6      PC13           189.076080           0.274766    0.025057\n7       PC3           168.413849           0.244739    0.022319\n8      PC11           167.146347           0.242897    0.022151\n9      PC24           159.061966           0.231149    0.021079\n10     PC19           120.138481           0.174586    0.015921\n11     PC97           108.921036           0.158284    0.014434\n12     PC10           106.459511           0.154707    0.014108\n13     PC15           104.881935           0.152415    0.013899\n14      PC1           101.662224           0.147736    0.013472\n15    PC182            85.187820           0.123795    0.011289\n16    PC205            83.684479           0.121610    0.011090\n17    PC111            83.373093           0.121158    0.011049\n18      PC5            82.712181           0.120198    0.010961\n19     PC45            71.626793           0.104088    0.009492",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variable</th>\n      <th>relative_importance</th>\n      <th>scaled_importance</th>\n      <th>percentage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>PC14</td>\n      <td>688.135315</td>\n      <td>1.000000</td>\n      <td>0.091193</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>PC4</td>\n      <td>246.798950</td>\n      <td>0.358649</td>\n      <td>0.032706</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PC20</td>\n      <td>236.119598</td>\n      <td>0.343130</td>\n      <td>0.031291</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>PC7</td>\n      <td>228.511597</td>\n      <td>0.332074</td>\n      <td>0.030283</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>PC2</td>\n      <td>203.115204</td>\n      <td>0.295168</td>\n      <td>0.026917</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>PC27</td>\n      <td>202.068222</td>\n      <td>0.293646</td>\n      <td>0.026778</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>PC13</td>\n      <td>189.076080</td>\n      <td>0.274766</td>\n      <td>0.025057</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>PC3</td>\n      <td>168.413849</td>\n      <td>0.244739</td>\n      <td>0.022319</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>PC11</td>\n      <td>167.146347</td>\n      <td>0.242897</td>\n      <td>0.022151</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>PC24</td>\n      <td>159.061966</td>\n      <td>0.231149</td>\n      <td>0.021079</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>PC19</td>\n      <td>120.138481</td>\n      <td>0.174586</td>\n      <td>0.015921</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>PC97</td>\n      <td>108.921036</td>\n      <td>0.158284</td>\n      <td>0.014434</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>PC10</td>\n      <td>106.459511</td>\n      <td>0.154707</td>\n      <td>0.014108</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>PC15</td>\n      <td>104.881935</td>\n      <td>0.152415</td>\n      <td>0.013899</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>PC1</td>\n      <td>101.662224</td>\n      <td>0.147736</td>\n      <td>0.013472</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>PC182</td>\n      <td>85.187820</td>\n      <td>0.123795</td>\n      <td>0.011289</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>PC205</td>\n      <td>83.684479</td>\n      <td>0.121610</td>\n      <td>0.011090</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>PC111</td>\n      <td>83.373093</td>\n      <td>0.121158</td>\n      <td>0.011049</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>PC5</td>\n      <td>82.712181</td>\n      <td>0.120198</td>\n      <td>0.010961</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>PC45</td>\n      <td>71.626793</td>\n      <td>0.104088</td>\n      <td>0.009492</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "<bound method ModelBase.model_performance of >"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605460552602
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from h2o.estimators import H2ORandomForestEstimator\r\n",
        "\r\n",
        "top_drf = H2ORandomForestEstimator(**extract_params_from_model(best_drf_model.actual_params, \r\n",
        "                                                             extra_params=['weights_column'],\r\n",
        "                                                             additional_keys= {'nfolds':5,\r\n",
        "                                                                               'fold_assignment':'random'}))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "top_drf.train(x=x, y=y, training_frame=train_pca_df_frame, validation_frame=test_pca_df_frame)\r\n",
        "\r\n",
        "# h2o.save_model(top_drf, MODELS_LOCATION + \"PCA300/top_drf\")\r\n",
        "\r\n",
        "\r\n",
        "print('AUC on test_pca_df_frame data: ', top_drf.model_performance(valid=True).auc(), \"\\n\\n============================\")\r\n",
        "\r\n",
        "top_drf.model_performance"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
            "AUC on test_pca_df_frame data:  0.5821051294151813 \n",
            "\n",
            "============================\n",
            "Model Details\n",
            "=============\n",
            "H2ORandomForestEstimator :  Distributed Random Forest\n",
            "Model Key:  DRF_model_python_1605450290525_795\n",
            "\n",
            "\n",
            "Model Summary: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "     number_of_trees  number_of_internal_trees  model_size_in_bytes  \\\n0              100.0                     100.0             115555.0   \n\n   min_depth  max_depth  mean_depth  min_leaves  max_leaves  mean_leaves  \n0       10.0       10.0        10.0        63.0       113.0        87.42  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>number_of_trees</th>\n      <th>number_of_internal_trees</th>\n      <th>model_size_in_bytes</th>\n      <th>min_depth</th>\n      <th>max_depth</th>\n      <th>mean_depth</th>\n      <th>min_leaves</th>\n      <th>max_leaves</th>\n      <th>mean_leaves</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>100.0</td>\n      <td>100.0</td>\n      <td>115555.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>63.0</td>\n      <td>113.0</td>\n      <td>87.42</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "ModelMetricsBinomial: drf\n",
            "** Reported on train data. **\n",
            "\n",
            "MSE: 0.09378924212244653\n",
            "RMSE: 0.3062502932609968\n",
            "LogLoss: 0.3338295215374348\n",
            "Mean Per-Class Error: 0.056559405940594054\n",
            "AUC: 0.977375464108911\n",
            "AUCPR: 0.980135446032191\n",
            "Gini: 0.9547509282178219\n",
            "\n",
            "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5673465723395894: \n",
            "\n",
            "Maximum Metrics: Maximum metrics at their respective thresholds\n",
            "\n",
            "Gains/Lift Table: Avg response rate: 49.75 %, avg score: 56.38 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "              0      1   Error            Rate\n0      0  757.0   51.0  0.0631    (51.0/808.0)\n1      1   40.0  760.0    0.05    (40.0/800.0)\n2  Total  797.0  811.0  0.0566   (91.0/1608.0)",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>757.0</td>\n      <td>51.0</td>\n      <td>0.0631</td>\n      <td>(51.0/808.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>40.0</td>\n      <td>760.0</td>\n      <td>0.05</td>\n      <td>(40.0/800.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>797.0</td>\n      <td>811.0</td>\n      <td>0.0566</td>\n      <td>(91.0/1608.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                         metric  threshold       value    idx\n0                        max f1   0.567347    0.943513  185.0\n1                        max f2   0.554408    0.947826  190.0\n2                  max f0point5   0.648927    0.955490  161.0\n3                  max accuracy   0.567347    0.943408  185.0\n4                 max precision   0.995143    1.000000    0.0\n5                    max recall   0.119408    1.000000  376.0\n6               max specificity   0.995143    1.000000    0.0\n7              max absolute_mcc   0.567347    0.886904  185.0\n8    max min_per_class_accuracy   0.582987    0.941250  180.0\n9   max mean_per_class_accuracy   0.567347    0.943441  185.0\n10                      max tns   0.995143  808.000000    0.0\n11                      max fns   0.995143  798.000000    0.0\n12                      max fps   0.018249  808.000000  399.0\n13                      max tps   0.119408  800.000000  376.0\n14                      max tnr   0.995143    1.000000    0.0\n15                      max fnr   0.995143    0.997500    0.0\n16                      max fpr   0.018249    1.000000  399.0\n17                      max tpr   0.119408    1.000000  376.0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.567347</td>\n      <td>0.943513</td>\n      <td>185.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.554408</td>\n      <td>0.947826</td>\n      <td>190.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.648927</td>\n      <td>0.955490</td>\n      <td>161.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.567347</td>\n      <td>0.943408</td>\n      <td>185.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>0.995143</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.119408</td>\n      <td>1.000000</td>\n      <td>376.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>0.995143</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.567347</td>\n      <td>0.886904</td>\n      <td>185.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.582987</td>\n      <td>0.941250</td>\n      <td>180.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.567347</td>\n      <td>0.943441</td>\n      <td>185.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>0.995143</td>\n      <td>808.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>0.995143</td>\n      <td>798.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.018249</td>\n      <td>808.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.119408</td>\n      <td>800.000000</td>\n      <td>376.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>0.995143</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>0.995143</td>\n      <td>0.997500</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.018249</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.119408</td>\n      <td>1.000000</td>\n      <td>376.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "ModelMetricsBinomial: drf\n",
            "** Reported on validation data. **\n",
            "\n",
            "MSE: 0.21987748973068402\n",
            "RMSE: 0.468910961410249\n",
            "LogLoss: 0.6322992883445343\n",
            "Mean Per-Class Error: 0.4282135985769775\n",
            "AUC: 0.5821051294151813\n",
            "AUCPR: 0.7520371662557974\n",
            "Gini: 0.16421025883036267\n",
            "\n",
            "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.28797825975519664: \n",
            "\n",
            "Maximum Metrics: Maximum metrics at their respective thresholds\n",
            "\n",
            "Gains/Lift Table: Avg response rate: 67.47 %, avg score: 69.08 %\n",
            "\n",
            "\n",
            "ModelMetricsBinomial: drf\n",
            "** Reported on cross-validation data. **\n",
            "\n",
            "MSE: 0.1480384722901824\n",
            "RMSE: 0.3847576799625739\n",
            "LogLoss: 0.45660318420183876\n",
            "Mean Per-Class Error: 0.18654550827423177\n",
            "AUC: 0.8844089834515367\n",
            "AUCPR: 0.9292240110585137\n",
            "Gini: 0.7688179669030735\n",
            "\n",
            "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.623777872790557: \n",
            "\n",
            "Maximum Metrics: Maximum metrics at their respective thresholds\n",
            "\n",
            "Gains/Lift Table: Avg response rate: 65.41 %, avg score: 71.56 %\n",
            "\n",
            "\n",
            "Cross-Validation Metrics Summary: \n",
            "\n",
            "See the whole table with table.as_data_frame()\n",
            "\n",
            "Scoring History: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "      group  cumulative_data_fraction  lower_threshold      lift  \\\n0         1                  0.010572         0.979453  2.010000   \n1         2                  0.020522         0.968347  2.010000   \n2         3                  0.030473         0.961837  2.010000   \n3         4                  0.040423         0.953626  2.010000   \n4         5                  0.050373         0.947936  2.010000   \n5         6                  0.100124         0.913712  2.010000   \n6         7                  0.150498         0.877486  1.985185   \n7         8                  0.200249         0.850112  1.984875   \n8         9                  0.300373         0.796541  1.997516   \n9        10                  0.399876         0.730431  1.922063   \n10       11                  0.500000         0.576023  1.523106   \n11       12                  0.600124         0.445800  0.299627   \n12       13                  0.699627         0.340139  0.150750   \n13       14                  0.799751         0.262819  0.012484   \n14       15                  0.899876         0.188404  0.062422   \n15       16                  1.000000         0.018249  0.037453   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0          2.010000       1.000000  0.986354                  1.000000   \n1          2.010000       1.000000  0.973256                  1.000000   \n2          2.010000       1.000000  0.965600                  1.000000   \n3          2.010000       1.000000  0.957496                  1.000000   \n4          2.010000       1.000000  0.951225                  1.000000   \n5          2.010000       1.000000  0.931750                  1.000000   \n6          2.001694       0.987654  0.894401                  0.995868   \n7          1.997516       0.987500  0.863214                  0.993789   \n8          1.997516       0.993789  0.823710                  0.993789   \n9          1.978740       0.956250  0.764863                  0.984448   \n10         1.887500       0.757764  0.660187                  0.939055   \n11         1.622580       0.149068  0.505380                  0.807254   \n12         1.413253       0.075000  0.394661                  0.703111   \n13         1.237885       0.006211  0.299262                  0.615863   \n14         1.107097       0.031056  0.225883                  0.550795   \n15         1.000000       0.018634  0.135817                  0.497512   \n\n    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n0           0.986354       0.02125                  0.02125  101.000000   \n1           0.980003       0.02000                  0.04125  101.000000   \n2           0.975300       0.02000                  0.06125  101.000000   \n3           0.970918       0.02000                  0.08125  101.000000   \n4           0.967028       0.02000                  0.10125  101.000000   \n5           0.949499       0.10000                  0.20125  101.000000   \n6           0.931057       0.10000                  0.30125   98.518519   \n7           0.914201       0.09875                  0.40000   98.487500   \n8           0.884037       0.20000                  0.60000   99.751553   \n9           0.854383       0.19125                  0.79125   92.206250   \n10          0.815496       0.15250                  0.94375   52.310559   \n11          0.763756       0.03000                  0.97375  -70.037267   \n12          0.711263       0.01500                  0.98875  -84.925000   \n13          0.659682       0.00125                  0.99000  -98.751553   \n14          0.611416       0.00625                  0.99625  -93.757764   \n15          0.563797       0.00375                  1.00000  -96.254658   \n\n    cumulative_gain  \n0        101.000000  \n1        101.000000  \n2        101.000000  \n3        101.000000  \n4        101.000000  \n5        101.000000  \n6        100.169421  \n7         99.751553  \n8         99.751553  \n9         97.874028  \n10        88.750000  \n11        62.258031  \n12        41.325333  \n13        23.788491  \n14        10.709744  \n15         0.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.010572</td>\n      <td>0.979453</td>\n      <td>2.010000</td>\n      <td>2.010000</td>\n      <td>1.000000</td>\n      <td>0.986354</td>\n      <td>1.000000</td>\n      <td>0.986354</td>\n      <td>0.02125</td>\n      <td>0.02125</td>\n      <td>101.000000</td>\n      <td>101.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.020522</td>\n      <td>0.968347</td>\n      <td>2.010000</td>\n      <td>2.010000</td>\n      <td>1.000000</td>\n      <td>0.973256</td>\n      <td>1.000000</td>\n      <td>0.980003</td>\n      <td>0.02000</td>\n      <td>0.04125</td>\n      <td>101.000000</td>\n      <td>101.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.030473</td>\n      <td>0.961837</td>\n      <td>2.010000</td>\n      <td>2.010000</td>\n      <td>1.000000</td>\n      <td>0.965600</td>\n      <td>1.000000</td>\n      <td>0.975300</td>\n      <td>0.02000</td>\n      <td>0.06125</td>\n      <td>101.000000</td>\n      <td>101.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.040423</td>\n      <td>0.953626</td>\n      <td>2.010000</td>\n      <td>2.010000</td>\n      <td>1.000000</td>\n      <td>0.957496</td>\n      <td>1.000000</td>\n      <td>0.970918</td>\n      <td>0.02000</td>\n      <td>0.08125</td>\n      <td>101.000000</td>\n      <td>101.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>0.050373</td>\n      <td>0.947936</td>\n      <td>2.010000</td>\n      <td>2.010000</td>\n      <td>1.000000</td>\n      <td>0.951225</td>\n      <td>1.000000</td>\n      <td>0.967028</td>\n      <td>0.02000</td>\n      <td>0.10125</td>\n      <td>101.000000</td>\n      <td>101.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>6</td>\n      <td>0.100124</td>\n      <td>0.913712</td>\n      <td>2.010000</td>\n      <td>2.010000</td>\n      <td>1.000000</td>\n      <td>0.931750</td>\n      <td>1.000000</td>\n      <td>0.949499</td>\n      <td>0.10000</td>\n      <td>0.20125</td>\n      <td>101.000000</td>\n      <td>101.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>0.150498</td>\n      <td>0.877486</td>\n      <td>1.985185</td>\n      <td>2.001694</td>\n      <td>0.987654</td>\n      <td>0.894401</td>\n      <td>0.995868</td>\n      <td>0.931057</td>\n      <td>0.10000</td>\n      <td>0.30125</td>\n      <td>98.518519</td>\n      <td>100.169421</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>8</td>\n      <td>0.200249</td>\n      <td>0.850112</td>\n      <td>1.984875</td>\n      <td>1.997516</td>\n      <td>0.987500</td>\n      <td>0.863214</td>\n      <td>0.993789</td>\n      <td>0.914201</td>\n      <td>0.09875</td>\n      <td>0.40000</td>\n      <td>98.487500</td>\n      <td>99.751553</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>9</td>\n      <td>0.300373</td>\n      <td>0.796541</td>\n      <td>1.997516</td>\n      <td>1.997516</td>\n      <td>0.993789</td>\n      <td>0.823710</td>\n      <td>0.993789</td>\n      <td>0.884037</td>\n      <td>0.20000</td>\n      <td>0.60000</td>\n      <td>99.751553</td>\n      <td>99.751553</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>10</td>\n      <td>0.399876</td>\n      <td>0.730431</td>\n      <td>1.922063</td>\n      <td>1.978740</td>\n      <td>0.956250</td>\n      <td>0.764863</td>\n      <td>0.984448</td>\n      <td>0.854383</td>\n      <td>0.19125</td>\n      <td>0.79125</td>\n      <td>92.206250</td>\n      <td>97.874028</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>11</td>\n      <td>0.500000</td>\n      <td>0.576023</td>\n      <td>1.523106</td>\n      <td>1.887500</td>\n      <td>0.757764</td>\n      <td>0.660187</td>\n      <td>0.939055</td>\n      <td>0.815496</td>\n      <td>0.15250</td>\n      <td>0.94375</td>\n      <td>52.310559</td>\n      <td>88.750000</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>12</td>\n      <td>0.600124</td>\n      <td>0.445800</td>\n      <td>0.299627</td>\n      <td>1.622580</td>\n      <td>0.149068</td>\n      <td>0.505380</td>\n      <td>0.807254</td>\n      <td>0.763756</td>\n      <td>0.03000</td>\n      <td>0.97375</td>\n      <td>-70.037267</td>\n      <td>62.258031</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>13</td>\n      <td>0.699627</td>\n      <td>0.340139</td>\n      <td>0.150750</td>\n      <td>1.413253</td>\n      <td>0.075000</td>\n      <td>0.394661</td>\n      <td>0.703111</td>\n      <td>0.711263</td>\n      <td>0.01500</td>\n      <td>0.98875</td>\n      <td>-84.925000</td>\n      <td>41.325333</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>14</td>\n      <td>0.799751</td>\n      <td>0.262819</td>\n      <td>0.012484</td>\n      <td>1.237885</td>\n      <td>0.006211</td>\n      <td>0.299262</td>\n      <td>0.615863</td>\n      <td>0.659682</td>\n      <td>0.00125</td>\n      <td>0.99000</td>\n      <td>-98.751553</td>\n      <td>23.788491</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>15</td>\n      <td>0.899876</td>\n      <td>0.188404</td>\n      <td>0.062422</td>\n      <td>1.107097</td>\n      <td>0.031056</td>\n      <td>0.225883</td>\n      <td>0.550795</td>\n      <td>0.611416</td>\n      <td>0.00625</td>\n      <td>0.99625</td>\n      <td>-93.757764</td>\n      <td>10.709744</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>16</td>\n      <td>1.000000</td>\n      <td>0.018249</td>\n      <td>0.037453</td>\n      <td>1.000000</td>\n      <td>0.018634</td>\n      <td>0.135817</td>\n      <td>0.497512</td>\n      <td>0.563797</td>\n      <td>0.00375</td>\n      <td>1.00000</td>\n      <td>-96.254658</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "            0      1   Error            Rate\n0      0  0.0  163.0     1.0   (163.0/163.0)\n1      1  0.0  338.0     0.0     (0.0/338.0)\n2  Total  0.0  501.0  0.3253   (163.0/501.0)",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>163.0</td>\n      <td>1.0</td>\n      <td>(163.0/163.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>338.0</td>\n      <td>0.0</td>\n      <td>(0.0/338.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>0.0</td>\n      <td>501.0</td>\n      <td>0.3253</td>\n      <td>(163.0/501.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                         metric  threshold       value    idx\n0                        max f1   0.287978    0.805721  399.0\n1                        max f2   0.287978    0.912035  399.0\n2                  max f0point5   0.501896    0.735430  358.0\n3                  max accuracy   0.490848    0.686627  364.0\n4                 max precision   0.976633    1.000000    0.0\n5                    max recall   0.287978    1.000000  399.0\n6               max specificity   0.976633    1.000000    0.0\n7              max absolute_mcc   0.834430    0.169249   68.0\n8    max min_per_class_accuracy   0.689065    0.550296  202.0\n9   max mean_per_class_accuracy   0.808645    0.571786   86.0\n10                      max tns   0.976633  163.000000    0.0\n11                      max fns   0.976633  337.000000    0.0\n12                      max fps   0.317697  163.000000  397.0\n13                      max tps   0.287978  338.000000  399.0\n14                      max tnr   0.976633    1.000000    0.0\n15                      max fnr   0.976633    0.997041    0.0\n16                      max fpr   0.317697    1.000000  397.0\n17                      max tpr   0.287978    1.000000  399.0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.287978</td>\n      <td>0.805721</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.287978</td>\n      <td>0.912035</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.501896</td>\n      <td>0.735430</td>\n      <td>358.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.490848</td>\n      <td>0.686627</td>\n      <td>364.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>0.976633</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.287978</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>0.976633</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.834430</td>\n      <td>0.169249</td>\n      <td>68.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.689065</td>\n      <td>0.550296</td>\n      <td>202.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.808645</td>\n      <td>0.571786</td>\n      <td>86.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>0.976633</td>\n      <td>163.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>0.976633</td>\n      <td>337.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.317697</td>\n      <td>163.000000</td>\n      <td>397.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.287978</td>\n      <td>338.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>0.976633</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>0.976633</td>\n      <td>0.997041</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.317697</td>\n      <td>1.000000</td>\n      <td>397.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.287978</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "      group  cumulative_data_fraction  lower_threshold      lift  \\\n0         1                  0.011976         0.945625  1.235207   \n1         2                  0.021956         0.932828  1.185799   \n2         3                  0.031936         0.919073  1.482249   \n3         4                  0.041916         0.900995  1.482249   \n4         5                  0.051896         0.888879  1.482249   \n5         6                  0.101796         0.856645  1.185799   \n6         7                  0.151697         0.838139  1.185799   \n7         8                  0.201597         0.817721  1.067219   \n8         9                  0.301397         0.773934  0.948639   \n9        10                  0.401198         0.726800  0.859704   \n10       11                  0.500998         0.694774  1.037574   \n11       12                  0.600798         0.658020  1.007929   \n12       13                  0.700599         0.618438  1.067219   \n13       14                  0.800399         0.577367  0.948639   \n14       15                  0.900200         0.511389  1.007929   \n15       16                  1.000000         0.287978  0.711479   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0          1.235207       0.833333  0.958670                  0.833333   \n1          1.212749       0.800000  0.936473                  0.818182   \n2          1.296967       1.000000  0.925097                  0.875000   \n3          1.341082       1.000000  0.912775                  0.904762   \n4          1.368229       1.000000  0.894768                  0.923077   \n5          1.278803       0.800000  0.867869                  0.862745   \n6          1.248209       0.800000  0.846720                  0.842105   \n7          1.203410       0.720000  0.829072                  0.811881   \n8          1.119049       0.640000  0.796048                  0.754967   \n9          1.054535       0.580000  0.751998                  0.711443   \n10         1.051156       0.700000  0.710728                  0.709163   \n11         1.043976       0.680000  0.675168                  0.704319   \n12         1.047287       0.720000  0.639085                  0.706553   \n13         1.034986       0.640000  0.599407                  0.698254   \n14         1.031987       0.680000  0.545050                  0.696231   \n15         1.000000       0.480000  0.450133                  0.674651   \n\n    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n0           0.958670      0.014793                 0.014793  23.520710   \n1           0.948581      0.011834                 0.026627  18.579882   \n2           0.941242      0.014793                 0.041420  48.224852   \n3           0.934464      0.014793                 0.056213  48.224852   \n4           0.926830      0.014793                 0.071006  48.224852   \n5           0.897927      0.059172                 0.130178  18.579882   \n6           0.881083      0.059172                 0.189349  18.579882   \n7           0.868209      0.053254                 0.242604   6.721893   \n8           0.844314      0.094675                 0.337278  -5.136095   \n9           0.821350      0.085799                 0.423077 -14.029586   \n10          0.799314      0.103550                 0.526627   3.757396   \n11          0.778692      0.100592                 0.627219   0.792899   \n12          0.758805      0.106509                 0.733728   6.721893   \n13          0.738930      0.094675                 0.828402  -5.136095   \n14          0.717435      0.100592                 0.928994   0.792899   \n15          0.690758      0.071006                 1.000000 -28.852071   \n\n    cumulative_gain  \n0         23.520710  \n1         21.274879  \n2         29.696746  \n3         34.108199  \n4         36.822940  \n5         27.880265  \n6         24.820928  \n7         20.340969  \n8         11.904855  \n9          5.453502  \n10         5.115632  \n11         4.397570  \n12         4.728670  \n13         3.498650  \n14         3.198677  \n15         0.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.011976</td>\n      <td>0.945625</td>\n      <td>1.235207</td>\n      <td>1.235207</td>\n      <td>0.833333</td>\n      <td>0.958670</td>\n      <td>0.833333</td>\n      <td>0.958670</td>\n      <td>0.014793</td>\n      <td>0.014793</td>\n      <td>23.520710</td>\n      <td>23.520710</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.021956</td>\n      <td>0.932828</td>\n      <td>1.185799</td>\n      <td>1.212749</td>\n      <td>0.800000</td>\n      <td>0.936473</td>\n      <td>0.818182</td>\n      <td>0.948581</td>\n      <td>0.011834</td>\n      <td>0.026627</td>\n      <td>18.579882</td>\n      <td>21.274879</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.031936</td>\n      <td>0.919073</td>\n      <td>1.482249</td>\n      <td>1.296967</td>\n      <td>1.000000</td>\n      <td>0.925097</td>\n      <td>0.875000</td>\n      <td>0.941242</td>\n      <td>0.014793</td>\n      <td>0.041420</td>\n      <td>48.224852</td>\n      <td>29.696746</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.041916</td>\n      <td>0.900995</td>\n      <td>1.482249</td>\n      <td>1.341082</td>\n      <td>1.000000</td>\n      <td>0.912775</td>\n      <td>0.904762</td>\n      <td>0.934464</td>\n      <td>0.014793</td>\n      <td>0.056213</td>\n      <td>48.224852</td>\n      <td>34.108199</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>0.051896</td>\n      <td>0.888879</td>\n      <td>1.482249</td>\n      <td>1.368229</td>\n      <td>1.000000</td>\n      <td>0.894768</td>\n      <td>0.923077</td>\n      <td>0.926830</td>\n      <td>0.014793</td>\n      <td>0.071006</td>\n      <td>48.224852</td>\n      <td>36.822940</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>6</td>\n      <td>0.101796</td>\n      <td>0.856645</td>\n      <td>1.185799</td>\n      <td>1.278803</td>\n      <td>0.800000</td>\n      <td>0.867869</td>\n      <td>0.862745</td>\n      <td>0.897927</td>\n      <td>0.059172</td>\n      <td>0.130178</td>\n      <td>18.579882</td>\n      <td>27.880265</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>0.151697</td>\n      <td>0.838139</td>\n      <td>1.185799</td>\n      <td>1.248209</td>\n      <td>0.800000</td>\n      <td>0.846720</td>\n      <td>0.842105</td>\n      <td>0.881083</td>\n      <td>0.059172</td>\n      <td>0.189349</td>\n      <td>18.579882</td>\n      <td>24.820928</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>8</td>\n      <td>0.201597</td>\n      <td>0.817721</td>\n      <td>1.067219</td>\n      <td>1.203410</td>\n      <td>0.720000</td>\n      <td>0.829072</td>\n      <td>0.811881</td>\n      <td>0.868209</td>\n      <td>0.053254</td>\n      <td>0.242604</td>\n      <td>6.721893</td>\n      <td>20.340969</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>9</td>\n      <td>0.301397</td>\n      <td>0.773934</td>\n      <td>0.948639</td>\n      <td>1.119049</td>\n      <td>0.640000</td>\n      <td>0.796048</td>\n      <td>0.754967</td>\n      <td>0.844314</td>\n      <td>0.094675</td>\n      <td>0.337278</td>\n      <td>-5.136095</td>\n      <td>11.904855</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>10</td>\n      <td>0.401198</td>\n      <td>0.726800</td>\n      <td>0.859704</td>\n      <td>1.054535</td>\n      <td>0.580000</td>\n      <td>0.751998</td>\n      <td>0.711443</td>\n      <td>0.821350</td>\n      <td>0.085799</td>\n      <td>0.423077</td>\n      <td>-14.029586</td>\n      <td>5.453502</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>11</td>\n      <td>0.500998</td>\n      <td>0.694774</td>\n      <td>1.037574</td>\n      <td>1.051156</td>\n      <td>0.700000</td>\n      <td>0.710728</td>\n      <td>0.709163</td>\n      <td>0.799314</td>\n      <td>0.103550</td>\n      <td>0.526627</td>\n      <td>3.757396</td>\n      <td>5.115632</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>12</td>\n      <td>0.600798</td>\n      <td>0.658020</td>\n      <td>1.007929</td>\n      <td>1.043976</td>\n      <td>0.680000</td>\n      <td>0.675168</td>\n      <td>0.704319</td>\n      <td>0.778692</td>\n      <td>0.100592</td>\n      <td>0.627219</td>\n      <td>0.792899</td>\n      <td>4.397570</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>13</td>\n      <td>0.700599</td>\n      <td>0.618438</td>\n      <td>1.067219</td>\n      <td>1.047287</td>\n      <td>0.720000</td>\n      <td>0.639085</td>\n      <td>0.706553</td>\n      <td>0.758805</td>\n      <td>0.106509</td>\n      <td>0.733728</td>\n      <td>6.721893</td>\n      <td>4.728670</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>14</td>\n      <td>0.800399</td>\n      <td>0.577367</td>\n      <td>0.948639</td>\n      <td>1.034986</td>\n      <td>0.640000</td>\n      <td>0.599407</td>\n      <td>0.698254</td>\n      <td>0.738930</td>\n      <td>0.094675</td>\n      <td>0.828402</td>\n      <td>-5.136095</td>\n      <td>3.498650</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>15</td>\n      <td>0.900200</td>\n      <td>0.511389</td>\n      <td>1.007929</td>\n      <td>1.031987</td>\n      <td>0.680000</td>\n      <td>0.545050</td>\n      <td>0.696231</td>\n      <td>0.717435</td>\n      <td>0.100592</td>\n      <td>0.928994</td>\n      <td>0.792899</td>\n      <td>3.198677</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>16</td>\n      <td>1.000000</td>\n      <td>0.287978</td>\n      <td>0.711479</td>\n      <td>1.000000</td>\n      <td>0.480000</td>\n      <td>0.450133</td>\n      <td>0.674651</td>\n      <td>0.690758</td>\n      <td>0.071006</td>\n      <td>1.000000</td>\n      <td>-28.852071</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "              0      1   Error             Rate\n0      0  272.0  151.0   0.357    (151.0/423.0)\n1      1   54.0  746.0  0.0675     (54.0/800.0)\n2  Total  326.0  897.0  0.1676   (205.0/1223.0)",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>272.0</td>\n      <td>151.0</td>\n      <td>0.357</td>\n      <td>(151.0/423.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>54.0</td>\n      <td>746.0</td>\n      <td>0.0675</td>\n      <td>(54.0/800.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>326.0</td>\n      <td>897.0</td>\n      <td>0.1676</td>\n      <td>(205.0/1223.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                         metric  threshold       value    idx\n0                        max f1   0.623778    0.879199  235.0\n1                        max f2   0.525139    0.925000  280.0\n2                  max f0point5   0.698162    0.870536  201.0\n3                  max accuracy   0.682321    0.834832  210.0\n4                 max precision   0.985729    1.000000    0.0\n5                    max recall   0.139715    1.000000  399.0\n6               max specificity   0.985729    1.000000    0.0\n7              max absolute_mcc   0.698162    0.629782  201.0\n8    max min_per_class_accuracy   0.730109    0.803783  180.0\n9   max mean_per_class_accuracy   0.698162    0.813454  201.0\n10                      max tns   0.985729  423.000000    0.0\n11                      max fns   0.985729  799.000000    0.0\n12                      max fps   0.139715  423.000000  399.0\n13                      max tps   0.139715  800.000000  399.0\n14                      max tnr   0.985729    1.000000    0.0\n15                      max fnr   0.985729    0.998750    0.0\n16                      max fpr   0.139715    1.000000  399.0\n17                      max tpr   0.139715    1.000000  399.0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.623778</td>\n      <td>0.879199</td>\n      <td>235.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.525139</td>\n      <td>0.925000</td>\n      <td>280.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.698162</td>\n      <td>0.870536</td>\n      <td>201.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.682321</td>\n      <td>0.834832</td>\n      <td>210.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>0.985729</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.139715</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>0.985729</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.698162</td>\n      <td>0.629782</td>\n      <td>201.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.730109</td>\n      <td>0.803783</td>\n      <td>180.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.698162</td>\n      <td>0.813454</td>\n      <td>201.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>0.985729</td>\n      <td>423.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>0.985729</td>\n      <td>799.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.139715</td>\n      <td>423.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.139715</td>\n      <td>800.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>0.985729</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>0.985729</td>\n      <td>0.998750</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.139715</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.139715</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "      group  cumulative_data_fraction  lower_threshold      lift  \\\n0         1                  0.010630         0.973447  1.528750   \n1         2                  0.020442         0.966153  1.401354   \n2         3                  0.030253         0.956775  1.528750   \n3         4                  0.040065         0.951030  1.528750   \n4         5                  0.050695         0.945337  1.528750   \n5         6                  0.100572         0.922875  1.528750   \n6         7                  0.150450         0.903162  1.478627   \n7         8                  0.200327         0.878481  1.403443   \n8         9                  0.300082         0.841677  1.428504   \n9        10                  0.399836         0.806635  1.378381   \n10       11                  0.500409         0.766653  1.143455   \n11       12                  0.600164         0.727136  1.190420   \n12       13                  0.699918         0.663034  0.977398   \n13       14                  0.799673         0.546061  0.538822   \n14       15                  0.899428         0.403196  0.250615   \n15       16                  1.000000         0.139141  0.136717   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0          1.528750       1.000000  0.976624                  1.000000   \n1          1.467600       0.916667  0.968725                  0.960000   \n2          1.487432       1.000000  0.961230                  0.972973   \n3          1.497551       1.000000  0.953947                  0.979592   \n4          1.504093       1.000000  0.948086                  0.983871   \n5          1.516321       1.000000  0.933242                  0.991870   \n6          1.503825       0.967213  0.912983                  0.983696   \n7          1.478832       0.918033  0.890297                  0.967347   \n8          1.462101       0.934426  0.860057                  0.956403   \n9          1.441214       0.901639  0.824239                  0.942740   \n10         1.381371       0.747967  0.786644                  0.903595   \n11         1.349632       0.778689  0.747643                  0.882834   \n12         1.296580       0.639344  0.701658                  0.848131   \n13         1.202054       0.352459  0.608000                  0.786299   \n14         1.096531       0.163934  0.475731                  0.717273   \n15         1.000000       0.089431  0.303825                  0.654129   \n\n    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n0           0.976624       0.01625                  0.01625  52.875000   \n1           0.972832       0.01375                  0.03000  40.135417   \n2           0.969069       0.01500                  0.04500  52.875000   \n3           0.965366       0.01500                  0.06000  52.875000   \n4           0.961743       0.01625                  0.07625  52.875000   \n5           0.947608       0.07625                  0.15250  52.875000   \n6           0.936129       0.07375                  0.22625  47.862705   \n7           0.924718       0.07000                  0.29625  40.344262   \n8           0.903223       0.14250                  0.43875  42.850410   \n9           0.883517       0.13750                  0.57625  37.838115   \n10          0.864048       0.11500                  0.69125  14.345528   \n11          0.844700       0.11875                  0.81000  19.042008   \n12          0.824313       0.09750                  0.90750  -2.260246   \n13          0.797329       0.05375                  0.96125 -46.117828   \n14          0.761661       0.02500                  0.98625 -74.938525   \n15          0.715615       0.01375                  1.00000 -86.328252   \n\n    cumulative_gain  \n0         52.875000  \n1         46.760000  \n2         48.743243  \n3         49.755102  \n4         50.409274  \n5         51.632114  \n6         50.382473  \n7         47.883163  \n8         46.210150  \n9         44.121421  \n10        38.137051  \n11        34.963215  \n12        29.658002  \n13        20.205394  \n14         9.653068  \n15         0.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.010630</td>\n      <td>0.973447</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>0.976624</td>\n      <td>1.000000</td>\n      <td>0.976624</td>\n      <td>0.01625</td>\n      <td>0.01625</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.020442</td>\n      <td>0.966153</td>\n      <td>1.401354</td>\n      <td>1.467600</td>\n      <td>0.916667</td>\n      <td>0.968725</td>\n      <td>0.960000</td>\n      <td>0.972832</td>\n      <td>0.01375</td>\n      <td>0.03000</td>\n      <td>40.135417</td>\n      <td>46.760000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.030253</td>\n      <td>0.956775</td>\n      <td>1.528750</td>\n      <td>1.487432</td>\n      <td>1.000000</td>\n      <td>0.961230</td>\n      <td>0.972973</td>\n      <td>0.969069</td>\n      <td>0.01500</td>\n      <td>0.04500</td>\n      <td>52.875000</td>\n      <td>48.743243</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.040065</td>\n      <td>0.951030</td>\n      <td>1.528750</td>\n      <td>1.497551</td>\n      <td>1.000000</td>\n      <td>0.953947</td>\n      <td>0.979592</td>\n      <td>0.965366</td>\n      <td>0.01500</td>\n      <td>0.06000</td>\n      <td>52.875000</td>\n      <td>49.755102</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>0.050695</td>\n      <td>0.945337</td>\n      <td>1.528750</td>\n      <td>1.504093</td>\n      <td>1.000000</td>\n      <td>0.948086</td>\n      <td>0.983871</td>\n      <td>0.961743</td>\n      <td>0.01625</td>\n      <td>0.07625</td>\n      <td>52.875000</td>\n      <td>50.409274</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>6</td>\n      <td>0.100572</td>\n      <td>0.922875</td>\n      <td>1.528750</td>\n      <td>1.516321</td>\n      <td>1.000000</td>\n      <td>0.933242</td>\n      <td>0.991870</td>\n      <td>0.947608</td>\n      <td>0.07625</td>\n      <td>0.15250</td>\n      <td>52.875000</td>\n      <td>51.632114</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>0.150450</td>\n      <td>0.903162</td>\n      <td>1.478627</td>\n      <td>1.503825</td>\n      <td>0.967213</td>\n      <td>0.912983</td>\n      <td>0.983696</td>\n      <td>0.936129</td>\n      <td>0.07375</td>\n      <td>0.22625</td>\n      <td>47.862705</td>\n      <td>50.382473</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>8</td>\n      <td>0.200327</td>\n      <td>0.878481</td>\n      <td>1.403443</td>\n      <td>1.478832</td>\n      <td>0.918033</td>\n      <td>0.890297</td>\n      <td>0.967347</td>\n      <td>0.924718</td>\n      <td>0.07000</td>\n      <td>0.29625</td>\n      <td>40.344262</td>\n      <td>47.883163</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>9</td>\n      <td>0.300082</td>\n      <td>0.841677</td>\n      <td>1.428504</td>\n      <td>1.462101</td>\n      <td>0.934426</td>\n      <td>0.860057</td>\n      <td>0.956403</td>\n      <td>0.903223</td>\n      <td>0.14250</td>\n      <td>0.43875</td>\n      <td>42.850410</td>\n      <td>46.210150</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>10</td>\n      <td>0.399836</td>\n      <td>0.806635</td>\n      <td>1.378381</td>\n      <td>1.441214</td>\n      <td>0.901639</td>\n      <td>0.824239</td>\n      <td>0.942740</td>\n      <td>0.883517</td>\n      <td>0.13750</td>\n      <td>0.57625</td>\n      <td>37.838115</td>\n      <td>44.121421</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>11</td>\n      <td>0.500409</td>\n      <td>0.766653</td>\n      <td>1.143455</td>\n      <td>1.381371</td>\n      <td>0.747967</td>\n      <td>0.786644</td>\n      <td>0.903595</td>\n      <td>0.864048</td>\n      <td>0.11500</td>\n      <td>0.69125</td>\n      <td>14.345528</td>\n      <td>38.137051</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>12</td>\n      <td>0.600164</td>\n      <td>0.727136</td>\n      <td>1.190420</td>\n      <td>1.349632</td>\n      <td>0.778689</td>\n      <td>0.747643</td>\n      <td>0.882834</td>\n      <td>0.844700</td>\n      <td>0.11875</td>\n      <td>0.81000</td>\n      <td>19.042008</td>\n      <td>34.963215</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>13</td>\n      <td>0.699918</td>\n      <td>0.663034</td>\n      <td>0.977398</td>\n      <td>1.296580</td>\n      <td>0.639344</td>\n      <td>0.701658</td>\n      <td>0.848131</td>\n      <td>0.824313</td>\n      <td>0.09750</td>\n      <td>0.90750</td>\n      <td>-2.260246</td>\n      <td>29.658002</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>14</td>\n      <td>0.799673</td>\n      <td>0.546061</td>\n      <td>0.538822</td>\n      <td>1.202054</td>\n      <td>0.352459</td>\n      <td>0.608000</td>\n      <td>0.786299</td>\n      <td>0.797329</td>\n      <td>0.05375</td>\n      <td>0.96125</td>\n      <td>-46.117828</td>\n      <td>20.205394</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>15</td>\n      <td>0.899428</td>\n      <td>0.403196</td>\n      <td>0.250615</td>\n      <td>1.096531</td>\n      <td>0.163934</td>\n      <td>0.475731</td>\n      <td>0.717273</td>\n      <td>0.761661</td>\n      <td>0.02500</td>\n      <td>0.98625</td>\n      <td>-74.938525</td>\n      <td>9.653068</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>16</td>\n      <td>1.000000</td>\n      <td>0.139141</td>\n      <td>0.136717</td>\n      <td>1.000000</td>\n      <td>0.089431</td>\n      <td>0.303825</td>\n      <td>0.654129</td>\n      <td>0.715615</td>\n      <td>0.01375</td>\n      <td>1.00000</td>\n      <td>-86.328252</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                                   mean           sd  cv_1_valid  cv_2_valid  \\\n0                  accuracy  0.85056084  0.012191841   0.8514056   0.8293651   \n1                       auc   0.8847304  0.005531013  0.88795096   0.8817204   \n2                     aucpr   0.9298648  0.011238017   0.9416512  0.92589223   \n3                       err  0.14943913  0.012191841  0.14859438  0.17063493   \n4                 err_count        36.6    3.7815342        37.0        43.0   \n5                  f0point5    0.873479  0.012376249   0.8841099  0.86845464   \n6                        f1   0.8886605  0.015630547   0.8888889   0.8634921   \n7                        f2   0.9053345  0.037887756   0.8937198  0.85858583   \n8            lift_top_group   1.5290636   0.03780725   1.5090909   1.5849056   \n9                   logloss  0.45639262  0.014040419   0.4562537   0.4768668   \n10      max_per_class_error   0.2801647   0.08775162  0.23809524  0.21505377   \n11                      mcc  0.66820604  0.019285075  0.66494715    0.636239   \n12  mean_per_class_accuracy  0.81861055   0.01890995  0.82943726   0.8201461   \n13     mean_per_class_error  0.18138944   0.01890995  0.17056277  0.17985393   \n14                      mse  0.14792621  0.007462843  0.14901493  0.15820105   \n15                   pr_auc   0.9298648  0.011238017   0.9416512  0.92589223   \n16                precision    0.864096  0.024094356  0.88095236   0.8717949   \n17                       r2   0.3456979  0.020746762  0.33340004   0.3205924   \n18                   recall   0.9173858  0.054722667   0.8969697   0.8553459   \n19                     rmse  0.38451424  0.009683092  0.38602453  0.39774495   \n\n    cv_3_valid  cv_4_valid  cv_5_valid  \n0    0.8577406   0.8589212   0.8553719  \n1   0.89064467   0.8767081   0.8866279  \n2    0.9382394  0.91313046  0.93041086  \n3   0.14225942  0.14107884   0.1446281  \n4         34.0        34.0        35.0  \n5   0.86206895  0.86358637  0.88917524  \n6    0.9011628  0.90229887   0.8874598  \n7   0.94397074    0.944645  0.88575095  \n8    1.5031446   1.4968944    1.551282  \n9   0.44247666  0.44437772  0.46198812  \n10       0.375       0.375  0.19767442  \n11    0.676859  0.67780364  0.68518126  \n12   0.7999214   0.8000776  0.84347045  \n13  0.20007862  0.19992235  0.15652952  \n14  0.14169522  0.13970213  0.15101774  \n15   0.9382394  0.91313046  0.93041086  \n16   0.8378378   0.8395722  0.89032257  \n17   0.3636971    0.370028    0.340772  \n18   0.9748428   0.9751553  0.88461536  \n19  0.37642425  0.37376747     0.38861  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>mean</th>\n      <th>sd</th>\n      <th>cv_1_valid</th>\n      <th>cv_2_valid</th>\n      <th>cv_3_valid</th>\n      <th>cv_4_valid</th>\n      <th>cv_5_valid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>accuracy</td>\n      <td>0.85056084</td>\n      <td>0.012191841</td>\n      <td>0.8514056</td>\n      <td>0.8293651</td>\n      <td>0.8577406</td>\n      <td>0.8589212</td>\n      <td>0.8553719</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>auc</td>\n      <td>0.8847304</td>\n      <td>0.005531013</td>\n      <td>0.88795096</td>\n      <td>0.8817204</td>\n      <td>0.89064467</td>\n      <td>0.8767081</td>\n      <td>0.8866279</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>aucpr</td>\n      <td>0.9298648</td>\n      <td>0.011238017</td>\n      <td>0.9416512</td>\n      <td>0.92589223</td>\n      <td>0.9382394</td>\n      <td>0.91313046</td>\n      <td>0.93041086</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>err</td>\n      <td>0.14943913</td>\n      <td>0.012191841</td>\n      <td>0.14859438</td>\n      <td>0.17063493</td>\n      <td>0.14225942</td>\n      <td>0.14107884</td>\n      <td>0.1446281</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>err_count</td>\n      <td>36.6</td>\n      <td>3.7815342</td>\n      <td>37.0</td>\n      <td>43.0</td>\n      <td>34.0</td>\n      <td>34.0</td>\n      <td>35.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>f0point5</td>\n      <td>0.873479</td>\n      <td>0.012376249</td>\n      <td>0.8841099</td>\n      <td>0.86845464</td>\n      <td>0.86206895</td>\n      <td>0.86358637</td>\n      <td>0.88917524</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>f1</td>\n      <td>0.8886605</td>\n      <td>0.015630547</td>\n      <td>0.8888889</td>\n      <td>0.8634921</td>\n      <td>0.9011628</td>\n      <td>0.90229887</td>\n      <td>0.8874598</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>f2</td>\n      <td>0.9053345</td>\n      <td>0.037887756</td>\n      <td>0.8937198</td>\n      <td>0.85858583</td>\n      <td>0.94397074</td>\n      <td>0.944645</td>\n      <td>0.88575095</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>lift_top_group</td>\n      <td>1.5290636</td>\n      <td>0.03780725</td>\n      <td>1.5090909</td>\n      <td>1.5849056</td>\n      <td>1.5031446</td>\n      <td>1.4968944</td>\n      <td>1.551282</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>logloss</td>\n      <td>0.45639262</td>\n      <td>0.014040419</td>\n      <td>0.4562537</td>\n      <td>0.4768668</td>\n      <td>0.44247666</td>\n      <td>0.44437772</td>\n      <td>0.46198812</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max_per_class_error</td>\n      <td>0.2801647</td>\n      <td>0.08775162</td>\n      <td>0.23809524</td>\n      <td>0.21505377</td>\n      <td>0.375</td>\n      <td>0.375</td>\n      <td>0.19767442</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>mcc</td>\n      <td>0.66820604</td>\n      <td>0.019285075</td>\n      <td>0.66494715</td>\n      <td>0.636239</td>\n      <td>0.676859</td>\n      <td>0.67780364</td>\n      <td>0.68518126</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>mean_per_class_accuracy</td>\n      <td>0.81861055</td>\n      <td>0.01890995</td>\n      <td>0.82943726</td>\n      <td>0.8201461</td>\n      <td>0.7999214</td>\n      <td>0.8000776</td>\n      <td>0.84347045</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>mean_per_class_error</td>\n      <td>0.18138944</td>\n      <td>0.01890995</td>\n      <td>0.17056277</td>\n      <td>0.17985393</td>\n      <td>0.20007862</td>\n      <td>0.19992235</td>\n      <td>0.15652952</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>mse</td>\n      <td>0.14792621</td>\n      <td>0.007462843</td>\n      <td>0.14901493</td>\n      <td>0.15820105</td>\n      <td>0.14169522</td>\n      <td>0.13970213</td>\n      <td>0.15101774</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>pr_auc</td>\n      <td>0.9298648</td>\n      <td>0.011238017</td>\n      <td>0.9416512</td>\n      <td>0.92589223</td>\n      <td>0.9382394</td>\n      <td>0.91313046</td>\n      <td>0.93041086</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>precision</td>\n      <td>0.864096</td>\n      <td>0.024094356</td>\n      <td>0.88095236</td>\n      <td>0.8717949</td>\n      <td>0.8378378</td>\n      <td>0.8395722</td>\n      <td>0.89032257</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>r2</td>\n      <td>0.3456979</td>\n      <td>0.020746762</td>\n      <td>0.33340004</td>\n      <td>0.3205924</td>\n      <td>0.3636971</td>\n      <td>0.370028</td>\n      <td>0.340772</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>recall</td>\n      <td>0.9173858</td>\n      <td>0.054722667</td>\n      <td>0.8969697</td>\n      <td>0.8553459</td>\n      <td>0.9748428</td>\n      <td>0.9751553</td>\n      <td>0.88461536</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>rmse</td>\n      <td>0.38451424</td>\n      <td>0.009683092</td>\n      <td>0.38602453</td>\n      <td>0.39774495</td>\n      <td>0.37642425</td>\n      <td>0.37376747</td>\n      <td>0.38861</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "See the whole table with table.as_data_frame()\n",
            "\n",
            "Variable Importances: \n",
            "\n",
            "See the whole table with table.as_data_frame()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                timestamp    duration  number_of_trees  training_rmse  \\\n0     2020-11-15 17:16:25  34.363 sec              0.0            NaN   \n1     2020-11-15 17:16:26  34.578 sec              1.0       0.484766   \n2     2020-11-15 17:16:26  34.650 sec              2.0       0.436246   \n3     2020-11-15 17:16:26  34.712 sec              3.0       0.435541   \n4     2020-11-15 17:16:26  34.775 sec              4.0       0.417959   \n5     2020-11-15 17:16:26  34.835 sec              5.0       0.407482   \n6     2020-11-15 17:16:26  34.900 sec              6.0       0.392713   \n7     2020-11-15 17:16:26  34.957 sec              7.0       0.377544   \n8     2020-11-15 17:16:26  35.032 sec              8.0       0.364893   \n9     2020-11-15 17:16:26  35.098 sec              9.0       0.368507   \n10    2020-11-15 17:16:26  35.166 sec             10.0       0.365489   \n11    2020-11-15 17:16:26  35.238 sec             11.0       0.357199   \n12    2020-11-15 17:16:26  35.316 sec             12.0       0.352161   \n13    2020-11-15 17:16:26  35.381 sec             13.0       0.349300   \n14    2020-11-15 17:16:26  35.452 sec             14.0       0.347158   \n15    2020-11-15 17:16:27  35.523 sec             15.0       0.345296   \n16    2020-11-15 17:16:27  35.584 sec             16.0       0.342888   \n17    2020-11-15 17:16:27  35.650 sec             17.0       0.341277   \n18    2020-11-15 17:16:27  35.711 sec             18.0       0.337992   \n19    2020-11-15 17:16:27  35.771 sec             19.0       0.337185   \n\n    training_logloss  training_auc  training_pr_auc  training_lift  \\\n0                NaN           NaN              NaN            NaN   \n1           6.422745      0.732803         0.724162       1.584808   \n2           4.268980      0.783656         0.777626       1.687577   \n3           4.044009      0.785518         0.764063       1.619364   \n4           3.142821      0.811935         0.796946       1.692268   \n5           2.776868      0.825337         0.807112       1.695458   \n6           1.956826      0.852800         0.835116       1.758750   \n7           1.405504      0.873801         0.864890       1.842500   \n8           1.089499      0.889264         0.883474       1.879350   \n9           1.016379      0.887268         0.883542       1.871813   \n10          0.908864      0.893159         0.894497       1.892628   \n11          0.813296      0.903258         0.901770       1.899213   \n12          0.684402      0.910875         0.911987       1.921842   \n13          0.621431      0.915466         0.913482       1.900761   \n14          0.541071      0.920144         0.916861       1.890000   \n15          0.500078      0.924577         0.921434       1.902321   \n16          0.476831      0.927257         0.927957       1.929600   \n17          0.414201      0.931873         0.937108       2.010000   \n18          0.409313      0.935721         0.939918       2.010000   \n19          0.408306      0.936905         0.941563       2.010000   \n\n    training_classification_error  validation_rmse  validation_logloss  \\\n0                             NaN              NaN                 NaN   \n1                        0.241379         0.676686           11.573860   \n2                        0.207305         0.574286            3.098114   \n3                        0.214739         0.533667            1.845286   \n4                        0.208034         0.512782            1.195344   \n5                        0.205285         0.501664            0.912134   \n6                        0.205497         0.486623            0.766033   \n7                        0.189622         0.479296            0.735066   \n8                        0.171628         0.477982            0.733914   \n9                        0.177136         0.477006            0.659835   \n10                       0.167500         0.470488            0.643114   \n11                       0.170200         0.466840            0.630077   \n12                       0.145262         0.466412            0.628228   \n13                       0.143746         0.472169            0.640399   \n14                       0.147388         0.473240            0.643043   \n15                       0.134328         0.470595            0.637670   \n16                       0.126866         0.471933            0.640382   \n17                       0.129975         0.473804            0.644666   \n18                       0.125000         0.473775            0.644610   \n19                       0.124378         0.474806            0.647191   \n\n    validation_auc  validation_pr_auc  validation_lift  \\\n0              NaN                NaN              NaN   \n1         0.503685           0.678196         1.012267   \n2         0.524195           0.697968         1.101099   \n3         0.533525           0.698375         1.004104   \n4         0.532317           0.692950         0.846999   \n5         0.551476           0.707181         0.988166   \n6         0.573320           0.728366         1.376374   \n7         0.585826           0.737493         1.347499   \n8         0.588068           0.732852         1.347499   \n9         0.578965           0.739755         1.482249   \n10        0.591997           0.748925         1.482249   \n11        0.601182           0.752480         1.482249   \n12        0.604222           0.758303         1.482249   \n13        0.581951           0.746363         1.482249   \n14        0.575380           0.742316         1.482249   \n15        0.582459           0.745816         1.482249   \n16        0.573511           0.742373         1.482249   \n17        0.561341           0.735158         1.482249   \n18        0.557828           0.733086         1.235207   \n19        0.556068           0.731769         1.235207   \n\n    validation_classification_error  \n0                               NaN  \n1                          0.325349  \n2                          0.325349  \n3                          0.325349  \n4                          0.323353  \n5                          0.325349  \n6                          0.319361  \n7                          0.323353  \n8                          0.309381  \n9                          0.313373  \n10                         0.307385  \n11                         0.313373  \n12                         0.307385  \n13                         0.311377  \n14                         0.313373  \n15                         0.309381  \n16                         0.309381  \n17                         0.313373  \n18                         0.321357  \n19                         0.319361  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>timestamp</th>\n      <th>duration</th>\n      <th>number_of_trees</th>\n      <th>training_rmse</th>\n      <th>training_logloss</th>\n      <th>training_auc</th>\n      <th>training_pr_auc</th>\n      <th>training_lift</th>\n      <th>training_classification_error</th>\n      <th>validation_rmse</th>\n      <th>validation_logloss</th>\n      <th>validation_auc</th>\n      <th>validation_pr_auc</th>\n      <th>validation_lift</th>\n      <th>validation_classification_error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>2020-11-15 17:16:25</td>\n      <td>34.363 sec</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2020-11-15 17:16:26</td>\n      <td>34.578 sec</td>\n      <td>1.0</td>\n      <td>0.484766</td>\n      <td>6.422745</td>\n      <td>0.732803</td>\n      <td>0.724162</td>\n      <td>1.584808</td>\n      <td>0.241379</td>\n      <td>0.676686</td>\n      <td>11.573860</td>\n      <td>0.503685</td>\n      <td>0.678196</td>\n      <td>1.012267</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>2020-11-15 17:16:26</td>\n      <td>34.650 sec</td>\n      <td>2.0</td>\n      <td>0.436246</td>\n      <td>4.268980</td>\n      <td>0.783656</td>\n      <td>0.777626</td>\n      <td>1.687577</td>\n      <td>0.207305</td>\n      <td>0.574286</td>\n      <td>3.098114</td>\n      <td>0.524195</td>\n      <td>0.697968</td>\n      <td>1.101099</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>2020-11-15 17:16:26</td>\n      <td>34.712 sec</td>\n      <td>3.0</td>\n      <td>0.435541</td>\n      <td>4.044009</td>\n      <td>0.785518</td>\n      <td>0.764063</td>\n      <td>1.619364</td>\n      <td>0.214739</td>\n      <td>0.533667</td>\n      <td>1.845286</td>\n      <td>0.533525</td>\n      <td>0.698375</td>\n      <td>1.004104</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>2020-11-15 17:16:26</td>\n      <td>34.775 sec</td>\n      <td>4.0</td>\n      <td>0.417959</td>\n      <td>3.142821</td>\n      <td>0.811935</td>\n      <td>0.796946</td>\n      <td>1.692268</td>\n      <td>0.208034</td>\n      <td>0.512782</td>\n      <td>1.195344</td>\n      <td>0.532317</td>\n      <td>0.692950</td>\n      <td>0.846999</td>\n      <td>0.323353</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>2020-11-15 17:16:26</td>\n      <td>34.835 sec</td>\n      <td>5.0</td>\n      <td>0.407482</td>\n      <td>2.776868</td>\n      <td>0.825337</td>\n      <td>0.807112</td>\n      <td>1.695458</td>\n      <td>0.205285</td>\n      <td>0.501664</td>\n      <td>0.912134</td>\n      <td>0.551476</td>\n      <td>0.707181</td>\n      <td>0.988166</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>2020-11-15 17:16:26</td>\n      <td>34.900 sec</td>\n      <td>6.0</td>\n      <td>0.392713</td>\n      <td>1.956826</td>\n      <td>0.852800</td>\n      <td>0.835116</td>\n      <td>1.758750</td>\n      <td>0.205497</td>\n      <td>0.486623</td>\n      <td>0.766033</td>\n      <td>0.573320</td>\n      <td>0.728366</td>\n      <td>1.376374</td>\n      <td>0.319361</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>2020-11-15 17:16:26</td>\n      <td>34.957 sec</td>\n      <td>7.0</td>\n      <td>0.377544</td>\n      <td>1.405504</td>\n      <td>0.873801</td>\n      <td>0.864890</td>\n      <td>1.842500</td>\n      <td>0.189622</td>\n      <td>0.479296</td>\n      <td>0.735066</td>\n      <td>0.585826</td>\n      <td>0.737493</td>\n      <td>1.347499</td>\n      <td>0.323353</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>2020-11-15 17:16:26</td>\n      <td>35.032 sec</td>\n      <td>8.0</td>\n      <td>0.364893</td>\n      <td>1.089499</td>\n      <td>0.889264</td>\n      <td>0.883474</td>\n      <td>1.879350</td>\n      <td>0.171628</td>\n      <td>0.477982</td>\n      <td>0.733914</td>\n      <td>0.588068</td>\n      <td>0.732852</td>\n      <td>1.347499</td>\n      <td>0.309381</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>2020-11-15 17:16:26</td>\n      <td>35.098 sec</td>\n      <td>9.0</td>\n      <td>0.368507</td>\n      <td>1.016379</td>\n      <td>0.887268</td>\n      <td>0.883542</td>\n      <td>1.871813</td>\n      <td>0.177136</td>\n      <td>0.477006</td>\n      <td>0.659835</td>\n      <td>0.578965</td>\n      <td>0.739755</td>\n      <td>1.482249</td>\n      <td>0.313373</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>2020-11-15 17:16:26</td>\n      <td>35.166 sec</td>\n      <td>10.0</td>\n      <td>0.365489</td>\n      <td>0.908864</td>\n      <td>0.893159</td>\n      <td>0.894497</td>\n      <td>1.892628</td>\n      <td>0.167500</td>\n      <td>0.470488</td>\n      <td>0.643114</td>\n      <td>0.591997</td>\n      <td>0.748925</td>\n      <td>1.482249</td>\n      <td>0.307385</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>2020-11-15 17:16:26</td>\n      <td>35.238 sec</td>\n      <td>11.0</td>\n      <td>0.357199</td>\n      <td>0.813296</td>\n      <td>0.903258</td>\n      <td>0.901770</td>\n      <td>1.899213</td>\n      <td>0.170200</td>\n      <td>0.466840</td>\n      <td>0.630077</td>\n      <td>0.601182</td>\n      <td>0.752480</td>\n      <td>1.482249</td>\n      <td>0.313373</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>2020-11-15 17:16:26</td>\n      <td>35.316 sec</td>\n      <td>12.0</td>\n      <td>0.352161</td>\n      <td>0.684402</td>\n      <td>0.910875</td>\n      <td>0.911987</td>\n      <td>1.921842</td>\n      <td>0.145262</td>\n      <td>0.466412</td>\n      <td>0.628228</td>\n      <td>0.604222</td>\n      <td>0.758303</td>\n      <td>1.482249</td>\n      <td>0.307385</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>2020-11-15 17:16:26</td>\n      <td>35.381 sec</td>\n      <td>13.0</td>\n      <td>0.349300</td>\n      <td>0.621431</td>\n      <td>0.915466</td>\n      <td>0.913482</td>\n      <td>1.900761</td>\n      <td>0.143746</td>\n      <td>0.472169</td>\n      <td>0.640399</td>\n      <td>0.581951</td>\n      <td>0.746363</td>\n      <td>1.482249</td>\n      <td>0.311377</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>2020-11-15 17:16:26</td>\n      <td>35.452 sec</td>\n      <td>14.0</td>\n      <td>0.347158</td>\n      <td>0.541071</td>\n      <td>0.920144</td>\n      <td>0.916861</td>\n      <td>1.890000</td>\n      <td>0.147388</td>\n      <td>0.473240</td>\n      <td>0.643043</td>\n      <td>0.575380</td>\n      <td>0.742316</td>\n      <td>1.482249</td>\n      <td>0.313373</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>2020-11-15 17:16:27</td>\n      <td>35.523 sec</td>\n      <td>15.0</td>\n      <td>0.345296</td>\n      <td>0.500078</td>\n      <td>0.924577</td>\n      <td>0.921434</td>\n      <td>1.902321</td>\n      <td>0.134328</td>\n      <td>0.470595</td>\n      <td>0.637670</td>\n      <td>0.582459</td>\n      <td>0.745816</td>\n      <td>1.482249</td>\n      <td>0.309381</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td></td>\n      <td>2020-11-15 17:16:27</td>\n      <td>35.584 sec</td>\n      <td>16.0</td>\n      <td>0.342888</td>\n      <td>0.476831</td>\n      <td>0.927257</td>\n      <td>0.927957</td>\n      <td>1.929600</td>\n      <td>0.126866</td>\n      <td>0.471933</td>\n      <td>0.640382</td>\n      <td>0.573511</td>\n      <td>0.742373</td>\n      <td>1.482249</td>\n      <td>0.309381</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td></td>\n      <td>2020-11-15 17:16:27</td>\n      <td>35.650 sec</td>\n      <td>17.0</td>\n      <td>0.341277</td>\n      <td>0.414201</td>\n      <td>0.931873</td>\n      <td>0.937108</td>\n      <td>2.010000</td>\n      <td>0.129975</td>\n      <td>0.473804</td>\n      <td>0.644666</td>\n      <td>0.561341</td>\n      <td>0.735158</td>\n      <td>1.482249</td>\n      <td>0.313373</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td></td>\n      <td>2020-11-15 17:16:27</td>\n      <td>35.711 sec</td>\n      <td>18.0</td>\n      <td>0.337992</td>\n      <td>0.409313</td>\n      <td>0.935721</td>\n      <td>0.939918</td>\n      <td>2.010000</td>\n      <td>0.125000</td>\n      <td>0.473775</td>\n      <td>0.644610</td>\n      <td>0.557828</td>\n      <td>0.733086</td>\n      <td>1.235207</td>\n      <td>0.321357</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td></td>\n      <td>2020-11-15 17:16:27</td>\n      <td>35.771 sec</td>\n      <td>19.0</td>\n      <td>0.337185</td>\n      <td>0.408306</td>\n      <td>0.936905</td>\n      <td>0.941563</td>\n      <td>2.010000</td>\n      <td>0.124378</td>\n      <td>0.474806</td>\n      <td>0.647191</td>\n      <td>0.556068</td>\n      <td>0.731769</td>\n      <td>1.235207</td>\n      <td>0.319361</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "   variable  relative_importance  scaled_importance  percentage\n0      PC14          1724.483154           1.000000    0.076722\n1       PC2           952.419678           0.552293    0.042373\n2      PC11           858.823853           0.498018    0.038209\n3       PC3           700.542847           0.406234    0.031167\n4       PC4           621.191162           0.360219    0.027637\n5       PC5           580.841248           0.336820    0.025842\n6      PC20           493.652649           0.286261    0.021963\n7      PC13           466.062317           0.270262    0.020735\n8       PC1           417.042847           0.241836    0.018554\n9       PC7           364.417877           0.211320    0.016213\n10     PC10           350.441589           0.203215    0.015591\n11     PC27           270.892731           0.157086    0.012052\n12     PC19           245.425873           0.142319    0.010919\n13     PC22           219.490494           0.127279    0.009765\n14      PC6           206.910248           0.119984    0.009205\n15     PC24           198.131271           0.114893    0.008815\n16     PC37           159.309555           0.092381    0.007088\n17    PC111           155.600647           0.090230    0.006923\n18      PC9           154.789062           0.089760    0.006887\n19      PC8           153.105988           0.088784    0.006812",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variable</th>\n      <th>relative_importance</th>\n      <th>scaled_importance</th>\n      <th>percentage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>PC14</td>\n      <td>1724.483154</td>\n      <td>1.000000</td>\n      <td>0.076722</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>PC2</td>\n      <td>952.419678</td>\n      <td>0.552293</td>\n      <td>0.042373</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PC11</td>\n      <td>858.823853</td>\n      <td>0.498018</td>\n      <td>0.038209</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>PC3</td>\n      <td>700.542847</td>\n      <td>0.406234</td>\n      <td>0.031167</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>PC4</td>\n      <td>621.191162</td>\n      <td>0.360219</td>\n      <td>0.027637</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>PC5</td>\n      <td>580.841248</td>\n      <td>0.336820</td>\n      <td>0.025842</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>PC20</td>\n      <td>493.652649</td>\n      <td>0.286261</td>\n      <td>0.021963</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>PC13</td>\n      <td>466.062317</td>\n      <td>0.270262</td>\n      <td>0.020735</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>PC1</td>\n      <td>417.042847</td>\n      <td>0.241836</td>\n      <td>0.018554</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>PC7</td>\n      <td>364.417877</td>\n      <td>0.211320</td>\n      <td>0.016213</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>PC10</td>\n      <td>350.441589</td>\n      <td>0.203215</td>\n      <td>0.015591</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>PC27</td>\n      <td>270.892731</td>\n      <td>0.157086</td>\n      <td>0.012052</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>PC19</td>\n      <td>245.425873</td>\n      <td>0.142319</td>\n      <td>0.010919</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>PC22</td>\n      <td>219.490494</td>\n      <td>0.127279</td>\n      <td>0.009765</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>PC6</td>\n      <td>206.910248</td>\n      <td>0.119984</td>\n      <td>0.009205</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>PC24</td>\n      <td>198.131271</td>\n      <td>0.114893</td>\n      <td>0.008815</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>PC37</td>\n      <td>159.309555</td>\n      <td>0.092381</td>\n      <td>0.007088</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>PC111</td>\n      <td>155.600647</td>\n      <td>0.090230</td>\n      <td>0.006923</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>PC9</td>\n      <td>154.789062</td>\n      <td>0.089760</td>\n      <td>0.006887</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>PC8</td>\n      <td>153.105988</td>\n      <td>0.088784</td>\n      <td>0.006812</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "<bound method ModelBase.model_performance of >"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605460593283
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from h2o.estimators import H2ODeepLearningEstimator\r\n",
        "\r\n",
        "top_dl = H2ODeepLearningEstimator(**extract_params_from_model(best_dl_model.actual_params))\r\n",
        "\r\n",
        "top_dl.train(x=x, y=y, training_frame=train_pca_df_frame, validation_frame=test_pca_df_frame)\r\n",
        "\r\n",
        "# h2o.save_model(top_dl, MODELS_LOCATION + \"PCA300/top_dl\")\r\n",
        "\r\n",
        "\r\n",
        "print('AUC on test_pca_df_frame data: ', top_dl.model_performance(valid=True).auc(), \"\\n\\n============================\")\r\n",
        "\r\n",
        "top_dl.model_performance"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
            "AUC on test_pca_df_frame data:  0.6520673757577958 \n",
            "\n",
            "============================\n",
            "Model Details\n",
            "=============\n",
            "H2ODeepLearningEstimator :  Deep Learning\n",
            "Model Key:  DeepLearning_model_python_1605450290525_1634\n",
            "\n",
            "\n",
            "Status of Neuron Layers: predicting Resistance_Status, 2-class classification, bernoulli distribution, CrossEntropy loss, 652,502 weights/biases, 7.6 MB, 25,205 training samples, mini-batch size 1\n",
            "\n",
            "\n",
            "ModelMetricsBinomial: deeplearning\n",
            "** Reported on train data. **\n",
            "\n",
            "MSE: 0.21647808355119072\n",
            "RMSE: 0.4652720532668932\n",
            "LogLoss: 1.1844031352260838"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "     layer  units     type dropout     l1 l2 mean_rate  rate_rms momentum  \\\n0        1    300    Input      20                                          \n1        2    500     Tanh       0  1e-05  0  0.645003  0.233455        0   \n2        3    500     Tanh       0  1e-05  0  0.859616  0.154739        0   \n3        4    500     Tanh       0  1e-05  0  0.855054  0.201579        0   \n4        5      2  Softmax          1e-05  0  0.464007  0.391594        0   \n\n   mean_weight weight_rms    mean_bias   bias_rms  \n0                                                  \n1 -3.57819e-05  0.0476456   0.00237935  0.0427654  \n2  -4.8051e-05   0.035249  -0.00144334  0.0708292  \n3 -5.30619e-05   0.030205   0.00291134  0.0463812  \n4  -0.00426867   0.214405 -0.000315784  0.0465284  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>layer</th>\n      <th>units</th>\n      <th>type</th>\n      <th>dropout</th>\n      <th>l1</th>\n      <th>l2</th>\n      <th>mean_rate</th>\n      <th>rate_rms</th>\n      <th>momentum</th>\n      <th>mean_weight</th>\n      <th>weight_rms</th>\n      <th>mean_bias</th>\n      <th>bias_rms</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>300</td>\n      <td>Input</td>\n      <td>20</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>500</td>\n      <td>Tanh</td>\n      <td>0</td>\n      <td>1e-05</td>\n      <td>0</td>\n      <td>0.645003</td>\n      <td>0.233455</td>\n      <td>0</td>\n      <td>-3.57819e-05</td>\n      <td>0.0476456</td>\n      <td>0.00237935</td>\n      <td>0.0427654</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>500</td>\n      <td>Tanh</td>\n      <td>0</td>\n      <td>1e-05</td>\n      <td>0</td>\n      <td>0.859616</td>\n      <td>0.154739</td>\n      <td>0</td>\n      <td>-4.8051e-05</td>\n      <td>0.035249</td>\n      <td>-0.00144334</td>\n      <td>0.0708292</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>500</td>\n      <td>Tanh</td>\n      <td>0</td>\n      <td>1e-05</td>\n      <td>0</td>\n      <td>0.855054</td>\n      <td>0.201579</td>\n      <td>0</td>\n      <td>-5.30619e-05</td>\n      <td>0.030205</td>\n      <td>0.00291134</td>\n      <td>0.0463812</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>2</td>\n      <td>Softmax</td>\n      <td></td>\n      <td>1e-05</td>\n      <td>0</td>\n      <td>0.464007</td>\n      <td>0.391594</td>\n      <td>0</td>\n      <td>-0.00426867</td>\n      <td>0.214405</td>\n      <td>-0.000315784</td>\n      <td>0.0465284</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mean Per-Class Error: 0.04183362884160746\n",
            "AUC: 0.9929536052009457\n",
            "AUCPR: 0.9962699561385636\n",
            "Gini: 0.9859072104018913\n",
            "\n",
            "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9999202972943253: \n",
            "\n",
            "Maximum Metrics: Maximum metrics at their respective thresholds\n",
            "\n",
            "Gains/Lift Table: Avg response rate: 65.41 %, avg score: 89.17 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "              0      1   Error            Rate\n0      0  399.0   24.0  0.0567    (24.0/423.0)\n1      1   25.0  775.0  0.0312    (25.0/800.0)\n2  Total  424.0  799.0  0.0401   (49.0/1223.0)",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>399.0</td>\n      <td>24.0</td>\n      <td>0.0567</td>\n      <td>(24.0/423.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>25.0</td>\n      <td>775.0</td>\n      <td>0.0312</td>\n      <td>(25.0/800.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>424.0</td>\n      <td>799.0</td>\n      <td>0.0401</td>\n      <td>(49.0/1223.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                         metric  threshold       value    idx\n0                        max f1   0.999920    0.969356   16.0\n1                        max f2   0.998390    0.978927   67.0\n2                  max f0point5   0.999977    0.973942    8.0\n3                  max accuracy   0.999920    0.959935   16.0\n4                 max precision   1.000000    1.000000    0.0\n5                    max recall   0.993959    1.000000  103.0\n6               max specificity   1.000000    1.000000    0.0\n7              max absolute_mcc   0.999920    0.911506   16.0\n8    max min_per_class_accuracy   0.999958    0.957447   11.0\n9   max mean_per_class_accuracy   0.999953    0.958166   12.0\n10                      max tns   1.000000  423.000000    0.0\n11                      max fns   1.000000  223.000000    0.0\n12                      max fps   0.000007  423.000000  399.0\n13                      max tps   0.993959  800.000000  103.0\n14                      max tnr   1.000000    1.000000    0.0\n15                      max fnr   1.000000    0.278750    0.0\n16                      max fpr   0.000007    1.000000  399.0\n17                      max tpr   0.993959    1.000000  103.0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.999920</td>\n      <td>0.969356</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.998390</td>\n      <td>0.978927</td>\n      <td>67.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.999977</td>\n      <td>0.973942</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.999920</td>\n      <td>0.959935</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.993959</td>\n      <td>1.000000</td>\n      <td>103.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.999920</td>\n      <td>0.911506</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.999958</td>\n      <td>0.957447</td>\n      <td>11.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.999953</td>\n      <td>0.958166</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>1.000000</td>\n      <td>423.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>1.000000</td>\n      <td>223.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.000007</td>\n      <td>423.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.993959</td>\n      <td>800.000000</td>\n      <td>103.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>1.000000</td>\n      <td>0.278750</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.000007</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.993959</td>\n      <td>1.000000</td>\n      <td>103.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "      group  cumulative_data_fraction  lower_threshold      lift  \\\n0         1                  0.010630         1.000000  1.528750   \n1         2                  0.020442         1.000000  1.528750   \n2         3                  0.030253         1.000000  1.528750   \n3         4                  0.040065         1.000000  1.528750   \n4         5                  0.050695         1.000000  1.528750   \n5         6                  0.100572         1.000000  1.528750   \n6         7                  0.150450         1.000000  1.528750   \n7         8                  0.200327         1.000000  1.528750   \n8         9                  0.300082         1.000000  1.528750   \n9        10                  0.399836         1.000000  1.528750   \n10       11                  0.500409         0.999999  1.528750   \n11       12                  0.600164         0.999987  1.403443   \n12       13                  0.699918         0.999247  0.877152   \n13       14                  0.799673         0.967340  0.075184   \n14       15                  0.899428         0.479037  0.000000   \n15       16                  1.000000         0.000004  0.000000   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0          1.528750       1.000000  1.000000                  1.000000   \n1          1.528750       1.000000  1.000000                  1.000000   \n2          1.528750       1.000000  1.000000                  1.000000   \n3          1.528750       1.000000  1.000000                  1.000000   \n4          1.528750       1.000000  1.000000                  1.000000   \n5          1.528750       1.000000  1.000000                  1.000000   \n6          1.528750       1.000000  1.000000                  1.000000   \n7          1.528750       1.000000  1.000000                  1.000000   \n8          1.528750       1.000000  1.000000                  1.000000   \n9          1.528750       1.000000  1.000000                  1.000000   \n10         1.528750       1.000000  0.999999                  1.000000   \n11         1.507922       0.918033  0.999995                  0.986376   \n12         1.418023       0.573770  0.999843                  0.927570   \n13         1.250511       0.049180  0.991431                  0.817996   \n14         1.111818       0.000000  0.822323                  0.727273   \n15         1.000000       0.000000  0.108235                  0.654129   \n\n    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n0           1.000000       0.01625                  0.01625   52.875000   \n1           1.000000       0.01500                  0.03125   52.875000   \n2           1.000000       0.01500                  0.04625   52.875000   \n3           1.000000       0.01500                  0.06125   52.875000   \n4           1.000000       0.01625                  0.07750   52.875000   \n5           1.000000       0.07625                  0.15375   52.875000   \n6           1.000000       0.07625                  0.23000   52.875000   \n7           1.000000       0.07625                  0.30625   52.875000   \n8           1.000000       0.15250                  0.45875   52.875000   \n9           1.000000       0.15250                  0.61125   52.875000   \n10          1.000000       0.15375                  0.76500   52.875000   \n11          0.999999       0.14000                  0.90500   40.344262   \n12          0.999977       0.08750                  0.99250  -12.284836   \n13          0.998911       0.00750                  1.00000  -92.481557   \n14          0.979326       0.00000                  1.00000 -100.000000   \n15          0.891718       0.00000                  1.00000 -100.000000   \n\n    cumulative_gain  \n0         52.875000  \n1         52.875000  \n2         52.875000  \n3         52.875000  \n4         52.875000  \n5         52.875000  \n6         52.875000  \n7         52.875000  \n8         52.875000  \n9         52.875000  \n10        52.875000  \n11        50.792234  \n12        41.802278  \n13        25.051125  \n14        11.181818  \n15         0.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.010630</td>\n      <td>1.000000</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.01625</td>\n      <td>0.01625</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.020442</td>\n      <td>1.000000</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.01500</td>\n      <td>0.03125</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.030253</td>\n      <td>1.000000</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.01500</td>\n      <td>0.04625</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.040065</td>\n      <td>1.000000</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.01500</td>\n      <td>0.06125</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>0.050695</td>\n      <td>1.000000</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.01625</td>\n      <td>0.07750</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>6</td>\n      <td>0.100572</td>\n      <td>1.000000</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.07625</td>\n      <td>0.15375</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>0.150450</td>\n      <td>1.000000</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.07625</td>\n      <td>0.23000</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>8</td>\n      <td>0.200327</td>\n      <td>1.000000</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.07625</td>\n      <td>0.30625</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>9</td>\n      <td>0.300082</td>\n      <td>1.000000</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.15250</td>\n      <td>0.45875</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>10</td>\n      <td>0.399836</td>\n      <td>1.000000</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.15250</td>\n      <td>0.61125</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>11</td>\n      <td>0.500409</td>\n      <td>0.999999</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>0.999999</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.15375</td>\n      <td>0.76500</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>12</td>\n      <td>0.600164</td>\n      <td>0.999987</td>\n      <td>1.403443</td>\n      <td>1.507922</td>\n      <td>0.918033</td>\n      <td>0.999995</td>\n      <td>0.986376</td>\n      <td>0.999999</td>\n      <td>0.14000</td>\n      <td>0.90500</td>\n      <td>40.344262</td>\n      <td>50.792234</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>13</td>\n      <td>0.699918</td>\n      <td>0.999247</td>\n      <td>0.877152</td>\n      <td>1.418023</td>\n      <td>0.573770</td>\n      <td>0.999843</td>\n      <td>0.927570</td>\n      <td>0.999977</td>\n      <td>0.08750</td>\n      <td>0.99250</td>\n      <td>-12.284836</td>\n      <td>41.802278</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>14</td>\n      <td>0.799673</td>\n      <td>0.967340</td>\n      <td>0.075184</td>\n      <td>1.250511</td>\n      <td>0.049180</td>\n      <td>0.991431</td>\n      <td>0.817996</td>\n      <td>0.998911</td>\n      <td>0.00750</td>\n      <td>1.00000</td>\n      <td>-92.481557</td>\n      <td>25.051125</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>15</td>\n      <td>0.899428</td>\n      <td>0.479037</td>\n      <td>0.000000</td>\n      <td>1.111818</td>\n      <td>0.000000</td>\n      <td>0.822323</td>\n      <td>0.727273</td>\n      <td>0.979326</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>-100.000000</td>\n      <td>11.181818</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>16</td>\n      <td>1.000000</td>\n      <td>0.000004</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.108235</td>\n      <td>0.654129</td>\n      <td>0.891718</td>\n      <td>0.00000</td>\n      <td>1.00000</td>\n      <td>-100.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "ModelMetricsBinomial: deeplearning\n",
            "** Reported on validation data. **\n",
            "\n",
            "MSE: 0.31077354828563575\n",
            "RMSE: 0.5574706703366875\n",
            "LogLoss: 2.708427410313107\n",
            "Mean Per-Class Error: 0.36601989327331474\n",
            "AUC: 0.6520673757577958\n",
            "AUCPR: 0.7955527958165935\n",
            "Gini: 0.30413475151559166\n",
            "\n",
            "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4457997026892857: \n",
            "\n",
            "Maximum Metrics: Maximum metrics at their respective thresholds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "            0      1   Error            Rate\n0      0  5.0  158.0  0.9693   (158.0/163.0)\n1      1  2.0  336.0  0.0059     (2.0/338.0)\n2  Total  7.0  494.0  0.3194   (160.0/501.0)",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>5.0</td>\n      <td>158.0</td>\n      <td>0.9693</td>\n      <td>(158.0/163.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2.0</td>\n      <td>336.0</td>\n      <td>0.0059</td>\n      <td>(2.0/338.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>7.0</td>\n      <td>494.0</td>\n      <td>0.3194</td>\n      <td>(160.0/501.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                         metric  threshold       value    idx\n0                        max f1   0.445800    0.807692  388.0\n1                        max f2   0.260430    0.913020  393.0\n2                  max f0point5   0.999374    0.742938  252.0\n3                  max accuracy   0.918174    0.686627  367.0\n4                 max precision   1.000000    0.958333    0.0\n5                    max recall   0.260430    1.000000  393.0\n6               max specificity   1.000000    0.993865    0.0\n7              max absolute_mcc   0.999985    0.258222   89.0\n8    max min_per_class_accuracy   0.999918    0.606509  163.0\n9   max mean_per_class_accuracy   0.999985    0.633980   89.0\n10                      max tns   1.000000  162.000000    0.0\n11                      max fns   1.000000  315.000000    0.0\n12                      max fps   0.179345  163.000000  395.0\n13                      max tps   0.260430  338.000000  393.0\n14                      max tnr   1.000000    0.993865    0.0\n15                      max fnr   1.000000    0.931953    0.0\n16                      max fpr   0.179345    1.000000  395.0\n17                      max tpr   0.260430    1.000000  393.0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.445800</td>\n      <td>0.807692</td>\n      <td>388.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.260430</td>\n      <td>0.913020</td>\n      <td>393.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.999374</td>\n      <td>0.742938</td>\n      <td>252.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.918174</td>\n      <td>0.686627</td>\n      <td>367.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>1.000000</td>\n      <td>0.958333</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.260430</td>\n      <td>1.000000</td>\n      <td>393.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>1.000000</td>\n      <td>0.993865</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.999985</td>\n      <td>0.258222</td>\n      <td>89.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.999918</td>\n      <td>0.606509</td>\n      <td>163.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.999985</td>\n      <td>0.633980</td>\n      <td>89.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>1.000000</td>\n      <td>162.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>1.000000</td>\n      <td>315.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.179345</td>\n      <td>163.000000</td>\n      <td>395.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.260430</td>\n      <td>338.000000</td>\n      <td>393.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>1.000000</td>\n      <td>0.993865</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>1.000000</td>\n      <td>0.931953</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.179345</td>\n      <td>1.000000</td>\n      <td>395.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.260430</td>\n      <td>1.000000</td>\n      <td>393.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gains/Lift Table: Avg response rate: 67.47 %, avg score: 97.72 %\n",
            "\n",
            "\n",
            "ModelMetricsBinomial: deeplearning\n",
            "** Reported on cross-validation data. **\n",
            "\n",
            "MSE: 0.2589494792202092\n",
            "RMSE: 0.5088707883345331\n",
            "LogLoss: 2.3278760615121326\n",
            "Mean Per-Class Error: 0.279887706855792\n",
            "AUC: 0.7888091016548463\n",
            "AUCPR: 0.8544025639820294\n",
            "Gini: 0.5776182033096926\n",
            "\n",
            "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.97072948764024: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "      group  cumulative_data_fraction  lower_threshold      lift  \\\n0         1                  0.011976         1.000000  1.482249   \n1         2                  0.021956         1.000000  1.482249   \n2         3                  0.031936         1.000000  1.482249   \n3         4                  0.041916         1.000000  1.185799   \n4         5                  0.051896         1.000000  1.482249   \n5         6                  0.101796         1.000000  1.185799   \n6         7                  0.151697         1.000000  1.126509   \n7         8                  0.201597         0.999999  1.185799   \n8         9                  0.301397         0.999995  1.156154   \n9        10                  0.401198         0.999982  1.215444   \n10       11                  0.500998         0.999943  0.918994   \n11       12                  0.600798         0.999827  0.830059   \n12       13                  0.700599         0.999466  1.007929   \n13       14                  0.800399         0.997309  0.830059   \n14       15                  0.900200         0.979862  0.741124   \n15       16                  1.000000         0.179345  0.830059   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0          1.482249           1.00  1.000000                  1.000000   \n1          1.482249           1.00  1.000000                  1.000000   \n2          1.482249           1.00  1.000000                  1.000000   \n3          1.411665           0.80  1.000000                  0.952381   \n4          1.425239           1.00  1.000000                  0.961538   \n5          1.307866           0.80  1.000000                  0.882353   \n6          1.248209           0.76  1.000000                  0.842105   \n7          1.232761           0.80  0.999999                  0.831683   \n8          1.207394           0.78  0.999997                  0.814570   \n9          1.209397           0.82  0.999990                  0.815920   \n10         1.151548           0.62  0.999966                  0.776892   \n11         1.098144           0.56  0.999889                  0.740864   \n12         1.085293           0.68  0.999683                  0.732194   \n13         1.053468           0.56  0.998648                  0.710723   \n14         1.018840           0.50  0.992659                  0.687361   \n15         1.000000           0.56  0.780699                  0.674651   \n\n    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n0           1.000000      0.017751                 0.017751  48.224852   \n1           1.000000      0.014793                 0.032544  48.224852   \n2           1.000000      0.014793                 0.047337  48.224852   \n3           1.000000      0.011834                 0.059172  18.579882   \n4           1.000000      0.014793                 0.073964  48.224852   \n5           1.000000      0.059172                 0.133136  18.579882   \n6           1.000000      0.056213                 0.189349  12.650888   \n7           1.000000      0.059172                 0.248521  18.579882   \n8           0.999999      0.115385                 0.363905  15.615385   \n9           0.999997      0.121302                 0.485207  21.544379   \n10          0.999991      0.091716                 0.576923  -8.100592   \n11          0.999974      0.082840                 0.659763 -16.994083   \n12          0.999932      0.100592                 0.760355   0.792899   \n13          0.999772      0.082840                 0.843195 -16.994083   \n14          0.998984      0.073964                 0.917160 -25.887574   \n15          0.977199      0.082840                 1.000000 -16.994083   \n\n    cumulative_gain  \n0         48.224852  \n1         48.224852  \n2         48.224852  \n3         41.166526  \n4         42.523896  \n5         30.786634  \n6         24.820928  \n7         23.276115  \n8         20.739449  \n9         20.939680  \n10        15.154766  \n11         9.814425  \n12         8.529308  \n13         5.346840  \n14         1.884045  \n15         0.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.011976</td>\n      <td>1.000000</td>\n      <td>1.482249</td>\n      <td>1.482249</td>\n      <td>1.00</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.017751</td>\n      <td>0.017751</td>\n      <td>48.224852</td>\n      <td>48.224852</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.021956</td>\n      <td>1.000000</td>\n      <td>1.482249</td>\n      <td>1.482249</td>\n      <td>1.00</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.014793</td>\n      <td>0.032544</td>\n      <td>48.224852</td>\n      <td>48.224852</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.031936</td>\n      <td>1.000000</td>\n      <td>1.482249</td>\n      <td>1.482249</td>\n      <td>1.00</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.014793</td>\n      <td>0.047337</td>\n      <td>48.224852</td>\n      <td>48.224852</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.041916</td>\n      <td>1.000000</td>\n      <td>1.185799</td>\n      <td>1.411665</td>\n      <td>0.80</td>\n      <td>1.000000</td>\n      <td>0.952381</td>\n      <td>1.000000</td>\n      <td>0.011834</td>\n      <td>0.059172</td>\n      <td>18.579882</td>\n      <td>41.166526</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>0.051896</td>\n      <td>1.000000</td>\n      <td>1.482249</td>\n      <td>1.425239</td>\n      <td>1.00</td>\n      <td>1.000000</td>\n      <td>0.961538</td>\n      <td>1.000000</td>\n      <td>0.014793</td>\n      <td>0.073964</td>\n      <td>48.224852</td>\n      <td>42.523896</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>6</td>\n      <td>0.101796</td>\n      <td>1.000000</td>\n      <td>1.185799</td>\n      <td>1.307866</td>\n      <td>0.80</td>\n      <td>1.000000</td>\n      <td>0.882353</td>\n      <td>1.000000</td>\n      <td>0.059172</td>\n      <td>0.133136</td>\n      <td>18.579882</td>\n      <td>30.786634</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>0.151697</td>\n      <td>1.000000</td>\n      <td>1.126509</td>\n      <td>1.248209</td>\n      <td>0.76</td>\n      <td>1.000000</td>\n      <td>0.842105</td>\n      <td>1.000000</td>\n      <td>0.056213</td>\n      <td>0.189349</td>\n      <td>12.650888</td>\n      <td>24.820928</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>8</td>\n      <td>0.201597</td>\n      <td>0.999999</td>\n      <td>1.185799</td>\n      <td>1.232761</td>\n      <td>0.80</td>\n      <td>0.999999</td>\n      <td>0.831683</td>\n      <td>1.000000</td>\n      <td>0.059172</td>\n      <td>0.248521</td>\n      <td>18.579882</td>\n      <td>23.276115</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>9</td>\n      <td>0.301397</td>\n      <td>0.999995</td>\n      <td>1.156154</td>\n      <td>1.207394</td>\n      <td>0.78</td>\n      <td>0.999997</td>\n      <td>0.814570</td>\n      <td>0.999999</td>\n      <td>0.115385</td>\n      <td>0.363905</td>\n      <td>15.615385</td>\n      <td>20.739449</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>10</td>\n      <td>0.401198</td>\n      <td>0.999982</td>\n      <td>1.215444</td>\n      <td>1.209397</td>\n      <td>0.82</td>\n      <td>0.999990</td>\n      <td>0.815920</td>\n      <td>0.999997</td>\n      <td>0.121302</td>\n      <td>0.485207</td>\n      <td>21.544379</td>\n      <td>20.939680</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>11</td>\n      <td>0.500998</td>\n      <td>0.999943</td>\n      <td>0.918994</td>\n      <td>1.151548</td>\n      <td>0.62</td>\n      <td>0.999966</td>\n      <td>0.776892</td>\n      <td>0.999991</td>\n      <td>0.091716</td>\n      <td>0.576923</td>\n      <td>-8.100592</td>\n      <td>15.154766</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>12</td>\n      <td>0.600798</td>\n      <td>0.999827</td>\n      <td>0.830059</td>\n      <td>1.098144</td>\n      <td>0.56</td>\n      <td>0.999889</td>\n      <td>0.740864</td>\n      <td>0.999974</td>\n      <td>0.082840</td>\n      <td>0.659763</td>\n      <td>-16.994083</td>\n      <td>9.814425</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>13</td>\n      <td>0.700599</td>\n      <td>0.999466</td>\n      <td>1.007929</td>\n      <td>1.085293</td>\n      <td>0.68</td>\n      <td>0.999683</td>\n      <td>0.732194</td>\n      <td>0.999932</td>\n      <td>0.100592</td>\n      <td>0.760355</td>\n      <td>0.792899</td>\n      <td>8.529308</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>14</td>\n      <td>0.800399</td>\n      <td>0.997309</td>\n      <td>0.830059</td>\n      <td>1.053468</td>\n      <td>0.56</td>\n      <td>0.998648</td>\n      <td>0.710723</td>\n      <td>0.999772</td>\n      <td>0.082840</td>\n      <td>0.843195</td>\n      <td>-16.994083</td>\n      <td>5.346840</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>15</td>\n      <td>0.900200</td>\n      <td>0.979862</td>\n      <td>0.741124</td>\n      <td>1.018840</td>\n      <td>0.50</td>\n      <td>0.992659</td>\n      <td>0.687361</td>\n      <td>0.998984</td>\n      <td>0.073964</td>\n      <td>0.917160</td>\n      <td>-25.887574</td>\n      <td>1.884045</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>16</td>\n      <td>1.000000</td>\n      <td>0.179345</td>\n      <td>0.830059</td>\n      <td>1.000000</td>\n      <td>0.56</td>\n      <td>0.780699</td>\n      <td>0.674651</td>\n      <td>0.977199</td>\n      <td>0.082840</td>\n      <td>1.000000</td>\n      <td>-16.994083</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "              0      1   Error             Rate\n0      0  169.0  254.0  0.6005    (254.0/423.0)\n1      1   58.0  742.0  0.0725     (58.0/800.0)\n2  Total  227.0  996.0  0.2551   (312.0/1223.0)",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>169.0</td>\n      <td>254.0</td>\n      <td>0.6005</td>\n      <td>(254.0/423.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>58.0</td>\n      <td>742.0</td>\n      <td>0.0725</td>\n      <td>(58.0/800.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>227.0</td>\n      <td>996.0</td>\n      <td>0.2551</td>\n      <td>(312.0/1223.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Maximum Metrics: Maximum metrics at their respective thresholds\n",
            "\n",
            "Gains/Lift Table: Avg response rate: 65.41 %, avg score: 88.14 %\n",
            "\n",
            "\n",
            "Cross-Validation Metrics Summary: \n",
            "\n",
            "See the whole table with table.as_data_frame()\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                         metric  threshold       value    idx\n0                        max f1   0.970729    0.826281  194.0\n1                        max f2   0.122379    0.911199  311.0\n2                  max f0point5   0.999983    0.804795    7.0\n3                  max accuracy   0.982993    0.745707  176.0\n4                 max precision   1.000000    0.899371    0.0\n5                    max recall   0.000014    1.000000  397.0\n6               max specificity   1.000000    0.886525    0.0\n7              max absolute_mcc   0.999983    0.421136    7.0\n8    max min_per_class_accuracy   0.999973    0.716312    9.0\n9   max mean_per_class_accuracy   0.999983    0.720112    7.0\n10                      max tns   1.000000  375.000000    0.0\n11                      max fns   1.000000  371.000000    0.0\n12                      max fps   0.000001  423.000000  399.0\n13                      max tps   0.000014  800.000000  397.0\n14                      max tnr   1.000000    0.886525    0.0\n15                      max fnr   1.000000    0.463750    0.0\n16                      max fpr   0.000001    1.000000  399.0\n17                      max tpr   0.000014    1.000000  397.0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.970729</td>\n      <td>0.826281</td>\n      <td>194.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.122379</td>\n      <td>0.911199</td>\n      <td>311.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.999983</td>\n      <td>0.804795</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.982993</td>\n      <td>0.745707</td>\n      <td>176.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>1.000000</td>\n      <td>0.899371</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.000014</td>\n      <td>1.000000</td>\n      <td>397.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>1.000000</td>\n      <td>0.886525</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.999983</td>\n      <td>0.421136</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.999973</td>\n      <td>0.716312</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.999983</td>\n      <td>0.720112</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>1.000000</td>\n      <td>375.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>1.000000</td>\n      <td>371.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.000001</td>\n      <td>423.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.000014</td>\n      <td>800.000000</td>\n      <td>397.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>1.000000</td>\n      <td>0.886525</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>1.000000</td>\n      <td>0.463750</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.000001</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.000014</td>\n      <td>1.000000</td>\n      <td>397.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "      group  cumulative_data_fraction  lower_threshold      lift  \\\n0         1                  0.010630     1.000000e+00  1.528750   \n1         2                  0.020442     1.000000e+00  1.528750   \n2         3                  0.030253     1.000000e+00  1.528750   \n3         4                  0.040065     1.000000e+00  1.528750   \n4         5                  0.050695     1.000000e+00  1.293558   \n5         6                  0.100572     1.000000e+00  1.453566   \n6         7                  0.150450     1.000000e+00  1.478627   \n7         8                  0.200327     1.000000e+00  1.378381   \n8         9                  0.300082     9.999998e-01  1.378381   \n9        10                  0.399836     9.999990e-01  1.152828   \n10       11                  0.500409     9.999936e-01  1.081311   \n11       12                  0.600164     9.999303e-01  0.977398   \n12       13                  0.699918     9.990381e-01  0.839559   \n13       14                  0.799673     9.822635e-01  0.839559   \n14       15                  0.899428     2.029151e-01  0.614006   \n15       16                  1.000000     3.222863e-07  0.223720   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0          1.528750       1.000000  1.000000                  1.000000   \n1          1.528750       1.000000  1.000000                  1.000000   \n2          1.528750       1.000000  1.000000                  1.000000   \n3          1.528750       1.000000  1.000000                  1.000000   \n4          1.479435       0.846154  1.000000                  0.967742   \n5          1.466606       0.950820  1.000000                  0.959350   \n6          1.470591       0.967213  1.000000                  0.961957   \n7          1.447633       0.901639  1.000000                  0.946939   \n8          1.424612       0.901639  1.000000                  0.931880   \n9          1.356805       0.754098  0.999999                  0.887526   \n10         1.301436       0.707317  0.999997                  0.851307   \n11         1.247577       0.639344  0.999973                  0.816076   \n12         1.189425       0.549180  0.999653                  0.778037   \n13         1.145781       0.549180  0.994677                  0.749489   \n14         1.086802       0.401639  0.792238                  0.710909   \n15         1.000000       0.146341  0.032151                  0.654129   \n\n    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n0           1.000000       0.01625                  0.01625  52.875000   \n1           1.000000       0.01500                  0.03125  52.875000   \n2           1.000000       0.01500                  0.04625  52.875000   \n3           1.000000       0.01500                  0.06125  52.875000   \n4           1.000000       0.01375                  0.07500  29.355769   \n5           1.000000       0.07250                  0.14750  45.356557   \n6           1.000000       0.07375                  0.22125  47.862705   \n7           1.000000       0.06875                  0.29000  37.838115   \n8           1.000000       0.13750                  0.42750  37.838115   \n9           1.000000       0.11500                  0.54250  15.282787   \n10          0.999999       0.10875                  0.65125   8.131098   \n11          0.999995       0.09750                  0.74875  -2.260246   \n12          0.999946       0.08375                  0.83250 -16.044057   \n13          0.999289       0.08375                  0.91625 -16.044057   \n14          0.976325       0.06125                  0.97750 -38.599385   \n15          0.881367       0.02250                  1.00000 -77.628049   \n\n    cumulative_gain  \n0         52.875000  \n1         52.875000  \n2         52.875000  \n3         52.875000  \n4         47.943548  \n5         46.660569  \n6         47.059103  \n7         44.763265  \n8         42.461172  \n9         35.680470  \n10        30.143587  \n11        24.757663  \n12        18.942465  \n13        14.578093  \n14         8.680227  \n15         0.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>0.010630</td>\n      <td>1.000000e+00</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.01625</td>\n      <td>0.01625</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2</td>\n      <td>0.020442</td>\n      <td>1.000000e+00</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.01500</td>\n      <td>0.03125</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>3</td>\n      <td>0.030253</td>\n      <td>1.000000e+00</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.01500</td>\n      <td>0.04625</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>4</td>\n      <td>0.040065</td>\n      <td>1.000000e+00</td>\n      <td>1.528750</td>\n      <td>1.528750</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.01500</td>\n      <td>0.06125</td>\n      <td>52.875000</td>\n      <td>52.875000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>5</td>\n      <td>0.050695</td>\n      <td>1.000000e+00</td>\n      <td>1.293558</td>\n      <td>1.479435</td>\n      <td>0.846154</td>\n      <td>1.000000</td>\n      <td>0.967742</td>\n      <td>1.000000</td>\n      <td>0.01375</td>\n      <td>0.07500</td>\n      <td>29.355769</td>\n      <td>47.943548</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>6</td>\n      <td>0.100572</td>\n      <td>1.000000e+00</td>\n      <td>1.453566</td>\n      <td>1.466606</td>\n      <td>0.950820</td>\n      <td>1.000000</td>\n      <td>0.959350</td>\n      <td>1.000000</td>\n      <td>0.07250</td>\n      <td>0.14750</td>\n      <td>45.356557</td>\n      <td>46.660569</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>7</td>\n      <td>0.150450</td>\n      <td>1.000000e+00</td>\n      <td>1.478627</td>\n      <td>1.470591</td>\n      <td>0.967213</td>\n      <td>1.000000</td>\n      <td>0.961957</td>\n      <td>1.000000</td>\n      <td>0.07375</td>\n      <td>0.22125</td>\n      <td>47.862705</td>\n      <td>47.059103</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>8</td>\n      <td>0.200327</td>\n      <td>1.000000e+00</td>\n      <td>1.378381</td>\n      <td>1.447633</td>\n      <td>0.901639</td>\n      <td>1.000000</td>\n      <td>0.946939</td>\n      <td>1.000000</td>\n      <td>0.06875</td>\n      <td>0.29000</td>\n      <td>37.838115</td>\n      <td>44.763265</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>9</td>\n      <td>0.300082</td>\n      <td>9.999998e-01</td>\n      <td>1.378381</td>\n      <td>1.424612</td>\n      <td>0.901639</td>\n      <td>1.000000</td>\n      <td>0.931880</td>\n      <td>1.000000</td>\n      <td>0.13750</td>\n      <td>0.42750</td>\n      <td>37.838115</td>\n      <td>42.461172</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>10</td>\n      <td>0.399836</td>\n      <td>9.999990e-01</td>\n      <td>1.152828</td>\n      <td>1.356805</td>\n      <td>0.754098</td>\n      <td>0.999999</td>\n      <td>0.887526</td>\n      <td>1.000000</td>\n      <td>0.11500</td>\n      <td>0.54250</td>\n      <td>15.282787</td>\n      <td>35.680470</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>11</td>\n      <td>0.500409</td>\n      <td>9.999936e-01</td>\n      <td>1.081311</td>\n      <td>1.301436</td>\n      <td>0.707317</td>\n      <td>0.999997</td>\n      <td>0.851307</td>\n      <td>0.999999</td>\n      <td>0.10875</td>\n      <td>0.65125</td>\n      <td>8.131098</td>\n      <td>30.143587</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>12</td>\n      <td>0.600164</td>\n      <td>9.999303e-01</td>\n      <td>0.977398</td>\n      <td>1.247577</td>\n      <td>0.639344</td>\n      <td>0.999973</td>\n      <td>0.816076</td>\n      <td>0.999995</td>\n      <td>0.09750</td>\n      <td>0.74875</td>\n      <td>-2.260246</td>\n      <td>24.757663</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td></td>\n      <td>13</td>\n      <td>0.699918</td>\n      <td>9.990381e-01</td>\n      <td>0.839559</td>\n      <td>1.189425</td>\n      <td>0.549180</td>\n      <td>0.999653</td>\n      <td>0.778037</td>\n      <td>0.999946</td>\n      <td>0.08375</td>\n      <td>0.83250</td>\n      <td>-16.044057</td>\n      <td>18.942465</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td></td>\n      <td>14</td>\n      <td>0.799673</td>\n      <td>9.822635e-01</td>\n      <td>0.839559</td>\n      <td>1.145781</td>\n      <td>0.549180</td>\n      <td>0.994677</td>\n      <td>0.749489</td>\n      <td>0.999289</td>\n      <td>0.08375</td>\n      <td>0.91625</td>\n      <td>-16.044057</td>\n      <td>14.578093</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td></td>\n      <td>15</td>\n      <td>0.899428</td>\n      <td>2.029151e-01</td>\n      <td>0.614006</td>\n      <td>1.086802</td>\n      <td>0.401639</td>\n      <td>0.792238</td>\n      <td>0.710909</td>\n      <td>0.976325</td>\n      <td>0.06125</td>\n      <td>0.97750</td>\n      <td>-38.599385</td>\n      <td>8.680227</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td></td>\n      <td>16</td>\n      <td>1.000000</td>\n      <td>3.222863e-07</td>\n      <td>0.223720</td>\n      <td>1.000000</td>\n      <td>0.146341</td>\n      <td>0.032151</td>\n      <td>0.654129</td>\n      <td>0.881367</td>\n      <td>0.02250</td>\n      <td>1.00000</td>\n      <td>-77.628049</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                                    mean           sd   cv_1_valid  \\\n0                  accuracy    0.8211441  0.025150714   0.77911645   \n1                       auc   0.86935127  0.019321516   0.83704907   \n2                     aucpr    0.9157969  0.004285994    0.9090783   \n3                       err    0.1788559  0.025150714   0.22088353   \n4                 err_count         43.8    6.7230945         55.0   \n5                  f0point5    0.8463545  0.026611382   0.80020386   \n6                        f1   0.87018394  0.014557321    0.8509485   \n7                        f2   0.89606255  0.018359225    0.9085648   \n8            lift_top_group    1.4292706   0.24340951    1.5090909   \n9                   logloss    2.3324084      1.30145    3.4787564   \n10      max_per_class_error    0.3589834   0.11770631    0.5595238   \n11                      mcc     0.592825  0.064513795   0.48165575   \n12  mean_per_class_accuracy   0.77782065  0.046770357    0.6959957   \n13     mean_per_class_error   0.22217934  0.046770357   0.30400434   \n14                      mse   0.25915498    0.0868468    0.3330674   \n15                   pr_auc    0.9157969  0.004285994    0.9090783   \n16                precision    0.8314651  0.035591256   0.76960784   \n17                       r2  -0.14800648   0.39047456  -0.48993585   \n18                   recall   0.91462475  0.030543698   0.95151514   \n19                     rmse   0.50263894   0.09020182    0.5771199   \n\n    cv_2_valid   cv_3_valid  cv_4_valid   cv_5_valid  \n0    0.8293651    0.8284519  0.84647304     0.822314  \n1   0.87049437   0.87236637   0.8880823   0.87876415  \n2    0.9166107    0.9176703   0.9206447    0.9149804  \n3   0.17063493   0.17154811  0.15352698   0.17768595  \n4         43.0         41.0        37.0         43.0  \n5    0.8612144    0.8581645   0.8648339    0.8473558  \n6    0.8660436    0.8753799  0.89085543    0.8676923  \n7   0.87092733   0.89330024   0.9184915     0.889029  \n8    1.5849056    1.5031446  0.99792963     1.551282  \n9      1.17136    3.5153666   0.7405249    2.7560341  \n10  0.24731183        0.325      0.3375    0.3255814  \n11  0.63133657   0.60466766   0.6434426   0.60302246  \n12    0.813451    0.7903302   0.8001941   0.78913236  \n13    0.186549   0.20966981   0.1998059   0.21086761  \n14   0.1896795    0.3225637  0.14289932   0.30756503  \n15   0.9166107    0.9176703   0.9206447    0.9149804  \n16   0.8580247   0.84705883   0.8483146   0.83431953  \n17  0.18540563  -0.44851893   0.3556106  -0.34259388  \n18   0.8742138    0.9056604   0.9378882   0.90384614  \n19   0.4355221    0.5679469  0.37802026   0.55458546  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>mean</th>\n      <th>sd</th>\n      <th>cv_1_valid</th>\n      <th>cv_2_valid</th>\n      <th>cv_3_valid</th>\n      <th>cv_4_valid</th>\n      <th>cv_5_valid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>accuracy</td>\n      <td>0.8211441</td>\n      <td>0.025150714</td>\n      <td>0.77911645</td>\n      <td>0.8293651</td>\n      <td>0.8284519</td>\n      <td>0.84647304</td>\n      <td>0.822314</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>auc</td>\n      <td>0.86935127</td>\n      <td>0.019321516</td>\n      <td>0.83704907</td>\n      <td>0.87049437</td>\n      <td>0.87236637</td>\n      <td>0.8880823</td>\n      <td>0.87876415</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>aucpr</td>\n      <td>0.9157969</td>\n      <td>0.004285994</td>\n      <td>0.9090783</td>\n      <td>0.9166107</td>\n      <td>0.9176703</td>\n      <td>0.9206447</td>\n      <td>0.9149804</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>err</td>\n      <td>0.1788559</td>\n      <td>0.025150714</td>\n      <td>0.22088353</td>\n      <td>0.17063493</td>\n      <td>0.17154811</td>\n      <td>0.15352698</td>\n      <td>0.17768595</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>err_count</td>\n      <td>43.8</td>\n      <td>6.7230945</td>\n      <td>55.0</td>\n      <td>43.0</td>\n      <td>41.0</td>\n      <td>37.0</td>\n      <td>43.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>f0point5</td>\n      <td>0.8463545</td>\n      <td>0.026611382</td>\n      <td>0.80020386</td>\n      <td>0.8612144</td>\n      <td>0.8581645</td>\n      <td>0.8648339</td>\n      <td>0.8473558</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>f1</td>\n      <td>0.87018394</td>\n      <td>0.014557321</td>\n      <td>0.8509485</td>\n      <td>0.8660436</td>\n      <td>0.8753799</td>\n      <td>0.89085543</td>\n      <td>0.8676923</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>f2</td>\n      <td>0.89606255</td>\n      <td>0.018359225</td>\n      <td>0.9085648</td>\n      <td>0.87092733</td>\n      <td>0.89330024</td>\n      <td>0.9184915</td>\n      <td>0.889029</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>lift_top_group</td>\n      <td>1.4292706</td>\n      <td>0.24340951</td>\n      <td>1.5090909</td>\n      <td>1.5849056</td>\n      <td>1.5031446</td>\n      <td>0.99792963</td>\n      <td>1.551282</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>logloss</td>\n      <td>2.3324084</td>\n      <td>1.30145</td>\n      <td>3.4787564</td>\n      <td>1.17136</td>\n      <td>3.5153666</td>\n      <td>0.7405249</td>\n      <td>2.7560341</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max_per_class_error</td>\n      <td>0.3589834</td>\n      <td>0.11770631</td>\n      <td>0.5595238</td>\n      <td>0.24731183</td>\n      <td>0.325</td>\n      <td>0.3375</td>\n      <td>0.3255814</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>mcc</td>\n      <td>0.592825</td>\n      <td>0.064513795</td>\n      <td>0.48165575</td>\n      <td>0.63133657</td>\n      <td>0.60466766</td>\n      <td>0.6434426</td>\n      <td>0.60302246</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>mean_per_class_accuracy</td>\n      <td>0.77782065</td>\n      <td>0.046770357</td>\n      <td>0.6959957</td>\n      <td>0.813451</td>\n      <td>0.7903302</td>\n      <td>0.8001941</td>\n      <td>0.78913236</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>mean_per_class_error</td>\n      <td>0.22217934</td>\n      <td>0.046770357</td>\n      <td>0.30400434</td>\n      <td>0.186549</td>\n      <td>0.20966981</td>\n      <td>0.1998059</td>\n      <td>0.21086761</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>mse</td>\n      <td>0.25915498</td>\n      <td>0.0868468</td>\n      <td>0.3330674</td>\n      <td>0.1896795</td>\n      <td>0.3225637</td>\n      <td>0.14289932</td>\n      <td>0.30756503</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>pr_auc</td>\n      <td>0.9157969</td>\n      <td>0.004285994</td>\n      <td>0.9090783</td>\n      <td>0.9166107</td>\n      <td>0.9176703</td>\n      <td>0.9206447</td>\n      <td>0.9149804</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>precision</td>\n      <td>0.8314651</td>\n      <td>0.035591256</td>\n      <td>0.76960784</td>\n      <td>0.8580247</td>\n      <td>0.84705883</td>\n      <td>0.8483146</td>\n      <td>0.83431953</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>r2</td>\n      <td>-0.14800648</td>\n      <td>0.39047456</td>\n      <td>-0.48993585</td>\n      <td>0.18540563</td>\n      <td>-0.44851893</td>\n      <td>0.3556106</td>\n      <td>-0.34259388</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>recall</td>\n      <td>0.91462475</td>\n      <td>0.030543698</td>\n      <td>0.95151514</td>\n      <td>0.8742138</td>\n      <td>0.9056604</td>\n      <td>0.9378882</td>\n      <td>0.90384614</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>rmse</td>\n      <td>0.50263894</td>\n      <td>0.09020182</td>\n      <td>0.5771199</td>\n      <td>0.4355221</td>\n      <td>0.5679469</td>\n      <td>0.37802026</td>\n      <td>0.55458546</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scoring History: \n",
            "\n",
            "Variable Importances: \n",
            "\n",
            "See the whole table with table.as_data_frame()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                timestamp           duration training_speed     epochs  \\\n0     2020-11-15 17:32:42          0.000 sec           None   0.000000   \n1     2020-11-15 17:32:46   6 min  0.989 sec    336 obs/sec   0.975470   \n2     2020-11-15 17:32:54   6 min  9.225 sec    322 obs/sec   2.943581   \n3     2020-11-15 17:33:02   6 min 17.686 sec    315 obs/sec   4.903516   \n4     2020-11-15 17:33:10   6 min 25.768 sec    317 obs/sec   6.871627   \n5     2020-11-15 17:33:19   6 min 33.925 sec    318 obs/sec   8.834015   \n6     2020-11-15 17:33:27   6 min 42.519 sec    314 obs/sec  10.793949   \n7     2020-11-15 17:33:35   6 min 50.648 sec    315 obs/sec  12.762878   \n8     2020-11-15 17:33:43   6 min 58.718 sec    315 obs/sec  14.722813   \n9     2020-11-15 17:33:52   7 min  7.214 sec    314 obs/sec  16.686018   \n10    2020-11-15 17:34:00   7 min 15.169 sec    315 obs/sec  18.647588   \n11    2020-11-15 17:34:08   7 min 23.192 sec    316 obs/sec  20.609158   \n\n    iterations  samples  training_rmse  training_logloss  training_r2  \\\n0            0      0.0            NaN               NaN          NaN   \n1            1   1193.0       0.629348          1.866074    -0.750671   \n2            3   3600.0       0.586466          4.555047    -0.520224   \n3            5   5997.0       0.481108          0.982743    -0.023074   \n4            7   8404.0       0.356065          0.588773     0.439620   \n5            9  10804.0       0.351338          0.587601     0.454401   \n6           11  13201.0       0.540425          2.407145    -0.290901   \n7           13  15609.0       0.510857          2.116638    -0.153511   \n8           15  18006.0       0.249086          0.268951     0.725765   \n9           17  20407.0       0.185765          0.113047     0.847472   \n10          19  22806.0       0.518106          1.936390    -0.186476   \n11          21  25205.0       0.465272          1.184403     0.043166   \n\n                 ...                 training_pr_auc  training_lift  \\\n0                ...                             NaN            NaN   \n1                ...                        0.900827        1.52875   \n2                ...                        0.856095        1.52875   \n3                ...                        0.955734        1.52875   \n4                ...                        0.964242        1.52875   \n5                ...                        0.982110        1.52875   \n6                ...                        0.972575        1.52875   \n7                ...                        0.964904        1.52875   \n8                ...                        0.987944        1.52875   \n9                ...                        0.997882        1.52875   \n10               ...                        0.995568        1.52875   \n11               ...                        0.996270        1.52875   \n\n    training_classification_error  validation_rmse  validation_logloss  \\\n0                             NaN              NaN                 NaN   \n1                        0.199509         0.719930            3.450869   \n2                        0.194603         0.570421            4.768948   \n3                        0.145544         0.549606            1.555836   \n4                        0.116926         0.524268            1.430804   \n5                        0.081766         0.639886            2.574600   \n6                        0.079313         0.572025            3.996023   \n7                        0.092396         0.568121            3.663142   \n8                        0.075225         0.558987            2.010111   \n9                        0.027800         0.543948            1.383707   \n10                       0.041701         0.564023            3.216685   \n11                       0.040065         0.557471            2.708427   \n\n    validation_r2  validation_auc  validation_pr_auc  validation_lift  \\\n0             NaN             NaN                NaN              NaN   \n1       -1.361300        0.580953           0.763153         1.482249   \n2       -0.482387        0.587360           0.723122         1.482249   \n3       -0.376176        0.613506           0.778840         1.482249   \n4       -0.252211        0.643691           0.762032         1.482249   \n5       -0.865420        0.631856           0.779005         1.235207   \n6       -0.490738        0.606282           0.754971         1.235207   \n7       -0.470458        0.617399           0.763622         1.482249   \n8       -0.423556        0.603024           0.771336         1.235207   \n9       -0.347988        0.618715           0.767918         1.235207   \n10      -0.449322        0.652185           0.795388         1.482249   \n11      -0.415843        0.652067           0.795553         1.482249   \n\n    validation_classification_error  \n0                               NaN  \n1                          0.325349  \n2                          0.325349  \n3                          0.321357  \n4                          0.325349  \n5                          0.325349  \n6                          0.325349  \n7                          0.325349  \n8                          0.317365  \n9                          0.323353  \n10                         0.323353  \n11                         0.319361  \n\n[12 rows x 21 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>timestamp</th>\n      <th>duration</th>\n      <th>training_speed</th>\n      <th>epochs</th>\n      <th>iterations</th>\n      <th>samples</th>\n      <th>training_rmse</th>\n      <th>training_logloss</th>\n      <th>training_r2</th>\n      <th>...</th>\n      <th>training_pr_auc</th>\n      <th>training_lift</th>\n      <th>training_classification_error</th>\n      <th>validation_rmse</th>\n      <th>validation_logloss</th>\n      <th>validation_r2</th>\n      <th>validation_auc</th>\n      <th>validation_pr_auc</th>\n      <th>validation_lift</th>\n      <th>validation_classification_error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>2020-11-15 17:32:42</td>\n      <td>0.000 sec</td>\n      <td>None</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2020-11-15 17:32:46</td>\n      <td>6 min  0.989 sec</td>\n      <td>336 obs/sec</td>\n      <td>0.975470</td>\n      <td>1</td>\n      <td>1193.0</td>\n      <td>0.629348</td>\n      <td>1.866074</td>\n      <td>-0.750671</td>\n      <td>...</td>\n      <td>0.900827</td>\n      <td>1.52875</td>\n      <td>0.199509</td>\n      <td>0.719930</td>\n      <td>3.450869</td>\n      <td>-1.361300</td>\n      <td>0.580953</td>\n      <td>0.763153</td>\n      <td>1.482249</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>2020-11-15 17:32:54</td>\n      <td>6 min  9.225 sec</td>\n      <td>322 obs/sec</td>\n      <td>2.943581</td>\n      <td>3</td>\n      <td>3600.0</td>\n      <td>0.586466</td>\n      <td>4.555047</td>\n      <td>-0.520224</td>\n      <td>...</td>\n      <td>0.856095</td>\n      <td>1.52875</td>\n      <td>0.194603</td>\n      <td>0.570421</td>\n      <td>4.768948</td>\n      <td>-0.482387</td>\n      <td>0.587360</td>\n      <td>0.723122</td>\n      <td>1.482249</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>2020-11-15 17:33:02</td>\n      <td>6 min 17.686 sec</td>\n      <td>315 obs/sec</td>\n      <td>4.903516</td>\n      <td>5</td>\n      <td>5997.0</td>\n      <td>0.481108</td>\n      <td>0.982743</td>\n      <td>-0.023074</td>\n      <td>...</td>\n      <td>0.955734</td>\n      <td>1.52875</td>\n      <td>0.145544</td>\n      <td>0.549606</td>\n      <td>1.555836</td>\n      <td>-0.376176</td>\n      <td>0.613506</td>\n      <td>0.778840</td>\n      <td>1.482249</td>\n      <td>0.321357</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>2020-11-15 17:33:10</td>\n      <td>6 min 25.768 sec</td>\n      <td>317 obs/sec</td>\n      <td>6.871627</td>\n      <td>7</td>\n      <td>8404.0</td>\n      <td>0.356065</td>\n      <td>0.588773</td>\n      <td>0.439620</td>\n      <td>...</td>\n      <td>0.964242</td>\n      <td>1.52875</td>\n      <td>0.116926</td>\n      <td>0.524268</td>\n      <td>1.430804</td>\n      <td>-0.252211</td>\n      <td>0.643691</td>\n      <td>0.762032</td>\n      <td>1.482249</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>2020-11-15 17:33:19</td>\n      <td>6 min 33.925 sec</td>\n      <td>318 obs/sec</td>\n      <td>8.834015</td>\n      <td>9</td>\n      <td>10804.0</td>\n      <td>0.351338</td>\n      <td>0.587601</td>\n      <td>0.454401</td>\n      <td>...</td>\n      <td>0.982110</td>\n      <td>1.52875</td>\n      <td>0.081766</td>\n      <td>0.639886</td>\n      <td>2.574600</td>\n      <td>-0.865420</td>\n      <td>0.631856</td>\n      <td>0.779005</td>\n      <td>1.235207</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>2020-11-15 17:33:27</td>\n      <td>6 min 42.519 sec</td>\n      <td>314 obs/sec</td>\n      <td>10.793949</td>\n      <td>11</td>\n      <td>13201.0</td>\n      <td>0.540425</td>\n      <td>2.407145</td>\n      <td>-0.290901</td>\n      <td>...</td>\n      <td>0.972575</td>\n      <td>1.52875</td>\n      <td>0.079313</td>\n      <td>0.572025</td>\n      <td>3.996023</td>\n      <td>-0.490738</td>\n      <td>0.606282</td>\n      <td>0.754971</td>\n      <td>1.235207</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>2020-11-15 17:33:35</td>\n      <td>6 min 50.648 sec</td>\n      <td>315 obs/sec</td>\n      <td>12.762878</td>\n      <td>13</td>\n      <td>15609.0</td>\n      <td>0.510857</td>\n      <td>2.116638</td>\n      <td>-0.153511</td>\n      <td>...</td>\n      <td>0.964904</td>\n      <td>1.52875</td>\n      <td>0.092396</td>\n      <td>0.568121</td>\n      <td>3.663142</td>\n      <td>-0.470458</td>\n      <td>0.617399</td>\n      <td>0.763622</td>\n      <td>1.482249</td>\n      <td>0.325349</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td></td>\n      <td>2020-11-15 17:33:43</td>\n      <td>6 min 58.718 sec</td>\n      <td>315 obs/sec</td>\n      <td>14.722813</td>\n      <td>15</td>\n      <td>18006.0</td>\n      <td>0.249086</td>\n      <td>0.268951</td>\n      <td>0.725765</td>\n      <td>...</td>\n      <td>0.987944</td>\n      <td>1.52875</td>\n      <td>0.075225</td>\n      <td>0.558987</td>\n      <td>2.010111</td>\n      <td>-0.423556</td>\n      <td>0.603024</td>\n      <td>0.771336</td>\n      <td>1.235207</td>\n      <td>0.317365</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td></td>\n      <td>2020-11-15 17:33:52</td>\n      <td>7 min  7.214 sec</td>\n      <td>314 obs/sec</td>\n      <td>16.686018</td>\n      <td>17</td>\n      <td>20407.0</td>\n      <td>0.185765</td>\n      <td>0.113047</td>\n      <td>0.847472</td>\n      <td>...</td>\n      <td>0.997882</td>\n      <td>1.52875</td>\n      <td>0.027800</td>\n      <td>0.543948</td>\n      <td>1.383707</td>\n      <td>-0.347988</td>\n      <td>0.618715</td>\n      <td>0.767918</td>\n      <td>1.235207</td>\n      <td>0.323353</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td></td>\n      <td>2020-11-15 17:34:00</td>\n      <td>7 min 15.169 sec</td>\n      <td>315 obs/sec</td>\n      <td>18.647588</td>\n      <td>19</td>\n      <td>22806.0</td>\n      <td>0.518106</td>\n      <td>1.936390</td>\n      <td>-0.186476</td>\n      <td>...</td>\n      <td>0.995568</td>\n      <td>1.52875</td>\n      <td>0.041701</td>\n      <td>0.564023</td>\n      <td>3.216685</td>\n      <td>-0.449322</td>\n      <td>0.652185</td>\n      <td>0.795388</td>\n      <td>1.482249</td>\n      <td>0.323353</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>2020-11-15 17:34:08</td>\n      <td>7 min 23.192 sec</td>\n      <td>316 obs/sec</td>\n      <td>20.609158</td>\n      <td>21</td>\n      <td>25205.0</td>\n      <td>0.465272</td>\n      <td>1.184403</td>\n      <td>0.043166</td>\n      <td>...</td>\n      <td>0.996270</td>\n      <td>1.52875</td>\n      <td>0.040065</td>\n      <td>0.557471</td>\n      <td>2.708427</td>\n      <td>-0.415843</td>\n      <td>0.652067</td>\n      <td>0.795553</td>\n      <td>1.482249</td>\n      <td>0.319361</td>\n    </tr>\n  </tbody>\n</table>\n<p>12 rows × 21 columns</p>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "   variable  relative_importance  scaled_importance  percentage\n0     PC182             1.000000           1.000000    0.004004\n1      PC14             0.996694           0.996694    0.003990\n2     PC218             0.959303           0.959303    0.003841\n3      PC20             0.951942           0.951942    0.003811\n4     PC159             0.942292           0.942292    0.003773\n5      PC66             0.941679           0.941679    0.003770\n6      PC19             0.941589           0.941589    0.003770\n7      PC45             0.935147           0.935147    0.003744\n8     PC136             0.933992           0.933992    0.003739\n9      PC97             0.930150           0.930150    0.003724\n10     PC40             0.927216           0.927216    0.003712\n11     PC92             0.925198           0.925198    0.003704\n12     PC18             0.925057           0.925057    0.003704\n13    PC162             0.924712           0.924712    0.003702\n14      PC4             0.922976           0.922976    0.003695\n15     PC22             0.921999           0.921999    0.003691\n16    PC152             0.921820           0.921820    0.003691\n17     PC85             0.921105           0.921105    0.003688\n18    PC189             0.917304           0.917304    0.003673\n19     PC17             0.916518           0.916518    0.003669",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variable</th>\n      <th>relative_importance</th>\n      <th>scaled_importance</th>\n      <th>percentage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>PC182</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.004004</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>PC14</td>\n      <td>0.996694</td>\n      <td>0.996694</td>\n      <td>0.003990</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PC218</td>\n      <td>0.959303</td>\n      <td>0.959303</td>\n      <td>0.003841</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>PC20</td>\n      <td>0.951942</td>\n      <td>0.951942</td>\n      <td>0.003811</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>PC159</td>\n      <td>0.942292</td>\n      <td>0.942292</td>\n      <td>0.003773</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>PC66</td>\n      <td>0.941679</td>\n      <td>0.941679</td>\n      <td>0.003770</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>PC19</td>\n      <td>0.941589</td>\n      <td>0.941589</td>\n      <td>0.003770</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>PC45</td>\n      <td>0.935147</td>\n      <td>0.935147</td>\n      <td>0.003744</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>PC136</td>\n      <td>0.933992</td>\n      <td>0.933992</td>\n      <td>0.003739</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>PC97</td>\n      <td>0.930150</td>\n      <td>0.930150</td>\n      <td>0.003724</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>PC40</td>\n      <td>0.927216</td>\n      <td>0.927216</td>\n      <td>0.003712</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>PC92</td>\n      <td>0.925198</td>\n      <td>0.925198</td>\n      <td>0.003704</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>PC18</td>\n      <td>0.925057</td>\n      <td>0.925057</td>\n      <td>0.003704</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>PC162</td>\n      <td>0.924712</td>\n      <td>0.924712</td>\n      <td>0.003702</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>PC4</td>\n      <td>0.922976</td>\n      <td>0.922976</td>\n      <td>0.003695</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>PC22</td>\n      <td>0.921999</td>\n      <td>0.921999</td>\n      <td>0.003691</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>PC152</td>\n      <td>0.921820</td>\n      <td>0.921820</td>\n      <td>0.003691</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>PC85</td>\n      <td>0.921105</td>\n      <td>0.921105</td>\n      <td>0.003688</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>PC189</td>\n      <td>0.917304</td>\n      <td>0.917304</td>\n      <td>0.003673</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>PC17</td>\n      <td>0.916518</td>\n      <td>0.916518</td>\n      <td>0.003669</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "<bound method ModelBase.model_performance of >"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605461652208
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tune the Stacked Ensemble for the best meta-learner"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator\r\n",
        "\r\n",
        "collection_of_models = [\r\n",
        "                        top_nb,\r\n",
        "                        top_glm,\r\n",
        "\r\n",
        "                        # checkpoint-enabled models\r\n",
        "                        top_gbm,\r\n",
        "                        top_xgb,\r\n",
        "                        top_dl,\r\n",
        "                        top_drf\r\n",
        "                        ]\r\n",
        "\r\n",
        "\r\n",
        "meta_algos = [\"auto\", \"xgboost\", \"drf\", \"gbm\", \"glm\", \"naivebayes\", \"deeplearning\"]\r\n",
        "\r\n",
        "ensemble_list = []\r\n",
        "\r\n",
        "for metalearner in meta_algos:\r\n",
        "    print(\"\\n\\n>>>>> \", metalearner, \" <<<<<<\")\r\n",
        "\r\n",
        "    ensemble = H2OStackedEnsembleEstimator(\r\n",
        "                                       base_models= collection_of_models,\r\n",
        "\r\n",
        "                                       model_id= \"stacked_ensemble_PCA300_FEATURES_ALL_MODELS_metalearner_\" + metalearner,\r\n",
        "                                       # model_id= \"stacked_ensemble_PCA300_FEATURES_CHECKPOINT_MODELS_metalearner_\" + metalearner,\r\n",
        "                                       # model_id= \"stacked_ensemble_PCA300_FEATURES_CHECKPOINT_nogbm_MODELS_metalearner_\" + metalearner,\r\n",
        "\r\n",
        "                                       metalearner_algorithm= metalearner,\r\n",
        "\r\n",
        "                                       #metalearner_params\r\n",
        "                                       )\r\n",
        "    ensemble.train(x=x, y=y, training_frame=train_pca_df_frame, validation_frame=test_pca_df_frame)\r\n",
        "\r\n",
        "    \r\n",
        " \r\n",
        "    h2o.save_model(ensemble, MODELS_LOCATION + \"PCA300/top_ensemble_ALL_MODELS_METALEARNER_\" + metalearner)\r\n",
        "\r\n",
        "   #  h2o.save_model(ensemble, MODELS_LOCATION + \"PCA300/top_ensemble_CHECKPOINT_MODELS_METALEARNER_\" + metalearner)\r\n",
        "\r\n",
        "   #  h2o.save_model(ensemble, MODELS_LOCATION + \"PCA300/top_ensemble_CHECKPOINT_nogbm_MODELS_METALEARNER_\" + metalearner)\r\n",
        "\r\n",
        "\r\n",
        "    print(\"AUC on test_pca_df_frame data: \",  ensemble.model_performance(valid=True).auc())\r\n",
        "\r\n",
        "    ensemble_list.append(ensemble)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            ">>>>>  auto  <<<<<<\n",
            "stackedensemble Model Build progress: |███████████████████████████████████| 100%\n",
            "AUC on test_pca_df_frame data:  0.6012088430682108\n",
            "\n",
            "\n",
            ">>>>>  xgboost  <<<<<<\n",
            "stackedensemble Model Build progress: |███████████████████████████████████| 100%\n",
            "AUC on test_pca_df_frame data:  0.5996932515337423\n",
            "\n",
            "\n",
            ">>>>>  drf  <<<<<<\n",
            "stackedensemble Model Build progress: |███████████████████████████████████| 100%\n",
            "AUC on test_pca_df_frame data:  0.6153483137909754\n",
            "\n",
            "\n",
            ">>>>>  gbm  <<<<<<\n",
            "stackedensemble Model Build progress: |███████████████████████████████████| 100%\n",
            "AUC on test_pca_df_frame data:  0.6163012306240243\n",
            "\n",
            "\n",
            ">>>>>  glm  <<<<<<\n",
            "stackedensemble Model Build progress: |███████████████████████████████████| 100%\n",
            "AUC on test_pca_df_frame data:  0.6173176752459433\n",
            "\n",
            "\n",
            ">>>>>  naivebayes  <<<<<<\n",
            "stackedensemble Model Build progress: |███████████████████████████████████| 100%\n",
            "AUC on test_pca_df_frame data:  0.5967346716520855\n",
            "\n",
            "\n",
            ">>>>>  deeplearning  <<<<<<\n",
            "stackedensemble Model Build progress: |███████████████████████████████████| 100%\n",
            "AUC on test_pca_df_frame data:  0.6050931135876866\n"
          ]
        }
      ],
      "execution_count": 33,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605372837065
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper-parameter tuning for meta-learner"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator\r\n",
        "\r\n",
        "collection_of_models = [\r\n",
        "                        top_nb,\r\n",
        "                        top_glm,\r\n",
        "\r\n",
        "                        # checkpoint-enabled models\r\n",
        "                        # top_gbm,\r\n",
        "                        # top_xgb,\r\n",
        "                        # top_dl,\r\n",
        "                        # top_drf\r\n",
        "                        ]\r\n",
        "\r\n",
        "\r\n",
        "meta_algos = [  \r\n",
        "# \"auto\",\r\n",
        "\r\n",
        "\r\n",
        "# These DON'T work with metalearner_params \r\n",
        "# \"xgboost\",\r\n",
        "# \"naivebayes\",\r\n",
        "\r\n",
        "\r\n",
        "# These work with metalearner_params \r\n",
        "# \"drf\", \r\n",
        "# \"gbm\", \r\n",
        "# \"glm\", \r\n",
        "# \"deeplearning\"\r\n",
        "]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "ensemble_list = []\r\n",
        "\r\n",
        "for metalearner in meta_algos:\r\n",
        "    print(\"\\n\\n>>>>> \", metalearner, \" <<<<<<\")\r\n",
        "\r\n",
        "    ensemble = H2OStackedEnsembleEstimator(\r\n",
        "                                       base_models= collection_of_models,\r\n",
        "\r\n",
        "                                       model_id= \"stacked_ensemble_PCA300_FEATURES_ALL_MODELS_metalearner_\" + metalearner,\r\n",
        " \r\n",
        "                                       metalearner_algorithm= metalearner,\r\n",
        "\r\n",
        "                                       metalearner_params = all_model_hyperparams[metalearner]['pca'],\r\n",
        "\r\n",
        "                                        metalearner_nfolds = 5,\r\n",
        "                                        metalearner_fold_assignment = 'random'\r\n",
        "                                       )\r\n",
        "\r\n",
        "    ensemble.train(x=x, y=y, training_frame=train_pca_df_frame, validation_frame=test_pca_df_frame)\r\n",
        "    \r\n",
        "    print(\"AUC on test_pca_df_frame data: \",  ensemble.model_performance(valid=True).auc())\r\n",
        "\r\n",
        "    ensemble_list.append(ensemble)\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            ">>>>>  drf  <<<<<<\n",
            "stackedensemble Model Build progress: |███████████████████████████████████| 100%\n",
            "AUC on test_pca_df_frame data:  0.5783660652702654\n",
            "\n",
            "\n",
            ">>>>>  gbm  <<<<<<\n",
            "stackedensemble Model Build progress: |███████████████████████████████████| 100%\n",
            "AUC on test_pca_df_frame data:  0.61105565034305\n",
            "\n",
            "\n",
            ">>>>>  glm  <<<<<<\n",
            "stackedensemble Model Build progress: |███████████████████████████████████| 100%\n",
            "AUC on test_pca_df_frame data:  0.6269920499509929\n",
            "\n",
            "\n",
            ">>>>>  deeplearning  <<<<<<\n",
            "stackedensemble Model Build progress: |███████████████ (cancelled)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "H2OJobCancelled",
          "evalue": "Job<$03017f00000132d4ffffffff$_b2c3b5bdc2c85813115fc07067264c9c> was cancelled by the user.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mH2OJobCancelled\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-6598ea14d9b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m                                        )\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_pca_df_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_pca_df_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AUC on test_pca_df_frame data: \"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/h2o/estimators/stackedensemble.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, training_frame, blending_frame, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0mparms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_parms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextend_parms_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextend_parms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         \u001b[0msup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/h2o/estimators/estimator_base.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, parms, verbose)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_model_scoring_history\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET /%d/Models/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrest_ver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdest_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"models\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdest_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/h2o/job.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, poll_updates)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# check if failed... and politely print relevant message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"CANCELLED\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mH2OJobCancelled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job<%s> was cancelled by the user.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"FAILED\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"stacktrace\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mH2OJobCancelled\u001b[0m: Job<$03017f00000132d4ffffffff$_b2c3b5bdc2c85813115fc07067264c9c> was cancelled by the user."
          ]
        }
      ],
      "execution_count": 58,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605468114953
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "H2OStackedEnsembleEstimator.metalearner_algorithm"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 55,
          "data": {
            "text/plain": "<property at 0x7efdaf103408>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 55,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605468208192
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_model_hyperparams = {\r\n",
        "'naivebayes' : {\r\n",
        "             'pca': {\r\n",
        "                'laplace': 0.6,\r\n",
        "                'min_sdev': 0.1,\r\n",
        "                'min_prob': 0.1,\r\n",
        "                'eps_sdev': 0.1,\r\n",
        "                'eps_prob': 0.3,\r\n",
        "        },\r\n",
        "            'non_pca': {\r\n",
        "                'laplace': 0.3,\r\n",
        "                'min_sdev': 0.9,\r\n",
        "                'min_prob': 0.1,\r\n",
        "                'eps_sdev': 1,\r\n",
        "                'eps_prob': 0.1,\r\n",
        "        }\r\n",
        "    },\r\n",
        "\r\n",
        "'glm' : {\r\n",
        "             'pca': {\r\n",
        "\r\n",
        "                'alpha': [\r\n",
        "                0.0\r\n",
        "            ],\r\n",
        "                'theta': 1,\r\n",
        "                'tweedie_link_power': 0,\r\n",
        "                'tweedie_variance_power': 3,\r\n",
        "        },\r\n",
        "            'non_pca': {\r\n",
        "\r\n",
        "                'alpha': [\r\n",
        "                1.0\r\n",
        "            ],\r\n",
        "                'theta': 0.3,\r\n",
        "                'tweedie_link_power': 0,\r\n",
        "                'tweedie_variance_power': 9,\r\n",
        "        }\r\n",
        "    },\r\n",
        "\r\n",
        "\r\n",
        "'gbm' : {\r\n",
        "             'pca': {\r\n",
        "\t'learn_rate': 0.9,\r\n",
        "\t'learn_rate_annealing': 1,\r\n",
        "\t'distribution':\t'bernoulli',\r\n",
        "\t'quantile_alpha': 0.3,\r\n",
        "\t'tweedie_power': 1.5,\r\n",
        "\t'balance_classes':\tFalse,\r\n",
        "\t'ntrees': 150,\r\n",
        "\t'max_depth': 10,\r\n",
        "\t'sample_rate': 0.9,\r\n",
        "\t'col_sample_rate': 0.3,\r\n",
        "\t'col_sample_rate_per_tree': 1,\r\n",
        "\t'col_sample_rate_change_per_level': 1.3,\r\n",
        "\t'histogram_type': 'RoundRobin',\r\n",
        "        },\r\n",
        "            'non_pca': {\r\n",
        "\r\n",
        "\t'learn_rate': 0.1,\r\n",
        "\t'learn_rate_annealing': 0.9,\r\n",
        "\t'distribution':\t\t'bernoulli',\r\n",
        "\t'quantile_alpha': 1,\r\n",
        "\t'tweedie_power': 1.9,\r\n",
        "\t'balance_classes':\t\tFalse,\r\n",
        "\t'ntrees': 50,\r\n",
        "\t'max_depth': 5,\r\n",
        "\t'sample_rate': 0.9,\r\n",
        "\t'col_sample_rate': 0.3,\r\n",
        "\t'col_sample_rate_per_tree': 0.6,\r\n",
        "\t'col_sample_rate_change_per_level': 0.8,\r\n",
        "\t'histogram_type':\t\t'Random',\r\n",
        "        }\r\n",
        "    },\r\n",
        "\r\n",
        "\r\n",
        "'drf' : {\r\n",
        "             'pca': {\r\n",
        "\r\n",
        "\t# 'mtries': 150, # doesn't work for some reason\r\n",
        "\t'balance_classes':\tTrue,\r\n",
        "\t'ntrees': 100,\r\n",
        "\t'max_depth': 10,\r\n",
        "\t'sample_rate': 0.6,\r\n",
        "\t'col_sample_rate_per_tree': 0.3,\r\n",
        "\t'col_sample_rate_change_per_level': 0.8,\r\n",
        "\t'histogram_type':\t'Auto',\r\n",
        "        },\r\n",
        "            'non_pca': {\r\n",
        "\t'mtries': -1,\r\n",
        "\t'balance_classes':\t\tTrue,\r\n",
        "\t'ntrees': 50,\r\n",
        "\t'max_depth': 10,\r\n",
        "\t'sample_rate': 0.3,\r\n",
        "\t'col_sample_rate_per_tree': 0.6,\r\n",
        "\t'col_sample_rate_change_per_level': 1.7,\r\n",
        "\t'histogram_type':\t\t'RoundRobin',\r\n",
        "        }\r\n",
        "    },\r\n",
        "\r\n",
        "\r\n",
        "'xgboost' : {\r\n",
        "             'pca': {\r\n",
        "\r\n",
        "\t'distribution':\t'multinomial',\r\n",
        "\t'categorical_encoding':\t'auto',\r\n",
        "\t'ntrees': 70,\r\n",
        "\t'booster':\t'gbtree',\r\n",
        "\t'col_sample_rate': 0.6,\r\n",
        "\t'col_sample_rate_bylevel': 0.6,\r\n",
        "\t'col_sample_rate_bytree': 0.6,\r\n",
        "\t'learn_rate': 0.1,\r\n",
        "\t'grow_policy':\t'lossguide',\r\n",
        "\t'max_depth': 6,\r\n",
        "\t'normalize_type':\t'forest',\r\n",
        "\t'sample_type':\t'uniform',\r\n",
        "\t'sample_rate': 1,\r\n",
        "\t'tree_method':\t'hist',\r\n",
        "\t'tweedie_power': 1.5,\r\n",
        "        },\r\n",
        "            'non_pca': {\r\n",
        "\r\n",
        "\t'distribution':\t\t'bernoulli',\r\n",
        "\t'categorical_encoding':\t\t'label_encoder',\r\n",
        "\t'ntrees': 50,\r\n",
        "\t'booster':\t\t'dart',\r\n",
        "\t'col_sample_rate': 0.8,\r\n",
        "\t'col_sample_rate_bylevel': 0.8,\r\n",
        "\t'col_sample_rate_bytree': 0.3,\r\n",
        "\t'learn_rate': 0.1,\r\n",
        "\t'grow_policy':\t\t'depthwise',\r\n",
        "\t'max_depth': 6,\r\n",
        "\t'normalize_type':\t\t'forest',\r\n",
        "\t'sample_type':\t\t'weighted',\r\n",
        "\t'sample_rate': 1,\r\n",
        "\t'tree_method':\t\t'hist',\r\n",
        "\t'tweedie_power': 1.5,\r\n",
        "        }\r\n",
        "    },\r\n",
        "\r\n",
        "'deeplearning' : {\r\n",
        "             'pca': {\r\n",
        "\t'distribution':\t'bernoulli',\r\n",
        "\t'epochs': 20.399,\r\n",
        "\t'loss':\t'CrossEntropy',\r\n",
        "\t'l1': 1e-5,\r\n",
        "\t'l2': 0,\r\n",
        "\t'sparse':\tFalse,\r\n",
        "\t'balance_classes':\tFalse,\r\n",
        "\t'average_activation': 10,\r\n",
        "\t'activation':\t'TanH',\r\n",
        "\t'hidden': [\r\n",
        "                500,\r\n",
        "                500,\r\n",
        "                500\r\n",
        "            ],\r\n",
        "\t'input_dropout_ratio': 0.2,\r\n",
        "\t'rho': 0.95,\r\n",
        "\t'standardize': \tFalse,\r\n",
        "        },\r\n",
        "            'non_pca': {\r\n",
        "\r\n",
        "\t'distribution':\t\t'bernoulli',\r\n",
        "\t'epochs': 31.1822,\r\n",
        "\t'loss':\t\t'Automatic',\r\n",
        "\t'l1': 0,\r\n",
        "\t'l2': 0,\r\n",
        "\t'sparse':\t\tFalse,\r\n",
        "\t'balance_classes':\t\tFalse,\r\n",
        "\t'average_activation': 0,\r\n",
        "\t'activation':\t\t'RectifierWithDropout',\r\n",
        "\t'hidden': [\r\n",
        "                500,\r\n",
        "                500,\r\n",
        "                500\r\n",
        "            ],\r\n",
        "\t'input_dropout_ratio': 0,\r\n",
        "\t'rho': 0.9,\r\n",
        "\t'standardize': \t\tTrue,\r\n",
        "        }\r\n",
        "    },\r\n",
        "}"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1605467638529
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}